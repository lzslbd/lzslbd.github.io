{"meta":{"title":"LBD's Blog","subtitle":"大数据与分布式","description":"大数据与分布式","author":"LBD","url":"http://linbingdong.com"},"pages":[{"title":"","date":"2017-10-02T13:28:33.000Z","updated":"2017-01-17T12:21:07.000Z","comments":true,"path":"google2e1f6eca2abac7fc.html","permalink":"http://linbingdong.com/google2e1f6eca2abac7fc.html","excerpt":"","text":"google-site-verification: google2e1f6eca2abac7fc.html","raw":null,"content":null},{"title":"","date":"2017-10-26T13:06:18.000Z","updated":"2017-10-26T13:06:18.000Z","comments":true,"path":"about/index.html","permalink":"http://linbingdong.com/about/index.html","excerpt":"","text":"不忘初心，砥砺前行 AboutLBD，北邮本科，国科大研究生。腾讯云后台开发工程师。专注于分布式系统、分布式数据库。 Contact邮 箱 : lzslbd@163.com微 信 : linbingdong公众号 : FullStackPlan","raw":null,"content":null},{"title":"分类","date":"2017-01-02T08:05:09.000Z","updated":"2017-03-07T12:50:47.000Z","comments":true,"path":"categories/index.html","permalink":"http://linbingdong.com/categories/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"标签","date":"2017-01-02T08:00:41.000Z","updated":"2017-03-07T12:50:33.000Z","comments":true,"path":"tags/index.html","permalink":"http://linbingdong.com/tags/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"PhxPaxos源码分析——Paxos算法实现","slug":"PhxPaxos源码分析——Paxos算法实现","date":"2017-11-20T16:00:00.000Z","updated":"2017-11-21T08:45:18.000Z","comments":true,"path":"2017/11/21/PhxPaxos源码分析——Paxos算法实现/","link":"","permalink":"http://linbingdong.com/2017/11/21/PhxPaxos源码分析——Paxos算法实现/","excerpt":"这篇主要来分析Paxos算法实现的部分，我想这应该也是读者最感兴趣的。在看这篇文章之前，如果之前对Paxos算法没有了解的童鞋可以看下这篇文章：Paxos算法原理与推导，相信了解Paxos算法后再来通过源码看算法实现应该会很酸爽。","text":"这篇主要来分析Paxos算法实现的部分，我想这应该也是读者最感兴趣的。在看这篇文章之前，如果之前对Paxos算法没有了解的童鞋可以看下这篇文章：Paxos算法原理与推导，相信了解Paxos算法后再来通过源码看算法实现应该会很酸爽。 Paxos算法中最重要的两个角色是Proposer和Acceptor。当然Leaner也很重要，特别是在PhxPaxos的实现中，Leaner具有重要的功能。但是因为《Paxos Made Simple》论文中主要还是Proposer和Acceptor，因此这篇文章还是以这两个角色为主，通过源码来回顾论文中Paxos算法的过程，同时也看看工程实现和论文的描述有什么区别。 这里先贴出Paxos算法的过程，方便大家对照接下来的工程实现。 prepare阶段： (a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 accept阶段： (a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 Proposer因为Proposer需要维护或者说记录一些状态信息，包括自己的提案编号ProposalID、提出的Value、其他Proposer提出的最大的提案编号HighestOtherProposalID、Acceptor已经接受过的编号最大的提案的值等，因此这里专门有一个ProposerState类来管理这些信息。同样Acceptor也有一个AcceptorState类来管理Acceptor相关的信息。 先来看下ProposerState的定义： class ProposerState&#123;public: ProposerState(const Config * poConfig); ~ProposerState(); void Init(); void SetStartProposalID(const uint64_t llProposalID); void NewPrepare(); void AddPreAcceptValue(const BallotNumber &amp; oOtherPreAcceptBallot, const std::string &amp; sOtherPreAcceptValue); ///////////////////////// const uint64_t GetProposalID(); const std::string &amp; GetValue(); void SetValue(const std::string &amp; sValue); void SetOtherProposalID(const uint64_t llOtherProposalID); void ResetHighestOtherPreAcceptBallot();public: uint64_t m_llProposalID; uint64_t m_llHighestOtherProposalID; std::string m_sValue; BallotNumber m_oHighestOtherPreAcceptBallot; Config * m_poConfig;&#125;; 基本都是对这些信息的set跟get，很容易理解。直接来看Proposer类的定义： class Proposer : public Base&#123;public: Proposer( const Config * poConfig, const MsgTransport * poMsgTransport, const Instance * poInstance, const Learner * poLearner, const IOLoop * poIOLoop); ~Proposer(); //设置起始的ProposalID void SetStartProposalID(const uint64_t llProposalID); //初始化新的一轮Paxos过程，每一轮叫做一个Paxos Instance，每一轮确定一个值 virtual void InitForNewPaxosInstance(); //Proposer发起提案的入口函数。参数sValue即Proposer自己想提出的value，当然最终提出的value不一定是这个，需要根据Acceptor再Prepare阶段的回复来确定 int NewValue(const std::string &amp; sValue); //判断Proposer是否处于Prepare阶段或Accept阶段 bool IsWorking(); ///////////////////////////// //对应Paxos算法中的Prepare阶段 void Prepare(const bool bNeedNewBallot = true); //Prepare阶段等待Acceptor的回复，统计投票并确定是否进入Accept阶段 void OnPrepareReply(const PaxosMsg &amp; oPaxosMsg); //Prepare阶段被拒绝 void OnExpiredPrepareReply(const PaxosMsg &amp; oPaxosMsg); //对应Paxos算法中的Accept阶段 void Accept(); //Accept阶段等待Acceptor的回复，统计投票并确定值(Value)是否被选定(Chosen) void OnAcceptReply(const PaxosMsg &amp; oPaxosMsg); //Accept阶段被拒绝 void OnExpiredAcceptReply(const PaxosMsg &amp; oPaxosMsg); //Prepare阶段超时 void OnPrepareTimeout(); //Accept阶段超时 void OnAcceptTimeout(); //退出Prepare阶段 void ExitPrepare(); //退出Accept阶段 void ExitAccept(); //取消跳过Prepare阶段，也就是必须先Prepare阶段再Accept阶段 void CancelSkipPrepare(); ///////////////////////////// void AddPrepareTimer(const int iTimeoutMs = 0); void AddAcceptTimer(const int iTimeoutMs = 0);public: ProposerState m_oProposerState; MsgCounter m_oMsgCounter; Learner * m_poLearner; bool m_bIsPreparing; bool m_bIsAccepting; IOLoop * m_poIOLoop; uint32_t m_iPrepareTimerID; int m_iLastPrepareTimeoutMs; uint32_t m_iAcceptTimerID; int m_iLastAcceptTimeoutMs; uint64_t m_llTimeoutInstanceID; bool m_bCanSkipPrepare; bool m_bWasRejectBySomeone; TimeStat m_oTimeStat;&#125;; NewValue下面就从NewValue方法入手： int Proposer :: NewValue(const std::string &amp; sValue)&#123; BP-&gt;GetProposerBP()-&gt;NewProposal(sValue); if (m_oProposerState.GetValue().size() == 0) &#123; m_oProposerState.SetValue(sValue); &#125; m_iLastPrepareTimeoutMs = START_PREPARE_TIMEOUTMS; m_iLastAcceptTimeoutMs = START_ACCEPT_TIMEOUTMS; //如果可以跳过Prepare阶段并且没有被Acceptor拒绝过，则直接进入Accept阶段 if (m_bCanSkipPrepare &amp;&amp; !m_bWasRejectBySomeone) &#123; BP-&gt;GetProposerBP()-&gt;NewProposalSkipPrepare(); PLGHead(\"skip prepare, directly start accept\"); Accept(); &#125; //否则先进入Prepare阶段 else &#123; //if not reject by someone, no need to increase ballot Prepare(m_bWasRejectBySomeone); &#125; return 0;&#125; 这里可以直接进入Accept阶段的前提是该Proposer已经发起过Prepare请求且得到半数以上的同意（即通过了Prepare阶段），并且没有被任何Acceptor拒绝（说明没有Acceptor响应过比该Proposer的提案编号更高的提案）。那么，什么情况下可以跳过Prepare请求呢，这里应该对应的是选出一个master的情况？相当于raft里的leader？ Prepare接下来直接看Prepare阶段： void Proposer :: Prepare(const bool bNeedNewBallot)&#123; PLGHead(\"START Now.InstanceID %lu MyNodeID %lu State.ProposalID %lu State.ValueLen %zu\", GetInstanceID(), m_poConfig-&gt;GetMyNodeID(), m_oProposerState.GetProposalID(), m_oProposerState.GetValue().size()); BP-&gt;GetProposerBP()-&gt;Prepare(); m_oTimeStat.Point(); ExitAccept(); //表明Proposer正处于Prepare阶段 m_bIsPreparing = true; //不能跳过Prepare阶段 m_bCanSkipPrepare = false; //目前还未被任意一个Acceptor拒绝 m_bWasRejectBySomeone = false; m_oProposerState.ResetHighestOtherPreAcceptBallot(); //如果需要产生新的投票，就调用NewPrepare产生新的ProposalID，新的ProposalID为当前已知的最大ProposalID+1 if (bNeedNewBallot) &#123; m_oProposerState.NewPrepare(); &#125; PaxosMsg oPaxosMsg; //设置Prepare消息的各个字段 oPaxosMsg.set_msgtype(MsgType_PaxosPrepare); oPaxosMsg.set_instanceid(GetInstanceID()); oPaxosMsg.set_nodeid(m_poConfig-&gt;GetMyNodeID()); oPaxosMsg.set_proposalid(m_oProposerState.GetProposalID()); //MsgCount是专门用来统计票数的，根据计算的结果确定是否通过Prepare阶段或者Accept阶段 m_oMsgCounter.StartNewRound(); //Prepare超时定时器 AddPrepareTimer(); PLGHead(\"END OK\"); //将Prepare消息发送到各个节点 BroadcastMessage(oPaxosMsg);&#125; Proposer在Prepare阶段主要做了这么几件事： 重置各个状态位，表明当前正处于Prepare阶段。 获取提案编号ProposalID。当bNeedNewBallot为true时需要将ProposalID+1。否则沿用之前的ProposalID。bNeedNewBallot是在NewValue中调用Prepare方法时传入的m_bWasRejectBySomeone参数。也就是如果之前没有被任何Acceptor拒绝（说明还没有明确出现更大的ProposalID），则不需要获取新的ProposalID。对应的场景是Prepare阶段超时了，在超时时间内没有收到过半Acceptor同意的消息，因此需要重新执行Prepare阶段，此时只需要沿用原来的ProposalID即可。 发送Prepare请求。该请求PaxosMsg是Protocol Buffer定义的一个message，包含MsgType、InstanceID、NodeID、ProposalID等字段。在BroadcastMessage(oPaxosMsg)中还会将oPaxosMsg序列化后才发送出去。 PaxosMsg的定义如下，Prepare和Accept阶段Proposer和Acceptor的所有消息都用PaxosMsg来表示： message PaxosMsg&#123; required int32 MsgType = 1; optional uint64 InstanceID = 2; optional uint64 NodeID = 3; optional uint64 ProposalID = 4; optional uint64 ProposalNodeID = 5; optional bytes Value = 6; optional uint64 PreAcceptID = 7; optional uint64 PreAcceptNodeID = 8; optional uint64 RejectByPromiseID = 9; optional uint64 NowInstanceID = 10; optional uint64 MinChosenInstanceID = 11; optional uint32 LastChecksum = 12; optional uint32 Flag = 13; optional bytes SystemVariables = 14; optional bytes MasterVariables = 15;&#125;; OnPrepareReplyProposer发出Prepare请求后就开始等待Acceptor的回复。当Proposer所在节点收到PaxosPrepareReply消息后，就会调用Proposer的OnPrepareReply(oPaxosMsg)，其中oPaxosMsg是Acceptor回复的消息。 void Proposer :: OnPrepareReply(const PaxosMsg &amp; oPaxosMsg)&#123; PLGHead(\"START Msg.ProposalID %lu State.ProposalID %lu Msg.from_nodeid %lu RejectByPromiseID %lu\", oPaxosMsg.proposalid(), m_oProposerState.GetProposalID(), oPaxosMsg.nodeid(), oPaxosMsg.rejectbypromiseid()); BP-&gt;GetProposerBP()-&gt;OnPrepareReply(); //如果Proposer不是在Prepare阶段，则忽略该消息 if (!m_bIsPreparing) &#123; BP-&gt;GetProposerBP()-&gt;OnPrepareReplyButNotPreparing(); //PLGErr(\"Not preparing, skip this msg\"); return; &#125; //如果ProposalID不同，也忽略 if (oPaxosMsg.proposalid() != m_oProposerState.GetProposalID()) &#123; BP-&gt;GetProposerBP()-&gt;OnPrepareReplyNotSameProposalIDMsg(); //PLGErr(\"ProposalID not same, skip this msg\"); return; &#125; //加入一个收到的消息，用于MsgCounter统计 m_oMsgCounter.AddReceive(oPaxosMsg.nodeid()); //如果该消息不是拒绝，即Acceptor同意本次Prepare请求 if (oPaxosMsg.rejectbypromiseid() == 0) &#123; BallotNumber oBallot(oPaxosMsg.preacceptid(), oPaxosMsg.preacceptnodeid()); PLGDebug(\"[Promise] PreAcceptedID %lu PreAcceptedNodeID %lu ValueSize %zu\", oPaxosMsg.preacceptid(), oPaxosMsg.preacceptnodeid(), oPaxosMsg.value().size()); //加入MsgCounter用于统计投票 m_oMsgCounter.AddPromiseOrAccept(oPaxosMsg.nodeid()); //将Acceptor返回的它接受过的编号最大的提案记录下来（如果有的话），用于确定Accept阶段的Value m_oProposerState.AddPreAcceptValue(oBallot, oPaxosMsg.value()); &#125; //Acceptor拒绝了Prepare请求 else &#123; PLGDebug(\"[Reject] RejectByPromiseID %lu\", oPaxosMsg.rejectbypromiseid()); //同样也要记录到MsgCounter用于统计投票 m_oMsgCounter.AddReject(oPaxosMsg.nodeid()); //记录被Acceptor拒绝过，待会儿如果重新进入Prepare阶段的话就需要获取更大的ProposalID m_bWasRejectBySomeone = true; //记录下别的Proposer提出的更大的ProposalID。这样重新发起Prepare请求时才知道需要用多大的ProposalID m_oProposerState.SetOtherProposalID(oPaxosMsg.rejectbypromiseid()); &#125; //本次Prepare请求通过了。也就是得到了半数以上Acceptor的同意 if (m_oMsgCounter.IsPassedOnThisRound()) &#123; int iUseTimeMs = m_oTimeStat.Point(); BP-&gt;GetProposerBP()-&gt;PreparePass(iUseTimeMs); PLGImp(\"[Pass] start accept, usetime %dms\", iUseTimeMs); m_bCanSkipPrepare = true; //进入Accept阶段 Accept(); &#125; //本次Prepare请求没有通过 else if (m_oMsgCounter.IsRejectedOnThisRound() || m_oMsgCounter.IsAllReceiveOnThisRound()) &#123; BP-&gt;GetProposerBP()-&gt;PrepareNotPass(); PLGImp(\"[Not Pass] wait 30ms and restart prepare\"); //随机等待一段时间后重新发起Prepare请求 AddPrepareTimer(OtherUtils::FastRand() % 30 + 10); &#125; PLGHead(\"END\");&#125; 该阶段Proposer主要做了以下事情： 判断消息是否有效。包括ProposalID是否相同，自身是否处于Prepare阶段等。因为网络是不可靠的，有些消息可能延迟很久，等收到的时候已经不需要了，所以需要做这些判断。 将收到的消息加入MsgCounter用于统计。 根据收到的消息更新自身状态。包括Acceptor承诺过的ProposalID，以及Acceptor接受过的编号最大的提案等。 根据MsgCounter统计的Acceptor投票结果决定是进入Acceptor阶段还是重新发起Prepare请求。这里如果判断需要重新发起Prepare请求的话，也不是立即进行，而是等待一段随机的时间，这样做的好处是减少不同Proposer之间的冲突，采取的策略跟raft中leader选举冲突时在一段随机的选举超时时间后重新发起选举的做法类似。 注：这里跟Paxos算法中提案编号对应的并不是ProposalID，而是BallotNumber。BallotNumber由ProposalID和NodeID组成。还实现了运算符重载。如果ProposalID大，则BallotNumber（即提案编号）大。在ProposalID相同的情况下，NodeID大的BallotNumber大。 Accept接下来Proposer就进入Accept阶段： void Proposer :: Accept()&#123; PLGHead(\"START ProposalID %lu ValueSize %zu ValueLen %zu\", m_oProposerState.GetProposalID(), m_oProposerState.GetValue().size(), m_oProposerState.GetValue().size()); BP-&gt;GetProposerBP()-&gt;Accept(); m_oTimeStat.Point(); ExitPrepare(); m_bIsAccepting = true; //设置Accept请求的消息内容 PaxosMsg oPaxosMsg; oPaxosMsg.set_msgtype(MsgType_PaxosAccept); oPaxosMsg.set_instanceid(GetInstanceID()); oPaxosMsg.set_nodeid(m_poConfig-&gt;GetMyNodeID()); oPaxosMsg.set_proposalid(m_oProposerState.GetProposalID()); oPaxosMsg.set_value(m_oProposerState.GetValue()); oPaxosMsg.set_lastchecksum(GetLastChecksum()); m_oMsgCounter.StartNewRound(); AddAcceptTimer(); PLGHead(\"END\"); //发给各个节点 BroadcastMessage(oPaxosMsg, BroadcastMessage_Type_RunSelf_Final);&#125; Accept请求中PaxosMsg里的Value是这样确定的：如果Prepare阶段有Acceptor的回复中带有提案值，则该Value为所有的Acceptor的回复中，编号最大的提案的值。否则就是Proposer在最初调用NewValue时传入的值。 OnAcceptReplyvoid Proposer :: OnAcceptReply(const PaxosMsg &amp; oPaxosMsg)&#123; PLGHead(\"START Msg.ProposalID %lu State.ProposalID %lu Msg.from_nodeid %lu RejectByPromiseID %lu\", oPaxosMsg.proposalid(), m_oProposerState.GetProposalID(), oPaxosMsg.nodeid(), oPaxosMsg.rejectbypromiseid()); BP-&gt;GetProposerBP()-&gt;OnAcceptReply(); if (!m_bIsAccepting) &#123; //PLGErr(\"Not proposing, skip this msg\"); BP-&gt;GetProposerBP()-&gt;OnAcceptReplyButNotAccepting(); return; &#125; if (oPaxosMsg.proposalid() != m_oProposerState.GetProposalID()) &#123; //PLGErr(\"ProposalID not same, skip this msg\"); BP-&gt;GetProposerBP()-&gt;OnAcceptReplyNotSameProposalIDMsg(); return; &#125; m_oMsgCounter.AddReceive(oPaxosMsg.nodeid()); if (oPaxosMsg.rejectbypromiseid() == 0) &#123; PLGDebug(\"[Accept]\"); m_oMsgCounter.AddPromiseOrAccept(oPaxosMsg.nodeid()); &#125; else &#123; PLGDebug(\"[Reject]\"); m_oMsgCounter.AddReject(oPaxosMsg.nodeid()); m_bWasRejectBySomeone = true; m_oProposerState.SetOtherProposalID(oPaxosMsg.rejectbypromiseid()); &#125; if (m_oMsgCounter.IsPassedOnThisRound()) &#123; int iUseTimeMs = m_oTimeStat.Point(); BP-&gt;GetProposerBP()-&gt;AcceptPass(iUseTimeMs); PLGImp(\"[Pass] Start send learn, usetime %dms\", iUseTimeMs); ExitAccept(); //让Leaner学习被选定（Chosen）的值 m_poLearner-&gt;ProposerSendSuccess(GetInstanceID(), m_oProposerState.GetProposalID()); &#125; else if (m_oMsgCounter.IsRejectedOnThisRound() || m_oMsgCounter.IsAllReceiveOnThisRound()) &#123; BP-&gt;GetProposerBP()-&gt;AcceptNotPass(); PLGImp(\"[Not pass] wait 30ms and Restart prepare\"); AddAcceptTimer(OtherUtils::FastRand() % 30 + 10); &#125; PLGHead(\"END\");&#125; 这里跟OnPrepareReply的过程基本一致，因此就不加太多注释了。比较大的区别在于最后如果过半的Acceptor接受了该Accept请求，则说明该Value被选定（Chosen）了，就发送消息，让每个节点上的Learner学习该Value。因为Leaner不是本文的重点，这里就不详细介绍了。 AcceptorAcceptor的逻辑比Proposer更简单。同样先看它的定义： class Acceptor : public Base&#123;public: Acceptor( const Config * poConfig, const MsgTransport * poMsgTransport, const Instance * poInstance, const LogStorage * poLogStorage); ~Acceptor(); virtual void InitForNewPaxosInstance(); int Init(); AcceptorState * GetAcceptorState(); //Prepare阶段回复Prepare请求 int OnPrepare(const PaxosMsg &amp; oPaxosMsg); //Accept阶段回复Accept请求 void OnAccept(const PaxosMsg &amp; oPaxosMsg);//private: AcceptorState m_oAcceptorState;&#125;; OnPrepareOnPrepare用于处理收到的Prepare请求，逻辑如下： int Acceptor :: OnPrepare(const PaxosMsg &amp; oPaxosMsg)&#123; PLGHead(\"START Msg.InstanceID %lu Msg.from_nodeid %lu Msg.ProposalID %lu\", oPaxosMsg.instanceid(), oPaxosMsg.nodeid(), oPaxosMsg.proposalid()); BP-&gt;GetAcceptorBP()-&gt;OnPrepare(); PaxosMsg oReplyPaxosMsg; oReplyPaxosMsg.set_instanceid(GetInstanceID()); oReplyPaxosMsg.set_nodeid(m_poConfig-&gt;GetMyNodeID()); oReplyPaxosMsg.set_proposalid(oPaxosMsg.proposalid()); oReplyPaxosMsg.set_msgtype(MsgType_PaxosPrepareReply); //构造接收到的Prepare请求里的提案编号 BallotNumber oBallot(oPaxosMsg.proposalid(), oPaxosMsg.nodeid()); //提案编号大于承诺过的提案编号 if (oBallot &gt;= m_oAcceptorState.GetPromiseBallot()) &#123; PLGDebug(\"[Promise] State.PromiseID %lu State.PromiseNodeID %lu \" \"State.PreAcceptedID %lu State.PreAcceptedNodeID %lu\", m_oAcceptorState.GetPromiseBallot().m_llProposalID, m_oAcceptorState.GetPromiseBallot().m_llNodeID, m_oAcceptorState.GetAcceptedBallot().m_llProposalID, m_oAcceptorState.GetAcceptedBallot().m_llNodeID); //返回之前接受过的提案的编号 oReplyPaxosMsg.set_preacceptid(m_oAcceptorState.GetAcceptedBallot().m_llProposalID); oReplyPaxosMsg.set_preacceptnodeid(m_oAcceptorState.GetAcceptedBallot().m_llNodeID); //如果接受过的提案编号大于0（&lt;=0说明没有接受过提案），则设置接受过的提案的Value if (m_oAcceptorState.GetAcceptedBallot().m_llProposalID &gt; 0) &#123; oReplyPaxosMsg.set_value(m_oAcceptorState.GetAcceptedValue()); &#125; //更新承诺的提案编号为新的提案编号（因为新的提案编号更大） m_oAcceptorState.SetPromiseBallot(oBallot); //信息持久化 int ret = m_oAcceptorState.Persist(GetInstanceID(), GetLastChecksum()); if (ret != 0) &#123; BP-&gt;GetAcceptorBP()-&gt;OnPreparePersistFail(); PLGErr(\"Persist fail, Now.InstanceID %lu ret %d\", GetInstanceID(), ret); return -1; &#125; BP-&gt;GetAcceptorBP()-&gt;OnPreparePass(); &#125; //提案编号小于承诺过的提案编号，需要拒绝 else &#123; BP-&gt;GetAcceptorBP()-&gt;OnPrepareReject(); PLGDebug(\"[Reject] State.PromiseID %lu State.PromiseNodeID %lu\", m_oAcceptorState.GetPromiseBallot().m_llProposalID, m_oAcceptorState.GetPromiseBallot().m_llNodeID); //拒绝该Prepare请求，并返回承诺过的ProposalID oReplyPaxosMsg.set_rejectbypromiseid(m_oAcceptorState.GetPromiseBallot().m_llProposalID); &#125; nodeid_t iReplyNodeID = oPaxosMsg.nodeid(); PLGHead(\"END Now.InstanceID %lu ReplyNodeID %lu\", GetInstanceID(), oPaxosMsg.nodeid());; //向发出Prepare请求的Proposer回复消息 SendMessage(iReplyNodeID, oReplyPaxosMsg); return 0;&#125; OnAccept再来看看OnAccept： void Acceptor :: OnAccept(const PaxosMsg &amp; oPaxosMsg)&#123; PLGHead(\"START Msg.InstanceID %lu Msg.from_nodeid %lu Msg.ProposalID %lu Msg.ValueLen %zu\", oPaxosMsg.instanceid(), oPaxosMsg.nodeid(), oPaxosMsg.proposalid(), oPaxosMsg.value().size()); BP-&gt;GetAcceptorBP()-&gt;OnAccept(); PaxosMsg oReplyPaxosMsg; oReplyPaxosMsg.set_instanceid(GetInstanceID()); oReplyPaxosMsg.set_nodeid(m_poConfig-&gt;GetMyNodeID()); oReplyPaxosMsg.set_proposalid(oPaxosMsg.proposalid()); oReplyPaxosMsg.set_msgtype(MsgType_PaxosAcceptReply); BallotNumber oBallot(oPaxosMsg.proposalid(), oPaxosMsg.nodeid()); //提案编号不小于承诺过的提案编号（注意：这里是“&gt;=”，而再OnPrepare中是“&gt;”，可以先思考下为什么），需要接受该提案 if (oBallot &gt;= m_oAcceptorState.GetPromiseBallot()) &#123; PLGDebug(\"[Promise] State.PromiseID %lu State.PromiseNodeID %lu \" \"State.PreAcceptedID %lu State.PreAcceptedNodeID %lu\", m_oAcceptorState.GetPromiseBallot().m_llProposalID, m_oAcceptorState.GetPromiseBallot().m_llNodeID, m_oAcceptorState.GetAcceptedBallot().m_llProposalID, m_oAcceptorState.GetAcceptedBallot().m_llNodeID); //更新承诺的提案编号；接受的提案编号、提案值 m_oAcceptorState.SetPromiseBallot(oBallot); m_oAcceptorState.SetAcceptedBallot(oBallot); m_oAcceptorState.SetAcceptedValue(oPaxosMsg.value()); //信息持久化 int ret = m_oAcceptorState.Persist(GetInstanceID(), GetLastChecksum()); if (ret != 0) &#123; BP-&gt;GetAcceptorBP()-&gt;OnAcceptPersistFail(); PLGErr(\"Persist fail, Now.InstanceID %lu ret %d\", GetInstanceID(), ret); return; &#125; BP-&gt;GetAcceptorBP()-&gt;OnAcceptPass(); &#125; //需要拒绝该提案 else &#123; BP-&gt;GetAcceptorBP()-&gt;OnAcceptReject(); PLGDebug(\"[Reject] State.PromiseID %lu State.PromiseNodeID %lu\", m_oAcceptorState.GetPromiseBallot().m_llProposalID, m_oAcceptorState.GetPromiseBallot().m_llNodeID); //拒绝的消息中附上承诺过的ProposalID oReplyPaxosMsg.set_rejectbypromiseid(m_oAcceptorState.GetPromiseBallot().m_llProposalID); &#125; nodeid_t iReplyNodeID = oPaxosMsg.nodeid(); PLGHead(\"END Now.InstanceID %lu ReplyNodeID %lu\", GetInstanceID(), oPaxosMsg.nodeid()); //将响应发送给Proposer SendMessage(iReplyNodeID, oReplyPaxosMsg);&#125; 结语通过阅读源码可以发现，整个PhxPaxos完全基于Lamport的《Paxos Made Simple》进行工程化，没有进行任何算法变种。这对于学习Paxos算法的人来说真的是一笔宝贵的财富，所以如果对Paxos算法感兴趣，应该深入地去阅读PhxPaxos的源码，相信看完后大家对Paxos会有更深的理解。同时我们也发现，在工程实现上还是有很多细节需要注意，这比单纯理解算法要难得多。","raw":null,"content":null,"categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://linbingdong.com/categories/源码分析/"}],"tags":[{"name":"Paxos","slug":"Paxos","permalink":"http://linbingdong.com/tags/Paxos/"},{"name":"PhxPaxos","slug":"PhxPaxos","permalink":"http://linbingdong.com/tags/PhxPaxos/"}]},{"title":"PhxPaxos源码分析——网络","slug":"PhxPaxos源码分析——网络","date":"2017-11-19T16:00:00.000Z","updated":"2017-11-20T09:29:20.000Z","comments":true,"path":"2017/11/20/PhxPaxos源码分析——网络/","link":"","permalink":"http://linbingdong.com/2017/11/20/PhxPaxos源码分析——网络/","excerpt":"了解分布式系统的童鞋肯定听过Paxos算法的大名。Paxos算法以晦涩难懂著称，其工程实现更难。目前，号称在工程上实现了Paxos算法的应该只有Google、阿里和腾讯。然而，只有腾讯的微信团队真正将代码开源出来，他们将Paxos算法的实现封装成了一个Paxos库，大家可以基于该库实现自己想要的功能，比如用于master选举，或者甚至利用它来实现一个分布式KV数据库等。","text":"了解分布式系统的童鞋肯定听过Paxos算法的大名。Paxos算法以晦涩难懂著称，其工程实现更难。目前，号称在工程上实现了Paxos算法的应该只有Google、阿里和腾讯。然而，只有腾讯的微信团队真正将代码开源出来，他们将Paxos算法的实现封装成了一个Paxos库，大家可以基于该库实现自己想要的功能，比如用于master选举，或者甚至利用它来实现一个分布式KV数据库等。 之前就对Paxos很感兴趣，但是一直没看过实现的代码，这次微信开源了PhxPaxos后终于有机会深入地了解Paxos的实现细节。在这里感谢微信团队。感谢PhxPaxos的作者。让我们一起来领略Paxos的魅力吧。 本次的源码分析先从网络部分开始。因为在分布式系统中不可避免会涉及到不同节点以及相同节点上不同进程之间的通信。因此网络部分也是至关重要，所以就先把网络单独拿出来看，接下来再去看Paxos算法的实现部分。 概览源码的include/phxpaxos目录下是公共头文件。include/phpaxos/network.h 是网络模块的抽象函数，如果用户想使用自己的网络协议，可以通过重写这些函数实现网络模块的自定义。 我们先来看下network.h的内容： namespace phxpaxos&#123;//You can use your own network to make paxos communicate. :)class Node;class NetWork&#123;public: NetWork(); virtual ~NetWork() &#123;&#125; //Network must not send/recieve any message before paxoslib called this funtion. virtual void RunNetWork() = 0; //If paxoslib call this function, network need to stop receive any message. virtual void StopNetWork() = 0; virtual int SendMessageTCP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage) = 0; virtual int SendMessageUDP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage) = 0; //When receive a message, call this funtion. //This funtion is async, just enqueue an return. int OnReceiveMessage(const char * pcMessage, const int iMessageLen);private: friend class Node; Node * m_poNode;&#125;; &#125; 这几个函数的作用从名字就可以看出来。而且都是虚函数，即需要重写这些函数。在PhxPaxos中，提供了一个默认的网络模块，就是继承了NetWork类。该类的名字叫DFNetWork，DF应该就是default的缩写了。如下： namespace phxpaxos &#123;class DFNetWork : public NetWork&#123;public: DFNetWork(); virtual ~DFNetWork(); int Init(const std::string &amp; sListenIp, const int iListenPort, const int iIOThreadCount); void RunNetWork(); void StopNetWork(); int SendMessageTCP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage); int SendMessageUDP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage);private: UDPRecv m_oUDPRecv; UDPSend m_oUDPSend; TcpIOThread m_oTcpIOThread;&#125;;&#125; 该类的私有成员里有UDPRecv、UDPSend和TcpIOThread三个类的对象，这三个类分别用于接收UDP消息、发送UDP消息以及收发TCP消息。 Init方法就是将UDPRecv、UDPSend和TcpIOThread分别初始化: int DFNetWork :: Init(const std::string &amp; sListenIp, const int iListenPort, const int iIOThreadCount) &#123; //初始化UDPSend int ret = m_oUDPSend.Init(); if (ret != 0) &#123; return ret; &#125; //初始化UDPRecv ret = m_oUDPRecv.Init(iListenPort); if (ret != 0) &#123; return ret; &#125; //初始化TCP ret = m_oTcpIOThread.Init(sListenIp, iListenPort, iIOThreadCount); if (ret != 0) &#123; PLErr(\"m_oTcpIOThread Init fail, ret %d\", ret); return ret; &#125; return 0;&#125; 具体的初始化过程就是调用socket的api。以UDPRecv为例，就是创建socket、设定端口、设置socket属性（如端口可重用）最后绑定端口。如下： int UDPRecv :: Init(const int iPort)&#123; //创建socket，获得socket fd if ((m_iSockFD = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) &#123; return -1; &#125; struct sockaddr_in addr; memset(&amp;addr, 0, sizeof(addr)); addr.sin_family = AF_INET; addr.sin_port = htons(iPort); //设定端口 addr.sin_addr.s_addr = htonl(INADDR_ANY); int enable = 1; //设定socket属性，端口可重用 setsockopt(m_iSockFD, SOL_SOCKET, SO_REUSEADDR, &amp;enable, sizeof(int)); //绑定，用于监听 if (bind(m_iSockFD, (struct sockaddr *)&amp;addr, sizeof(addr)) &lt; 0) &#123; return -1; &#125; return 0;&#125; RunNetWork就是将UDPRecv、UDPSend和TcpIOThread分别运行起来： void DFNetWork :: RunNetWork()&#123; //UDPSend和UDPRecv都是调用Thread的start方法 m_oUDPSend.start(); m_oUDPRecv.start(); //TCP的Start是封装过的 m_oTcpIOThread.Start();&#125; TcpIOThread的Start()实际执行的代码如下，分别启动了TcpAcceptor、TcpWrite和TcpRead： void TcpIOThread :: Start()&#123; m_oTcpAcceptor.start(); for (auto &amp; poTcpWrite : m_vecTcpWrite) &#123; poTcpWrite-&gt;start(); &#125; for (auto &amp; poTcpRead : m_vecTcpRead) &#123; poTcpRead-&gt;start(); &#125; m_bIsStarted = true;&#125; StopNetWork就是将UDPRecv、UDPSend和TcpIOThread停止。 SendMessageTCP就是将消息用TCP发送： int DFNetWork :: SendMessageTCP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage)&#123; return m_oTcpIOThread.AddMessage(iGroupIdx, sIp, iPort, sMessage);&#125; SendMessageUDP就是将消息用UDP发送：int DFNetWork :: SendMessageUDP(const int iGroupIdx, const std::string &amp; sIp, const int iPort, const std::string &amp; sMessage)&#123; return m_oUDPSend.AddMessage(sIp, iPort, sMessage);&#125; UDPUDPSend前面SendMessageUDP调用了m_oUDPSend.AddMessage。这里的UDPSend维护了一个发送队列，如下： Queue&lt;QueueData *&gt; m_oSendQueue; m_oUDPSend.AddMessage就是将消息加入到UDP的m_oSendQueue中。 然后UDPSend在run方法中一直循环将m_oSendQueue中的消息发送出去： void UDPSend :: run()&#123; m_bIsStarted = true; while(true) &#123; QueueData * poData = nullptr; //同步，线程安全 m_oSendQueue.lock(); bool bSucc = m_oSendQueue.peek(poData, 1000); if (bSucc) &#123; //取出队头消息 m_oSendQueue.pop(); &#125; m_oSendQueue.unlock(); if (poData != nullptr) &#123; //将消息发送出去 SendMessage(poData-&gt;m_sIP, poData-&gt;m_iPort, poData-&gt;m_sMessage); delete poData; &#125; if (m_bIsEnd) &#123; PLHead(\"UDPSend [END]\"); return; &#125; &#125;&#125; 因此UDPSend就是把消息加入到消息队列，然后循环将消息队列里的消息发送出去。 UDPRecv接下来看看UDPRecv。UDPRecv的初始化前面已经看过了，就是简单的获得socket fd，设定sockaddr_in，设置socket属性最后将socket fd和sockaddr_in绑定用于监听。 主要来看看UDPRecv的run方法。这里主要用了I/O多路复用中的poll，注册了一个pollfd，该pollfd的fd即之前创建的绑定了端口的socket fd，events为POLLIN，表示监听数据可读事件，如果有数据可读了，则调用recvfrom读入数据。最后调用OnReceiveMessage将消息添加到当前instance的IoLoop中： void UDPRecv :: run()&#123; m_bIsStarted = true; char sBuffer[65536] = &#123;0&#125;; struct sockaddr_in addr; socklen_t addr_len = sizeof(struct sockaddr_in); memset(&amp;addr, 0, sizeof(addr)); while(true) &#123; if (m_bIsEnd) &#123; PLHead(\"UDPRecv [END]\"); return; &#125; struct pollfd fd; int ret; fd.fd = m_iSockFD; //注册POLLIN事件 fd.events = POLLIN; //调用poll检查是否有数据可读 ret = poll(&amp;fd, 1, 500); if (ret == 0 || ret == -1) &#123; continue; &#125; //将接收到的数据放入sBuffer中 int iRecvLen = recvfrom(m_iSockFD, sBuffer, sizeof(sBuffer), 0, (struct sockaddr *)&amp;addr, &amp;addr_len); BP-&gt;GetNetworkBP()-&gt;UDPReceive(iRecvLen); if (iRecvLen &gt; 0) &#123; //这里会依次调用Node和Instance的OnReceiveMessage方法，最后将消息加入到Instance的IoLoop中 m_poDFNetWork-&gt;OnReceiveMessage(sBuffer, iRecvLen); &#125; &#125;&#125; TCPTcpIOThread接下来看看收发TCP消息的TcpIOThread： class TcpIOThread &#123;public: TcpIOThread(NetWork * poNetWork); ~TcpIOThread(); //用于初始化TcpAcceptor以及iIOThreadCount个m_vecTcpRead和m_vecTcpWrite int Init(const std::string &amp; sListenIp, const int iListenPort, const int iIOThreadCount); //启动TcpAcceptor用于监听以及所有的m_vecTcpRead和m_vecTcpWrite用于读写消息 void Start(); //停止TcpAcceptor和所有的m_vecTcpRead及m_vecTcpWrite void Stop(); //将消息加入到特定TcpWrite的消息队列中 int AddMessage(const int iGroupIdx, const std::string &amp; sIP, const int iPort, const std::string &amp; sMessage);private: NetWork * m_poNetWork; TcpAcceptor m_oTcpAcceptor; std::vector&lt;TcpRead *&gt; m_vecTcpRead; std::vector&lt;TcpWrite *&gt; m_vecTcpWrite; bool m_bIsStarted;&#125;; TcpRead类似于前面讲的UDPRecv，TcpWrite类似于于UDPSend。严格来讲，TcpAcceptor + TcpRead才是UDPRecv。这里把TcpAcceptor单独抽出来，专门用于监听连接请求并建立连接。TcpRead只需要负责读消息就行。 TcpAcceptor我们来看看TcpAcceptor： class TcpAcceptor : public Thread&#123;public: TcpAcceptor(); ~TcpAcceptor(); //监听端口 void Listen(const std::string &amp; sListenIP, const int iListenPort); //一直while循环，监听连接事件并建立连接获得fd，然后添加事件到EventLoop中 void run(); void Stop(); void AddEventLoop(EventLoop * poEventLoop); void AddEvent(int iFD, SocketAddress oAddr);private: //服务端的socket，用于监听 ServerSocket m_oSocket; std::vector&lt;EventLoop *&gt; m_vecEventLoop;private: bool m_bIsEnd; bool m_bIsStarted;&#125;; 这里主要来看下run方法： void TcpAcceptor :: run()&#123; m_bIsStarted = true; PLHead(\"start accept...\"); m_oSocket.setAcceptTimeout(500); m_oSocket.setNonBlocking(true); while (true) &#123; struct pollfd pfd; int ret; pfd.fd = m_oSocket.getSocketHandle(); //注册事件 pfd.events = POLLIN; //等待事件到来 ret = poll(&amp;pfd, 1, 500); if (ret != 0 &amp;&amp; ret != -1) &#123; SocketAddress oAddr; int fd = -1; try &#123; //建立连接，获得fd。这里的acceptfd对accept进行了简单的封装 fd = m_oSocket.acceptfd(&amp;oAddr); &#125; catch(...) &#123; fd = -1; &#125; if (fd &gt;= 0) &#123; BP-&gt;GetNetworkBP()-&gt;TcpAcceptFd(); PLImp(\"accepted!, fd %d ip %s port %d\", fd, oAddr.getHost().c_str(), oAddr.getPort()); //添加事件 AddEvent(fd, oAddr); &#125; &#125; if (m_bIsEnd) &#123; PLHead(\"TCP.Acceptor [END]\"); return; &#125; &#125;&#125; 再看看AddEvent方法： void TcpAcceptor :: AddEvent(int iFD, SocketAddress oAddr)&#123; EventLoop * poMinActiveEventLoop = nullptr; int iMinActiveEventCount = 1 &lt;&lt; 30; for (auto &amp; poEventLoop : m_vecEventLoop) &#123; int iActiveCount = poEventLoop-&gt;GetActiveEventCount(); if (iActiveCount &lt; iMinActiveEventCount) &#123; iMinActiveEventCount = iActiveCount; poMinActiveEventLoop = poEventLoop; &#125; &#125;oAddr.getPort()); poMinActiveEventLoop-&gt;AddEvent(iFD, oAddr);&#125; 即找到活跃数最少的EventLoop，将事件添加到该EventLoop中。这里应该是为了负载均衡，防止有些线程工作量很大，有些则很空闲。 具体EventLoop的AddEvent就是将事件加入到FDQueue中，如下： void EventLoop :: AddEvent(int iFD, SocketAddress oAddr)&#123; std::lock_guard&lt;std::mutex&gt; oLockGuard(m_oMutex); m_oFDQueue.push(make_pair(iFD, oAddr));&#125; 到这里TcpAcceptor的作用及实现基本就很清晰了。 TcpRead先来看看TcpRead类的定义： class TcpRead : public Thread&#123;public: TcpRead(NetWork * poNetWork); ~TcpRead(); int Init(); void run(); void Stop(); EventLoop * GetEventLoop();private: EventLoop m_oEventLoop;&#125;; 这里的成员变量是一个EventLoop对象。通过源码发现，Init、run、Stop方法其实都是调用了m_oEventLoop相应的方法，如下： int TcpRead :: Init()&#123; return m_oEventLoop.Init(20480);&#125;void TcpRead :: run()&#123; m_oEventLoop.StartLoop();&#125;void TcpRead :: Stop()&#123; m_oEventLoop.Stop(); join(); PLHead(\"TcpReadThread [END]\");&#125; 因此主要来看下EventLoop。 首先说下Event。PhxPaxos在TCP这块主要用了I/O多路复用中的epoll。这里主要将数据和通知等都封装成Event，然后由TcpWrite和TcpRead的EventLoop去执行。PhxPaxos中的Event包含两个子类，分别是MessageEvent和Notify。其中MessageEvent主要用于数据的读写；而Notify主要用于通知事件发生。这里的Notify基于管道pipe和EPOLLIN事件来实现，可以通过Notify的Init方法看出： int Notify :: Init()&#123; //m_iPipeFD是一个长度为2的int数组，用于存放管道两端的socket fd int ret = pipe(m_iPipeFD); if (ret != 0) &#123; PLErr(\"create pipe fail, ret %d\", ret); return ret; &#125; fcntl(m_iPipeFD[0], F_SETFL, O_NONBLOCK); fcntl(m_iPipeFD[1], F_SETFL, O_NONBLOCK); AddEvent(EPOLLIN); return 0;&#125; 继续回到EventLoop。首先看下EventLoop的Init方法： int EventLoop :: Init(const int iEpollLength)&#123; //创建epoll句柄，iEpollLength为监听的fd数 m_iEpollFd = epoll_create(iEpollLength); if (m_iEpollFd == -1) &#123; PLErr(\"epoll_create fail, ret %d\", m_iEpollFd); return -1; &#125; m_poNotify = new Notify(this); assert(m_poNotify != nullptr); //初始化Notify：创建pipe，设置m_iPipeFD并添加EPOLLIN事件 int ret = m_poNotify-&gt;Init(); if (ret != 0) &#123; return ret; &#125; return 0;&#125; 接着来看下最重要的StartLoop： void EventLoop :: StartLoop()&#123; m_bIsEnd = false; while(true) &#123; BP-&gt;GetNetworkBP()-&gt;TcpEpollLoop(); int iNextTimeout = 1000; DealwithTimeout(iNextTimeout); //PLHead(\"nexttimeout %d\", iNextTimeout); OneLoop(iNextTimeout); CreateEvent(); if (m_poTcpClient != nullptr) &#123; m_poTcpClient-&gt;DealWithWrite(); &#125; if (m_bIsEnd) &#123; PLHead(\"TCP.EventLoop [END]\"); break; &#125; &#125;&#125; 主循环是OneLoop： void EventLoop :: OneLoop(const int iTimeoutMs)&#123; //调用epoll_wait等待事件发生 int n = epoll_wait(m_iEpollFd, m_EpollEvents, MAX_EVENTS, 1); if (n == -1) &#123; if (errno != EINTR) &#123; PLErr(\"epoll_wait fail, errno %d\", errno); return; &#125; &#125; //逐一处理发生的epoll事件 for (int i = 0; i &lt; n; i++) &#123; int iFd = m_EpollEvents[i].data.fd; auto it = m_mapEvent.find(iFd); if (it == end(m_mapEvent)) &#123; continue; &#125; int iEvents = m_EpollEvents[i].events; Event * poEvent = it-&gt;second.m_poEvent; int ret = 0; if (iEvents &amp; EPOLLERR) &#123; OnError(iEvents, poEvent); continue; &#125; try &#123; //如果是EPOLLIN事件，表明由数据可读，则调用poEvent的OnRead方法处理 if (iEvents &amp; EPOLLIN) &#123; ret = poEvent-&gt;OnRead(); &#125; //如果是EPOLLOUT事件，表明由数据可写，则调用poEvent的OnWrite方法处理 if (iEvents &amp; EPOLLOUT) &#123; ret = poEvent-&gt;OnWrite(); &#125; &#125; catch (...) &#123; ret = -1; &#125; if (ret != 0) &#123; OnError(iEvents, poEvent); &#125; &#125;&#125; 其他具体的细节这里就不再赘述了，有兴趣的可以自己去看看源码。 TcpWrite看完了TcpRead，再来看看TcpWrite。首先还是看它的定义： class TcpWrite : public Thread&#123;public: TcpWrite(NetWork * poNetWork); ~TcpWrite(); int Init(); void run(); void Stop(); int AddMessage(const std::string &amp; sIP, const int iPort, const std::string &amp; sMessage);private: TcpClient m_oTcpClient; EventLoop m_oEventLoop;&#125;; Init、run、Stop跟TcpRead中对应方法的作用一致。AddMessage则是调用了m_oTcpClient的AddMessage方法。发现TcpWrite的成员变量比TcpRead多了一个TcpClient对象，因此主要来看看这个TcpClient是干嘛的。 刚刚说TcpWrite的AddMessage调用了m_oTcpClient的AddMessage方法。在m_oTcpClient的AddMessage方法中，则是先创建了一个指向MessageEvent对象的指针poEvent，然后再调用poEvent的AddMessage方法： int TcpClient :: AddMessage(const std::string &amp; sIP, const int iPort, const std::string &amp; sMessage)&#123; //PLImp(\"ok\"); MessageEvent * poEvent = GetEvent(sIP, iPort); if (poEvent == nullptr) &#123; PLErr(\"no event created for this ip %s port %d\", sIP.c_str(), iPort); return -1; &#125; return poEvent-&gt;AddMessage(sMessage);&#125; 因此继续看看MessageEvent的AddMessage方法： int MessageEvent :: AddMessage(const std::string &amp; sMessage)&#123; m_llLastActiveTime = Time::GetSteadyClockMS(); std::unique_lock&lt;std::mutex&gt; oLock(m_oMutex); if ((int)m_oInQueue.size() &gt; TCP_QUEUE_MAXLEN) &#123; BP-&gt;GetNetworkBP()-&gt;TcpQueueFull(); //PLErr(\"queue length %d too long, can't enqueue\", m_oInQueue.size()); return -2; &#125; if (m_iQueueMemSize &gt; MAX_QUEUE_MEM_SIZE) &#123; //PLErr(\"queue memsize %d too large, can't enqueue\", m_iQueueMemSize); return -2; &#125; QueueData tData; //将消息封装成QueueData后放入队列 tData.llEnqueueAbsTime = Time::GetSteadyClockMS(); tData.psValue = new string(sMessage); m_oInQueue.push(tData); m_iQueueMemSize += sMessage.size(); oLock.unlock(); //退出EpollWait，实际是调用SendNotify发送了一个通知 JumpoutEpollWait(); return 0;&#125; 可以看到这里将消息加上入队时间后封装成一个QueueDate，然后放入m_oInQueue队列中。最后调用EventLoop的SendNotify发送了一个通知（利用之前创建的pipe）退出EpollWait。 说完了消息怎么入队，那消息是怎么发送出去的呢？ 这里主要涉及到MessageEvent的OnWrite函数： int MessageEvent :: OnWrite()&#123; int ret = 0; //只要发送队列不为空或者还有上次未发送完的数据，就调用DoOnWrite执行真正的发送操作 while (!m_oInQueue.empty() || m_iLeftWriteLen &gt; 0) &#123; ret = DoOnWrite(); if (ret != 0 &amp;&amp; ret != 1) &#123; return ret; &#125; else if (ret == 1) &#123; //need break, wait next write return 0; &#125; &#125; WriteDone(); return 0;&#125; DoOnWrite: int MessageEvent :: DoOnWrite()&#123; //上一次的消息还未发送完毕，将剩下的发送完 if (m_iLeftWriteLen &gt; 0) &#123; return WriteLeft(); &#125; m_oMutex.lock(); if (m_oInQueue.empty()) &#123; m_oMutex.unlock(); return 0; &#125; //从队列中取出一条新消息，准备发送 QueueData tData = m_oInQueue.front(); m_oInQueue.pop(); m_iQueueMemSize -= tData.psValue-&gt;size(); m_oMutex.unlock(); std::string * poMessage = tData.psValue; //如果该消息入队太久没有被处理，则抛弃，不发送 uint64_t llNowTime = Time::GetSteadyClockMS(); int iDelayMs = llNowTime &gt; tData.llEnqueueAbsTime ? (int)(llNowTime - tData.llEnqueueAbsTime) : 0; BP-&gt;GetNetworkBP()-&gt;TcpOutQueue(iDelayMs); if (iDelayMs &gt; TCP_OUTQUEUE_DROP_TIMEMS) &#123; //PLErr(\"drop request because enqueue timeout, nowtime %lu unqueuetime %lu\", //llNowTime, tData.llEnqueueAbsTime); delete poMessage; return 0; &#125; //计算发送缓冲区长度，需要加上4字节用于表示消息长度 int iBuffLen = poMessage-&gt;size(); int niBuffLen = htonl(iBuffLen + 4); int iLen = iBuffLen + 4; //申请缓冲区 m_oWriteCacheBuffer.Ready(iLen); //将消息长度及消息内容拷贝到缓冲区 memcpy(m_oWriteCacheBuffer.GetPtr(), &amp;niBuffLen, 4); memcpy(m_oWriteCacheBuffer.GetPtr() + 4, poMessage-&gt;c_str(), iBuffLen); m_iLeftWriteLen = iLen; m_iLastWritePos = 0; delete poMessage; //PLImp(\"write len %d ip %s port %d\", iLen, m_oAddr.getHost().c_str(), m_oAddr.getPort()); //开始发送消息，有可能消息太大一次发送不完 int iWriteLen = m_oSocket.send(m_oWriteCacheBuffer.GetPtr(), iLen); if (iWriteLen &lt; 0) &#123; PLErr(\"fail, write len %d ip %s port %d\", iWriteLen, m_oAddr.getHost().c_str(), m_oAddr.getPort()); return -1; &#125; //需要下次再发送 if (iWriteLen == 0) &#123; //need wait next write AddEvent(EPOLLOUT); return 1; &#125; //PLImp(\"real write len %d\", iWriteLen); //发送成功 if (iWriteLen == iLen) &#123; m_iLeftWriteLen = 0; m_iLastWritePos = 0; //write done &#125; //没有一次性全部发送完，剩下的需要下次发送 else if (iWriteLen &lt; iLen) &#123; //m_iLastWritePos和m_iLeftWriteLen分别用来表示上次写的位置以及剩下需要发送的长度 m_iLastWritePos = iWriteLen; m_iLeftWriteLen = iLen - iWriteLen; PLImp(\"write buflen %d smaller than expectlen %d\", iWriteLen, iLen); &#125; else &#123; PLErr(\"write buflen %d large than expectlen %d\", iWriteLen, iLen); &#125; return 0;&#125; 结语先介绍这么多吧，接下去会有更多相关的文章，特别是PhxPaxos中实现Paxos算法的那部分，相信看过Paxos相关论文的童鞋会对这块很感兴趣。 最后，附上PhxPaxos源码的地址：https://github.com/Tencent/phxpaxos","raw":null,"content":null,"categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://linbingdong.com/categories/源码分析/"}],"tags":[{"name":"Paxos","slug":"Paxos","permalink":"http://linbingdong.com/tags/Paxos/"},{"name":"PhxPaxos","slug":"PhxPaxos","permalink":"http://linbingdong.com/tags/PhxPaxos/"}]},{"title":"Java回调机制","slug":"Java回调机制","date":"2017-11-12T16:00:00.000Z","updated":"2017-11-13T14:13:50.000Z","comments":true,"path":"2017/11/13/Java回调机制/","link":"","permalink":"http://linbingdong.com/2017/11/13/Java回调机制/","excerpt":"对Java回调机制进行简单的介绍，并给出简单的示例。","text":"对Java回调机制进行简单的介绍，并给出简单的示例。 什么是回调回调，即callback。简单来讲，回调就是A包含B，A的函数Af1调用B的函数Bf1，Bf1又调用A的另一个函数Af2。这个Af2是回调接口中的方法，即A实现了回调接口。那么，Bf1为什么能调用Af2呢，是因为A将自身作为参数传给了Bf1。回调一般用在异步调用中。 举个通俗点的例子：A是Boss，B是worker。Boss让Worker去干活，并且让worker干完活后向Boss报告。Boss分发任务（dispatchWork），让woker去执行（startWork）。worker执行完后调用回调接口的report()函数报告任务完成。 示例 CallbackReport.java public interface CallbackReport &#123; void report(String msg);&#125; Boss.java public class Boss implements CallbackReport&#123; Worker worker; public Boss(Worker worker) &#123; this.worker = worker; &#125; public void dispatchWork() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; worker.startWork(Boss.this); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; @Override public void report(String msg) &#123; System.out.println(\"worker reported: \" + msg); &#125;&#125; Worker.java public class Worker &#123; public void startWork(CallbackReport callback) throws InterruptedException &#123; System.out.println(\"worker starts working...\"); Thread.sleep(3000); callback.report(\"work is done!\"); &#125;&#125; CallbackTest.java public class CallbackTest &#123; public static void main(String[] args) throws InterruptedException &#123; Worker worker = new Worker(); Boss boss = new Boss(worker); boss.dispatchWork(); System.out.println(\"dispatched work,wait for done!\"); &#125;&#125; 输出worker starts working...dispatched work,wait for done!worker reported: work is done! //等待3秒后才出现这句Process finished with exit code 0","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"Java NIO示例","slug":"Java NIO示例","date":"2017-11-12T16:00:00.000Z","updated":"2017-11-13T09:03:38.000Z","comments":true,"path":"2017/11/13/Java NIO示例/","link":"","permalink":"http://linbingdong.com/2017/11/13/Java NIO示例/","excerpt":"给出Java NIO的示例。包含客户端和服务端。","text":"给出Java NIO的示例。包含客户端和服务端。 示例 NIOServer.java import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;/** * NIOServer */public class NIOServer &#123; private Selector selector; ServerSocketChannel serverSocketChannel; public void initServer(int port) throws IOException &#123; serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.socket().bind(new InetSocketAddress(\"localhost\", port)); this.selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); &#125; public void listen() throws IOException &#123; System.out.println(\"server started succeed!\"); while (true) &#123; selector.select(); Iterator&lt;SelectionKey&gt; ite = selector.selectedKeys().iterator(); while (ite.hasNext()) &#123; SelectionKey key = ite.next(); if(key.isAcceptable()) &#123; SocketChannel channel = serverSocketChannel.accept(); channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_READ); &#125; else if(key.isReadable()) &#123; recvAndReply(key); &#125; ite.remove(); &#125; &#125; &#125; public void recvAndReply(SelectionKey key) throws IOException &#123; SocketChannel channel = (SocketChannel)key.channel(); ByteBuffer buffer = ByteBuffer.allocate(256); int i = channel.read(buffer); if (i != -1) &#123; //用于判断客户端是否断开了连接 String msg = new String(buffer.array()).trim(); System.out.println(\"server received message: \" + msg); System.out.println(\"server reply: \" + msg); channel.write(ByteBuffer.wrap(msg.getBytes())); &#125; else &#123; channel.close(); //如果客户端断开连接就关闭该连接 &#125; &#125; public static void main(String[] args) throws IOException &#123; NIOServer server = new NIOServer(); server.initServer(7788); server.listen(); &#125;&#125; NIOClient.java import java.io.IOError;import java.io.IOException;import java.net.InetAddress;import java.net.InetSocketAddress;import java.nio.channels.NotYetConnectedException;import java.nio.channels.SocketChannel;import java.nio.ByteBuffer;/** * NIOClient */public class NIOClient &#123; SocketChannel channel; public void initClient(String host, int port) throws IOException &#123; InetSocketAddress servAddr = new InetSocketAddress(host, port); this.channel = SocketChannel.open(servAddr); &#125; public void sendAndRecv(String words) throws IOException &#123; byte[] msg = new String(words).getBytes(); ByteBuffer buffer = ByteBuffer.wrap(msg); System.out.println(\"sending: \" + words); channel.write(buffer); buffer.clear(); channel.read(buffer); System.out.println(\"received: \" + new String(buffer.array()).trim()); buffer.clear(); System.out.println(\"sending: \" + \"again\"); buffer = ByteBuffer.wrap(new String(\"again\").getBytes()); channel.write(buffer); buffer.clear(); channel.read(buffer); System.out.println(\"received: \" + new String(buffer.array()).trim()); channel.close(); &#125; public static void main(String[] args) throws IOException&#123; NIOClient client = new NIOClient(); client.initClient(\"localhost\", 7788); client.sendAndRecv(\"this is client\"); &#125;&#125; 运行程序运行顺序如下： 运行NIOServer 运行NIOClient 输出 NIOServer server started succeed!server received message: this is clientserver reply: this is clientserver received message: againserver reply: again NIOClient sending: this is clientreceived: this is clientsending: againreceived: againProcess finished with exit code 0","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"http://linbingdong.com/tags/NIO/"}]},{"title":"Java RPC","slug":"Java RPC","date":"2017-11-12T16:00:00.000Z","updated":"2017-11-13T09:03:22.000Z","comments":true,"path":"2017/11/13/Java RPC/","link":"","permalink":"http://linbingdong.com/2017/11/13/Java RPC/","excerpt":"使用Java原生的序列化、动态代理、反射等实现简单的RPC框架。本示例来源于《分布式服务框架》。","text":"使用Java原生的序列化、动态代理、反射等实现简单的RPC框架。本示例来源于《分布式服务框架》。 示例 EchoService.java public interface EchoService &#123; String echo(String ping);&#125; EchoServiceImpl.java public class EchoServiceImpl implements EchoService &#123; @Override public String echo(String ping) &#123; return ping != null ? ping + \"--&gt; I am OK.\" : \" I am OK.\"; &#125;&#125; RpcExporter.java import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.lang.reflect.Method;import java.net.InetSocketAddress;import java.net.ServerSocket;import java.net.Socket;import java.util.concurrent.Executor;import java.util.concurrent.Executors;/** * Created by lbd on 2017/11/12. */public class RpcExporter &#123; static Executor executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); public static void exporter(String hostName, int port) throws Exception &#123; ServerSocket server = new ServerSocket(); server.bind(new InetSocketAddress(hostName, port)); try &#123; while (true) &#123; executor.execute(new ExporterTask(server.accept())); &#125; &#125; finally &#123; server.close(); &#125; &#125; private static class ExporterTask implements Runnable &#123; Socket client = null; public ExporterTask(Socket client) &#123; this.client = client; &#125; @Override public void run() &#123; ObjectInputStream input = null; ObjectOutputStream output = null; try &#123; input = new ObjectInputStream(client.getInputStream()); String interfaceName = input.readUTF(); Class&lt;?&gt; service = Class.forName(interfaceName); String methodName = input.readUTF(); Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[])input.readObject(); Object[] arguments = (Object[])input.readObject(); Method method = service.getMethod(methodName, parameterTypes); Object result = method.invoke(service.newInstance(), arguments); output = new ObjectOutputStream(client.getOutputStream()); output.writeObject(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (output != null) try &#123; output.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (input != null) try &#123; input.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; RpcImporter.java import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.net.InetSocketAddress;import java.net.Socket;/** * Created by lbd on 2017/11/12. */public class RpcImporter&lt;S&gt; &#123; public S importer(final Class&lt;?&gt; serviceClass, final InetSocketAddress addr) &#123; return (S) Proxy.newProxyInstance(serviceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;serviceClass.getInterfaces()[0]&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Socket socket = null; ObjectOutputStream output = null; ObjectInputStream input = null; try &#123; socket = new Socket(); socket.connect(addr); output = new ObjectOutputStream(socket.getOutputStream()); output.writeUTF(serviceClass.getName()); output.writeUTF(method.getName()); output.writeObject(method.getParameterTypes()); output.writeObject(args); input = new ObjectInputStream(socket.getInputStream()); return input.readObject(); &#125; finally &#123; if (socket != null) socket.close(); if (output != null) output.close(); if (input != null) input.close(); &#125; &#125; &#125;); &#125;&#125; RpcTest.java import java.net.InetSocketAddress;/** * Created by lbd on 2017/11/12. */public class RpcTest &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; RpcExporter.exporter(\"localhost\", 7890); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); RpcImporter&lt;EchoService&gt; proxyImporter = new RpcImporter&lt;&gt;(); EchoService echoService = proxyImporter.importer(EchoServiceImpl.class, new InetSocketAddress(\"localhost\", 7890)); System.out.println(echoService.echo(\"Are you ok ?\")); &#125;&#125; 输出Are you ok ?--&gt; I am OK.","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"RPC","slug":"RPC","permalink":"http://linbingdong.com/tags/RPC/"}]},{"title":"Java动态代理","slug":"Java动态代理","date":"2017-11-11T16:00:00.000Z","updated":"2017-11-12T03:15:00.000Z","comments":true,"path":"2017/11/12/Java动态代理/","link":"","permalink":"http://linbingdong.com/2017/11/12/Java动态代理/","excerpt":"给出Java动态代理的示例，直接贴《Java编程思想》里的代码了。","text":"给出Java动态代理的示例，直接贴《Java编程思想》里的代码了。 示例 import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * DynamicProxyDemo */public class DynamicProxyDemo &#123; public static void consumer(Interface iface) &#123; iface.doSomething(); iface.somethingElse(\"hahaha\"); &#125; public static void main(String[] args) &#123; RealObject real = new RealObject(); consumer(real); System.out.println('\\n' + \"-------------------------\" + '\\n'); Interface proxy = (Interface)Proxy.newProxyInstance(Interface.class.getClassLoader(), new Class[] &#123;Interface.class&#125;, new DynamicProxyHandler(real)); consumer(proxy); &#125;&#125;interface Interface &#123; void doSomething(); void somethingElse(String arg); &#125;class RealObject implements Interface &#123; public void doSomething() &#123; System.out.println(\"doSomething\"); &#125; public void somethingElse(String arg) &#123; System.out.println(\"somethingElse \" + arg); &#125;&#125;class DynamicProxyHandler implements InvocationHandler &#123; private Object proxied; public DynamicProxyHandler(Object proxied) &#123; this.proxied = proxied; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"**** proxy: \" + proxy.getClass() + \", method: \" + method + \", args: \" + args); return method.invoke(proxied, args); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"Java RMI示例","slug":"Java RMI示例","date":"2017-11-11T16:00:00.000Z","updated":"2017-11-13T09:03:02.000Z","comments":true,"path":"2017/11/12/Java RMI示例/","link":"","permalink":"http://linbingdong.com/2017/11/12/Java RMI示例/","excerpt":"给出Java RMI（Remote Method Invocation,远程方法调用）的示例。","text":"给出Java RMI（Remote Method Invocation,远程方法调用）的示例。 示例 HelloInterface.java import java.rmi.Remote;import java.rmi.RemoteException;/** * Created by lbd on 2017/11/12. */public interface HelloInterface extends Remote &#123; public String helloWorld() throws RemoteException; public String sayHello(String name) throws RemoteException;&#125; HelloImpl.java import java.rmi.RemoteException;import java.rmi.server.UnicastRemoteObject;/** * Created by lbd on 2017/11/12. */public class HelloImpl extends UnicastRemoteObject implements HelloInterface &#123; public HelloImpl() throws RemoteException &#123;&#125; public String helloWorld() throws RemoteException &#123; return \"hello world!\"; &#125; public String sayHello(String name) throws RemoteException &#123; return \"hello \" + name + \"!\"; &#125;&#125; HelloServer.java import java.net.MalformedURLException;import java.rmi.AlreadyBoundException;import java.rmi.Naming;import java.rmi.RemoteException;import java.rmi.registry.LocateRegistry;/** * Created by lbd on 2017/11/12. */public class HelloServer &#123; public static void main(String[] args) &#123; try &#123; HelloInterface hello = new HelloImpl(); LocateRegistry.createRegistry(6789); Naming.bind(\"rmi://localhost:6789/rHello\", hello); System.out.println(\"远程HelloInterface对象绑定成功,可以被调用\"); &#125; catch (RemoteException e) &#123; System.out.println(\"创建远程对象发生异常!\"); e.printStackTrace(); &#125; catch (MalformedURLException e) &#123; System.out.println(\"url异常!\"); e.printStackTrace(); &#125; catch (AlreadyBoundException e) &#123; System.out.println(\"重复绑定异常!\"); e.printStackTrace(); &#125; &#125;&#125; HelloClient.java import java.net.MalformedURLException;import java.rmi.Naming;import java.rmi.NotBoundException;import java.rmi.RemoteException;/** * Created by lbd on 2017/11/12. */public class HelloClient &#123; public static void main(String[] args) &#123; try &#123; HelloInterface rHello = (HelloInterface) Naming.lookup(\"rmi://localhost:6789/rHello\"); System.out.println(rHello.helloWorld()); System.out.println(rHello.sayHello(\"lbd\")); &#125; catch (RemoteException | MalformedURLException | NotBoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行程序运行顺序如下： 运行HelloServer 运行HelloClient","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"RMI","slug":"RMI","permalink":"http://linbingdong.com/tags/RMI/"}]},{"title":"设计模式-适配器模式","slug":"设计模式-适配器模式","date":"2017-11-10T16:00:00.000Z","updated":"2017-11-11T03:53:34.000Z","comments":true,"path":"2017/11/11/设计模式-适配器模式/","link":"","permalink":"http://linbingdong.com/2017/11/11/设计模式-适配器模式/","excerpt":"本文介绍适配器模式。","text":"本文介绍适配器模式。 定义适配器模式将一个类的接口，转换成客户端期待的另一个接口。 比如我们想用苹果的充电线给安卓充电。但是安卓的充电接口（type-c）跟苹果（lightning）的不一样，所以就需要一个适配器，将安卓的type-c接口转换成苹果的lightning接口，这样就能用苹果的充电线给安卓充电了。 图中玫瑰金色的就是适配器。 角色 目标（Target）：即期望的接口。 适配器（Adapter）：用于将源接口转换成目标接口。 被适配者（Adaptee）：即源接口。 类图 示例public class AdapterDP &#123; public static void main(String[] args) &#123; AppleLightning appleLighting = new AppleLightning(); System.out.println(\"use lightning to charge\"); appleLighting.chargeWithLightning(); System.out.println('\\n' + \"use type-c to charge\"); AndroidTypeC androidTypeC = new AndroidTypeC(); androidTypeC.chargeWithTypeC(); System.out.println('\\n' + \"use lightning to charge\"); Lightning adapter = new Adapter(androidTypeC); adapter.chargeWithLightning(); &#125;&#125;interface Lightning &#123; void chargeWithLightning();&#125;class AppleLightning implements Lightning &#123; public void chargeWithLightning() &#123; System.out.println(\"charging iPhone...\"); &#125;&#125;class AndroidTypeC &#123; public void chargeWithTypeC() &#123; System.out.println(\"charging android...\"); &#125;&#125;class Adapter implements Lightning &#123; public AndroidTypeC androidTypeC; public Adapter(AndroidTypeC androidTypeC) &#123; this.androidTypeC = androidTypeC; &#125; public void chargeWithLightning() &#123; androidTypeC.chargeWithTypeC(); &#125;&#125; 输出 use lightning to chargecharging iPhone...use type-c to chargecharging android...use lightning to chargecharging android... 注：以上的例子是对象适配器模式，还有另一种适配器模式叫类适配器模式，这里不再赘述。 适配器模式在Hadoop源码中的应用Hadoop作为广泛应用的大数据组件，其本质是一个分布式系统，在分布式系统中，各个节点之间的通信和交互是必不可少的，为此，Hadoop实现了一套自己的RPC框架，该RPC框架默认使用Protocol Buffer作为序列化工具。 ClientProtocol协议定义了HDFS Client和NameNode交互的所有方法，但是ClientProtocol协议中方法的参数是无法在网络中传输的，需要对参数进行序列化操作，所以HDFS又定义了ClientNamenodeProtocolPB协议，该协议包含了ClientProtocol定义的所有方法，但是参数却是使用protobuf序列化后的格式。 ClientNamenodeProtocolTranslatorPB类作为Client侧的适配器类，实现了ClientProtocol接口，它内部拥有一个实现了ClientNamenodeProtocolPB接口的对象，可以将ClientProtocol调用适配成ClientNamenodeProtocolPB调用。以rename()调用为例，ClientNamenodeProtocolPB将rename(String, String)调用中的两个String参数序列化成一个RenameRequestProto对象，然后调用ClientNamenodeProtocolPB对象的rename(RenameRequestProto)方法，这样就完成了ClientProtocol接口到ClientNamenodeProtocolPB接口的适配。 在该例子中，ClientNamenodeProtocolTranslatorPB类为适配器，ClientProtocol为目标接口（这里的目标是对客户端来说的），ClientNamenodeProtocolPB为源接口。","raw":null,"content":null,"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://linbingdong.com/categories/设计模式/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://linbingdong.com/tags/设计模式/"}]},{"title":"分布式系列文章——Paxos算法原理与推导","slug":"分布式系列文章——Paxos算法原理与推导","date":"2017-04-16T16:00:00.000Z","updated":"2017-09-03T02:12:37.000Z","comments":true,"path":"2017/04/17/分布式系列文章——Paxos算法原理与推导/","link":"","permalink":"http://linbingdong.com/2017/04/17/分布式系列文章——Paxos算法原理与推导/","excerpt":"Paxos算法在分布式领域具有非常重要的地位。但是Paxos算法有两个比较明显的缺点：1.难以理解 2.工程实现更难。\n网上有很多讲解Paxos算法的文章，但是质量参差不齐。看了很多关于Paxos的资料后发现，学习Paxos最好的资料是论文《Paxos Made Simple》，其次是中、英文版维基百科对Paxos的介绍。本文试图带大家一步步揭开Paxos神秘的面纱。","text":"Paxos算法在分布式领域具有非常重要的地位。但是Paxos算法有两个比较明显的缺点：1.难以理解 2.工程实现更难。 网上有很多讲解Paxos算法的文章，但是质量参差不齐。看了很多关于Paxos的资料后发现，学习Paxos最好的资料是论文《Paxos Made Simple》，其次是中、英文版维基百科对Paxos的介绍。本文试图带大家一步步揭开Paxos神秘的面纱。 Paxos是什么 Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。 Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。 虽然Mike Burrows说得有点夸张，但是至少说明了Paxos算法的地位。然而，Paxos算法也因为晦涩难懂而臭名昭著。本文的目的就是带领大家深入浅出理解Paxos算法，不仅理解它的执行流程，还要理解算法的推导过程，作者是怎么一步步想到最终的方案的。只有理解了推导过程，才能深刻掌握该算法的精髓。而且理解推导过程对于我们的思维也是非常有帮助的，可能会给我们带来一些解决问题的思路，对我们有所启发。 问题产生的背景在常见的分布式系统中，总会发生诸如机器宕机或网络异常（包括消息的延迟、丢失、重复、乱序，还有网络分区）等情况。Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 注：这里某个数据的值并不只是狭义上的某个数，它可以是一条日志，也可以是一条命令（command）。。。根据应用场景不同，某个数据的值有不同的含义。 相关概念在Paxos算法中，有三种角色： Proposer Acceptor Learners 在具体的实现中，一个进程可能同时充当多种角色。比如一个进程可能既是Proposer又是Acceptor又是Learner。 还有一个很重要的概念叫提案（Proposal）。最终要达成一致的value就在提案里。 注： 暂且认为『提案=value』，即提案只包含value。在我们接下来的推导过程中会发现如果提案只包含value，会有问题，于是我们再对提案重新设计。 暂且认为『Proposer可以直接提出提案』。在我们接下来的推导过程中会发现如果Proposer直接提出提案会有问题，需要增加一个学习提案的过程。 Proposer可以提出（propose）提案；Acceptor可以接受（accept）提案；如果某个提案被选定（chosen），那么该提案里的value就被选定了。 回到刚刚说的『对某个数据的值达成一致』，指的是Proposer、Acceptor、Learner都认为同一个value被选定（chosen）。那么，Proposer、Acceptor、Learner分别在什么情况下才能认为某个value被选定呢？ Proposer：只要Proposer发的提案被Acceptor接受（刚开始先认为只需要一个Acceptor接受即可，在推导过程中会发现需要半数以上的Acceptor同意才行），Proposer就认为该提案里的value被选定了。 Acceptor：只要Acceptor接受了某个提案，Acceptor就认为该提案里的value被选定了。 Learner：Acceptor告诉Learner哪个value被选定，Learner就认为那个value被选定。 问题描述假设有一组可以提出（propose）value（value在提案Proposal里）的进程集合。一个一致性算法需要保证提出的这么多value中，只有一个value被选定（chosen）。如果没有value被提出，就不应该有value被选定。如果一个value被选定，那么所有进程都应该能学习（learn）到这个被选定的value。对于一致性算法，安全性（safaty）要求如下： 只有被提出的value才能被选定。 只有一个value被选定，并且 如果某个进程认为某个value被选定了，那么这个value必须是真的被选定的那个。 我们不去精确地定义其活性（liveness）要求。我们的目标是保证最终有一个提出的value被选定。当一个value被选定后，进程最终也能学习到这个value。 Paxos的目标：保证最终有一个value会被选定，当value被选定后，进程最终也能获取到被选定的value。 假设不同角色之间可以通过发送消息来进行通信，那么： 每个角色以任意的速度执行，可能因出错而停止，也可能会重启。一个value被选定后，所有的角色可能失败然后重启，除非那些失败后重启的角色能记录某些信息，否则等他们重启后无法确定被选定的值。 消息在传递过程中可能出现任意时长的延迟，可能会重复，也可能丢失。但是消息不会被损坏，即消息内容不会被篡改（拜占庭将军问题）。 推导过程最简单的方案——只有一个Acceptor假设只有一个Acceptor（可以有多个Proposer），只要Acceptor接受它收到的第一个提案，则该提案被选定，该提案里的value就是被选定的value。这样就保证只有一个value会被选定。 但是，如果这个唯一的Acceptor宕机了，那么整个系统就无法工作了！ 因此，必须要有多个Acceptor！ 多个Acceptor多个Acceptor的情况如下图。那么，如何保证在多个Proposer和多个Acceptor的情况下选定一个value呢？ 下面开始寻找解决方案。 如果我们希望即使只有一个Proposer提出了一个value，该value也最终被选定。 那么，就得到下面的约束： P1：一个Acceptor必须接受它收到的第一个提案。 但是，这又会引出另一个问题：如果每个Proposer分别提出不同的value，发给不同的Acceptor。根据P1，Acceptor分别接受自己收到的value，就导致不同的value被选定。出现了不一致。如下图： 刚刚是因为『一个提案只要被一个Acceptor接受，则该提案的value就被选定了』才导致了出现上面不一致的问题。因此，我们需要加一个规定： 规定：一个提案被选定需要被半数以上的Acceptor接受 这个规定又暗示了：『一个Acceptor必须能够接受不止一个提案！』不然可能导致最终没有value被选定。比如上图的情况。v1、v2、v3都没有被选定，因为它们都只被一个Acceptor的接受。 最开始讲的『提案=value』已经不能满足需求了，于是重新设计提案，给每个提案加上一个提案编号，表示提案被提出的顺序。令『提案=提案编号+value』。 虽然允许多个提案被选定，但必须保证所有被选定的提案都具有相同的value值。否则又会出现不一致。 于是有了下面的约束： P2：如果某个value为v的提案被选定了，那么每个编号更高的被选定提案的value必须也是v。 一个提案只有被Acceptor接受才可能被选定，因此我们可以把P2约束改写成对Acceptor接受的提案的约束P2a。 P2a：如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v。 只要满足了P2a，就能满足P2。 但是，考虑如下的情况：假设总的有5个Acceptor。Proposer2提出[M1,V1]的提案，Acceptor2~5（半数以上）均接受了该提案，于是对于Acceptor2~5和Proposer2来讲，它们都认为V1被选定。Acceptor1刚刚从宕机状态恢复过来（之前Acceptor1没有收到过任何提案），此时Proposer1向Acceptor1发送了[M2,V2]的提案（V2≠V1且M2&gt;M1），对于Acceptor1来讲，这是它收到的第一个提案。根据P1（一个Acceptor必须接受它收到的第一个提案。）,Acceptor1必须接受该提案！同时Acceptor1认为V2被选定。这就出现了两个问题： Acceptor1认为V2被选定，Acceptor2~5和Proposer2认为V1被选定。出现了不一致。 V1被选定了，但是编号更高的被Acceptor1接受的提案[M2,V2]的value为V2，且V2≠V1。这就跟P2a（如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v）矛盾了。 所以我们要对P2a约束进行强化！ P2a是对Acceptor接受的提案约束，但其实提案是Proposer提出来的，所有我们可以对Proposer提出的提案进行约束。得到P2b： P2b：如果某个value为v的提案被选定了，那么之后任何Proposer提出的编号更高的提案的value必须也是v。 由P2b可以推出P2a进而推出P2。 那么，如何确保在某个value为v的提案被选定后，Proposer提出的编号更高的提案的value都是v呢？ 只要满足P2c即可： P2c：对于任意的N和V，如果提案[N, V]被提出，那么存在一个半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个： S中每个Acceptor都没有接受过编号小于N的提案。 S中Acceptor接受过的最大编号的提案的value为V。 Proposer生成提案为了满足P2b，这里有个比较重要的思想：Proposer生成提案之前，应该先去『学习』已经被选定或者可能被选定的value，然后以该value作为自己提出的提案的value。如果没有value被选定，Proposer才可以自己决定value的值。这样才能达成一致。这个学习的阶段是通过一个『Prepare请求』实现的。 于是我们得到了如下的提案生成算法： Proposer选择一个新的提案编号N，然后向某个Acceptor集合（半数以上）发送请求，要求该集合中的每个Acceptor做出如下响应（response）。(a) 向Proposer承诺保证不再接受任何编号小于N的提案。(b) 如果Acceptor已经接受过提案，那么就向Proposer响应已经接受过的编号小于N的最大编号的提案。 我们将该请求称为编号为N的Prepare请求。 如果Proposer收到了半数以上的Acceptor的响应，那么它就可以生成编号为N，Value为V的提案[N,V]。这里的V是所有的响应中编号最大的提案的Value。如果所有的响应中都没有提案，那 么此时V就可以由Proposer自己选择。生成提案后，Proposer将该提案发送给半数以上的Acceptor集合，并期望这些Acceptor能接受该提案。我们称该请求为Accept请求。（注意：此时接受Accept请求的Acceptor集合不一定是之前响应Prepare请求的Acceptor集合） Acceptor接受提案Acceptor可以忽略任何请求（包括Prepare请求和Accept请求）而不用担心破坏算法的安全性。因此，我们这里要讨论的是什么时候Acceptor可以响应一个请求。 我们对Acceptor接受提案给出如下约束： P1a：一个Acceptor只要尚未响应过任何编号大于N的Prepare请求，那么他就可以接受这个编号为N的提案。 如果Acceptor收到一个编号为N的Prepare请求，在此之前它已经响应过编号大于N的Prepare请求。根据P1a，该Acceptor不可能接受编号为N的提案。因此，该Acceptor可以忽略编号为N的Prepare请求。当然，也可以回复一个error，让Proposer尽早知道自己的提案不会被接受。 因此，一个Acceptor只需记住：1. 已接受的编号最大的提案 2. 已响应的请求的最大编号。 Paxos算法描述经过上面的推导，我们总结下Paxos算法的流程。 Paxos算法分为两个阶段。具体如下： 阶段一： (a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二： (a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 Learner学习被选定的valueLearner学习（获取）被选定的value有如下三种方案： 如何保证Paxos算法的活性 通过选取主Proposer，就可以保证Paxos算法的活性。至此，我们得到一个既能保证安全性，又能保证活性的分布式一致性算法——Paxos算法。 参考资料 论文《Paxos Made Simple》 论文《The Part-Time Parliament》 英文版维基百科的Paxos 中文版维基百科的Paxos 书籍《从Paxos到ZooKeeper》","raw":null,"content":null,"categories":[{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/categories/分布式一致性算法/"},{"name":"Paxos","slug":"分布式一致性算法/Paxos","permalink":"http://linbingdong.com/categories/分布式一致性算法/Paxos/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"},{"name":"Paxos","slug":"Paxos","permalink":"http://linbingdong.com/tags/Paxos/"},{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/tags/分布式一致性算法/"}]},{"title":"深入理解HashMap","slug":"深入理解HashMap","date":"2017-04-16T12:47:53.000Z","updated":"2017-04-16T12:47:53.000Z","comments":true,"path":"2017/04/16/深入理解HashMap/","link":"","permalink":"http://linbingdong.com/2017/04/16/深入理解HashMap/","excerpt":"JDK1.7和JDK1.8中HashMap的实现不尽相同，JDK1.8中做了一些优化，比如当链表多长时转化成红黑树，提高插入和查找的效率；扩容时不再重新哈希。","text":"JDK1.7和JDK1.8中HashMap的实现不尽相同，JDK1.8中做了一些优化，比如当链表多长时转化成红黑树，提高插入和查找的效率；扩容时不再重新哈希。 HashMap的源码比较长，加上注释有2000行左右，会在文末贴出。这里主要以提问题的形式来加深对HashMap的理解，读者可以先独立思考这些问题，再参照我的回答和文末的源码进行学习。 实现原理数组+链表+红黑树 数组是一个Node数组，Node是一个Key-Value对，Node实现了Map.Entry。链表/红黑树是用来解决hash冲突的。当链表的长度大于8时会转化成红黑树（Node-&gt;TreeNode），提高插入和查询的效率。 HashMap继承了哪些类，实现了哪些接口继承了AbstractMap类，实现了Serializable/Cloneable/Map接口 如何put和getget 确定key对应的Node的索引： h = key.hashCode(); hash = h ^ (h &gt;&gt;&gt; 16); index = hash &amp; (length - 1) 如果第一个Node的key跟该key相等（hash值相同且equals），则返回第一个Node的value。 如果第一个是TreeNode，则用红黑树的方法进行搜索，找到key相同的返回该Node的value；如果第一个是Node，则按链表逐个搜索，找到key相同的返回该Node的value。 返回null put 如果数组长度为0，先扩容。如果已经是最大容量，则不再扩。 计算放置的位置（数组下标）。h = key.hashCode(); hash = h ^ h &gt;&gt;&gt; 16; index = hash &amp; (length - 1) 若该位置为null，则直接将新节点放入该位置 若该位置不为null，如果第一个节点的key跟要put的key相同（hashCode和equals），直接覆盖value 否则，判断是否为TreeNode，若是，则直接在红黑树中插入键值对。 若是链表，判断链表的长度是否大于8，如果大于8则转为红黑树，并在红黑树中插入。否则执行链表中的插入操作。遍历链表时若发现key已经存在则直接覆盖value。 如果超过阈值，就扩容。 初始容量和最大容量分别是多少默认初始容量为16（1&lt;&lt;4），可以在初始化时自己指定。最大容量为2的30次方（1&lt;&lt;30）,容量一定是2的整数幂 加载因子（loadFactor）是多少，为什么0.75 加载因子默认为0.75是对时间和空间的折中。加载因子越大，空间利用率越高，但是产生冲突的概率就越大，会导致put和get效率降低。 如何确定Node在数组中的位置（如何构造哈希函数） 通过key.hashCode()获得 h = key.hashCode()， 将h的高16位和低16位异或。 hash = h ^ (h &gt;&gt;&gt; 16) index = hash &amp; (length - 1) 等价于hash % length。前提是length必须为2的整数幂 如何减少冲突 合理的加载因子，如果加载因子设置得过大会增加冲突的概率 合理的hash函数。比如将hashCode的高16位和低16位异或。 如何解决冲突采用拉链法解决冲突（链表的插入采用头插法）。 什么时候扩容，如何扩容当Node数（size）超过阈值（threshold = 容量*加载因子）时会扩容。扩容为原来的两倍。 新建一个两倍大的数组 把旧数组中的Node全部放入新数组。JDK1.7中所有的Node都会重新hash来确定在新数组中的位置，效率很低；但其实扩容为两倍后，新的Node下标要么跟原来相等，要么比原来大length。JDK1.8中就采取后面的方法，效率更高. 构造函数 包含 初始容量和加载因子 两个参数的构造函数如果指定的初始容量大于最大容量，会以最大容量作为初始容量；如果指定的初始容量不是2的整数幂，会找到大于该值的最小的2的整数幂作为初始容量。 默认构造函数初始容量为16；加载因子为0.75 包含子map的构造函数 为什么数组容量要是2的整数幂 这样hash % length 可以转化为 hash &amp; (length -1) 位运算效率更高 保证length - 1二进制表示的最低位为1。 如果最低位为 0 ，则按位与之后一定得到偶数（下标都是偶数），这样浪费了一大半的空间。 什么情况下HashMap会线程不安全 如线程A和线程B同时put并写入相同的位置。两个线程都会得到该位置当前的头节点。如果A先写入新的头节点，然后B也写入新的头节点，那么B的操作就会覆盖A的操作造成A的写入操作丢失。 如多个线程同时put并刚好都达到门限值，然后都进行了resize（扩容）。此时每个线程都会生成一个新的数组并将table指针指向新的数组，结果最终只有最后一个线程的生成的新数组被赋给table变量，其他线程的均会丢失。 HashMap源码（JDK1.8） package java.util;import java.io.IOException;import java.io.InvalidObjectException;import java.io.Serializable;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.function.BiConsumer;import java.util.function.BiFunction;import java.util.function.Consumer;import java.util.function.Function;public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /** * The default initial capacity - MUST be a power of two. */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */ static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */ static final int UNTREEIFY_THRESHOLD = 6; /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */ static final int MIN_TREEIFY_CAPACITY = 64; /** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; /* ---------------- Static utilities -------------- */ /** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; /** * Returns x's Class if it is of the form \"class C implements * Comparable&lt;C&gt;\", else null. */ static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; return null; &#125; /** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. */ @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) // for cast to Comparable static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x)); &#125; /** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; /* ---------------- Fields -------------- */ /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node&lt;K,V&gt;[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * The number of key-value mappings contained in this map. */ transient int size; /** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * The load factor for the hash table. * * @serial */ final float loadFactor; /* ---------------- Public operations -------------- */ /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; /** * Implements Map.putAll and Map constructor * * @param m the map * @param evict false when initially constructing this map, else * true (relayed to method afterNodeInsertion). */ final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; /** * Returns the number of key-value mappings in this map. * * @return the number of key-value mappings in this map */ public int size() &#123; return size; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings. * * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings */ public boolean isEmpty() &#123; return size == 0; &#125; /** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null : * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise * it returns &#123;@code null&#125;. (There can be at most one such mapping.) * * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the * specified key. * * @param key The key whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified * key. */ public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; /** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; /** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */ final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; /** * Copies all of the mappings from the specified map to this map. * These mappings will replace any mappings that this map had for * any of the keys currently in the specified map. * * @param m mappings to be stored in this map * @throws NullPointerException if the specified map is null */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true); &#125; /** * Removes the mapping for the specified key from this map if present. * * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; /** * Implements Map.remove and related methods * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; /** * Removes all of the mappings from this map. * The map will be empty after this call returns. */ public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value. * * @param value value whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value */ public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; /** * Returns a &#123;@link Set&#125; view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * &lt;tt&gt;Iterator.remove&lt;/tt&gt;, &lt;tt&gt;Set.remove&lt;/tt&gt;, * &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt;, and &lt;tt&gt;clear&lt;/tt&gt; * operations. It does not support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; * operations. * * @return a set view of the keys contained in this map */ public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks; return (ks = keySet) == null ? (keySet = new KeySet()) : ks; &#125; final class KeySet extends AbstractSet&lt;K&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public final boolean contains(Object o) &#123; return containsKey(o); &#125; public final boolean remove(Object key) &#123; return removeNode(hash(key), key, null, false, true) != null; &#125; public final Spliterator&lt;K&gt; spliterator() &#123; return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Collection&#125; view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Collection.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, * &lt;tt&gt;retainAll&lt;/tt&gt; and &lt;tt&gt;clear&lt;/tt&gt; operations. It does not * support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a view of the values contained in this map */ public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs; return (vs = values) == null ? (values = new Values()) : vs; &#125; final class Values extends AbstractCollection&lt;V&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(); &#125; public final boolean contains(Object o) &#123; return containsValue(o); &#125; public final Spliterator&lt;V&gt; spliterator() &#123; return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Set&#125; view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map */ public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() &#123; return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; // Overrides of JDK8 Map extension methods @Override public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value; &#125; @Override public V putIfAbsent(K key, V value) &#123; return putVal(hash(key), key, value, true, true); &#125; @Override public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null; &#125; @Override public boolean replace(K key, V oldValue, V newValue) &#123; Node&lt;K,V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) &#123; e.value = newValue; afterNodeAccess(e); return true; &#125; return false; &#125; @Override public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; &#125; return null; &#125; @Override public V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; if (mappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) &#123; afterNodeAccess(old); return oldValue; &#125; &#125; V v = mappingFunction.apply(key); if (v == null) &#123; return null; &#125; else if (old != null) &#123; old.value = v; afterNodeAccess(old); return v; &#125; else if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); return v; &#125; public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) &#123; V v = remappingFunction.apply(key, oldValue); if (v != null) &#123; e.value = v; afterNodeAccess(e); return v; &#125; else removeNode(hash, key, null, false, true); &#125; return null; &#125; @Override public V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; V oldValue = (old == null) ? null : old.value; V v = remappingFunction.apply(key, oldValue); if (old != null) &#123; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); &#125; else if (v != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return v; &#125; @Override public V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; if (old != null) &#123; V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); return v; &#125; if (value != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, value); else &#123; tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return value; &#125; @Override public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; @Override public void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; e.value = function.apply(e.key, e.value); &#125; &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; /* ------------------------------------------------------------ */ // Cloning and serialization /** * Returns a shallow copy of this &lt;tt&gt;HashMap&lt;/tt&gt; instance: the keys and * values themselves are not cloned. * * @return a shallow copy of this map */ @SuppressWarnings(\"unchecked\") @Override public Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result; &#125; // These methods are also used when serializing HashSets final float loadFactor() &#123; return loadFactor; &#125; final int capacity() &#123; return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY; &#125; /** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */ private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s); &#125; /** * Reconstitute the &#123;@code HashMap&#125; instance from a stream (i.e., * deserialize it). */ private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException(\"Illegal load factor: \" + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException(\"Illegal mappings count: \" + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings(\"unchecked\") K key = (K) s.readObject(); @SuppressWarnings(\"unchecked\") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // iterators abstract class HashIterator &#123; Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125; &#125; final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125; &#125; final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; &#123; public final V next() &#123; return nextNode().value; &#125; &#125; final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125; &#125; /* ------------------------------------------------------------ */ // spliterators static class HashMapSpliterator&lt;K,V&gt; &#123; final HashMap&lt;K,V&gt; map; Node&lt;K,V&gt; current; // current node int index; // current index, modified on advance/split int fence; // one past last index int est; // size estimate int expectedModCount; // for comodification checks HashMapSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; this.map = m; this.index = origin; this.fence = fence; this.est = est; this.expectedModCount = expectedModCount; &#125; final int getFence() &#123; // initialize fence and size on first use int hi; if ((hi = fence) &lt; 0) &#123; HashMap&lt;K,V&gt; m = map; est = m.size; expectedModCount = m.modCount; Node&lt;K,V&gt;[] tab = m.table; hi = fence = (tab == null) ? 0 : tab.length; &#125; return hi; &#125; public final long estimateSize() &#123; getFence(); // force init return (long) est; &#125; &#125; static final class KeySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;K&gt; &#123; KeySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public KeySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new KeySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super K&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.key); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super K&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; K k = current.key; current = current.next; action.accept(k); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; static final class ValueSpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;V&gt; &#123; ValueSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public ValueSpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new ValueSpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super V&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.value); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super V&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; V v = current.value; current = current.next; action.accept(v); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0); &#125; &#125; static final class EntrySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; EntrySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public EntrySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new EntrySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; Node&lt;K,V&gt; e = current; current = current.next; action.accept(e); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; /* ------------------------------------------------------------ */ // LinkedHashMap support /* * The following package-protected methods are designed to be * overridden by LinkedHashMap, but not by any other subclass. * Nearly all other internal methods are also package-protected * but are declared final, so can be used by LinkedHashMap, view * classes, and HashSet. */ // Create a regular (non-tree) node Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next); &#125; // For conversion from TreeNodes to plain nodes Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next); &#125; // Create a tree bin node TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(hash, key, value, next); &#125; // For treeifyBin TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; /** * Reset to initial default state. Called by clone and readObject. */ void reinitialize() &#123; table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0; &#125; // Callbacks to allow LinkedHashMap post-actions void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125; void afterNodeInsertion(boolean evict) &#123; &#125; void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; // Called only from writeObject, to ensure compatible ordering. void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Tree bins /** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; /** * Ensures that the given root is the first node of its bin. */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) &#123; Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; &#125; assert checkInvariants(root); &#125; &#125; /** * Finds the node starting at root p with the given hash and key. * The kc argument caches comparableClassFor(key) upon first use * comparing keys. */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null; &#125; /** * Calls find for root node. */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. */ static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; &#125; /** * Forms tree of the nodes linked from this node. * @return root of tree */ final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root); &#125; /** * Returns a list of non-TreeNodes replacing those linked from * this node. */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd; &#125; /** * Tree version of putVal. */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125; &#125; /** * Removes the given node, that must be present before this call. * This is messier than typical red-black deletion code because we * cannot swap the contents of an interior node with a leaf * successor that is pinned by \"next\" pointers that are accessible * independently during traversal. So instead we swap the tree * linkages. If the current tree appears to have too few nodes, * the bin is converted back to a plain bin. (The test triggers * somewhere between 2 and 6 nodes, depending on tree structure). */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) &#123; int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) &#123; tab[index] = first.untreeify(map); // too small return; &#125; TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) &#123; TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) &#123; // p was s's direct parent p.parent = s; s.right = p; &#125; else &#123; TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) &#123; if (s == sp.left) sp.left = p; else sp.right = p; &#125; if ((s.right = pr) != null) pr.parent = s; &#125; p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; &#125; else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) &#123; TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; &#125; TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) &#123; // detach TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) &#123; if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; &#125; &#125; if (movable) moveRootToFront(tab, r); &#125; /** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) &#123; if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) &#123; if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) &#123; if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.right) &#123; root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateRight(root, xpp); &#125; &#125; &#125; &#125; else &#123; if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.left) &#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) &#123; if (x == null || x == root) return root; else if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (x.red) &#123; x.red = false; return root; &#125; else if ((xpl = xp.left) == x) &#123; if ((xpr = xp.right) != null &amp;&amp; xpr.red) &#123; xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) &#123; xpr.red = true; x = xp; &#125; else &#123; if (sr == null || !sr.red) &#123; if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr != null) &#123; xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateLeft(root, xp); &#125; x = root; &#125; &#125; &#125; else &#123; // symmetric if (xpl != null &amp;&amp; xpl.red) &#123; xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) &#123; xpl.red = true; x = xp; &#125; else &#123; if (sl == null || !sl.red) &#123; if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl != null) &#123; xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateRight(root, xp); &#125; x = root; &#125; &#125; &#125; &#125; &#125; /** * Recursive invariant check */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) &#123; TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"生产者消费者模式","slug":"生产者消费者模式","date":"2017-04-14T08:16:06.000Z","updated":"2017-04-14T08:16:06.000Z","comments":true,"path":"2017/04/14/生产者消费者模式/","link":"","permalink":"http://linbingdong.com/2017/04/14/生产者消费者模式/","excerpt":"在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。","text":"在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。 什么是生产者消费者模式生产者消费者模式通过一个容器（比如阻塞队列 BlockingQueue ）来解决生产者和消费者的紧耦合问题。生产者和消费者之间不直接通信，而是通过阻塞队列来通信。生产者生产完数据后不用等待消费者处理，而是直接将生产的数据放入阻塞队列；消费者不从生产者那里要数据，而是直接从阻塞队列里取。阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 阻塞队列提供了可阻塞的 put 和 take 方法，以及支持定时的 offer 和 poll 方法。如果队列已经满了，那么 put 方法将阻塞直到有空间可用；如果队列为空，那么 take 方法将会阻塞直到阻塞队列里有元素可用。 为什么要用生产者消费者模式 生产者消费者模式可以使生产者类和消费者类解耦，这样能大大简化开发过程，因为它消除了生产者类和消费者类之间的代码依赖性。 生产者消费者模式可以解决生产消费能力不均衡的问题，从而提高整体处理数据的速度。假设不使用生产者消费者模式，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据；有了生产者消费者模式，生产者就可以不用等待消费者了，这样提高了生产者生产数据的效率。 使用阻塞队列实现生产者消费者模式代码如下: /** * Created by lbd */import java.util.concurrent.BlockingQueue;import java.util.concurrent.LinkedBlockingDeque;public class ProducerConsumerPattern &#123; public static void main(String[] args) &#123; BlockingQueue&lt;String&gt; blockingQueue = new LinkedBlockingDeque&lt;&gt;(10); for (int i = 0; i &lt; 20; i++) &#123; new Thread(new Producer(blockingQueue), \"Producer\" + i).start(); &#125; for (int i = 0; i &lt; 2; i++) &#123; new Thread(new Consumer(blockingQueue), \"Consumer\" + i).start(); &#125; &#125;&#125;class Producer implements Runnable &#123; private BlockingQueue&lt;String&gt; blockingQueue; public Producer(BlockingQueue&lt;String&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; &#125; @Override public void run() &#123; try &#123; String product = \"Produced by \" + Thread.currentThread().getName(); blockingQueue.put(product); System.out.println(Thread.currentThread().getName() + \" produced a product\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Consumer implements Runnable &#123; private BlockingQueue&lt;String&gt; blockingQueue; public Consumer(BlockingQueue&lt;String&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; &#125; @Override public void run() &#123; while (true) &#123; try &#123; String product = blockingQueue.take(); System.out.println(Thread.currentThread().getName() + \" cunsumed product \"+ product); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 输出： Producer0 produced a productProducer2 produced a productProducer3 produced a productProducer1 produced a productProducer4 produced a productProducer5 produced a productProducer6 produced a productProducer7 produced a productProducer8 produced a productProducer9 produced a productConsumer0 cunsumed product Produced by Producer0Producer11 produced a productProducer12 produced a productProducer10 produced a productConsumer1 cunsumed product Produced by Producer1Consumer0 cunsumed product Produced by Producer2Producer13 produced a productConsumer1 cunsumed product Produced by Producer3Consumer1 cunsumed product Produced by Producer5Producer15 produced a productConsumer0 cunsumed product Produced by Producer4Producer16 produced a productConsumer1 cunsumed product Produced by Producer6Producer14 produced a productProducer18 produced a productConsumer1 cunsumed product Produced by Producer8Producer17 produced a productConsumer0 cunsumed product Produced by Producer7Producer19 produced a productConsumer1 cunsumed product Produced by Producer9Consumer0 cunsumed product Produced by Producer10Consumer1 cunsumed product Produced by Producer11Consumer0 cunsumed product Produced by Producer12Consumer1 cunsumed product Produced by Producer13Consumer0 cunsumed product Produced by Producer14Consumer1 cunsumed product Produced by Producer15Consumer0 cunsumed product Produced by Producer16Consumer1 cunsumed product Produced by Producer17Consumer0 cunsumed product Produced by Producer18Consumer1 cunsumed product Produced by Producer19","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"程序员必读书单","slug":"程序员必读书单","date":"2017-04-14T08:15:36.000Z","updated":"2017-04-14T08:15:36.000Z","comments":true,"path":"2017/04/14/程序员必读书单/","link":"","permalink":"http://linbingdong.com/2017/04/14/程序员必读书单/","excerpt":"","text":"Lucida大神这篇文章写得非常详细，点此查看。","raw":null,"content":null,"categories":[{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/categories/学习资料/"}],"tags":[{"name":"好文转载","slug":"好文转载","permalink":"http://linbingdong.com/tags/好文转载/"},{"name":"必读书单","slug":"必读书单","permalink":"http://linbingdong.com/tags/必读书单/"},{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/tags/学习资料/"}]},{"title":"tmpfs","slug":"tmpfs","date":"2017-04-11T06:03:33.000Z","updated":"2017-04-11T06:03:33.000Z","comments":true,"path":"2017/04/11/tmpfs/","link":"","permalink":"http://linbingdong.com/2017/04/11/tmpfs/","excerpt":"tmpfs是一种基于内存的文件系统，它和虚拟磁盘ramdisk比较类似像，但不完全相同。和ramdisk一样，tmpfs可以使用内存，但它也可以使用swap分区来存储。而且传统的ramdisk是个块设备，要用mkfs格式化才能使用；而tmpfs是一个文件系统，并不是块设备，不需要格式化。tmpfs是最好的基于内存的文件系统。","text":"tmpfs是一种基于内存的文件系统，它和虚拟磁盘ramdisk比较类似像，但不完全相同。和ramdisk一样，tmpfs可以使用内存，但它也可以使用swap分区来存储。而且传统的ramdisk是个块设备，要用mkfs格式化才能使用；而tmpfs是一个文件系统，并不是块设备，不需要格式化。tmpfs是最好的基于内存的文件系统。 用一个简单的mount命令就可以创建tmpfs文件系统： mount tmpfs -t tmpfs /data/test -o size=10g 将tmpfs挂载到/data/mfs目录后，往/data/mfs写入的内容都会写到内存里。如果需要重新设置分配的内存大小，可以先umount，再重新挂载： umount /data/mfsmount tmpfs -t tmpfs /data/test -o size=20g 也可以在/etc/fstab里设置。 MooseFS是分布式文件系统，正常情况下文件是写到chunkserver节点的磁盘里。如果想让文件写入内存，可以将tmpfs挂到MooseFS的chunkserver节点的数据目录下： mount tmpfs -t tmpfs /data/mfs -o size=50g 这样以后往MooseFS里写数据就都写到内存里了。 注意： 挂载前应该先关闭MooseFS，挂载后再启动MooseFS。没有启动MooseFS的话执行df -h命令会无响应。 该方法只是用来尝鲜，如果想使用基于内存的分布式文件系统，应该使用类似Alluxio这样的组件。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://linbingdong.com/categories/Linux/"}],"tags":[{"name":"tmpfs","slug":"tmpfs","permalink":"http://linbingdong.com/tags/tmpfs/"}]},{"title":"分布式系统(Distributed System)资料大全","slug":"分布式系统(Distributed System)资料大全","date":"2017-04-09T15:17:43.000Z","updated":"2017-04-09T15:17:43.000Z","comments":true,"path":"2017/04/09/分布式系统(Distributed System)资料大全/","link":"","permalink":"http://linbingdong.com/2017/04/09/分布式系统(Distributed System)资料大全/","excerpt":"分布式系统资料大全，enjoy！","text":"分布式系统资料大全，enjoy！ 《Reconfigurable Distributed Storage for Dynamic Networks》 介绍:这是一篇介绍在动态网络里面实现分布式系统重构的paper.论文的作者(导师)是MIT读博的时候是做分布式系统的研究的,现在在NUS带学生,不仅仅是分布式系统,还有无线网络.如果感兴趣可以去他的主页了解. 《Distributed porgramming liboratory》 介绍:分布式编程实验室,他们发表的很多的paper,其中不仅仅是学术研究,还有一些工业界应用的论文. 《MIT Theory of Distributed Systems》 介绍:麻省理工的分布式系统理论主页,作者南希·林奇在2002年证明了CAP理论,并且著《分布式算法》一书. 《Notes on Distributed Systems for Young Bloods》 介绍:分布式系统搭建初期的一些建议 《Principles of Distributed Computing》 介绍:分布式计算原理课程 《Google’s Globally-Distributed Database》 介绍:Google全球分布式数据介绍,中文版 《The Architecture Of Algolia’s Distributed Search Network》 介绍:Algolia的分布式搜索网络的体系架构介绍 《Build up a High Availability Distributed Key-Value Store》 介绍:构建高可用分布式Key-Value存储系统 《Distributed Search Engine with Nanomsg and Bond》 介绍:Nanomsg和Bond的分布式搜索引擎 《Distributed Processing With MongoDB And Mongothon》 介绍:使用MongoDB和Mongothon进行分布式处理 《Salt: Combining ACID and BASE in a Distributed Database》 介绍:分布式数据库中把ACID与BASE结合使用. 《Makes it easy to understand Paxos for Distributed Systems》 介绍:理解的Paxos的分布式系统,参考阅读:关于Paxos的历史 《There is No Now Problems with simultaneity in distributed systems》 介绍:There is No Now Problems with simultaneity in distributed systems 《Distributed Systems》 介绍:伦敦大学学院分布式系统课程课件. 《Distributed systems for fun and profit》 介绍:分布式系统电子书籍. 《Distributed Systems Spring 2015》 介绍:卡内基梅隆大学春季分布式课程主页 《Distributed Systems: Concepts and Design (5th Edition)》 介绍: 电子书,分布式系统概念与设计(第五版) 《走向分布式》 介绍:这是一位台湾网友 ccshih 的文字，短短的篇幅介绍了分布式系统的若干要点。pdf 《Introduction to Distributed Systems Spring 2013》 介绍:清华大学分布式系统课程主页,里面的schedule栏目有很多宝贵的资源 《Distributed systems》 介绍:免费的在线分布式系统书籍 《Some good resources for learning about distributed computing》 介绍:Quora上面的一篇关于学习分布式计算的资源. 《Spanner: Google’s Globally-Distributed Database》 介绍:这个是第一个全球意义上的分布式数据库，也是Google的作品。其中介绍了很多一致性方面的设计考虑，为了简单的逻辑设计，还采用了原子钟，同样在分布式系统方面具有很强的借鉴意义. 《The Chubby lock service for loosely-coupled distributed systems》 介绍:Google的统面向松散耦合的分布式系统的锁服务,这篇论文详细介绍了Google的分布式锁实现机制Chubby。Chubby是一个基于文件实现的分布式锁，Google的Bigtable、Mapreduce和Spanner服务都是在这个基础上构建的，所以Chubby实际上是Google分布式事务的基础，具有非常高的参考价值。另外，著名的zookeeper就是基于Chubby的开源实现.推荐The google stack,Youtube:The Chubby lock service for loosely-coupled distributed systems 《Sinfonia: a new paradigm for building scalable distributed systems》 介绍:这篇论文是SOSP2007的Best Paper，阐述了一种构建分布式文件系统的范式方法，个人感觉非常有用。淘宝在构建TFS、OceanBase和Tair这些系统时都充分参考了这篇论文. 《Data-Intensive Text Processing with MapReduce》 介绍:Ebook:Data-Intensive Text Processing with MapReduce. 《Design and Implementation of a Query Processor for a Trusted Distributed Data Base Management System》 介绍:Design and Implementation of a Query Processor for a Trusted Distributed Data Base Management System. 《Distributed Query Processing》 介绍:分布式查询入门. 《Distributed Systems and the End of the API》 介绍:分布式系统和api总结. 《Distributed Query Reading》 介绍:分布式系统阅读论文，此外还推荐github上面的一个论文列表The Distributed Reader。 《Replication, atomicity and order in distributed systems》 介绍:Replication, atomicity and order in distributed systems 《MIT course:Distributed Systems》 介绍:2015年MIT分布式系统课程主页，这次用Golang作为授课语言。6.824 Distributed Systems课程主页 《Distributed systems for fun and profit》 介绍:免费分布式系统电子书。 《Ori：A Secure Distributed File System》 介绍:斯坦福开源的分布式文件系统。 《Availability in Globally Distributed Storage Systems》 介绍:Google论文：设计一个高可用的全球分布式存储系统。 《Calvin: Fast Distributed Transactions For Partitioned Database Systems》 介绍:对于分区数据库的分布式事务处理。 《Distributed Systems Building Block: Flake Ids》 介绍:Distributed Systems Building Block: Flake Ids. 《Introduction to Distributed System Design》 介绍:Google Code University课程，如何设计一个分布式系统。 《Sheepdog: Distributed Storage System for KVM》 介绍:KVM的分布式存储系统. 《Readings in Distributed Systems Systems》 介绍:分布式系统课程列表,包括数据库、算法等. 《Tera》 介绍:来自百度的分布式表格系统. 《Distributed systems: for fun and profit》 介绍:分布式系统的在线电子书. 《Distributed Systems Reading List》 介绍:分布式系统资料,此外还推荐Various articles about distributed systems. 《Designs, Lessons and Advice from Building Large Distributed Systems》 介绍:Designs, Lessons and Advice from Building Large Distributed Systems. 《Testing a Distributed System》 介绍:Testing a distributed system can be trying even under the best of circumstances. 《The Google File System》 介绍: 基于普通服务器构建超大规模文件系统的典型案例，主要面向大文件和批处理系统， 设计简单而实用。 GFS是google的重要基础设施， 大数据的基石， 也是Hadoop HDFS的参考对象。 主要技术特点包括： 假设硬件故障是常态（容错能力强）， 64MB大块， 单Master设计，Lease/链式复制， 支持追加写不支持随机写. 《Bigtable: A Distributed Storage System for Structured Data》 介绍:支持PB数据量级的多维非关系型大表， 在google内部应用广泛，大数据的奠基作品之一 ， Hbase就是参考BigTable设计。 Bigtable的主要技术特点包括： 基于GFS实现数据高可靠， 使用非原地更新技术（LSM树）实现数据修改， 通过range分区并实现自动伸缩等.中文版 《PacificA: Replication in Log-Based Distributed Storage Systems》 介绍:面向log-based存储的强一致的主从复制协议， 具有较强实用性。 这篇文章系统地讲述了主从复制系统应该考虑的问题， 能加深对主从强一致复制的理解程度。 技术特点： 支持强一致主从复制协议， 允许多种存储实现， 分布式的故障检测/Lease/集群成员管理方法. 《Object Storage on CRAQ, High-throughput chain replication for read-mostly workloads》 介绍:分布式存储论文:支持强一直的链式复制方法， 支持从多个副本读取数据,实现code. 《Finding a needle in Haystack: Facebook’s photo storage》 介绍:Facebook分布式Blob存储,主要用于存储图片. 主要技术特色:小文件合并成大文件,小文件元数据放在内存因此读写只需一次IO. 《Windows Azure Storage: A Highly Available Cloud Storage Service with Strong Consistency》 介绍: 微软的分布式存储平台, 除了支持类S3对象存储，还支持表格、队列等数据模型. 主要技术特点：采用Stream/Partition两层设计（类似BigTable）;写错（写满）就封存Extent,使得副本字节一致, 简化了选主和恢复操作; 将S3对象存储、表格、队列、块设备等融入到统一的底层存储架构中. 《Paxos Made Live – An Engineering Perspective》 介绍:从工程实现角度说明了Paxo在chubby系统的应用， 是理解Paxo协议及其应用场景的必备论文。 主要技术特点： paxo协议， replicated log， multi-paxo.参考阅读:关于Paxos的历史 《Dynamo: Amazon’s Highly Available Key-Value Store》 介绍:Amazon设计的高可用的kv系统,主要技术特点：综和运用一致性哈希,vector clock,最终一致性构建一个高可用的kv系统， 可应用于amazon购物车场景.新内容来自分布式存储必读论文 《Efficient Replica Maintenance for Distributed Storage Systems》 介绍:分布式存储系统中的副本存储问题. 《PADS: A Policy Architecture for Distributed Storage Systems》 介绍:分布式存储系统架构. 《The Chirp Distributed Filesystem》 介绍:开源分布式文件系统Chirp,对于想深入研究的开发者可以阅读文章的相关Papers. 《Time, Clocks, and the Ordering of Events in a Distributed System》 介绍:经典论文分布式时钟顺序的实现原理. 《Making reliable distributed systems in the presence of sodware errors》 介绍:面向软件错误构建可靠的分布式系统,中文笔记. 《MapReduce: Simplified Data Processing on Large Clusters》 介绍:MapReduce:超大集群的简单数据处理. 《Distributed Computer Systems Engineering》 介绍:麻省理工的分布式计算课程主页,里面的ppt和阅读列表很多干货. 《The Styx Architecture for Distributed Systems》 介绍:分布式系统Styx的架构剖析. 《What are some good resources for learning about distributed computing? Why?》 介绍:Quora上面的一个问答:有哪些关于分布式计算学习的好资源. 《RebornDB: The Next Generation Distributed Key-Value Store》 介绍:下一代分布式k-v存储数据库. 《Operating System Concepts Ninth Edition》 介绍:分布式系统归根结底还是需要操作系统的知识,这是耶鲁大学的操作系统概念书籍首页,里面有提供了第8版的在线电子版和最新的学习操作系统指南,学习分布式最好先学习操作系统. 《The Log: What every software engineer should know about real-time data’s unifying abstraction》 介绍:分布式系统Log剖析,非常的详细与精彩. 中文翻译 | 中文版笔记. 《Operating Systems Study Guide》 介绍:分布式系统基础之操作系统学习指南. 《分布式系统领域经典论文翻译集》 介绍:分布式系统领域经典论文翻译集. 《Maintaining performance in distributed systems》 介绍:分布式系统性能维护. 《Computer Science from the Bottom Up》 介绍:计算机科学，自底向上,小到机器码,大到操作系统内部体系架构,学习操作系统的另一个在线好材料. 《Operating Systems: Three Easy Pieces》 介绍:&lt;操作系统:三部曲&gt;在线电子书,虚拟、并发、持续. 《Database Systems: reading list》 介绍:数据库系统经典论文阅读列,此外推送github上面的db reading. 《Unix System Administration》 介绍:Unix System Administration ebook. 《The Amoeba Distributed Operating System》 介绍:分布式系统经典论文. 《Principles of Computer Systems》 介绍:计算机系统概念，以分布式为主.此外推荐Introduction to Operating Systems笔记 《Person page of EMİN GÜN SİRER》 介绍:推荐康奈尔大学的教授EMİN GÜN SİRER的主页,他的研究项目有分布式,数据存储。例如HyperDex数据库就是他的其中一个项目之一. 《Scalable, Secure, and Highly Available Distributed File Access》 介绍:来自卡内基梅隆如何构建可扩展的、安全、高可用性的分布式文件系统,其他papers. 《Distributed (Deep) Machine Learning Common》 介绍:分布式机器学习常用库. 《The Datacenter as a Computer》 介绍:介绍了如何构建仓储式数据中心,尤其是对于现在的云计算,分布式学习来说很有帮助.本书是Synthesis Lectures on Computer Architecture系列的书籍之一,这套丛书还有 《The Memory System》,《Automatic Parallelization》,《Computer Architecture Techniques for Power Efficiency》,《Performance Analysis and Tuning for General Purpose Graphics Processing Units》,《Introduction to Reconfigurable Supercomputing》,Memory Systems Cache, DRAM, Disk 等 《helsinki:Distributed Systems Course slider》 介绍:来自芬兰赫尔辛基的分布式系统课程课件:什么是分布式,复制,一致性,容错,同步,通信. 《TiDB is a distributed SQL database》 介绍:分布式数据库TiDB,Golang开发. 《S897: Large-Scale Systems》 介绍:课程资料:大规模系统. 《Large-scale L-BFGS using MapReduce》 介绍:使用MapReduce进行大规模分布式集群环境下并行L-BFGS. 《Twitter是如何构建高性能分布式日志的》 介绍:Twitter是如何构建高性能分布式日志的. 《Distributed Systems: When Limping Hardware Is Worse Than Dead Hardware》 介绍:在分布式系统中某个组件彻底死了影响很小，但半死不活（网络/磁盘），对整个系统却是毁灭性的. 《Tera - 高性能、可伸缩的结构化数据库》 介绍:来自百度的分布式数据库. 《SequoiaDB is a distributed document-oriented NoSQL Database》 介绍:SequoiaDB分布式文档数据库开源. 《Readings in distributed systems》 介绍:这个网址里收集了一堆各TOP大学分布式相关的课程. 《Paxos vs Raft》 介绍:这个网站是Raft算法的作者为教授Paxos和Raft算法做的，其中有两个视频链接，分别讲上述两个算法.参考阅读:关于Paxos的历史 《A Scalable Content-Addressable Network》 介绍:A Scalable Content-Addressable Network. 《500 Lines or Less》 介绍:这个项目其实是一本书（ The Architecture of Open Source Applications）的源代码附录，是一堆大牛合写的. 《MIT 6.824 Distributed System》 介绍:这只是一个课程主页，没有上课的视频，但是并不影响你跟着它上课：每一周读两篇课程指定的论文，读完之后看lecture-notes里对该论文内容的讨论，回答里面的问题来加深理解，最后在课程lab里把所看的论文实现。当你把这门课的作业刷完后，你会发现自己实现了一个分布式数据库. 《HDFS-alike in Go》 介绍:使用go开发的分布式文件系统. 《What are some good resources for learning about distributed computing? Why?》 介绍:Quora上关于学习分布式的资源问答. 《SeaweedFS is a simple and highly scalable distributed file system》 介绍:SeaweedFS是使用go开发的分布式文件系统项目,代码简单，逻辑清晰. 《Codis - yet another fast distributed solution for Redis》 介绍:Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别 《Paper: Coordination Avoidance In Distributed Databases By Peter Bailis》 介绍:Coordination Avoidance In Distributed Databases. 《从零开始写分布式数据库》 介绍:本文以TiDB 源码为例. 《what we talk about when we talk about distributed systems》 介绍:分布式系统概念梳理,为分布式系统涉及的主要概念进行了梳理. 《Distributed locks with Redis》 介绍:使用Redis实现分布式锁. 《CS244b: Distributed Systems》 介绍: 斯坦福2014年秋季分布式课程. 《RAMP Made Easy》 介绍: 分布式的“读原子性”. 《Strategies and Principles of Distributed Machine Learning on Big Data》 介绍: 大数据分布式机器学习的策略与原理. 《Distributed Systems: What is the CAP theorem?》 介绍: 分布式CAP法则. 《How should I start to learn distributed storage system as a beginner?》 介绍: 新手如何步入分布式存储系统. 《Cassandra - A Decentralized Structured Storage System》 介绍: 分布式存储系统Cassandra剖析,推荐白皮书Introduction to Apache Cassandra. 《What is the best resource to learn about distributed systems?》 介绍: 分布式系统学习资源. 《What are some high performance TCP hacks?》 介绍: 一些高性能TCP黑客技巧. 《Maintaining performance in distributed systems》 介绍:分布式系统性能提升. 《A simple totally ordered broadcast protocol》 介绍:Benjamin Reed 和 Flavio P.Junqueira 所著论文,对Zab算法进行了介绍,zab算法是Zookeeper保持数据一致性的核心,在国内有很多公司都使用zookeeper做为分布式的解决方案.推荐与此相关的一篇文章ZooKeeper’s atomic broadcast protocol: Theory and practice. 《zFS - A Scalable Distributed File System Using Object Disk》 介绍:可扩展的分布式文件系统ZFS,The Zettabyte File System,End-to-end Data Integrity for File Systems: A ZFS Case Study. 《A Distributed Haskell for the Modern Web》 介绍:分布式Haskell在当前web中的应用. 《Reasoning about Consistency Choices in Distributed Systems》 介绍:POPL2016的论文,关于分布式系统一致性选择的论述,POPL所接受的论文,github上已经有人整理. 《Paxos Made Simple》 介绍:Paxos让分布式更简单.译文.参考阅读:关于Paxos的历史,understanding Paxos part1,Understanding Paxos – Part 2.Quora: What is a simple explanation of the Paxos algorithm?,Tutorial Summary: Paxos Explained from Scratch,Paxos algorithm explained, part 1: The essentials,Paxos algorithm explained, part 2: Insights 《Consensus Protocols: Paxos》 介绍:分布式系统一致性协议:Paxos.参考阅读:关于Paxos的历史 《Consensus on Transaction Commit》 介绍：事务提交的一致性探讨. 《The Part-Time Parliaments》 介绍:在《The Part-Time Parliament》中描述了基本协议的交互过程。在基本协议的基础上完善各种问题得到了最终的议会协议。 为了让人更容易理解《The Part-Time Parliament》中描述的Paxos算法，Lamport在2001发表了《Paxos Made Simple》，以更平直的口头语言描述了Paxos，而没有包含正式的证明和数学术语。《Paxos Made Simple》中，将算法的参与者更细致的划分成了几个角色：Proposer、Acceptor、Learner。另外还有Leader和Client.参考阅读:关于Paxos的历史 《Paxos Made Practical》 介绍:看这篇论文时可以先看看理解Paxos Made Practical. 《PaxosLease: Diskless Paxos for Leases》 介绍：PaxosLease：实现租约的无盘Paxos算法,译文. 《Paxos Made Moderately Complex》 介绍：Paxos算法实现,译文,同时推荐42 Paxos Made Moderately Complex. 《Hadoop Reading List》 介绍：Hadoop学习清单. 《Hadoop Reading List》 介绍：Hadoop学习清单. 《2010 NoSQL Summer Reading List》 介绍：NoSQL知识清单,里面不仅仅包含了数据库阅读清单还包含了分布式系统资料. 《Raft: Understandable Distributed Consensus》 介绍：Raft可视化图帮助理解分布式一致性 《Etcd:Distributed reliable key-value store for the most critical data of a distributed system》 介绍：Etcd分布式Key-Value存储引擎 《Understanding Availability》 介绍：理解peer-to-peer系统中的可用性究竟是指什么.同时推荐基于 Peer-to-Peer 的分布式存储系统的设计 《Process structuring, synchronization, and recovery using atomic actions》 介绍：经典论文 《Programming Languages for Parallel Processing》 介绍：并行处理的编程语音 《Analysis of Six Distributed File Systems》 介绍：此篇论文对HDFS,MooseFS,iRODS,Ceph,GlusterFS,Lustre六个存储系统做了详细分析.如果是自己研发对应的存储系统推荐先阅读此篇论文 《A Survey of Distributed File Systems》 介绍：分布式文件系统综述 《Concepts of Concurrent Programming》 介绍：并行编程的概念,同时推荐卡内基梅隆FTP 《Concurrency Control Performance Modeling:Alternatives and Implications》 介绍：并发控制性能建模：选择与意义 《Distributed Systems - Concepts and Design 5th Edition》 介绍：ebook分布式系统概念与设计 《分布式系统设计的形式方法》 介绍：分布式系统设计的形式方法 《互斥和选举算法》 介绍：互斥和选举算法 《Actors：A model Of Concurrent Cornputation In Distributed Systems》 介绍：经典论文 《Security Engineering: A Guide to Building Dependable Distributed Systems》 介绍：如何构建一个安全可靠的分布式系统,About the Author,Bibliography:文献资料,章节访问把链接最后的01换成01-27即可 《15-712 Advanced and Distributed Operating Systems》 介绍：卡内基梅隆大学的分布式系统博士生课程主页,有很丰富的资料 《Dapper, Google’s Large-Scale Distributed Systems Tracing Infrastructure》 介绍：Dapper，大规模分布式系统的跟踪系统,译文,译文对照 《CS262a: Advanced Topics in Computer Systems》 介绍：伯克利大学计算机系统进阶课程,内容有深度,涵盖分布式,数据库等内容 《Egnyte Architecture: Lessons Learned In Building And Scaling A Multi Petabyte Distributed System》 介绍：PB级分布式系统构建/扩展经验 《CS162: Operating Systems and Systems Programming》 介绍：伯克利大学计算机系统课程:操作系统与系统编程 《MDCC: Multi-Data Center Consistency》 介绍：MDCC主要解决跨数据中心的一致性问题中间件,一种新的协议 《Research at Google:Distributed Systems and Parallel Computing》 介绍：google公开对外发表的分布式系统与并行计算论文 《HDFS Architecture Guide》 介绍：分布式文件系统HDFS架构 《ActorDB distributed SQL database》 介绍：分布式 Key/Value数据库 《An efficient data location protocol for self-organizing storage clusters》 介绍：是著名的Ceph的负载平衡策略，文中提出的几种策略都值得尝试，比较赞的一点是可以对照代码体会和实践,如果你还需要了解可以看看Ceph:一个 Linux PB 级分布式文件系统,除此以外,论文的引用部分也挺值得阅读的,同时推荐Ceph: A Scalable, High-Performance Distributed File System 《A Self-Organizing Storage Cluster for Parallel Data-Intensive Applications》 介绍：Surrento的冷热平衡策略就采用了延迟写技术 《HBA: Distributed Metadata Management for Large Cluster-Based Storage Systems》 介绍：对于分布式存储系统的元数据管理. 《Server-Side I/O Coordination for Parallel File Systems》 介绍：服务器端的I/O协调并行文件系统处理,网络,文件存储等都会涉及到IO操作.不过里面涉及到很多技巧性的思路在实践时需要斟酌 《Distributed File Systems: Concepts and Examples》 介绍：分布式文件系统概念与应用 《CSE 221: Graduate Operating Systems》 介绍：加利福尼亚大学的研究生操作系统课程主页，论文很值得阅读 《S4: Distributed Stream Computing Platform》 介绍：Yahoo出品的流式计算系统，目前最流行的两大流式计算系统之一（另一个是storm），Yahoo的主要广告计算平台 《Pregel: a system for large-scale graph processing》 介绍：Google的大规模图计算系统，相当长一段时间是Google PageRank的主要计算系统，对开源的影响也很大（包括GraphLab和GraphChi） 《GraphLab: A New Framework for Parallel Machine Learning》 介绍：CMU基于图计算的分布式机器学习框架，目前已经成立了专门的商业公司，在分布式机器学习上很有两把刷子，其单机版的GraphChi在百万维度的矩阵分解都只需要2~3分钟； 《F1: A Distributed SQL Database That Scales》 介绍：这篇论文是Google 2013年发表的，介绍了F1的架构思路，13年时就开始支撑Google的AdWords业务，另外两篇介绍文章F1 - The Fault-Tolerant Distributed RDBMS Supporting Google’s Ad Business .Google NewSQL之F1 《Cockroach DB:A Scalable, Survivable, Strongly-Consistent SQL Database》 介绍：CockroachDB ：一个可伸缩的、跨地域复制的，且支持事务的数据存储,InfoQ介绍,Design and Architecture of CockroachDb 《Multi-Paxos: An Implementation and Evaluation》 介绍：Multi-Paxos实现与总结，此外推荐Paxos/Multi-paxos Algorithm,Multi-Paxos Example，地址:ftp://ftp.cs.washington.edu/tr/2009/09/UW-CSE-09-09-02.PDF 《Zab: High-performance broadcast for primary-backup systems》 介绍：一致性协议zab分析 《A Distributed Hash Table》 介绍：分布式哈希算法论文,扩展阅读Introduction to Distributed Hash Tables,Distributed Hash Tables 《Comparing the performance of distributed hash tables under churn》 介绍：分布式hash表性能的Churn问题 《Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web》 介绍：分布式系统的CAP问题,推荐Perspectives on the CAP Theorem.对CAP理论的解析文章,PODC ppt,A plain english introduction to CAP Theorem,IEEE Computer issue on the CAP Theorem 《F2FS: A New File System for Flash Storage》 介绍：闪存存储文件系统F2FS 《Better I/O Through Byte-Addressable, Persistent Memory》 介绍：微软发表的关于i/o访问优化论文 《tmpfs: A Virtual Memory File System》 介绍：虚拟内存文件系统tmpfs 《BTRFS: The Linux B-tree Filesystem》 介绍：Linux B-tree文件系统. 《Akamai technical publication》 介绍：Akamai是全球最大的云计算机平台之一，承载了全球15-30%网络流量,如果你是做CDN或者是云服务,这个里面的论文会给你很有帮助.例如这几天看facebook开源的osquery。找到通过db的方式运维,找到Keeping Track of 70,000+ Servers: The Akamai Query System这篇论文，先看论文领会思想，然后再使用工具osquery实践 《BASE: An Acid Alternative》 介绍：来自eBay 的解决方案,译文Base: 一种Acid的替代方案,应用案例参考保证分布式系统数据一致性的6种方案 《A Note on Distributed Computing》 介绍：Jim Waldo和Sam Kendall等人共同撰写了一篇非常有名的论文“分布式计算备忘录”，这篇论文在Reddit上被人推荐为“每个程序员都应当至少读上两篇”的论文。在这篇论文中，作者表示“忽略本地计算与分布式计算之间的区别是一种危险的思想”，特别指出了Emerald、Argus、DCOM以及CORBA的设计问题。作者将这些设计问题归纳为“三个错误的原则”： “对于某个应用来说，无论它的部署环境如何，总有一种单一的、自然的面向对象设计可以符合其需求。” “故障与性能问题与某个应用的组件实现直接相关，在最初的设计中无需考虑这些问题。” “对象的接口与使用对象的上下文无关”. 《Distributed Systems Papers》 介绍：分布式系统领域经典论文列表. 《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》 介绍：Consistent Hashing算法描述. 《SIGMOD 2016: Accepted Research Papers》 介绍：SIGMOD是世界上最有名的数据库会议之一,最具有权威性,收录论文审核非常严格.2016年的SIGMOD 会议照常进行,上面收录了今年SIGMOD收录的论文,把题目输入google中加上pdf就能找到,很多论文值得阅读,SIGMOD 2015 《Notes on CPSC 465/565: Theory of Distributed Systems》 介绍:耶鲁大学的分布式系统理论课程笔记 《Distributed Operating System Doc PDF》 介绍:分布式系统文档资源（可下载） 《Anatomy of a database system》 介绍:数据库系统剖析，这本书是由伯克利大学的Joseph M. Hellerstein和M. Stonebraker合著的一篇论文.对数据库剖析很有深度.除此以外还有一篇文章Architecture of a Database System。数据库系统架构,厦门大学的数据库实验室教授林子雨组织过翻译-ALL.pdf) 《A Relational Model of Data for Large Shared Data Banks》 介绍:数据库关系模型论文 《RUC Innovative data systems reaserch lab recommand papers》 介绍:中国人民大学数据研究实验室推荐的数据库领域论文 《A Scalable Distributed Information Management System》 介绍:构建可扩展的分布式信息管理系统 《Distributed Systems in Haskell》 介绍:Haskell中的分布式系统开发 《Large-scale cluster management at Google with Borg》 介绍:Google使用Borg进行大规模集群的管理,伯克利大学ppt介绍,中文版 《Lock Free Programming Practice》 介绍:并发编程（Concurrency Programming）资料,主要涵盖lock free数据结构实现、内存回收方法、memory model等备份链接 密码: xc5j 《Distributed Algorithms Lecture Notes for 6.852》 介绍:Nancy Lynch’s的分布式算法研究生课程讲义 《Distributed Algorithms for Topic Models》 介绍:分布式算法主题模型. 《RecSys - ACM Recommender Systems》 介绍:世界上非常有名的推荐系统会议，我比较推荐接收的PAPER 《All Things Distributed》 介绍:推荐一个博客,博主是Amazon CTO Werner Vogels,这是一个关注分布式领域的博客.大部分博文是关于在工业界应用. 《programming, database, distributed system resource list》 介绍:这个Git是由阿里(alibaba)的技术专家何登成维护,主要是分布式数据库. 《Making reliable distributed systems in the presence of sodware errors》 介绍:Erlang的作者Joe Armstrong撰写的论文，面对软件错误构建可靠的分布式系统.中文译版 《CS 525: Advanced Distributed Systems[Spring 2016]》 介绍:伊利诺伊大学的Advanced Distributed Systems 里把各个方向重要papers（updated Spring 2015）列举出来，可以参考一下 《Distributed Algorithms》 介绍:这是一本分布式算法电子书,作者是Jukka Suomela.讲述了多个计算模型,一致性,唯一标示,并发等. 《TinyLFU: A Highly Efficient Cache Admission Policy》 介绍:当时是在阅读如何设计一个缓存系统时看到的，然后通过Google找到了这一篇关于缓存策略的论文，它是LFU的改良版,中文介绍.如果有兴趣可以看看Golang实现版。结合起来可能会帮助你理解 《6.S897: Large-Scale Systems》 介绍:斯坦福大学给研究生开的分布式系统课程。教师是 spark 作者 matei. 能把这些内容真正理解透，分布式系统的功力就很强了。 《学习分布式系统需要怎样的知识？》 介绍:[怎么学系列]学习分布式系统需要怎样的知识？ 《Distributed systems theory for the distributed systems engineer》 介绍:分布式系统工程师的分布式系统理论 《A Distributed Systems Reading List》 介绍:分布式系统论文阅读列表,此外推荐威斯康星大学麦迪逊分校计算机系分布式系统学习推荐阅读列表 《Distributed Systems Reading Group》 介绍:麻省理工大学分布式系统小组，他们会把平时阅读到的优秀论文分享出来。虽然有些论文本页已经收录，但是里面的安排表schedule还是挺赞的 《Scalable Software Architecture》 介绍:分布式系统、可扩展性与系统设计相关报告、论文与网络资源汇总. 《MapReduce&amp;Hadoop resource》 介绍:MapReduce&amp;Hadoop相关论文，涉及分布式系统设计，性能分析，实践，优化等多个方面 《Distributed Systems: Principles and Paradigms(second edtion)》_-_Tannenbaum-distributed_systems_principles_and_paradigms_2nd_edition.pdf) 介绍:分布式系统原理与范型第二版,课后解答 《Distributed Systems Seminar’s reading list for Spring 2017》 介绍:分布式系统研讨会论文阅读列表 《A Critique of the CAP Theorem》 介绍:这是一篇评论CAP定理的论文，学习CAP很有帮助,推荐阅读评论文章“A Critique of the CAP Theorem” 《Evolving Distributed Systems》 介绍:推荐文章《不断演进的分布式系统》. 《Ask HN: Recommendations for a book on Distributed Systems?》 介绍:HN上面关于分布式系统相关领域学习的书籍推荐. 《SeaweedFS:A simple and highly scalable distributed file system》 介绍:Golang开源项目,分布式文件存储系统SeaweedFS 《The Design and Implementation of a Log-Structured File System》 介绍:论文推荐:设计并实现一个日志结构的文件系统. 原文链接：https://raw.githubusercontent.com/ty4z2008/Qix/master/ds.md","raw":null,"content":null,"categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/categories/分布式系统/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"},{"name":"资料大全","slug":"资料大全","permalink":"http://linbingdong.com/tags/资料大全/"}]},{"title":"JVM之Java内存区域与内存溢出异常","slug":"JVM之Java内存区域与内存溢出异常","date":"2017-04-08T13:57:17.000Z","updated":"2017-04-08T13:57:17.000Z","comments":true,"path":"2017/04/08/JVM之Java内存区域与内存溢出异常/","link":"","permalink":"http://linbingdong.com/2017/04/08/JVM之Java内存区域与内存溢出异常/","excerpt":"Java的JVM可以自动管理内存，包括内存动态分配和垃圾收集等。","text":"Java的JVM可以自动管理内存，包括内存动态分配和垃圾收集等。 简介JVM在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着JVM进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 先看看JVM运行时数据区包括哪几个部分： 可以看出JVM运行时数据区包括：堆、虚拟机栈、本地方法栈、方法区、程序计数器和运行时常量池。其中，运行时常量池在方法区里。 接下来对这几个区域一一介绍。 Java堆Java堆（Java Heap）是JVM所管理的内存中最大的一块。 堆的作用是用来存放对象实例，所有的对象实例和数组都在堆上分配内存。 堆也是垃圾收集器管理的主要区域，因此也被称为“GC堆”。因为垃圾收集器主要用来收集对象，对象在堆上分配，所以自然堆是垃圾收集器管理的主要区域。 堆被所有的线程共享，在虚拟机启动时创建，物理上可在不连续的内存空间中，跟磁盘空间一样。 Java堆溢出什么情况下会堆溢出当创建新对象，堆上内存不够时就会产生堆溢出。 只要不断创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么当堆上的内存不够创建新对象时就会产生内存溢出异常。 制造堆溢出/** * -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError */public class HeapOOM &#123; static class OOMObject&#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); long length=0; while (true)&#123; try &#123; list.add(new OOMObject()); length += 1; &#125; catch (Throwable e)&#123; System.out.println(\"number of obj: \"+length); throw e; &#125; &#125; &#125;&#125; 输出： java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid39193.hprof ...Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap spaceHeap dump file created [27917334 bytes in 0.227 secs] at java.util.Arrays.copyOf(Arrays.java:3210)number of obj: 810325 at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at com.lbd.jvm.HeapOOM.main(HeapOOM.java:20) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)Process finished with exit code 1 解决堆溢出重点确认内存中的对象是否是必要的，也就是确认到底是出现了内存泄露（Memory Leak）还是内存溢出（Memory Overflow）。 方法：通过内存映像分析工具（如Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析。 如果是内存泄露： 进一步通过工具查看泄露对象到GC Roots的引用链，这样就能找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的，这样就可以比较准确地定位出泄露代码的位置 如果不是内存泄露： 也就是内存中的对象确实还必须存活这，那就应该检查虚拟机的堆参数（-Xms和-Xmx），看看是否可以调大一些。 方法区方法区与Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息（类的版本、字段、方法、接口等描述信息）、常量、静态变量、即使编译器编译后的代码等数据。 方法区的内存回收主要针对常量池的回收和堆类型的卸载。垃圾收集行为在该区域比较少出现。 在HotSpot虚拟机中，方法区又被称为“永久代”（Permanent Generation），这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，就不用专门为方法区编写内存管理代码了。 方法区溢出如果产生大量的类或者大量的字符串常量（运行时常量池溢出）可能导致方法区溢出。 Java SE API可以动态产生类，如反射时的GeneratedConstructorAccessor和动态代理等。 运行时常量池运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 运行时常量池溢出什么时候会运行时常量池溢出产生大量的字符串常量。 制造运行时常量池溢出注：以下代码只在JDK1.6及之前的版本才会产生运行时常量池溢出异常，因为在这些版本中常量池分配在永久代内，可以通过-XX:PermSize=1M -XX:MaxPermSize=1M来限制方法区的大小，从而间接限制其中常量池的容量。 /** * -XX:PermSize=1M -XX:MaxPermSize=1M */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true)&#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 虚拟机栈虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的时候都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应者一个栈帧在虚拟机栈中入栈到出栈的过程。 虚拟机栈是线程私有的。为Java方法服务。 虚拟机栈中最重要的是局部变量表。局部变量表存放了编译期可知的各种基本数据类型和对象引用类型。是在编译期确定的。 虚拟机栈溢出什么情况下会Java虚拟机栈溢出 如果线程请求的栈深度大于虚拟机所允许的最大深度（一般是递归），将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 制造虚拟机栈溢出（StackOverflowError）递归。因为递归需要用到栈。设置栈容量为256k（-Xss256k）。 /** * -Xss256k */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak()&#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e)&#123; System.out.println(\"stack length:\" + oom.stackLength); throw e; &#125; &#125;&#125; 输出： Exception in thread &quot;main&quot; java.lang.StackOverflowErrorstack length:2789 at com.lbd.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at com.lbd.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at com.lbd.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at com.lbd.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at com.lbd.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) 当调用了2789次后出现了栈溢出StackOverflowError。 制造虚拟机栈溢出（OutOfMemoryError）创建足够多的线程，当扩展栈时无法申请到足够的内存空间，就会抛出OutOfMemoryError异常。 /** * -Xss2M * dangerous,don't run this program! */public class JavaVMStackOOM &#123; private void dontStop() &#123; while (true); &#125; public void stackLeakByThread () &#123; while (true) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; dontStop(); &#125; &#125;); thread.start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125; 本地方法栈本地方法栈与虚拟机栈所发挥的作用很相似。区别在于：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈为虚拟机使用到的Native方法服务。 程序计数器程序计数器用来记录正在执行的虚拟机字节码指令的地址。程序计数器是线程私有的。是唯一一个没有规定任何OutOfMemoryError情况的区域。 因为Java虚拟机的多线程是通过线程轮流切换并分配CPU执行时间的方式来实现的。为了线程切换后能恢复到正确的执行位置，每个线程需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储。 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。 JDK1.4中新加入了NIO(New Input/Ouput)类，引入了一种基于通道（Channel）和缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBufer对象作为这块内存的引用进行操作。","raw":null,"content":null,"categories":[{"name":"JVM","slug":"JVM","permalink":"http://linbingdong.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://linbingdong.com/tags/JVM/"}]},{"title":"CountDownLatch && CyclicBarrier example","slug":"CountDownLatch && CyclicBarrier example","date":"2017-04-04T16:00:00.000Z","updated":"2017-09-03T02:16:14.000Z","comments":true,"path":"2017/04/05/CountDownLatch && CyclicBarrier example/","link":"","permalink":"http://linbingdong.com/2017/04/05/CountDownLatch && CyclicBarrier example/","excerpt":"CountDownLatch &amp;&amp; CyclicBarrier example","text":"CountDownLatch &amp;&amp; CyclicBarrier example CountDownLatchpackage com.lbd.concurrent;import java.util.Random;import java.util.concurrent.*;/** * Created by lbd. */public class CountDownLatchDemo &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); CountDownLatch latch = new CountDownLatch(3); Worker w1 = new Worker(\"worker1\", latch); Worker w2 = new Worker(\"worker2\", latch); Worker w3 = new Worker(\"worker3\", latch); Boss boss = new Boss(latch); executor.execute(w1); executor.execute(w2); executor.execute(w3); executor.execute(boss); executor.shutdown(); &#125;&#125;class Worker implements Runnable &#123; private CountDownLatch downLatch; private String name; public Worker(String name, CountDownLatch downLatch) &#123; this.name = name; this.downLatch = downLatch; &#125; public void run() &#123; System.out.println(this.name + \" is working...\"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(this.name + \" is done!\"); downLatch.countDown(); &#125;&#125;class Boss implements Runnable &#123; private CountDownLatch downLatch; public Boss(CountDownLatch downLatch) &#123; this.downLatch = downLatch; &#125; public void run() &#123; System.out.println(\"boss is waiting for all workers...\"); try &#123; downLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"all work is done! Boss gonna check\"); &#125;&#125; output: worker1 is working...worker2 is working...worker3 is working...boss is waiting for all workers...worker2 is done!worker3 is done!worker1 is done!all work is done! Boss gonna check CyclicBarrierpackage com.lbd.concurrent;import java.util.Random;import java.util.concurrent.*;/** * Created by lbd. */public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); CyclicBarrier barrier = new CyclicBarrier(3); Worker1 w1 = new Worker1(\"worker1\", barrier); Worker1 w2 = new Worker1(\"worker2\", barrier); Worker1 w3 = new Worker1(\"worker3\", barrier); executor.execute(w1); executor.execute(w2); executor.execute(w3); executor.shutdown(); &#125;&#125;class Worker1 implements Runnable &#123; private CyclicBarrier barrier; private String name; public Worker1(String name, CyclicBarrier barrier) &#123; this.barrier = barrier; this.name = name; &#125; @Override public void run() &#123; try &#123; Thread.sleep(new Random().nextInt(10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(barrier.getNumberWaiting() + \" worker arrived\"); System.out.println(this.name + \" arrived\"); try &#123; barrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println(\"all arrived,star working!\"); &#125;&#125; output: 0 worker arrivedworker2 arrived1 worker arrivedworker1 arrived2 worker arrivedworker3 arrivedall arrived,star working!all arrived,star working!all arrived,star working!","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"MooseFS安装配置","slug":"MooseFS安装配置","date":"2017-03-30T09:32:18.000Z","updated":"2017-03-30T09:32:18.000Z","comments":true,"path":"2017/03/30/MooseFS安装配置/","link":"","permalink":"http://linbingdong.com/2017/03/30/MooseFS安装配置/","excerpt":"记录 MooseFS 的部署过程。","text":"记录 MooseFS 的部署过程。 简介MooseFS 是一个分布式文件系统，支持挂载的形式。 主要角色 master 节点：元数据节点，复制调度和管理元数据。 metalogger 节点：用于备份 master 的元数据和日志。 chunkserver 节点：数据节点，数据实际存放的节点。 client ：客户端。通过 FUSE 将 mfs 文件系统挂载到客户端后，客户端可以像使用一个普通的磁盘分区一样来使用 mfs 。 集群规划 mfsmaster mfsmetalogger mfschunkserver mfsclient 192.168.20.96 192.168.20.97 192.168.20.98 192.168.20.99 192.168.20.96 192.168.20.97 192.168.20.98 192.168.20.99 准备工作安装fuse模块确保需要安装 mfsclient 的节点上已经安装了 Linux 内核模块 FUSE 。 若未安装，可通过 yum 或者编译安装的方式进行安装。 创建用户和用户组每个节点都要创建 mfs 用户和用户组。 groupadd mfsuseradd -g mfs mfs 修改/etc/hosts在每个节点上为 mfsmaster 所在节点（192.168.20.96）增加一个别名 mfsmaster 。 修改 /etc/hosts ： 192.168.20.96 mfsmaster 解压rpm包将 mfs.tar.gz 解压到每个节点的 /opt 目录下，解压后会生成 /opt/mfs 目录。 安装配置mfsmaster+cgi节点 192.168.20.96 cd /opt/mfsrpm -ivh moosefs-2.0.77-1.x86_64.rpm moosefs-master-2.0.77-1.x86_64.rpm moosefs-cgi-2.0.77-1.x86_64.rpm moosefs-cgiserv-2.0.77-1.x86_64.rpm mfsmetalogger节点 192.168.20.97 安装： cd /opt/mfsrpm -ivh moosefs-2.0.77-1.x86_64.rpm moosefs-metalogger-2.0.77-1.x86_64.rpm mfschunkserver节点 192.168.20.98 、 192.168.20.99 创建 /mnt/mfs 目录： mkdir -p /mnt/mfschown -R mfs:mfs /mnt/mfs 修改 /etc/mfs/mfshdd.cfg ，在任意位置增加一行: /mnt/mfs 安装： cd /opt/mfsrpm -ivh moosefs-2.0.77-1.x86_64.rpm moosefs-chunkserver-2.0.77-1.x86_64.rpm mfsclient节点 192.168.20.96 、192.168.20.97 、192.168.20.98 、192.168.20.99 创建 /mnt/mfs-cli 目录： mkdir /mnt/mfs-clichown -R mfs:mfs /mnt/mfs-cli/ 安装： rpm -ivh moosefs-client-2.0.77-1.x86_64.rpm 挂载： mfsmount /mnt/mfs-cli/ -H mfsmaster 启动 mfsmaster systemctl start moosefs-master mfscgiserv systemctl start moosefs-cgiserv 启动 mfsmaster 和 mfscgiserv 后，在浏览器中输入 http://192.168.20.96:9425 查看Web 页面 ： mfsmetalogger systemctl start moosefs-metalogger mfschunkserver systemctl start moosefs-chunkserver 使用所有客户端节点 /mnt/mfs-cli 目录下的内容都是相同的。只需把文件放入任意客户端节点的 /mnt/mfs-cli 目录下即可，该目录对所有客户端节点可见。","raw":null,"content":null,"categories":[{"name":"MooseFS","slug":"MooseFS","permalink":"http://linbingdong.com/categories/MooseFS/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"},{"name":"分布式文件系统","slug":"分布式文件系统","permalink":"http://linbingdong.com/tags/分布式文件系统/"},{"name":"MooseFS","slug":"MooseFS","permalink":"http://linbingdong.com/tags/MooseFS/"}]},{"title":"PostgreSQL安装PostGIS插件并使用","slug":"PostgreSQL安装PostGISC插件并使用","date":"2017-03-25T12:15:11.000Z","updated":"2017-03-25T12:15:11.000Z","comments":true,"path":"2017/03/25/PostgreSQL安装PostGISC插件并使用/","link":"","permalink":"http://linbingdong.com/2017/03/25/PostgreSQL安装PostGISC插件并使用/","excerpt":"PostGIS是对象关系型数据库PostgreSQL的一个插件，PostGIS提供如下空间信息服务功能：空间对象、空间索引、空间操作函数和空间操作符。同时，PostGIS遵循OpenGIS的规范。","text":"PostGIS是对象关系型数据库PostgreSQL的一个插件，PostGIS提供如下空间信息服务功能：空间对象、空间索引、空间操作函数和空间操作符。同时，PostGIS遵循OpenGIS的规范。 1. 简介PostGIS是对象关系型数据库PostgreSQL的一个插件，PostGIS提供如下空间信息服务功能：空间对象、空间索引、空间操作函数和空间操作符。同时，PostGIS遵循OpenGIS的规范。 PostGIS支持所有的空间数据类型，这些类型包括：点（POINT）、线（LINESTRING）、多边形（POLYGON）、多点 （MULTIPOINT）、多线（MULTILINESTRING）、多多边形（MULTIPOLYGON）和集合对象集 （GEOMETRYCOLLECTION）等。PostGIS支持所有的对象表达方法，比如WKT和WKB。 PostGIS支持所有的数据存取和构造方法，如GeomFromText()、AsBinary()，以及GeometryN()等。 PostGIS提供简单的空间分析函数（如Area和Length）同时也提供其他一些具有复杂分析功能的函数，比如Distance。 PostGIS提供了对于元数据的支持，如GEOMETRY_COLUMNS和SPATIAL_REF_SYS，同时，PostGIS也提供了相应的支持函数，如AddGeometryColumn和DropGeometryColumn。 PostGIS提供了一系列的二元谓词（如Contains、Within、Overlaps和Touches）用于检测空间对象之间的空间关系，同时返回布尔值来表征对象之间符合这个关系。 PostGIS提供了空间操作符（如Union和Difference）用于空间数据操作。比如，Union操作符融合多边形之间的边界。两个交迭的多边形通过Union运算就会形成一个新的多边形，这个新的多边形的边界为两个多边形中最大边界。 PostGIS还提供以下功能： 数据库坐标变换 数据库中的几何类型可以通过Transform函数从一种投影系变换到另一种投影系中。在OpenGIS中的几何类型都将SRID作为自身结构的一部分，但不知什么原因，在OpenGIS的SFSQL规范中，并没有引入Transform。 球体长度运算 存储在普通地理坐标系中的集合类型如果不进行坐标变换是无法进行程度运算的，OpenGIS所提供的坐标变换使得积累类型的程度计算变成可能。 三维的几何类型 SFSQL规范只是针对二维集合类型。OpenGIS提供了对三维集合类型的支持，具体是利用输入的集合类型维数来决定输出的表现方式。例如，即便 所有几何对象内部都以三维形式存储，纯粹的二维交叉点通常还是以二维的形式返回。此外，还提供几何对象在不同维度间转换的功能。 空间聚集函数 在数据库中，聚集函数是一个执行某一属性列所有数据操作的函数。比如Sum和Average，Sum是求某一关系属性列的数据总和，Average 则是求取某一关系属性列的数据平均值。与此对应，空间聚集函数也是执行相同的操作，不过操作的对象是空间数据。例如聚集函数Extent返回一系列要素中 的最大的包裹矩形框，如“SELECT EXTENT(GEOM) FROM ROADS”这条SQL语句的执行结果是返回ROADS这个数据表中所有的包裹矩形框。 栅格数据类型 PostGIS通过一种新的数据类型片，提供对于大的栅格数据对象的存储。片由以下几个部分组成：包裹矩形框、SRID、类型和一个字节序列。通过 将片的大小控制在数据库页值（32×32）以下，使得快速的随即访问变成可能。一般大的图片也是通过将其切成32×32像素的片然后再存储在数据库中的。 2. 部署2.1 安装PostGIS yum install postgis2_94 # 因为安装的PostgreSQL版本为9.4，所以是postgis2_94 注： 需要PostgreSQL9.1以上版本才支持PostGIS. 2.2 使PostGIS可用想要在PostgreSQL中使用PostGIS插件，安装只是第一步。每个数据库想要使用PostGIS必须先在该数据库中使PostGIS可用。假设我们想在gisdb这个数据库中使用PostGIS,先进入gisdb数据库，执行以下步骤： gisdb=# CREATE EXTENSION postgis;gisdb=# CREATE EXTENSION postgis_topology; 2.3 查看是否安装成功 在gisdb数据库中输入\\du，查看已安装的插件 gisdb=# \\dx 已安装扩展列表 名称 | 版本 | 架构模式 | 描述------------------+-------+------------+--------------------------------------------------------------------- plpgsql | 1.0 | pg_catalog | PL/pgSQL procedural language postgis | 2.1.8 | public | PostGIS geometry, geography, and raster spatial types and functions postgis_topology | 2.1.8 | topology | PostGIS topology spatial types and functions(3 行记录) 可以看到已经安装了postgis和postgis_topology。 3. 使用3.1 创建空间数据表首先建立一个常规的表格存储有关城市（cities）的信息。这个表格有两栏，一个是 ID 编号，一个是城市名： gisdb=# CREATE TABLE cities (id int4, name varchar(50)); 现在添加一个空间列用于存储城市的位置。习惯上这个列叫做 the_geom。它记录了数据为什么类型（点、线、面）、有几维（这里是二维）以及空间坐标系统。此处使用 EPSG:4326 坐标系统： gisdb=# SELECT AddGeometryColumn (&apos;cities&apos;, &apos;the_geom&apos;, 4326, &apos;POINT&apos;, 2); 完成后，查询 cities 表单应当显示这个新栏目。同时页面将显示当前表达没有记录（0 rows）。 gisdb=# select * from cities; id | name | the_geom----+-----------------+----------------------------------------------------（0行记录） 为添加记录，需要使用 SQL 命令。对于空间列，使用 PostGIS 的 ST_GeomFromText可以将文本转化为坐标与参考系号的记录： gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (1,ST_GeomFromText(&apos;POINT(-0.1257 51.508)&apos;,4326),&apos;London, England&apos;);gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (2,ST_GeomFromText(&apos;POINT(-81.233 42.983)&apos;,4326),&apos;London, Ontario&apos;);gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (3,ST_GeomFromText(&apos;POINT(27.91162491 -33.01529)&apos;,4326),&apos;East London,SA&apos;); 当然，这样的输入方式难以操作。其它方式可以更快的输入数据。就目前来说，表格内已经有了一些城市数据，可以先进行查询等操作。 3.2 简单查询标准的 SQL 操作都可以用于 PostGIS 表： gisdb=# SELECT * FROM cities; id | name | the_geom----+-----------------+---------------------------------------------------- 1 | London, England | 0101000020E6100000BBB88D06F016C0BF1B2FDD2406C14940 2 | London, Ontario | 0101000020E6100000F4FDD478E94E54C0E7FBA9F1D27D4540 3 | East London,SA | 0101000020E610000040AB064060E93B4059FAD005F58140C0(3 行记录) 这里的坐标是无法阅读的 16 进制格式。要以 WKT 文本显示，使用 ST_AsText(the_geom) 或ST_AsEwkt(the_geom) 函数。也可以使用 ST_X(the_geom) 和 ST_Y(the_geom) 显示一个维度的坐标： gisdb=# SELECT id, ST_AsText(the_geom), ST_AsEwkt(the_geom), ST_X(the_geom), ST_Y(the_geom) FROM cities; id | st_astext | st_asewkt | st_x | st_y----+------------------------------+----------------------------------------+-------------+----------- 1 | POINT(-0.1257 51.508) | SRID=4326;POINT(-0.1257 51.508) | -0.1257 | 51.508 2 | POINT(-81.233 42.983) | SRID=4326;POINT(-81.233 42.983) | -81.233 | 42.983 3 | POINT(27.91162491 -33.01529) | SRID=4326;POINT(27.91162491 -33.01529) | 27.91162491 | -33.01529(3 行记录) 3.3 空间查询PostGIS 为 PostgreSQL 扩展了许多空间操作功能。以上已经涉及了转换空间坐标格式的 ST_GeomFromText 。多数空间操作以 ST（spatial type）开头，在 PostGIS 文档相应章节有罗列。这里回答一个具体的问题：上面三个城市相互的距离是多少？查询语句怎么写？ gisdb=# SELECT p1.name,p2.name,ST_Distance_Sphere(p1.the_geom,p2.the_geom) FROM cities AS p1, cities AS p2 WHERE p1.id &gt; p2.id; name | name | st_distance_sphere-----------------+-----------------+-------------------- London, Ontario | London, England | 5875787.03777356 East London,SA | London, England | 9789680.59961472 East London,SA | London, Ontario | 13892208.6782928(3 行记录) 输出显示了距离数据。注意 ‘WHERE’ 部分防止了输出城市到自身的距离（0）或者两个城市不同排列的距离数据（London, England 到 London, Ontario 和 London, Ontario 到 London, England 的距离是一样的）。","raw":null,"content":null,"categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/categories/PostgreSQL/"}],"tags":[{"name":"关系数据库","slug":"关系数据库","permalink":"http://linbingdong.com/tags/关系数据库/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/tags/PostgreSQL/"}]},{"title":"复杂链表的复制","slug":"复杂链表的复制","date":"2017-03-23T16:00:00.000Z","updated":"2017-09-03T02:11:33.000Z","comments":true,"path":"2017/03/24/复杂链表的复制/","link":"","permalink":"http://linbingdong.com/2017/03/24/复杂链表的复制/","excerpt":"题目描述\n输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）","text":"题目描述 输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 分析 本题的Node多了一个random指针，比较复杂，可以分三步走： 在原链表中复制节点（在旧链表每个节点后插入一个跟它值相同的节点。如原来是A-&gt;B-C,复制完后是A-&gt;A’-&gt;B-&gt;B’-&gt;C-&gt;C’。复制的节点的random域暂不设置） 设置复制节点的random域（复制节点的random域为原节点的random域的next） 拆分链表（将复制的节点从原链表中拆出来） 代码: /*public class RandomListNode &#123; int label; RandomListNode next = null; RandomListNode random = null; RandomListNode(int label) &#123; this.label = label; &#125;&#125;*/public class Solution &#123; public RandomListNode Clone(RandomListNode pHead) &#123; CloneNodes(pHead); ConnectRandomNodes(pHead); return rebuildNodes(pHead); &#125; public void CloneNodes(RandomListNode pHead) &#123; RandomListNode p = pHead; while (p != null) &#123; RandomListNode q = new RandomListNode(p.label); q.next = p.next; p.next = q; p = q.next; &#125; &#125; public void ConnectRandomNodes(RandomListNode pHead) &#123; RandomListNode p = pHead; while(p != null) &#123; if (p.random != null) p.next.random = p.random.next; p = p.next.next; &#125; &#125; public RandomListNode rebuildNodes(RandomListNode pHead) &#123; RandomListNode p = pHead; RandomListNode q1 = null; RandomListNode q2 = null; if (p != null) &#123; q1 = p.next; q2 = p.next; &#125; while(p != null) &#123; p.next = p.next.next; if(q2.next != null) q2.next = q2.next.next; p = p.next; q2 = q2.next; &#125; return q1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"ZooKeeper原理及其在Hadoop和HBase中的应用","slug":"ZooKeeper原理及其在Hadoop和HBase中的应用","date":"2017-03-23T00:47:28.000Z","updated":"2017-03-23T00:47:28.000Z","comments":true,"path":"2017/03/23/ZooKeeper原理及其在Hadoop和HBase中的应用/","link":"","permalink":"http://linbingdong.com/2017/03/23/ZooKeeper原理及其在Hadoop和HBase中的应用/","excerpt":"ZooKeeper是一个开源的分布式协调服务，由雅虎创建，是Google Chubby的开源实现。分布式应用程序可以基于ZooKeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。","text":"ZooKeeper是一个开源的分布式协调服务，由雅虎创建，是Google Chubby的开源实现。分布式应用程序可以基于ZooKeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。 简介ZooKeeper是一个开源的分布式协调服务，由雅虎创建，是Google Chubby的开源实现。分布式应用程序可以基于ZooKeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。 基本概念本节将介绍ZooKeeper的几个核心概念。这些概念贯穿于之后对ZooKeeper更深入的讲解，因此有必要预先了解这些概念。 集群角色在ZooKeeper中，有三种角色： Leader Follower Observer 一个ZooKeeper集群同一时刻只会有一个Leader，其他都是Follower或Observer。 ZooKeeper配置很简单，每个节点的配置文件(zoo.cfg)都是一样的，只有myid文件不一样。myid的值必须是zoo.cfg中server.{数值}的{数值}部分。 zoo.cfg文件内容示例： maxClientCnxns=0# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.dataDir=/var/lib/zookeeper/data# the port at which the clients will connectclientPort=2181# the directory where the transaction logs are stored.dataLogDir=/var/lib/zookeeper/logsserver.1=192.168.20.101:2888:3888server.2=192.168.20.102:2888:3888server.3=192.168.20.103:2888:3888server.4=192.168.20.104:2888:3888server.5=192.168.20.105:2888:3888minSessionTimeout=4000maxSessionTimeout=100000 在装有ZooKeeper的机器的终端执行 zookeeper-server status 可以看当前节点的ZooKeeper是什么角色（Leader or Follower）。 [root@node-20-103 ~]# zookeeper-server statusJMX enabled by defaultUsing config: /etc/zookeeper/conf/zoo.cfgMode: follower [root@node-20-104 ~]# zookeeper-server statusJMX enabled by defaultUsing config: /etc/zookeeper/conf/zoo.cfgMode: leader 如上，node-20-104是Leader，node-20-103是follower。 ZooKeeper默认只有Leader和Follower两种角色，没有Observer角色。 为了使用Observer模式，在任何想变成Observer的节点的配置文件中加入：peerType=observer并在所有server的配置文件中，配置成observer模式的server的那行配置追加:observer，例如：server.1:localhost:2888:3888:observer ZooKeeper集群的所有机器通过一个Leader选举过程来选定一台被称为『Leader』的机器，Leader服务器为客户端提供读和写服务。 Follower和Observer都能提供读服务，不能提供写服务。两者唯一的区别在于，Observer机器不参与Leader选举过程，也不参与写操作的『过半写成功』策略，因此Observer可以在不影响写性能的情况下提升集群的读性能。 会话（Session）Session是指客户端会话，在讲解客户端会话之前，我们先来了解下客户端连接。在ZooKeeper中，一个客户端连接是指客户端和ZooKeeper服务器之间的TCP长连接。ZooKeeper对外的服务端口默认是2181，客户端启动时，首先会与服务器建立一个TCP连接，从第一次连接建立开始，客户端会话的生命周期也开始了，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向ZooKeeper服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的Watch事件通知。Session的SessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在SessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。 数据节点（ZNode）在谈到分布式的时候，一般『节点』指的是组成集群的每一台机器。而ZooKeeper中的数据节点是指数据模型中的数据单元，称为ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠（/）进行分割的路径，就是一个ZNode，如/hbase/master,其中hbase和master都是ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。 注：这里的ZNode可以理解成既是Unix里的文件，又是Unix里的目录。因为每个ZNode不仅本身可以写数据（相当于Unix里的文件），还可以有下一级文件或目录（相当于Unix里的目录）。 在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。 持久节点 所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在ZooKeeper上。 临时节点 临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。 版本ZooKeeper的每个ZNode上都会存储数据，对应于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和aversion（当前ZNode的ACL版本）。 状态信息每个ZNode除了存储数据内容之外，还存储了ZNode本身的一些状态信息。用 get 命令可以同时获得某个ZNode的内容和状态信息。如下： [zk: localhost:2181(CONNECTED) 23] get /yarn-leader-election/appcluster-yarn/ActiveBreadCrumbappcluster-yarnrm1cZxid = 0x1b00133dc0 //Created ZXID,表示该ZNode被创建时的事务IDctime = Tue Jan 03 15:44:42 CST 2017 //Created Time,表示该ZNode被创建的时间mZxid = 0x1d00000063 //Modified ZXID，表示该ZNode最后一次被更新时的事务IDmtime = Fri Jan 06 08:44:25 CST 2017 //Modified Time，表示该节点最后一次被更新的时间pZxid = 0x1b00133dc0 //表示该节点的子节点列表最后一次被修改时的事务ID。注意，只有子节点列表变更了才会变更pZxid，子节点内容变更不会影响pZxid。cversion = 0 //子节点的版本号dataVersion = 11 //数据节点的版本号aclVersion = 0 //ACL版本号ephemeralOwner = 0x0 //创建该节点的会话的seddionID。如果该节点是持久节点，那么这个属性值为0。dataLength = 22 //数据内容的长度numChildren = 0 //子节点的个数 在ZooKeeper中，version属性是用来实现乐观锁机制中的『写入校验』的（保证分布式数据原子性操作）。 事务操作在ZooKeeper中，能改变ZooKeeper服务器状态的操作称为事务操作。一般包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。 WatcherWatcher（事件监听器），是ZooKeeper中一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去。该机制是ZooKeeper实现分布式协调服务的重要特性。 ACLZooKeeper采用ACL（Access Control Lists）策略来进行权限控制。ZooKeeper定义了如下5种权限。 CREATE: 创建子节点的权限。 READ: 获取节点数据和子节点列表的权限。 WRITE：更新节点数据的权限。 DELETE: 删除子节点的权限。 ADMIN: 设置节点ACL的权限。 注意：CREATE 和 DELETE 都是针对子节点的权限控制。 ZooKeeper典型应用场景ZooKeeper是一个高可用的分布式数据管理与协调框架。基于对ZAB算法的实现，该框架能够很好地保证分布式环境中数据的一致性。也是基于这样的特性，使得ZooKeeper成为了解决分布式一致性问题的利器。 数据发布与订阅（配置中心）数据发布与订阅，即所谓的配置中心，顾名思义就是发布者将数据发布到ZooKeeper节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。 在我们平常的应用系统开发中，经常会碰到这样的需求：系统中需要使用一些通用的配置信息，例如机器列表信息、数据库配置信息等。这些全局配置信息通常具备以下3个特性。 数据量通常比较小。 数据内容在运行时动态变化。 集群中各机器共享，配置一致。 对于这样的全局配置信息就可以发布到ZooKeeper上，让客户端（集群的机器）去订阅该消息。 发布/订阅系统一般有两种设计模式，分别是推（Push）和拉（Pull）模式。 推：服务端主动将数据更新发送给所有订阅的客户端。 拉：客户端主动发起请求来获取最新数据，通常客户端都采用定时轮询拉取的方式。 ZooKeeper采用的是推拉相结合的方式。如下： 客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送Watcher事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。 命名服务(Naming Service)命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架（如RPC、RMI）中的服务地址列表。通过在ZooKeepr里创建顺序节点，能够很容易创建一个全局唯一的路径，这个路径就可以作为一个名字。 ZooKeeper的命名服务即生成全局唯一的ID。 分布式协调/通知ZooKeeper中特有Watcher注册与异步通知机制，能够很好的实现分布式环境下不同机器，甚至不同系统之间的通知与协调，从而实现对数据变更的实时处理。使用方法通常是不同的客户端都对ZK上同一个ZNode进行注册，监听ZNode的变化（包括ZNode本身内容及子节点的），如果ZNode发生了变化，那么所有订阅的客户端都能够接收到相应的Watcher通知，并做出相应的处理。 ZK的分布式协调/通知，是一种通用的分布式系统机器间的通信方式。 心跳检测机器间的心跳检测机制是指在分布式环境中，不同机器（或进程）之间需要检测到彼此是否在正常运行，例如A机器需要知道B机器是否正常运行。在传统的开发中，我们通常是通过主机直接是否可以相互PING通来判断，更复杂一点的话，则会通过在机器之间建立长连接，通过TCP连接固有的心跳检测机制来实现上层机器的心跳检测，这些都是非常常见的心跳检测方法。 下面来看看如何使用ZK来实现分布式机器（进程）间的心跳检测。 基于ZK的临时节点的特性，可以让不同的进程都在ZK的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过ZK上的某个节点进行关联，大大减少了系统耦合。 工作进度汇报在一个常见的任务分发系统中，通常任务被分发到不同的机器上执行后，需要实时地将自己的任务执行进度汇报给分发系统。这个时候就可以通过ZK来实现。在ZK上选择一个节点，每个任务客户端都在这个节点下面创建临时子节点，这样便可以实现两个功能： 通过判断临时节点是否存在来确定任务机器是否存活。 各个任务机器会实时地将自己的任务执行进度写到这个临时节点上去，以便中心系统能够实时地获取到任务的执行进度。 Master选举Master选举可以说是ZooKeeper最典型的应用场景了。比如HDFS中Active NameNode的选举、YARN中Active ResourceManager的选举和HBase中Active HMaster的选举等。 针对Master选举的需求，通常情况下，我们可以选择常见的关系型数据库中的主键特性来实现：希望成为Master的机器都向数据库中插入一条相同主键ID的记录，数据库会帮我们进行主键冲突检查，也就是说，只有一台机器能插入成功——那么，我们就认为向数据库中成功插入数据的客户端机器成为Master。 依靠关系型数据库的主键特性确实能够很好地保证在集群中选举出唯一的一个Master。但是，如果当前选举出的Master挂了，那么该如何处理？谁来告诉我Master挂了呢？显然，关系型数据库无法通知我们这个事件。但是，ZooKeeper可以做到！ 利用ZooKeepr的强一致性，能够很好地保证在分布式高并发情况下节点的创建一定能够保证全局唯一性，即ZooKeeper将会保证客户端无法创建一个已经存在的ZNode。也就是说，如果同时有多个客户端请求创建同一个临时节点，那么最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很容易地在分布式环境中进行Master选举了。 成功创建该节点的客户端所在的机器就成为了Master。同时，其他没有成功创建该节点的客户端，都会在该节点上注册一个子节点变更的Watcher，用于监控当前Master机器是否存活，一旦发现当前的Master挂了，那么其他客户端将会重新进行Master选举。 这样就实现了Master的动态选举。 分布式锁分布式锁是控制分布式系统之间同步访问共享资源的一种方式。 分布式锁又分为排他锁和共享锁两种。 排他锁排他锁（Exclusive Locks，简称X锁），又称为写锁或独占锁。 如果事务T1对数据对象O1加上了排他锁，那么在整个加锁期间，只允许事务T1对O1进行读取和更新操作，其他任何事务都不能在对这个数据对象进行任何类型的操作（不能再对该对象加锁），直到T1释放了排他锁。 可以看出，排他锁的核心是如何保证当前只有一个事务获得锁，并且锁被释放后，所有正在等待获取锁的事务都能够被通知到。 如何利用ZooKeeper实现排他锁？ 定义锁 ZooKeeper上的一个ZNode可以表示一个锁。例如/exclusive_lock/lock节点就可以被定义为一个锁。 获得锁 如上所说，把ZooKeeper上的一个ZNode看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/exclusive_lock节点下创建临时子节点/exclusive_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/exclusive_lock节点上注册一个子节点变更的Watcher监听，以便实时监听到lock节点的变更情况。 释放锁 因为/exclusive_lock/lock是一个临时节点，因此在以下两种情况下，都有可能释放锁。 当前获得锁的客户端机器发生宕机或重启，那么该临时节点就会被删除，释放锁。 正常执行完业务逻辑后，客户端就会主动将自己创建的临时节点删除，释放锁。 无论在什么情况下移除了lock节点，ZooKeeper都会通知所有在/exclusive_lock节点上注册了节点变更Watcher监听的客户端。这些客户端在接收到通知后，再次重新发起分布式锁获取，即重复『获取锁』过程。 共享锁 共享锁（Shared Locks，简称S锁），又称为读锁。如果事务T1对数据对象O1加上了共享锁，那么T1只能对O1进行读操作，其他事务也能同时对O1加共享锁（不能是排他锁），直到O1上的所有共享锁都释放后O1才能被加排他锁。 总结：可以多个事务同时获得一个对象的共享锁（同时读），有共享锁就不能再加排他锁（因为排他锁是写锁） ZooKeeper在大型分布式系统中的应用前面已经介绍了ZooKeeper的典型应用场景。本节将以常见的大数据产品Hadoop和HBase为例来介绍ZooKeeper在其中的应用，帮助大家更好地理解ZooKeeper的分布式应用场景。 ZooKeeper在Hadoop中的应用在Hadoop中，ZooKeeper主要用于实现HA(High Availability），包括HDFS的NamaNode和YARN的ResourceManager的HA。同时，在YARN中，ZooKeepr还用来存储应用的运行状态。HDFS的NamaNode和YARN的ResourceManager利用ZooKeepr实现HA的原理是一样的，所以本节以YARN为例来介绍。 从上图可以看出，YARN主要由ResourceManager（RM）、NodeManager（NM）、ApplicationMaster（AM）和Container四部分组成。其中最核心的就是ResourceManager。 ResourceManager负责集群中所有资源的统一管理和分配，同时接收来自各个节点（NodeManager）的资源汇报信息，并把这些信息按照一定的策略分配给各个应用程序（Application Manager），其内部维护了各个应用程序的ApplicationMaster信息、NodeManager信息以及资源使用信息等。 为了实现HA，必须有多个ResourceManager并存（一般就两个），并且只有一个ResourceManager处于Active状态，其他的则处于Standby状态，当Active节点无法正常工作（如机器宕机或重启）时，处于Standby的就会通过竞争选举产生新的Active节点。 主备切换下面我们就来看看YARN是如何实现多个ResourceManager之间的主备切换的。 创建锁节点在ZooKeeper上会有一个/yarn-leader-election/appcluster-yarn的锁节点，所有的ResourceManager在启动的时候，都会去竞争写一个Lock子节点：/yarn-leader-election/appcluster-yarn/ActiveBreadCrumb，该节点是临时节点。ZooKeepr能够为我们保证最终只有一个ResourceManager能够创建成功。创建成功的那个ResourceManager就切换为Active状态，没有成功的那些ResourceManager则切换为Standby状态。 [zk: localhost:2181(CONNECTED) 16] get /yarn-leader-election/appcluster-yarn/ActiveBreadCrumbappcluster-yarnrm2cZxid = 0x1b00133dc0ctime = Tue Jan 03 15:44:42 CST 2017mZxid = 0x1f00000540mtime = Sat Jan 07 00:50:20 CST 2017pZxid = 0x1b00133dc0cversion = 0dataVersion = 28aclVersion = 0ephemeralOwner = 0x0dataLength = 22numChildren = 0 可以看到此时集群中ResourceManager2为Active。 注册Watcher监听所有Standby状态的ResourceManager都会向/yarn-leader-election/appcluster-yarn/ActiveBreadCrumb节点注册一个节点变更的Watcher监听，利用临时节点的特性，能够快速感知到Active状态的ResourceManager的运行情况。 主备切换当Active状态的ResourceManager出现诸如宕机或重启的异常情况时，其在ZooKeeper上连接的客户端会话就会失效，因此/yarn-leader-election/appcluster-yarn/ActiveBreadCrumb节点就会被删除。此时其余各个Standby状态的ResourceManager就都会接收到来自ZooKeeper服务端的Watcher事件通知，然后会重复进行步骤1的操作。 以上就是利用ZooKeeper来实现ResourceManager的主备切换的过程，实现了ResourceManager的HA。 HDFS中NameNode的HA的实现原理跟YARN中ResourceManager的HA的实现原理相同。其锁节点为/hadoop-ha/mycluster/ActiveBreadCrumb。 ResourceManager状态存储在 ResourceManager 中，RMStateStore 能够存储一些 RM 的内部状态信息，包括 Application 以及它们的 Attempts 信息、Delegation Token 及 Version Information 等。需要注意的是，RMStateStore 中的绝大多数状态信息都是不需要持久化存储的，因为很容易从上下文信息中将其重构出来，如资源的使用情况。在存储的设计方案中，提供了三种可能的实现，分别如下。 基于内存实现，一般是用于日常开发测试。 基于文件系统的实现，如HDFS。 基于ZooKeeper实现。 由于这些状态信息的数据量都不是很大，因此Hadoop官方建议基于ZooKeeper来实现状态信息的存储。在ZooKeepr上，ResourceManager 的状态信息都被存储在/rmstore这个根节点下面。 [zk: localhost:2181(CONNECTED) 28] ls /rmstore/ZKRMStateRoot[RMAppRoot, AMRMTokenSecretManagerRoot, EpochNode, RMDTSecretManagerRoot, RMVersionNode] RMAppRoot 节点下存储的是与各个 Application 相关的信息，RMDTSecretManagerRoot 存储的是与安全相关的 Token 等信息。每个 Active 状态的 ResourceManager 在初始化阶段都会从 ZooKeeper 上读取到这些状态信息，并根据这些状态信息继续进行相应的处理。 小结： ZooKeepr在Hadoop中的应用主要有： HDFS中NameNode的HA和YARN中ResourceManager的HA。 存储RMStateStore状态信息 ZooKeeper在HBase中的应用HBase主要用ZooKeeper来实现HMaster选举与主备切换、系统容错、RootRegion管理、Region状态管理和分布式SplitWAL任务管理等。 HMaster选举与主备切换HMaster选举与主备切换的原理和HDFS中NameNode及YARN中ResourceManager的HA原理相同。 系统容错当HBase启动时，每个RegionServer都会到ZooKeeper的/hbase/rs节点下创建一个信息节点（下文中，我们称该节点为”rs状态节点”），例如/hbase/rs/[Hostname]，同时，HMaster会对这个节点注册监听。当某个 RegionServer 挂掉的时候，ZooKeeper会因为在一段时间内无法接受其心跳（即 Session 失效），而删除掉该 RegionServer 服务器对应的 rs 状态节点。与此同时，HMaster 则会接收到 ZooKeeper 的 NodeDelete 通知，从而感知到某个节点断开，并立即开始容错工作。 HBase为什么不直接让HMaster来负责RegionServer的监控呢？如果HMaster直接通过心跳机制等来管理RegionServer的状态，随着集群越来越大，HMaster的管理负担会越来越重，另外它自身也有挂掉的可能，因此数据还需要持久化。在这种情况下，ZooKeeper就成了理想的选择。 RootRegion管理对应HBase集群来说，数据存储的位置信息是记录在元数据region，也就是RootRegion上的。每次客户端发起新的请求，需要知道数据的位置，就会去查询RootRegion，而RootRegion自身位置则是记录在ZooKeeper上的（默认情况下，是记录在ZooKeeper的/hbase/meta-region-server节点中）。当RootRegion发生变化，比如Region的手工移动、重新负载均衡或RootRegion所在服务器发生了故障等是，就能够通过ZooKeeper来感知到这一变化并做出一系列相应的容灾措施，从而保证客户端总是能够拿到正确的RootRegion信息。 Region管理HBase里的Region会经常发生变更，这些变更的原因来自于系统故障、负载均衡、配置修改、Region分裂与合并等。一旦Region发生移动，它就会经历下线（offline）和重新上线（online）的过程。 在下线期间数据是不能被访问的，并且Region的这个状态变化必须让全局知晓，否则可能会出现事务性的异常。对于大的HBase集群来说，Region的数量可能会多达十万级别，甚至更多，这样规模的Region状态管理交给ZooKeeper来做也是一个很好的选择。 分布式SplitWAL任务管理当某台RegionServer服务器挂掉时，由于总有一部分新写入的数据还没有持久化到HFile中，因此在迁移该RegionServer的服务时，一个重要的工作就是从WAL中恢复这部分还在内存中的数据，而这部分工作最关键的一步就是SplitWAL，即HMaster需要遍历该RegionServer服务器的WAL，并按Region切分成小块移动到新的地址下，并进行日志的回放（replay）。 由于单个RegionServer的日志量相对庞大（可能有上千个Region，上GB的日志），而用户又往往希望系统能够快速完成日志的恢复工作。因此一个可行的方案是将这个处理WAL的任务分给多台RegionServer服务器来共同处理，而这就又需要一个持久化组件来辅助HMaster完成任务的分配。当前的做法是，HMaster会在ZooKeeper上创建一个SplitWAL节点（默认情况下，是/hbase/SplitWAL节点），将“哪个RegionServer处理哪个Region”这样的信息以列表的形式存放到该节点上，然后由各个RegionServer服务器自行到该节点上去领取任务并在任务执行成功或失败后再更新该节点的信息，以通知HMaster继续进行后面的步骤。ZooKeeper在这里担负起了分布式集群中相互通知和信息持久化的角色。 小结： 以上就是一些HBase中依赖ZooKeeper完成分布式协调功能的典型场景。但事实上，HBase对ZooKeepr的依赖还不止这些，比如HMaster还依赖ZooKeeper来完成Table的enable/disable状态记录，以及HBase中几乎所有的元数据存储都是放在ZooKeeper上的。 由于ZooKeeper出色的分布式协调能力及良好的通知机制，HBase在各版本的演进过程中越来越多地增加了ZooKeeper的应用场景，从趋势上来看两者的交集越来越多。HBase中所有对ZooKeeper的操作都封装在了org.apache.hadoop.hbase.zookeeper这个包中，感兴趣的同学可以自行研究。 参考 《从Paxos到Zookeeper》","raw":null,"content":null,"categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://linbingdong.com/categories/ZooKeeper/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://linbingdong.com/tags/ZooKeeper/"}]},{"title":"Python函数式编程","slug":"Python函数式编程","date":"2017-03-15T08:24:20.000Z","updated":"2017-03-15T08:24:20.000Z","comments":true,"path":"2017/03/15/Python函数式编程/","link":"","permalink":"http://linbingdong.com/2017/03/15/Python函数式编程/","excerpt":"虽然 Python 不是函数式编程语言（是命令式编程语言），但是支持许多有价值的函数式编程工具。Python 提供 3 种内建函数和 lambda 表达式等来支持函数式编程。","text":"虽然 Python 不是函数式编程语言（是命令式编程语言），但是支持许多有价值的函数式编程工具。Python 提供 3 种内建函数和 lambda 表达式等来支持函数式编程。 匿名函数Python 允许用 lambda 关键字创造匿名函数。匿名顾名思义就是没有名字，即不需要以标准的方式来声明，比如说，使用 def 加函数名来声明。一个完整的 lambda “语句”代表了一个表达式，这个表达式的定义体必须和声明放在同一行。语法如下： lambda [arg1[, arg2, ... argN]]: expression 参数是可选的，如果使用参数的话，参数通常也会出现在表达式中。 注意：lambda 表达式返回可调用的函数对象。其实 lambda 表达式本身就是一个函数，这个函数定义了输入（冒号左边）和输出（冒号右边），只不过这个函数没有名字，但是我们可以把它赋给一个变量。 比如简单的加法函数。一般我们是这么写的： def add(x, y): return x+y lambda 表达式这么写： lambda x, y : x + y 我们可以把 lambda x, y : x + y 赋值给 f ，然后给 f 传参数： &gt;&gt;&gt; f = lambda x, y : x + y&gt;&gt;&gt; f&lt;function &lt;lambda&gt; at 0x10377f320&gt;&gt;&gt;&gt; f(-10,8)-2&gt;&gt;&gt; f(12, 100)112&gt;&gt;&gt; f(-33, -22)-55 可以看到，f 确实是个函数，可以接收两个参数，并返回这两个参数的和，等价于上面的 add 函数。 高阶函数高阶函数英文叫 Higher-order function 。一般函数的输入参数和返回值都只能是变量或常量，如果某个函数可以接收函数作为其输入参数，或者其返回值中包含函数，那么该函数就是高阶函数。 Python 中有三个内建的用来支持函数式编程的高阶函数，分别是 filter()，map() 和 reduce()。 filter()filter(function, sequence) 返回一个 sequence (序列)，返回的序列中包括了输入序列中所有调用 function(item) 后返回值为 true 的元素。 filter() 工作流程如下图： 举个栗子： &gt;&gt;&gt; def f(x): return x % 3 == 0 or x % 5 == 0...&gt;&gt;&gt; filter(f, range(2, 25))[3, 5, 6, 9, 10, 12, 15, 18, 20, 21, 24] 因为 filter() 的输入参数中包含函数 f() ，所以 filter() 是高阶函数。上面的例子中返回 2~24 中能被 3 或 5 整除的数组成的列表。 当然，也可以使用匿名函数 lambda 表达式实现： &gt;&gt;&gt; filter(lambda x : x % 3 == 0 or x % 5 == 0, range(2, 25))[3, 5, 6, 9, 10, 12, 15, 18, 20, 21, 24] 或者使用列表生成式： &gt;&gt;&gt; [x for x in range(2, 25) if x % 3 == 0 or x % 5 == 0][3, 5, 6, 9, 10, 12, 15, 18, 20, 21, 24] map()map() 与 filter() 相似，因为它也能通过函数来处理序列。map()将函数调用“映射”到序列的每个元素上，并返回一个含有所有返回值的列表。 map() 工作流程如下图： 举个栗子： &gt;&gt;&gt; def cube(x): return x**3...&gt;&gt;&gt; map(cube, range(1,11))[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] 上面的例子中，将 1~10 里的每个数分别调用 cube() ，并将返回值（x 的 3 次方）放入列表中。 lambda 表达式： &gt;&gt;&gt; map(lambda x : x**3, range(1, 11))[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] 列表生成式： &gt;&gt;&gt; [x**3 for x in range(1, 11)][1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] 注意：map() 也可以处理多个序列。 &gt;&gt;&gt; map(lambda x, y: x + y, [1, 3, 5], [2, 4, 6])[3, 7, 11]&gt;&gt;&gt; map(lambda x, y: (x+y, x-y), [1, 3, 5], [2, 4, 6])[(3, -1), (7, -1), (11, -1)]&gt;&gt;&gt; map(None, [1, 3, 5], [2, 4, 6])[(1, 2), (3, 4), (5, 6)] 工作流程如下： reduce()reduce(function, sequence) 返回一个单值，它是这样构造的：首先以序列的前两个元素调用函数 function，再以返回值和第三个参数调用，依次执行下去。 reduce() 工作流程如下： 例如，以下程序计算 0 到 5 的整数之和: &gt;&gt;&gt; def add(x, y): return x+y...&gt;&gt;&gt; reduce(add, range(0, 5))10 实际上 reduce() 执行了如下的运算： ((((0+1)+2)+3)+4) ==&gt; 10 lambda 表达式： reduce(lambda x, y : x + y, range(0, 5)) 偏函数偏函数解决这样的问题：如果我们有函数是多个参数的，我们希望能固定其中某几个参数的值（类似于默认值）。 举个栗子： int() 函数可以把字符串转换为整数，当仅传入字符串时，int() 函数默认按十进制转换： &gt;&gt;&gt; int('11111')11111 但 int() 函数还提供额外的 base 参数（默认值为10） 。如果传入 base 参数，就可以做 N 进制的转换： &gt;&gt;&gt; int('11111',8)4681&gt;&gt;&gt; int('11111',base=16)69905 假设要转换大量的二进制字符串，每次都传入 int(x, base=2) 非常麻烦，于是，我们想到，可以定义一个 int2() 的函数，默认把 base=2 传进去： def int2(x, base=2): return int(x, base) 这样，我们就可以方便地转换二进制了： &gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 functools.partial 就是帮助我们创建一个偏函数的，不需要我们自己定义 int2() ，可以直接使用下面的代码创建一个新的函数 int2 ： &gt;&gt;&gt; import functools&gt;&gt;&gt; int2 = functools.partial(int, base=2)&gt;&gt;&gt; int2('11111')31&gt;&gt;&gt; int2('10000')16 总结一下，functools.partial 的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 需要注意的是，上面的新的 int2 函数，仅仅是把 base 参数重新设定默认值为 2 ，但也可以在函数调用时传入其他值： &gt;&gt;&gt; int2('11111',base=10)11111&gt;&gt;&gt; int2('11111',base=8)4681 参考 《Python核心编程》 Python官方文档 廖雪峰的Python教程","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/tags/Python/"}]},{"title":"Apache Kylin综述","slug":"Apache Kylin综述","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Apache Kylin综述/","link":"","permalink":"http://linbingdong.com/2017/03/11/Apache Kylin综述/","excerpt":"","text":"1. 简介1.1 Kylin概览Apache Kylin是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力（可以把Kylin定义为OLAP on Hadoop）。Apache Kylin于2015年11月正式毕业成为Apache基金会(ASF) 顶级项目，是第一个由中国团队完整贡献到Apache的顶级项目。 Apache Kyiln构建在Hadoop等分布式计算平台之上，充分利用了MapReduce的并行处理能力和可扩展基础设施，高效地处理超大规模数据，可根据数据的规模实现架构的可伸缩。Apache Kylin作为OLAP引擎包含了从数据源（Hive／Kafka等）获取源数据，基于MapReduce构建多维立方体(Cube)，并充分利用HBase的列式特性来分布式的存储立方体数据，提供标准SQL解析与查询优化，以及ODBC／JDBC驱动及REST API等多个模块。可插拔的灵活架构，允许支持更多的数据源接入Kylin，也支持采用其它技术作为存储引擎。 大多数的Hadoop分析工具和SQL是友好的，所以Apache Kylin拥有SQL接口这一点就显得尤为重要。Kylin用的SQL解析器是开源的Apache Calcite，支持几乎所有的SQL标准。Hive用的也是Calcite。 Kylin和其它SQL ON Hadoop的主要区别是预计算（离线计算）。用户在使用之前先选择一个Hive Table的集合，然后在这个基础上做一个离线的Cube构建，Cube构建完了之后就可以做SQL查询了。 用离线计算来代替在线计算，在离线过程当中把复杂的、计算量很大的工作做完，在线计算量就会变小，就可以更快的返回查询结果。通过这种方式，Kylin可以有更少的计算量，更高的吞吐量。 Apache Kylin开源一年左右的时间，已经在国内国际多个公司被采用作为大数据分析平台的关键组成部分，包括eBay、Expedia、Exponential、百度、京东、美团、明略数据、网易、中国移动、唯品会、58同城等。 1.2 Kylin架构 Apache Kylin包含以下核心组件： 元数据引擎：包含模型设计，Cube设计，表结构同步，数据采样分析等。支持层级维度、联合维度、可推导维度等维度降维优化技术，避免Cube数据膨胀。支持多种字典编码算法，实现数据高效压缩存储。 Job引擎：用于向Hadoop平台提交Cube构建任务，支持全表构建、增量构建、流式构建等多种构建机制，支持Cube自动合并等IO优化手段，内置多种Cube预计算算法以及数十个Job性能调优参数，充分发挥MapReduce的计算能力。 存储引擎：将关系型表的源数据，经过预计算，保存在支持高通量大并发快速读写的键值数据库HBase中，充分利用HBase高效的Fuzzy Key过滤技术和Coprocessor并行处理技术，以并行计算方式检索数据，支持查询逻辑下压存储节点，实现了数据检索问题由O(N)的计算复杂度降低为O(1)。 查询引擎：构建在Apache Calcite语法解析器之上，支持JDBC／ODBC／REST等多种协议和接口，支持ANSI SQL，包含绝大多数SQL函数，提供自定义计算函数机制，与Tableau等主流BI工具完美对接。 Web管理端：内置用户友好的交互界面，支持向导式的模型构建，直观的任务监控与告警，以及用户权限管理。 1.3 Kylin特点 可扩展超快OLAP引擎: Kylin是为减少在Hadoop上百亿规模数据查询延迟而设计 Hadoop ANSI SQL 接口: Kylin为Hadoop提供标准SQL支持大部分查询功能 交互式查询能力: 通过Kylin，用户可以与Hadoop数据进行亚秒级交互，在同样的数据集上提供比Hive更好的性能 多维立方体（MOLAP Cube）:用户能够在Kylin里为百亿以上数据集定义数据模型并构建立方体 与BI工具无缝整合:Kylin提供与BI工具，如Tableau，的整合能力，即将提供对其他工具的整合 其他特性: Job管理与监控 压缩与编码 增量更新 利用HBase Coprocessor 基于HyperLogLog的Dinstinc Count近似算法 - 友好的web界面以管理，监控和使用立方体 项目及立方体级别的访问控制安全 支持LDAP 1.4 Kylin生态圈 Kylin 核心: Kylin OLAP引擎基础框架，包括元数据（Metadata）引擎，查询引擎，Job引擎及存储引擎等，同时包括REST服务器以响应客户端请求 扩展: 支持额外功能和特性的插件 整合: 与调度系统，ETL，监控等生命周期管理系统的整合 用户界面: 在Kylin核心之上扩展的第三方用户界面 驱动: ODBC 和 JDBC 驱动以支持不同的工具和产品，比如Tableau 1.5 Kylin在各大公司的实践 Apache Kylin在美团数十亿数据OLAP场景下的实践 Apache Kylin在百度地图的实践 Apache Kylin在京东云海的实践 Apache Kylin 在电信运营商的实践和案例分享 Apache Kylin在国美在线的应用 Apache Kylin在魅族的实践 1.6 Kylin基础概念 星型模型 Cube 在HBase中存储 1.6.1 CUBE Table - 表， 是Cube的数据源；在创建Cube之前，KAP需要从数据源（通常为Hive）同步表的元数据，包含表名、列名、列属性等。 Data Model - 数据模型，定义了由若干张表的一个连接关系。Kylin支持星型模型的多维分析；在创建Cube之前，用户需定义这么一个数据模型（目前Kylin只支持星型模型，未来会支持雪花模型）。 Cube - 数据立方体，是一种多维分析的技术，通过预计算，将计算结果存储在某多个维度值所映射的空间中；在运行时通过对Cube的再处理而快速获取结果。 Partition - 分区，用户可以定义一个分区日期或时间列，随后对Cube的构建按此列的值范围而进行，从而将Cube分成多个Segment。 Cube Segment - 每个Cube Segment是对特定时间范围的数据计算而成的Cube。每个Segment对应一张HBase表。 Aggregation Group - 聚合组，每个聚合组是全部维度的一个子集；通过将很多个维度分组，并把常一起使用的维度放在一起，可以有效降低Cube的组合数。 1.6.2 维度 &amp; 度量 Mandotary - 必需的维度：这种类型用于对Cube生成树做剪枝：如果一个维度被标记为“Mandatory”，会认为所有的查询都会包含此维度，故所有不含此维度的组合，在Cube构建时都会被剪枝（不计算）. Hierarchy - 层级维度：如果多个维度之间有层级（或包含）的关系，通过设置为“Hierarchy”，那些不满足层级的组合会被剪枝。如果A, B, C是层级，并且A&gt;B&gt;C，那么只需要计算组合A, AB, ABC; 其它组合如B, C, BC, AC将不做预计算。 Derived - 衍生维度：维度表的列值，可以从它的主键值衍生而来，那么通过将这些列定义为衍生维度，可以仅将主键加入到Cube的预计算来，而在运行时通过使用维度表的快照，衍生出非PK列的值，从而起到降维的效果。 Count Distinct(HyperLogLog) - 基于HyperLogLog的Count Distint：快速、精确的COUNT DISTINCT是较难计算的, 一个近似的轻量级算法 - HyperLogLog 为此而发明, 能够在大规模数据集上做去重并保持较低的误差率. Count Distinct(Bitmap) - 基于Bitmap的COUNT DISTINCT，可以精确去重，但是存储开销较大。目前只支持int的数据类型. Top N - 预计算最top的某些记录的度量，如交易量最大的1000个卖家。 1.6.3 CUBE 操作 BUILD - 构建：给定一个时间范围，将源数据通过运算而生成一个新的Cube Segment。 REFRESH - 刷新：对某个已经构建过的Cube Segment，重新从数据源抽取数据并构建，从而获得更新。 MERGE - 合并：将多个Cube Segment合并为一个Segment。这个操作可以减少Segment的数量，同时减少Cube的存储空间。 PURGE - 清空：将Cube的所有Cube Segment删除。 1.6.4 JOB状态 NEW - 新任务，刚刚创建。 PENDING - 等待被调度执行的任务. RUNNING - 正在运行的任务。 FINISHED - 正常完成的任务（终态）。 ERROR - 执行出错的任务。 DISCARDED - 丢弃的任务（终态）。 1.6.5 JOB 操作 RESUME - 恢复：处于ERROR状态的任务，用户在排查或解决问题后，通过此操作来重试执行。 DISCARD - 丢弃：放弃此任务，立即停止执行且不会再恢复。 2. 使用2.1 样例数据集二进制包中包含了一份用于测试的样例数据集，总共大小仅1MB左右，共计3张表，其中事实表有10000条数据。 Kylin仅支持星型数据模型，这里用到的样例数据集就是一个规范的星型模型结构，它总共包含了3个数据表： KYLIN_SALES 该表是事实表，保存了销售订单的明细信息。每一列保存了卖家、商品分类、订单金额、商品数量等信息，每一行对应着一笔交易订单。 KYLIN_CATEGORY_GROUPINGS 该表是维表，保存了商品分类的详细介绍，例如商品分类名称等。 KYLIN_CAL_DT 该表是维表，保存了时间的扩展信息。如单个日期所在的年始、月始、周始、年份、月份等。这三张表一起构成了整个星型模型的结构，下图是实例-关系图（图中未列出表上的所有列）： 数据表与关系 表 字段 意义 KYLIN_SALES PART_DT 订单日期 KYLIN_SALES LEAF_CATEG_ID 商品分类ID KYLIN_SALES SELLER_ID 卖家ID KYLIN_SALES PRICE 订单金额 KYLIN_SALES ITEM_COUNT 购买商品个数 KYLIN_SALES LSTG_FORMAT_NAME 订单交易类型 KYLIN_CATEGORY_GROUPINGS USER_DEFINED_FIELD1 用户定义字段1 KYLIN_CATEGORY_GROUPINGS USER_DEFINED_FIELD3 用户定义字段3 KYLIN_CATEGORY_GROUPINGS UPD_DATE 更新日期 KYLIN_CATEGORY_GROUPINGS UPD_USER 更新负责人 KYLIN_CATEGORY_GROUPINGS META_CATEG_NAME 一级分类 KYLIN_CATEGORY_GROUPINGS CATEG_LVL2_NAME 二级分类 KYLIN_CATEGORY_GROUPINGS CATEG_LVL3_NAME 三级分类 KYLIN_CAL_DT CAL_DT 日期 KYLIN_CAL_DT WEEK_BEG_DT 周始日期 2.2 数据导入2.2.1 导入Hive数据源目前，Kylin支持Hive作为默认的输入数据源。为了使用Kylin中自带的样例数据，需要把数据表导入Hive中。在Kylin安装目录的bin文件夹中，有一个可执行脚本，可以把样例数据导入Hive： $KYLIN_HOME/bin/sample.sh 脚本执行成功之后，进入Hive CLI，确认这些数据已经导入成功，命令如下： hivehive&gt; show tables;OKkylin_cal_dtkylin_category_groupingskylin_salesTime taken: 0.127 seconds, Fetched: 3 row(s)hive&gt; select count(*) from kylin_sales;Query ID = root_20160707221515_b040318d-1f08-44ab-b337-d1f858c46d7dTotal jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapreduce.job.reduces=&lt;number&gt;Starting Job = job_1467288198207_0129, Tracking URL = http://sandbox.hortonworks.com:8088/proxy/application_1467288198207_0129/Kill Command = /usr/hdp/2.2.4.2-2/hadoop/bin/hadoop job -kill job_1467288198207_0129Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12016-07-07 22:15:11,897 Stage-1 map = 0%, reduce = 0%2016-07-07 22:15:17,502 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1.64 sec2016-07-07 22:15:25,039 Stage-1 map = 100%, reduce = 100%, Cumulative CPU 3.37 secMapReduce Total cumulative CPU time: 3 seconds 370 msecEnded Job = job_1467288198207_0129MapReduce Jobs Launched:Stage-Stage-1: Map: 1 Reduce: 1 Cumulative CPU: 3.37 sec HDFS Read: 505033 HDFS Write: 6 SUCCESSTotal MapReduce CPU Time Spent: 3 seconds 370 msecOK10000Time taken: 24.966 seconds, Fetched: 1 row(s) 2.2.2 创建项目打开Kylin的Web UI（:7070/kylin），如下图所示的操作创建一个新的项目（Project），并命名为KAP_Sample_1。 在Web UI的左上角选择刚刚创建的项目，表示我们接下来的全部操作都在这个项目中，在当前项目的操作不会对其他项目产生影响。 2.2.3 同步Hive表需要把Hive数据表同步到Kylin当中才能使用。 在弹出的对话框中展开default数据库，并选择需要的三张表，如图所示 导入后系统会自动计算各表各列的维数，以掌握数据的基本情况。稍等几分钟后，我们可以通过数据源表的详情页查看这些信息。 2.3 创建数据模型（model）在数据源就绪的基础之上，我们开始创建数据模型。以Kylin自带的数据集为例，该数据集的数据模型包含1个事实表和2个维表，表间通过外键进行关联。实际上，并不是表上所有的字段都有被分析的需要，因此我们可以有目的地仅选择所需字段添加到数据模型中；然后，根据具体的分析场景，把这些字段设置为维度或度量。 打开Kylin的Web UI，在左上角项目列表中选择刚刚创建的KAP_Sample_1项目，然后进入“模型”页面，并创建一个模型。 第一步，在基本信息页，输入模型名称为Sample_Model_1，然后单击下一步。 第二步，为模型选择事实表（Fact Table）和查找表（Lookup Table）。根据星型模型结构，选择KYLIN_SALES为事实表，然后添加KYLIN_CAL_DT和KYLIN_CATEGORY_GROUPINGS作为查找表，并设置好连接条件： KYLIN_CAL_DT 连接类型：Inner 连接条件： DEFAULT.KYLIN_SALES.PART_DT = DEFAULT.KYLIN_CAL_DT.CAL_DT KYLIN_CATEGORY_GROUPINGS 连接类型：Inner 连接条件： KYLIN_SALES.LEAF_CATEG_ID = KYLIN_CATEGORY_GROUPINGS.LEAF_CATEG_IDKYLIN_SALES.LSTG_SITE_ID = KYLIN_CATEGORY_GROUPINGS.SITE_ID 下图是设置好之后的界面： 第三步，从上一步添加的事实表和查找表中选择需要作为维度的字段。一般的，时间经常用来作为过滤条件，所以我们首先添加时间字段。此外，我们再添加商品分类、卖家ID等字段为维度，具体情况如下图所示： 第四步，根据业务需要，从事实表上选择衡量指标的字段作为度量。例如，PRICE字段用来衡量销售额，ITEM_COUNT字段用来衡量商品销量，SELLER_ID用来衡量卖家的销售能力。最终结果如下图所示： 第五步，设置根据时间分段。一般来说，销售数据都是与日俱增的，每天都会有新数据通过ETL到达Hive中，需要选择增量构建方式构建Cube，所以需要选择用于分段的时间字段DEFAULT.KYLIN_SALES.PART_DT。根据样例数据可以看到，这一列时间的格式是yyyy-MM-dd，所以选择对应的日期格式。此外，我们既不需要设置单独的分区时间列，也不需要添加固定的过滤条件。设置效果如下图所示。 最终，单击“保存”按钮，到此数据模型就创建成功了。 2.4 创建Cube在创建好数据模型的基础上，我们还需要根据查询需求定义度量的预计算类型、维度的组合等，这个过程就是Cube设计的过程。本文将以Kylin自带的样例数据为例，介绍Cube的创建过程。 打开Kylin的Web UI，首先选择KAP_Sample_1项目，跳转到模型页面，然后按照下图所示创建一个Cube。 第一步，在“模型名称”中选择Sample_Model_1，输入新建Cube的名称Sample_Cube_1，其余字段保持默认，然后单击“下一步”。 第二步，从数据模型的维度中选择一些列作为Cube的维度。这里的设置会影响到生成的Cuboid数量，进而影响Cube的数据量大小。 在KYLIN_CATEGORY_GROUPINGS表里，和商品分类相关的三个字段（META_CATEG_NAME、CATEG_LVL2_NAME、CATEG_LVL3_NAME）都可能出现在过滤条件中，我们先把他们添加为普通类型维度。因为从查询表上添加普通维度不能通过自动生成器（Auto Generator）生成，因此采用手动添加方式，过程如下： 单击“添加维度”按钮，然后选择“普通维度”。 针对每一个维度字段，首先在Name输入框中输入维度名称，在Table Name中选择KYLIN_CATEGORY_GROUPINGS表，然后在Column Name中选择相应的列名。 此外，在查询中还经常把时间作为过滤或聚合的条件，如按周过滤、按周聚合等。这里我们以按周为例，需要用到KYLIN_CAL_DT中的WEEK_BEG_DT字段，但是该字段实际上可以由PART_DT字段决定，即根据每一个PART_DT值可以对应出一个WEEK_BEG_DT字段，因此，我们添加WEEK_BEG_DT字段为可推倒维度。 同样的，KYLIN_CATEGORY_GROUPINGS表中还有一些可作为可推到维度的字段，如USER_DEFINED_FIELD1、USER_DEFINED_FIELD3、UPD_DATE、UPD_USER等。 在事实表上，表征交易类型的LSTG_FORMAT_NAME字段也会用于过滤或聚合条件，因此，我们再添加LSTG_FORMAT_NAME字段作为普通维度。 最终，维度的设置结果如下图所示： 第三步，根据数据分析中的聚合需求，我们需要为Cube定义度量的聚合形式。默认的，根据数据类型，系统会自动创建好一些COUNT()聚合和SUM()聚合，用于考量交易订单的数量或者卖出商品的总量。默认建好的聚合仍然可以手动修改或删除。在这个案例中，我们还需要通过PRICE的不同聚合形式考量销售额，如总销售额为SUM(PRICE)、最高订单金额为MAX(PRICE)、最低订单金额为MIN(PRICE)。因此，我们手动创建三个度量，分别选择聚合表达式为SUM、MIN、MAX，并选择PRICE列作为目标列。 其次，我们还需要通过COUNT(DISTINCT SELLER_ID)考量卖家个数。根据前面章节的介绍，Kylin默认使用HyperLogLog算法进行COUNT_DISTINCT的计算，该算法是个近似算法，在创建度量时需要选择一个近似度，本案例对精确性要求不高，为了提升查询性能，我们选择精度较低的“Error Rate &lt; 9.75%”。同样的，我们再创建一个COUNT(DISTINCT LSTG_FORMAT_NAME)的度量考量不同条件下的交易类型。 在销售业务分析的场景中，往往需要挑选出销售业绩最好的商家，这时候就需要TOP-N的度量了。在这个例子中，我们会选出SUM(PRICE)最高的一些SELLER_ID，实际上就是执行如下的SQL语句： SELECT SELLER_ID, SUM(PRICE) FROM KYLIN_SALES GROUP BY SELLER_ID ORDER BY SUM(PRICE) 因此，我们创建一个TOP-N的度量，选择PRICE字段作为SUM/OPDER BY字段，选择SELLER_ID字段作为GROUP BY字段，并选择TOPN(100)作为度量的精度。 最终添加的度量如下图所示： 第四步，我们对Cube的构建和维护进行配置。一般的，一个销售统计的SQL查询往往会按月、周进行过滤和聚合，所以我们可以设置Cube自动按周、月进行自动合并，即每7天进行一次合并，每4周（28天）进行一次合并，设置“触发自动合并的时间阈值”如下所示： 因为存在对于历史订单的查询需求，我们在此不对Cube做自动清理，所以需要设置“保留时间阈值”为0。 在创建数据模型的时候我们提到，我们希望采用增量构建方式对Cube进行构建，并选择了PART_DT字段作为分区时间列。在创建Cube时，我们需要指定Cube构建的起始时间，在这个例子中，根据样例数据中的时间条件，我们选择2012-01-01 00:00:00作为分区起始时间。 第五步，通过对Cube进行高级设置优化Cube的存储大小和查询速度，主要包括聚合组和Rowkey。在前文我们提到，添加聚合组可以利用字段间的层级关系和包含关系有效地降低Cuboid的数量。在这个案例当中，与商品分类相关的三个字段（META_CATEG_NAME、CATEG_LVL2_NAME、CATEG_LVL3_NAME）实际上具有层级关系，如一级类别（META_CATEG_NAME）包含多个二级类别（CATEG_LVL2_NAME），二级类别又包含多个三级类别（CATEG_LVL3_NAME），所以，我们可以为它们创建层级结构的组合（Hierarchy Dimensions）。最终，聚合组的设计如下图所示： 由于参与Cuboid生成的维度都会作为Rowkey，因此我们需要把这些列添加为Rowkey当中。在这个案例中，总共需要添加7个Rowkey。在每个Rowkey上，还需要为列值设置编码方法。在这个案例中，我们除了把LSTG_FORMAT_NAME设置为fixed_length类型（长度为12）外，将其余的Rowkey都设置为dict编码。 Rowkey的顺序对于查询性能来说至关重要，如第六章所讲，一般把最经常出现在过滤条件中的列放置在Rowkey的前面，在这个案例中，我们首先把PART_DT放在Rowkey的第一位。接下来，按照层级把商品分类的字段跟随其后。最终，Rowkey的设置如下图所示： 对Plus版本：Raw Table是Plus版本的特有功能。如果启用，Kylin将在构建Cube之外也保存所有的原始记录，支持高速的明细查询。Raw Table还处于beta测试阶段，仅支持最简单的启用或者不启用。其他的Raw Table配置参数暂时不起作用。 第六步，设置Cube的配置覆盖。在这里添加的配置项可以在Cube级别覆盖从kylin.properties配置文件读取出来的全局配置。在这个案例中，我们可以直接采用默认配置，在此不做任何修改。 ​第七步，对Cube的信息进行概览。请读者仔细确认这些基本信息，包括数据模型名称、事实表以及维度和度量个数。确认无误后单击“保存”按钮，并在弹出的确认提示框中选择“Yes”。 ​最终，Cube的创建就完成了。我们可以刷新Model页面，在Cube列表中就可以看到新创建的Cube了。因为新创建的Cube没有被构建过，是不能被查询的，所以状态仍然是“禁用”。 2.5 构建Cube在创建好Cube之后，只有对Cube进行构建，才能利用它执行SQL查询。本文以Kylin样例数据为例，介绍Cube构建的过程。 初次构建 首先打开Kylin的Web UI，并选择Kylin_Sample_1项目，然后跳转到模型页面，找到Cube列表。 第一步，在Cube列表中找到Kylin_Sample_Cube_1。单击右侧的Action按钮，在弹出的菜单中选择“构建”。 第二步，在弹出的Cube构建确认对话框中确认Cube的分段时间列（Partition Date Column）是DEFAULT.KYLIN_SALES.PART_DT，以及起始时间是2012-01-01 00:00:00。在KAP中，一次构建会为Cube产生一个新的Segment，每次的SQL查询都会访问一个或多个符合条件的Segment；我们需要尽可能地让一个Segment更好地适用于查询条件，因此我们可以按年构建，即每个年份构建一个Segment。在这个例子中，我们输入结束日期（End Date）为2013-01-01 00:00:00。设置完成后单击Submit按钮。 注意：增量构建是具体按年构建还是按月构建应该根据实际的业务需求、ETL时效及数据量大小而定。如果一次构建的数据量过大，可能导致构建时间过长，或出现内存溢出等异常。在当前的样例数据中，数据量较小，按年构建是可以顺利完成的。 当任务成功提交之后，切换到Monitor页面，这里会列出所有的任务列表。我们找到列表最上面的一个任务（名称是：Kylin_Sample_Cube_1 - 20120101000000_20130101000000），这就是我们刚刚提交的任务。在这一行双击或单击右侧的箭头图标，页面右侧会显示当前任务的详细信息。 待构建任务完成，可以在Monitor页面看到该任务状态已被置为完成（Finished）。这时候，第一个Segment就构建完成了。前往Cube列表中查看，会发现该Cube的状态已被置为“就绪（Ready）”了。 增量构建 在第一个Segment构建完成之后，我们开始构建第二个Segment。首先在Model页面的Cube列表中找到该Cube，单击右侧的Actions按钮，然后选择“Build”，打开Cube构建确认对话框。 在这个对话框中，首先确认起始时间（Start Date）是2013-01-01 00:00:00，因为这是上次构建的结束日期，为保障所构建数据的连续性，Apache Kylin自动为新一次构建的起始时间更新为上次构建的结束日期。同样的，在结束时间（End Date）里输入2014-01-01 00:00:00，然后单击Submit按钮，开始构建下一年的Segment。 待构建完成，我们可以在Cube的详情页中查看，发现Cube的两个Segment都已就绪。 3. 参考资料 http://kylin.apache.org/cn/ https://kyligence.gitbooks.io/kap-manual/content/zh-cn/introduction/concepts.cn.html http://webdataanalysis.net/web-data-warehouse/multidimensional-data-model/ http://www.cnblogs.com/mq0036/p/4155832.html","raw":null,"content":null,"categories":[{"name":"Kylin","slug":"Kylin","permalink":"http://linbingdong.com/categories/Kylin/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"Kylin","slug":"Kylin","permalink":"http://linbingdong.com/tags/Kylin/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"}]},{"title":"LeetCode[102] Binary Tree Level Order Traversal","slug":"LeetCode[102] Binary Tree Level Order Traversal","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[102] Binary Tree Level Order Traversal/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[102] Binary Tree Level Order Traversal/","excerpt":"Given a binary tree, return the level order traversal of its nodes’ values. (ie, from left to right, level by level).","text":"Given a binary tree, return the level order traversal of its nodes’ values. (ie, from left to right, level by level). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \\9 20 / \\ 15 7 return its level order traversal as: [ [3], [9,20], [15,7]] 分析: 使用队列。每出来一个将它的左右子节点依次加入。 代码: public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;List&lt;Integer&gt;&gt;(); if (root == null) return result; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); TreeNode n = root; q.offer(n); while(!q.isEmpty()) &#123; List&lt;Integer&gt; levelList = new ArrayList&lt;Integer&gt;(); int num = q.size(); for (int i = 0; i &lt; num; i++) &#123; TreeNode temp = q.poll(); levelList.add(temp.val); if (temp.left != null) q.offer(temp.left); if (temp.right != null) q.offer(temp.right); &#125; result.add(levelList); &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Hive安装配置文档（含Hive Metastore三种配置方式详解）","slug":"Hive安装配置文档","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Hive安装配置文档/","link":"","permalink":"http://linbingdong.com/2017/03/11/Hive安装配置文档/","excerpt":"本文介绍Hive安装配置的整个过程，包括MySQL、Hive及Metastore的安装配置，并分析了Metastore三种配置方式的区别。","text":"本文介绍Hive安装配置的整个过程，包括MySQL、Hive及Metastore的安装配置，并分析了Metastore三种配置方式的区别。 网上有很多介绍Hive Metastore三种配置方式的文章，但是理解都不对，给读者造成了很多误导。本人详细阅读Apache和CDH官方文档中关于Hive Metastore的部分，并经过实践，终于填好各种坑，安装配置成功，遂记录下本文，供大家参考。 1. 相关概念Hive Metastore有三种配置方式，分别是： Embedded Metastore Database (Derby) 内嵌模式 Local Metastore Server 本地元存储 Remote Metastore Server 远程元存储 Metadata、Metastore作用 metadata即元数据。元数据包含用Hive创建的database、tabel等的元信息。元数据存储在关系型数据库中。如Derby、MySQL等。 Metastore的作用是：客户端连接metastore服务，metastore再去连接MySQL数据库来存取元数据。有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可。 三种配置方式区别 内嵌模式使用的是内嵌的Derby数据库来存储元数据，也不需要额外起Metastore服务。这个是默认的，配置简单，但是一次只能一个客户端连接，适用于用来实验，不适用于生产环境。 本地元存储和远程元存储都采用外部数据库来存储元数据，目前支持的数据库有：MySQL、Postgres、Oracle、MS SQL Server.在这里我们使用MySQL。 本地元存储和远程元存储的区别是：本地元存储不需要单独起metastore服务，用的是跟hive在同一个进程里的metastore服务。远程元存储需要单独起metastore服务，然后每个客户端都在配置文件里配置连接到该metastore服务。远程元存储的metastore服务和hive运行在不同的进程里。 在生产环境中，建议用远程元存储来配置Hive Metastore。 集群规划本教程Hadoop相关软件全部基于CDH5.5.1，用yum安装，系统环境如下： 操作系统：CentOS 7.2 Hadoop 2.6.0 Hive1.1.0 Spark1.5.0 MySQL 5.6 JDK 1.8 Maven 3.3.3 Scala 2.10 各节点规划如下： 192.168.117.51 Goblin01 nn1 jn1 rm1 worker master hive metastore mysql192.168.117.52 Goblin02 zk2 nn2 jn2 rm2 worker hive metastore192.168.117.53 Goblin03 zk3 dn1 jn3 worker hive192.168.117.54 Goblin04 zk4 dn2 worker hive 说明：Goblin01~04是每台机器的hostname，zk代表zookeeper，nn代表hadoop的namenode，dn代表datanode，jn代表journalnode，rm代表resourcemanager，worker代表Spark的slaves，master代表Spark的master 如果不需要Hive on Spark，只需要Hive on MR，则不需要安装Spark、Maven和Scala。 我们把metastore服务和MySQL都装在51上（装在哪一台都可以），51-54都安装Hive，这样多个客户端可以同时执行Hive命令。 在执行以下步骤之前，请确保已经安装了Hadoop集群 安装MySQL 下载mysql的repo源 $ wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm 安装mysql-community-release-el7-5.noarch.rpm包 $ sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm 安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo。 安装mysql $ sudo yum install mysql-server 配置MySQL和metastoreStep 1: Install and start MySQL if you have notalready done so $ sudo yum install mysql-server$ sudo service mysqld start Step 2: Configure the MySQL Service and Connector 因为使用MySQL作为存储元数据的数据库，所以需要把连接MySQL的jar包放入或链接到$HIVE_HOME/lib目录下。 $ sudo yum install mysql-connector-java$ ln -s /usr/share/java/mysql-connector-java.jar /usr/lib/hive/lib/mysql-connector-java.jar To set the MySQL root password: $ sudo /usr/bin/mysql_secure_installation[...]Enter current password for root (enter for none):OK, successfully used password, moving on...[...]Set root password? [Y/n] yNew password:Re-enter new password:Remove anonymous users? [Y/n] Y[...]Disallow root login remotely? [Y/n] N[...]Remove test database and access to it [Y/n] Y[...]Reload privilege tables now? [Y/n] YAll done! To make sure the MySQL server starts at boot: $ sudo /sbin/chkconfig mysqld on$ sudo /sbin/chkconfig --list mysqldmysqld 0:off 1:off 2:on 3:on 4:on 5:on 6:off Step 3. Create the Database and User $ mysql -u root -pEnter password:mysql&gt; CREATE DATABASE metastore;mysql&gt; USE metastore;mysql&gt; SOURCE /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-0.12.0.mysql.sql;mysql&gt; CREATE USER &apos;hive&apos;@&apos;metastorehost&apos; IDENTIFIED BY &apos;mypassword&apos;;...mysql&gt; REVOKE ALL PRIVILEGES, GRANT OPTION FROM &apos;hive&apos;@&apos;metastorehost&apos;;mysql&gt; GRANT ALL ON metastore.* TO &apos;hive&apos;@&apos;metastorehost&apos; IDENTIFIED BY &apos;hive&apos;;mysql&gt; GRANT ALL ON metastore.* TO &apos;hive&apos;@&apos;%&apos; IDENTIFIED BY &apos;hive&apos;;mysql&gt; FLUSH PRIVILEGES;mysql&gt; ALTER DATABASE metastore CHARACTER SET latin1;mysql&gt; quit; Step 4. Format the Database $ cd /usr/lib/hive/bin$ ./schematool --dbType mysql --initSchema Hive配置HDFS存储位置配置Hive配置文件里要用到HDFS的一些路径，需要先手动创建。 hdfs dfs -mkdir -p /usr/hive/warehousehdfs dfs -mkdir -p /usr/hive/tmphdfs dfs -mkdir -p /usr/hive/loghdfs dfs -chmod g+w /usr/hive/warehousehdfs dfs -chmod g+w /usr/hive/tmphdfs dfs -chmod g+w /usr/hive/log 上述语句涉及hive-site.xml hive.metastore.warehouse.dir等，表示数据在hdfs中的存储位置 hive-env.sh (所有节点）export HADOOP_HOME=/usr/lib/hadoopexport HIVE_CONF_DIR=/usr/lib/hive/conf hive-log4j.properties（所有节点）首先创建log存放的文件夹 mkdir /usr/lib/hive/logs 然后配置hive-log4j.properties hive.log.dir=/usr/lib/hive/logs 服务端hive-site.xml服务端指的是Metastore服务所在的机器，即安装metastore的机器，这里是51和52。 &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://Goblin01:3306/metastore?createDatabaseIfNotExist=true&lt;/value&gt; &lt;description&gt;the URL of the MySQL database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/usr/hive/warehouse&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hive.exec.scratchdir&lt;/name&gt;&lt;value&gt;/usr/hive/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hive.querylog.location&lt;/name&gt;&lt;value&gt;/usr/hive/log&lt;/value&gt;&lt;/property&gt; 客户端hive-site.xml这里指的是53和54。 &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://Goblin01:9083,Goblin02:9083&lt;/value&gt; &lt;description&gt;IP address (or fully-qualified domain name) and port of the metastore host&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/usr/hive/warehouse&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.exec.scratchdir&lt;/name&gt; &lt;value&gt;/usr/hive/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/usr/hive/log&lt;/value&gt;&lt;/property&gt; 启动Hive 启动MySQL $ service mysqld start 启动metastore服务 $ service hive-metastore start 启动Hive CLI 因为在4台机器上都安装了hive，并且作了相关的配置，所有四台机器均可以启动Hive CLI（Hive交互式shell） $ hive 参考资料 https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin#AdminManualMetastoreAdmin-RemoteMetastoreDatabase http://www.cloudera.com/documentation/archive/cdh/4-x/4-2-0/CDH4-Installation-Guide/cdh4ig_topic_18_4.html \u0003\u0001","raw":null,"content":null,"categories":[{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/categories/Hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/tags/Hive/"}]},{"title":"LeetCode[136] Single Number","slug":"LeetCode[136] Single Number","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[136] Single Number/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[136] Single Number/","excerpt":"Given an array of integers, every element appears twice except for one. Find that single one.\nNote:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n思路:\n直接用异或搞定，简单粗暴效率高。\n代码:","text":"Given an array of integers, every element appears twice except for one. Find that single one. Note:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? 思路: 直接用异或搞定，简单粗暴效率高。 代码: public class Solution &#123; public int singleNumber(int[] nums) &#123; int result = 0; for(int i = 0;i &lt; nums.length;i++) result ^= nums[i]; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[137] Single Number II","slug":"LeetCode[137] Single Number II","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[137] Single Number II/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[137] Single Number II/","excerpt":"Given an array of integers, every element appears three times except for one. Find that single one.\nNote:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n思路:\n创建一个sizeof(int)长度的数组，count[sizeof(int)],count[i]表示在i位出现的1的次数。如果count[i]是3的倍数，则忽略；否则取出来组成result。\n代码:","text":"Given an array of integers, every element appears three times except for one. Find that single one. Note:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? 思路: 创建一个sizeof(int)长度的数组，count[sizeof(int)],count[i]表示在i位出现的1的次数。如果count[i]是3的倍数，则忽略；否则取出来组成result。 代码: public class Solution &#123; public int singleNumber(int[] nums) &#123; final int W = Integer.SIZE; int[] count = new int[W]; for (int i = 0; i &lt; nums.length; i++)&#123; for (int j = 0; j &lt; W; j++)&#123; count[j] += (nums[i] &gt;&gt; j) &amp; 1; &#125; &#125; int result = 0; for (int i = 0; i &lt; W; i++)&#123; count[i] %= 3; result += count[i] &lt;&lt; i; &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[144] Binary Tree Preorder Traversal","slug":"LeetCode[144] Binary Tree Preorder Traversal","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[144] Binary Tree Preorder Traversal/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[144] Binary Tree Preorder Traversal/","excerpt":"Given a binary tree, return the preorder traversal of its nodes’ values.","text":"Given a binary tree, return the preorder traversal of its nodes’ values. For example:Given binary tree {1,#,2,3}, 1 \\ 2 /3 return [1,2,3]. 分析: 两种种方法： 递归法 递归是最简单的。 迭代法 迭代法使用一个栈来保存每个节点的右节点。列表 result 用来保存最后的结果。每次将节点值放入 relust 列表中，并将其右节点入栈，然后令该节点等于它的左节点，如果左节点为空，就令该节点等于栈顶元素，并让栈顶元素出栈。当节点为 null 时结束。 代码: 递归法： /** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */public class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if(root != null) &#123; result.add(root.val); result.addAll(preorderTraversal(root.left)); result.addAll(preorderTraversal(root.right)); &#125; return result; &#125;&#125; 迭代法： public class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; rightNodes = new Stack&lt;TreeNode&gt;(); TreeNode n = root; while (n != null) &#123; result.add(n.val); if (n.right != null) &#123; rightNodes.push(n.right); &#125; n = n.left; if (n == null &amp;&amp; !rightNodes.empty()) &#123; n = rightNodes.pop(); &#125; &#125; return result; &#125;&#125; or public class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if (root == null) return result; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode n = root; stack.push(n); while (!stack.empty()) &#123; n = stack.pop(); result.add(n.val); if (n.right != null) stack.push(n.right); if (n.left != null) stack.push(n.left); &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[145] Binary Tree Postorder Traversal","slug":"LeetCode[145] Binary Tree Postorder Traversal","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[145] Binary Tree Postorder Traversal/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[145] Binary Tree Postorder Traversal/","excerpt":"Given a binary tree, return the inorder traversal of its nodes’ values.","text":"Given a binary tree, return the inorder traversal of its nodes’ values. For example:Given binary tree {1,null,2,3}, 1 \\ 2 /3 return [3,2,1]. 分析: 两种种方法： 递归法 递归是最简单的。 迭代法 代码: 递归法： public class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); if (root != null) &#123; result.addAll(inorderTraversal(root.left)); result.addAll(inorderTraversal(root.right)); result.add(root.val); &#125; return result; &#125;&#125; 迭代法： public class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; LinkedList&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); if (root == null) return result; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode n = root; stack.push(n); while (!stack.empty()) &#123; n = stack.pop(); result.addFirst(n.val); if (n.left != null) stack.push(n.left); if (n.right != null) stack.push(n.right); &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"}]},{"title":"LeetCode[150] Evaluate Reverse Polish Notation","slug":"LeetCode[150] Evaluate Reverse Polish Notation","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[150] Evaluate Reverse Polish Notation/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[150] Evaluate Reverse Polish Notation/","excerpt":"Evaluate the value of an arithmetic expression in Reverse Polish Notation.\nValid operators are +, -, *, /. Each operand may be an integer or another expression.\nSome examples:\n[&quot;2&quot;, &quot;1&quot;, &quot;+&quot;, &quot;3&quot;, &quot;*&quot;] -&gt; ((2 + 1) * 3) -&gt; 9[&quot;4&quot;, &quot;13&quot;, &quot;5&quot;, &quot;/&quot;, &quot;+&quot;] -&gt; (4 + (13 / 5)) -&gt; 6\n分析:\n使用栈，很简单。\n代码:","text":"Evaluate the value of an arithmetic expression in Reverse Polish Notation. Valid operators are +, -, *, /. Each operand may be an integer or another expression. Some examples: [&quot;2&quot;, &quot;1&quot;, &quot;+&quot;, &quot;3&quot;, &quot;*&quot;] -&gt; ((2 + 1) * 3) -&gt; 9[&quot;4&quot;, &quot;13&quot;, &quot;5&quot;, &quot;/&quot;, &quot;+&quot;] -&gt; (4 + (13 / 5)) -&gt; 6 分析: 使用栈，很简单。 代码: public class Solution &#123; public int evalRPN(String[] tokens) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); for (String s : tokens)&#123; switch (s)&#123; case \"+\": stack.push(stack.pop() + stack.pop()); break; case \"-\": stack.push(-(stack.pop() - stack.pop())); break; case \"*\": stack.push(stack.pop() * stack.pop()); break; case \"/\": int a = stack.pop(); int b = stack.pop(); stack.push(b / a); break; default: stack.push(Integer.parseInt(s)); break; &#125; &#125; return stack.pop(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[155] Min Stack","slug":"LeetCode[155] Min Stack","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[155] Min Stack/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[155] Min Stack/","excerpt":"Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\npush(x) – Push element x onto stack.\npop() – Removes the element on top of the stack.\ntop() – Get the top element.\ngetMin() – Retrieve the minimum element in the stack.\n\nExample:\nMinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin();   –&gt; Returns -3.minStack.pop();minStack.top();      –&gt; Returns 0.minStack.getMin();   –&gt; Returns -2.\n分析:\nJava中本来就有Stack。本题跟普通Stack的区别是需要记住最小值，关键在于push和pop方法。在push时，若x比当前的min更小，则先push值min，再push值x，并令min = x。在pop时，若该值为min值，需要pop两次，并且让第二次pop的值为min值。push和pop相呼应。\n代码:","text":"Design a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) – Push element x onto stack. pop() – Removes the element on top of the stack. top() – Get the top element. getMin() – Retrieve the minimum element in the stack. Example: MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); –&gt; Returns -3.minStack.pop();minStack.top(); –&gt; Returns 0.minStack.getMin(); –&gt; Returns -2. 分析: Java中本来就有Stack。本题跟普通Stack的区别是需要记住最小值，关键在于push和pop方法。在push时，若x比当前的min更小，则先push值min，再push值x，并令min = x。在pop时，若该值为min值，需要pop两次，并且让第二次pop的值为min值。push和pop相呼应。 代码: public class MinStack &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int min = Integer.MAX_VALUE; /** initialize your data structure here. */ public MinStack() &#123; &#125; public void push(int x) &#123; if (x &lt;= min) &#123; stack.push(min); min = x; &#125; stack.push(x); &#125; public void pop() &#123; if (stack.pop() == min) &#123; min = stack.pop(); &#125; &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return min; &#125;&#125;/** * Your MinStack object will be instantiated and called as such: * MinStack obj = new MinStack(); * obj.push(x); * obj.pop(); * int param_3 = obj.top(); * int param_4 = obj.getMin(); */","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[190] Reverse Bits","slug":"LeetCode[190] Reverse Bits","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[190] Reverse Bits/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[190] Reverse Bits/","excerpt":"Reverse bits of a given 32 bits unsigned integer.\nFor example, given input 43261596 (represented in binary as 00000010100101000001111010011100), return 964176192 (represented in binary as 00111001011110000010100101000000).\nFollow up:\nIf this function is called many times, how would you optimize it?\n分析：\n最简单直接的做法，从右向左把一位位取出来，添加到新生成的整数的最低位即可。\n代码:","text":"Reverse bits of a given 32 bits unsigned integer. For example, given input 43261596 (represented in binary as 00000010100101000001111010011100), return 964176192 (represented in binary as 00111001011110000010100101000000). Follow up: If this function is called many times, how would you optimize it? 分析： 最简单直接的做法，从右向左把一位位取出来，添加到新生成的整数的最低位即可。 代码: public class Solution &#123; // you need treat n as an unsigned value public int reverseBits(int n) &#123; int result = 0; for (int i = 0; i &lt; 32;i++)&#123; result &lt;&lt;= 1; result += n &amp; 1; n &gt;&gt;&gt;= 1; //无符号右移 &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[191] Number of 1 Bits","slug":"LeetCode[191] Number of 1 Bits","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[191] Number of 1 Bits/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[191] Number of 1 Bits/","excerpt":"Write a function that takes an unsigned integer and returns the number of ’1’ bits it has (also known as the Hamming weight).\nFor example, the 32-bit integer ’11’ has binary representation 00000000000000000000000000001011, so the function should return 3.\n分析：\n题目要求算出一个int数二进制表示中1的个数。\nn和n-1按位与可以去掉n二进制表示中最右边一位1.\n令   n =1101011000\n则  n-1=1101010111\nn&amp;(n-1)=1101010000\n经过K次n&amp;n-1,n变为0.K即n的二进制表示中1的个数。\n代码:","text":"Write a function that takes an unsigned integer and returns the number of ’1’ bits it has (also known as the Hamming weight). For example, the 32-bit integer ’11’ has binary representation 00000000000000000000000000001011, so the function should return 3. 分析： 题目要求算出一个int数二进制表示中1的个数。 n和n-1按位与可以去掉n二进制表示中最右边一位1. 令 n =1101011000 则 n-1=1101010111 n&amp;(n-1)=1101010000 经过K次n&amp;n-1,n变为0.K即n的二进制表示中1的个数。 代码: public class Solution &#123; // you need to treat n as an unsigned value public int hammingWeight(int n) &#123; int count = 0; while(n != 0)&#123; n &amp;= n - 1; count++; &#125; return count; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[202] Happy Number","slug":"LeetCode[202] Happy Number","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[202] Happy Number/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[202] Happy Number/","excerpt":"Write an algorithm to determine if a number is “happy”.\nA happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.\nExample: 19 is a happy number\n1^2 + 9^2 = 82\n8^2 + 2^2 = 68\n6^2 + 8^2 = 100\n1^2 + 0^2 + 0^2 = 1\n分析：\n这题找到规律后就简单了。如果右边的出现了某个重复的数，但不是1，说明会无限循环下去，这个数就不是快乐数，如果是1，则是快乐数。\n代码:","text":"Write an algorithm to determine if a number is “happy”. A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: 19 is a happy number 1^2 + 9^2 = 82 8^2 + 2^2 = 68 6^2 + 8^2 = 100 1^2 + 0^2 + 0^2 = 1 分析： 这题找到规律后就简单了。如果右边的出现了某个重复的数，但不是1，说明会无限循环下去，这个数就不是快乐数，如果是1，则是快乐数。 代码: public class Solution &#123; public boolean isHappy(int n) &#123; Set&lt;Integer&gt; existed = new HashSet&lt;Integer&gt;(); while(true)&#123; int sum = 0; while (n &gt; 0)&#123; int digit = n % 10; sum += digit * digit; n /= 10; &#125; if(existed.contains(sum))&#123; return sum == 1; &#125;else&#123; existed.add(sum); &#125; n = sum; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[205] Isomorphic Strings","slug":"LeetCode[205] Isomorphic Strings","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[205] Isomorphic Strings/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[205] Isomorphic Strings/","excerpt":"Given two strings s and t, determine if they are isomorphic.\nTwo strings are isomorphic if the characters in s can be replaced to get t.\nAll occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself.\nFor example,Given “egg”, “add”, return true.\nGiven “foo”, “bar”, return false.\nGiven “paper”, “title”, return true.\nNote:You may assume both s and t have the same length.\n分析：\n这道题思路跟 LeetCode[290] Word Pattern 一模一样。\n代码:","text":"Given two strings s and t, determine if they are isomorphic. Two strings are isomorphic if the characters in s can be replaced to get t. All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself. For example,Given “egg”, “add”, return true. Given “foo”, “bar”, return false. Given “paper”, “title”, return true. Note:You may assume both s and t have the same length. 分析： 这道题思路跟 LeetCode[290] Word Pattern 一模一样。 代码: public class Solution &#123; public boolean isIsomorphic(String s, String t) &#123; char a,b; HashMap&lt;Character,Character&gt; map = new HashMap&lt;Character,Character&gt;(); for(int i = 0; i &lt; s.length(); i++)&#123; a = s.charAt(i); b = t.charAt(i); if(map.containsKey(a))&#123; if(map.get(a) != b) return false; &#125;else if(map.containsValue(b)) return false; else map.put(a,b); &#125; return true; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[20] Valid Parentheses","slug":"LeetCode[20] Valid Parentheses","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[20] Valid Parentheses/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[20] Valid Parentheses/","excerpt":"Given a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid.\nThe brackets must close in the correct order, “()” and “()[]{}” are all valid but “(]” and “([)]” are not.\n分析:\n使用栈。\n代码:","text":"Given a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid. The brackets must close in the correct order, “()” and “()[]{}” are all valid but “(]” and “([)]” are not. 分析: 使用栈。 代码: public class Solution &#123; public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;Character&gt;(); for (char c : s.toCharArray()) &#123; if (c == '(') &#123; stack.push(')'); &#125; else if (c == '[') &#123; stack.push(']'); &#125; else if (c == '&#123;') &#123; stack.push('&#125;'); &#125; else if (stack.isEmpty() || stack.pop() != c) &#123; return false; &#125; &#125; return stack.isEmpty(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[215] Kth Largest Element in an Array","slug":"LeetCode[215] Kth Largest Element in an Array","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[215] Kth Largest Element in an Array/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[215] Kth Largest Element in an Array/","excerpt":"Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element.\nFor example,Given [3,2,1,5,6,4] and k = 2, return 5.\nNote:You may assume k is always valid, 1 ≤ k ≤ array’s length.\n分析:\nPriorityQueue内部是由堆实现的。每次remove()都会将最小的元素删除。\n建一个PriorityQueue，将数组元素都加入该队列。然后移出nums.length-k个，下一个出来的就是第K大的。\n代码:","text":"Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element. For example,Given [3,2,1,5,6,4] and k = 2, return 5. Note:You may assume k is always valid, 1 ≤ k ≤ array’s length. 分析: PriorityQueue内部是由堆实现的。每次remove()都会将最小的元素删除。 建一个PriorityQueue，将数组元素都加入该队列。然后移出nums.length-k个，下一个出来的就是第K大的。 代码: public class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; Queue&lt;Integer&gt; q = new PriorityQueue&lt;Integer&gt;(); for(int i = 0;i &lt; nums.length;i++) q.add(nums[i]); for(int i = 0; i &lt; nums.length - k;i++) q.remove(); return q.peek(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[225] Implement Stack using Queues","slug":"LeetCode[225] Implement Stack using Queues","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[225] Implement Stack using Queues/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[225] Implement Stack using Queues/","excerpt":"Implement the following operations of a stack using queues.\n\npush(x) – Push element x onto stack.\npop() – Removes the element on top of the stack.\ntop() – Get the top element.\nempty() – Return whether the stack is empty.\n","text":"Implement the following operations of a stack using queues. push(x) – Push element x onto stack. pop() – Removes the element on top of the stack. top() – Get the top element. empty() – Return whether the stack is empty. Notes: You must use only standard operations of a queue – which means only push to back, peek/pop from front, size, and is empty operations are valid. Depending on your language, queue may not be supported natively. You may simulate a queue by using a list or deque (double-ended queue), as long as you use only standard operations of a queue. You may assume that all operations are valid (for example, no pop or top operations will be called on an empty stack). 分析: 可以用Queue实现，也可以用Deque实现。 代码: 使用Queue： public class MyStack &#123; Queue&lt;Integer&gt; q = new LinkedList&lt;Integer&gt;(); /** Push element x onto stack. */ public void push(int x) &#123; q.offer(x); int n = q.size(); while (n-- &gt; 1) &#123; q.offer(q.poll()); &#125; &#125; /** Removes the element on top of the stack and returns that element. */ public int pop() &#123; return q.poll(); &#125; /** Get the top element. */ public int top() &#123; return q.peek(); &#125; /** Returns whether the stack is empty. */ public boolean empty() &#123; return q.isEmpty(); &#125;&#125; 使用Deque： public class MyStack &#123; Deque&lt;Integer&gt; dq = new LinkedList&lt;Integer&gt;(); /** Push element x onto stack. */ public void push(int x) &#123; dq.offerLast(x); &#125; /** Removes the element on top of the stack and returns that element. */ public int pop() &#123; return dq.pollLast(); &#125; /** Get the top element. */ public int top() &#123; return dq.peekLast(); &#125; /** Returns whether the stack is empty. */ public boolean empty() &#123; return dq.isEmpty(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[232] Implement Queue using Stacks","slug":"LeetCode[232] Implement Queue using Stacks","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[232] Implement Queue using Stacks/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[232] Implement Queue using Stacks/","excerpt":"Implement the following operations of a queue using stacks.\n\npush(x) – Push element x to the back of queue.\npop() – Removes the element from in front of queue.\npeek() – Get the front element.\nempty() – Return whether the queue is empty.\n","text":"Implement the following operations of a queue using stacks. push(x) – Push element x to the back of queue. pop() – Removes the element from in front of queue. peek() – Get the front element. empty() – Return whether the queue is empty. Notes: You must use only standard operations of a stack – which means only push to top, peek/pop from top, size, and is empty operations are valid. Depending on your language, stack may not be supported natively. You may simulate a stack by using a list or deque (double-ended queue), as long as you use only standard operations of a stack. You may assume that all operations are valid (for example, no pop or peek operations will be called on an empty queue). 分析: 这题跟LeetCode[225] Implement Stack using Queues相反。 两种方案： 方案 A ： 可以用两个栈 a 和 b 来实现队列。其中，push（）都在栈 a 中进行，pop（）和 peek（）都在栈 b 中进行。如果b中没有元素可以 pop（）或 peek（），则依次从 a 中 pop（）出来并 push（）到 b 中。 若 a 和 b 均为空则该队列为空。 方案 B ： 也是用两个栈。其中栈 temp 是用来辅助使栈 queue 维持与入栈时相反的顺序。如入栈顺序为 1、2、3、4、5 ，最终栈 queue 维持的顺序为 5、4、3、2、1 。这样就可以在栈 queue 上直接 pop（）和 peek（）了。 代码: 方案 A ： public class MyQueue &#123; Stack&lt;Integer&gt; a = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; b = new Stack&lt;Integer&gt;(); /** Initialize your data structure here. */ public MyQueue() &#123; &#125; /** Push element x to the back of queue. */ public void push(int x) &#123; a.push(x); &#125; /** Removes the element from in front of queue and returns that element. */ public int pop() &#123; if (b.empty()) &#123; while (!a.empty()) &#123; b.push(a.pop()); &#125; &#125; return b.pop(); &#125; /** Get the front element. */ public int peek() &#123; if (b.empty()) &#123; while (!a.empty()) &#123; b.push(a.pop()); &#125; &#125; return b.peek(); &#125; /** Returns whether the queue is empty. */ public boolean empty() &#123; return a.empty() &amp;&amp; b.empty() ? true : false; &#125;&#125; 方案 B ： public class MyQueue &#123; Stack&lt;Integer&gt; queue = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; temp = new Stack&lt;Integer&gt;(); /** Initialize your data structure here. */ public MyQueue() &#123; &#125; /** Push element x to the back of queue. */ public void push(int x) &#123; while (!queue.empty()) &#123; temp.push(queue.pop()); &#125; queue.push(x); while (!temp.empty()) &#123; queue.push(temp.pop()); &#125; &#125; /** Removes the element from in front of queue and returns that element. */ public int pop() &#123; return queue.pop(); &#125; /** Get the front element. */ public int peek() &#123; return queue.peek(); &#125; /** Returns whether the queue is empty. */ public boolean empty() &#123; return queue.empty(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[26] Remove Duplicates from Sorted Array","slug":"LeetCode[26] Remove Duplicates from Sorted Array","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[26] Remove Duplicates from Sorted Array/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[26] Remove Duplicates from Sorted Array/","excerpt":"Given a sorted array, remove the duplicates in place such that each element appear only once and return the new length.\nDo not allocate extra space for another array, you must do this in place with constant memory.\nFor example,Given input array nums = [1,1,2],\nYour function should return length = 2, with the first two elements of nums being 1 and 2 respectively. It doesn’t matter what you leave beyond the new length.\n代码:","text":"Given a sorted array, remove the duplicates in place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this in place with constant memory. For example,Given input array nums = [1,1,2], Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively. It doesn’t matter what you leave beyond the new length. 代码: public class Solution &#123; public int removeDuplicates(int[] nums) &#123; int index = 1; for (int i = 1;i &lt; nums.length;i++)&#123; if(nums[i] != nums[index-1]) nums[index++] = nums[i]; &#125; return index; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[290] Word Pattern","slug":"LeetCode[290] Word Pattern","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[290] Word Pattern/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[290] Word Pattern/","excerpt":"Given a pattern and a string str, find if str follows the same pattern.\nHere follow means a full match, such that there is a bijection between a letter in pattern and a non-empty word in str.\nExamples:\npattern = “abba”, str = “dog cat cat dog” should return true.pattern = “abba”, str = “dog cat cat fish” should return false.pattern = “aaaa”, str = “dog cat cat dog” should return false.pattern = “abba”, str = “dog dog dog dog” should return false.\nNotes:\nYou may assume pattern contains only lowercase letters, and str contains lowercase letters separated by a single space.\n分析：\n用一个HashMap，建立字母和单词的对应关系。\n代码:","text":"Given a pattern and a string str, find if str follows the same pattern. Here follow means a full match, such that there is a bijection between a letter in pattern and a non-empty word in str. Examples: pattern = “abba”, str = “dog cat cat dog” should return true.pattern = “abba”, str = “dog cat cat fish” should return false.pattern = “aaaa”, str = “dog cat cat dog” should return false.pattern = “abba”, str = “dog dog dog dog” should return false. Notes: You may assume pattern contains only lowercase letters, and str contains lowercase letters separated by a single space. 分析： 用一个HashMap，建立字母和单词的对应关系。 代码: public class Solution &#123; public boolean wordPattern(String pattern, String str) &#123; String[] words = str.split(\" \"); HashMap&lt;Character,String&gt; map = new HashMap&lt;Character,String&gt;(); if(pattern.length() != words.length) return false; for(int i=0; i &lt; pattern.length(); i++)&#123; Character p = pattern.charAt(i); if(map.containsKey(p))&#123; if(!map.get(p).equals(words[i])) return false; &#125;else if(map.containsValue(words[i])) return false; else map.put(p,words[i]); &#125; return true; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[32] Longest Valid Parentheses!","slug":"LeetCode[32] Longest Valid Parentheses","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[32] Longest Valid Parentheses/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[32] Longest Valid Parentheses/","excerpt":"Given a string containing just the characters ‘(‘ and ‘)’, find the length of the longest valid (well-formed) parentheses substring.\nFor “(()”, the longest valid parentheses substring is “()”, which has length = 2.\nAnother example is “)()())”, where the longest valid parentheses substring is “()()”, which has length = 4.\n分析:\n还是使用栈。不过因为要求的是长度，所以这次入栈的是字符的下标。需要注意的是，”()((()))”的length = 8。\n代码:","text":"Given a string containing just the characters ‘(‘ and ‘)’, find the length of the longest valid (well-formed) parentheses substring. For “(()”, the longest valid parentheses substring is “()”, which has length = 2. Another example is “)()())”, where the longest valid parentheses substring is “()()”, which has length = 4. 分析: 还是使用栈。不过因为要求的是长度，所以这次入栈的是字符的下标。需要注意的是，”()((()))”的length = 8。 代码: public class Solution &#123; public int longestValidParentheses(String s) &#123; int maxLen = 0; int left = -1; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); for (int i = 0; i &lt; s.length(); i++) &#123; if (s.charAt(i) == '(')&#123; stack.push(i); &#125; else &#123; if (stack.isEmpty()) &#123; left = i; &#125; else &#123; stack.pop(); if (stack.isEmpty()) &#123; maxLen = Math.max(maxLen, i - left); &#125; else &#123; maxLen = Math.max(maxLen, i - stack.peek()); &#125; &#125; &#125; &#125; return maxLen; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[3] 最大字符不重复的子串","slug":"LeetCode[3] 最大字符不重复的子串","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[3] 最大字符不重复的子串/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[3] 最大字符不重复的子串/","excerpt":"题目描述\nGiven a string, find the length of the longest substring without repeating characters. For example, the longest substring without repeating letters for “abcabcbb” is “abc”, which the length is 3. For “bbbbb” the longest substring is “b”, with the length of 1.\n\n即给定一个字符串，返回最长的没有重复字符的子串的长度\n思路用一个HashMap来存储字符串。其中key为字符，value为该字符在字符串中的位置。\n使用两个指针i，j来指示最长子串的位置。刚开始i，j都为0，指向第一个字符。然后i开始向右遍历。若遍历到的字符已在HashMap中，则更新它的value为现在i的位置。并且将j指向该字符的下一个位置（j只能往右移，或者不移，不能左移）。若未在HashMap中，则将该字符以及它的位置放入HashMap中。最大的（i-j+1）即为最长子串的长度。\n代码如下","text":"题目描述 Given a string, find the length of the longest substring without repeating characters. For example, the longest substring without repeating letters for “abcabcbb” is “abc”, which the length is 3. For “bbbbb” the longest substring is “b”, with the length of 1. 即给定一个字符串，返回最长的没有重复字符的子串的长度 思路用一个HashMap来存储字符串。其中key为字符，value为该字符在字符串中的位置。 使用两个指针i，j来指示最长子串的位置。刚开始i，j都为0，指向第一个字符。然后i开始向右遍历。若遍历到的字符已在HashMap中，则更新它的value为现在i的位置。并且将j指向该字符的下一个位置（j只能往右移，或者不移，不能左移）。若未在HashMap中，则将该字符以及它的位置放入HashMap中。最大的（i-j+1）即为最长子串的长度。 代码如下 public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; if (s.length() == 0) return 0; HashMap&lt;Character,Integer&gt; map = new HashMap&lt;Character,Integer&gt;(); int max=0; for(int i=0,j=0;i&lt;s.length();i++)&#123; if(map.containsKey(s.charAt(i)))&#123; j = Math.max(j,map.get(s.charAt(i))+1); &#125; map.put(s.charAt(i),i); max = Math.max(max,i-j+1); &#125; return max; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[50] Pow(x, n)","slug":"LeetCode[50] Pow(x, n)","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[50] Pow(x, n)/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[50] Pow(x, n)/","excerpt":"Implement pow(x, n).\n分析：\n直接用二分法。要考虑n为负数的情况。\nx^n = x^{n/2}  x^{n/2}  x^{n%2}\n代码:","text":"Implement pow(x, n). 分析： 直接用二分法。要考虑n为负数的情况。 x^n = x^{n/2} x^{n/2} x^{n%2} 代码: public class Solution &#123; public double myPow(double x, int n) &#123; if (n &lt; 0)&#123; return 1.0 / power(x,-n); &#125;else&#123; return power(x,n); &#125; &#125; public double power(double x, int n)&#123; if (n == 0) return 1; double v = power(x,n/2); if (n % 2 == 0)&#123; return v * v; &#125;else&#123; return x * v * v; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[5] 最长的回文子串","slug":"LeetCode[5] 最长的回文子串","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[5] 最长的回文子串/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[5] 最长的回文子串/","excerpt":"题目描述\nGiven a string S, find the longest palindromic substring in S. You may assume that the maximum length of S is 1000, and there exists one unique longest palindromic substring.\n\n即给定一个字符串，返回该字符串最长的回文子串如给出“acabcddcbadike”,返回“abcddcba”。\n思路回文子串分为长度为偶数（中间两个字符相同，就像示例）和长度为奇数两种。从头往后遍历s.length()趟，第i趟指针j，k从i（奇数）或j从i，k从i+1（偶数）向两边扩散（s.charAt(i)和s.charAt(j)相等才扩散），k-j-1为该回文子串长度，若比之前maxlen大，则更新maxlen。\n代码如下","text":"题目描述 Given a string S, find the longest palindromic substring in S. You may assume that the maximum length of S is 1000, and there exists one unique longest palindromic substring. 即给定一个字符串，返回该字符串最长的回文子串如给出“acabcddcbadike”,返回“abcddcba”。 思路回文子串分为长度为偶数（中间两个字符相同，就像示例）和长度为奇数两种。从头往后遍历s.length()趟，第i趟指针j，k从i（奇数）或j从i，k从i+1（偶数）向两边扩散（s.charAt(i)和s.charAt(j)相等才扩散），k-j-1为该回文子串长度，若比之前maxlen大，则更新maxlen。 代码如下 public class Solution &#123; private int lo,maxlen;//子串的起始和长度 public String longestPalindrome(String s) &#123; int len=s.length(); if (len&lt;2) return s; for (int i=0;i&lt;len-1;i++)&#123;//n躺遍历 extendPalindrome(s,i,i); //子串长度为奇数 extendPalindrome(s,i,i+1);//子串长度为偶数 &#125; return s.substring(lo,lo + maxlen); &#125; private void extendPalindrome(String s,int j,int k)&#123; while(j&gt;=0 &amp;&amp; k&lt;s.length() &amp;&amp; s.charAt(j)==s.charAt(k))&#123; --j; ++k; &#125; if(maxlen&lt;k-j-1)&#123; lo=j+1; maxlen=k-j-1; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[7] 反转整数","slug":"LeetCode[7] 反转整数","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[7] 反转整数/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[7] 反转整数/","excerpt":"Reverse digits of an integer.Example1: x = 123, return 321\nExample2: x = -123, return -321\nMy Solution","text":"Reverse digits of an integer.Example1: x = 123, return 321 Example2: x = -123, return -321 My Solution public class Solution &#123; public int reverse(int x) &#123; long result=0; while(x!=0)&#123; result=result*10+x%10; if(result&gt;Integer.MAX_VALUE||result&lt;Integer.MIN_VALUE) return 0; x/=10; &#125; return (int)result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[80] Remove Duplicates from Sorted Array II","slug":"LeetCode[80] Remove Duplicates from Sorted Array II","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[80] Remove Duplicates from Sorted Array II/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[80] Remove Duplicates from Sorted Array II/","excerpt":"Follow up for “Remove Duplicates”:What if duplicates are allowed at most twice?\nFor example,Given sorted array nums = [1,1,1,2,2,3],\nYour function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3. It doesn’t matter what you leave beyond the new length.\nSubscribe to see which companies asked this question\n代码:","text":"Follow up for “Remove Duplicates”:What if duplicates are allowed at most twice? For example,Given sorted array nums = [1,1,1,2,2,3], Your function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3. It doesn’t matter what you leave beyond the new length. Subscribe to see which companies asked this question 代码: public class Solution &#123; public int removeDuplicates(int[] nums) &#123; if (nums.length &lt;= 2) return nums.length; int index=2; for (int i = 2; i &lt; nums.length; i++)&#123; if (nums[i] != nums[index-2]) nums[index++] = nums[i]; &#125; return index; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[84] Largest Rectangle in Histogram!","slug":"LeetCode[84] Largest Rectangle in Histogram!","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[84] Largest Rectangle in Histogram!/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[84] Largest Rectangle in Histogram!/","excerpt":"Given n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram.","text":"Given n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Above is a histogram where width of each bar is 1, given height = [2,1,5,6,2,3]. The largest rectangle is shown in the shaded area, which has area = 10 unit. For example,Given heights = [2,1,5,6,2,3],return 10. 分析: 本题比较经典，解法也十分巧妙。 首先：最大矩形的高度必然和某一个立柱的高度相等，或者说，最大矩形必然包含了某一个立柱的全部。所以我们要依次计算包含完整立柱 i 的最大矩形面积。 以图中 i = 2（即立柱的高为5）为例。包含完整该立柱的最大矩形的面积为 5 * 2 = 10。5为该立柱的高度，那么2是怎么来的呢？ 方法是：分别找出该立柱左右两边离它最近的高度小于它的立柱。两个下标相减再减一即可。例如，图中立柱 i = 2(高为5）左右两边离它最近且高度小于它的立柱分别是立柱 i = 1(高为1）和立柱 i = 4（高为2），4 - 1 - 1 = 2，所以包含完整立柱 i = 2 的最大矩形面积为 5 * （4 - 1 - 1）= 10。 同理，包含完整立柱 i = 3(高为6）的最大矩形面积为 6 * (4 - 2 - 1) = 6。 使用栈可以巧妙地实现该思路。 代码: public class Solution &#123; public int largestRectangleArea(int[] heights) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int maxArea = 0; for (int i = 0; i &lt;= heights.length; i++) &#123; int h = (i == heights.length ? 0 : heights[i]); if (stack.isEmpty() || h &gt;= heights[stack.peek()]) &#123; stack.push(i); &#125; else &#123; int temp = stack.pop(); maxArea = Math.max(maxArea, heights[temp] * (stack.isEmpty() ? i : i - 1 - stack.peek())); i--; &#125; &#125; return maxArea; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[94] Binary Tree Inorder Traversal!","slug":"LeetCode[94] Binary Tree Inorder Traversal","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/LeetCode[94] Binary Tree Inorder Traversal/","link":"","permalink":"http://linbingdong.com/2017/03/11/LeetCode[94] Binary Tree Inorder Traversal/","excerpt":"Given a binary tree, return the inorder traversal of its nodes’ values.","text":"Given a binary tree, return the inorder traversal of its nodes’ values. For example:Given binary tree {1,null,2,3}, 1 \\ 2 /3 return [1,3,2]. 分析: 两种种方法： 递归法 递归是最简单的。 迭代法 迭代法比先序遍历难想一些，读者自己体会。 代码: 递归法： public class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); if (root != null) &#123; result.addAll(inorderTraversal(root.left)); result.add(root.val); result.addAll(inorderTraversal(root.right)); &#125; return result; &#125;&#125; 迭代法： public class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode n = root; while (n != null || !stack.empty()) &#123; while (n != null) &#123; stack.push(n); n = n.left; &#125; n = stack.pop(); result.add(n.val); n = n.right; &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java 7新机制之自动关闭资源——try-with-resources","slug":"Java 7新机制之自动关闭资源——try-with-resources","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java 7新机制之自动关闭资源——try-with-resources/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java 7新机制之自动关闭资源——try-with-resources/","excerpt":"在Java 7之前，IO操作为了保证资源能被关闭，往往会在try代码块后加上finally代码块来处理资源的关闭。","text":"在Java 7之前，IO操作为了保证资源能被关闭，往往会在try代码块后加上finally代码块来处理资源的关闭。 如下： BufferedReader br = new BufferedReader(new FileReader(path));try &#123; return br.readLine();&#125; finally &#123; if (br != null) br.close();&#125; Java 7新增了try-with-resources语法来保证资源的关闭。现在你可以这么写： try(BufferedReader br = new BufferedReader(new FileReader(path));) &#123; return br.readLine();&#125; 代码块里处理完后会自动关闭资源，不需要显示调用close()方法。也不需要finally。代码简洁了很多。 注意： 被关闭的资源类需要实现AutoClosable接口或者是Closable接口。 需要自动关闭的资源在try后面的括号里声明。允许声明多个被关闭的资源，关闭的顺序是与创建资源的顺序相反。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"浅析列式存储格式Parquet","slug":"Parquet调研","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Parquet调研/","link":"","permalink":"http://linbingdong.com/2017/03/11/Parquet调研/","excerpt":"Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Hadoop、Spark等)，被多种查询引擎支持(Hive、Impala、Drill等)，并且它是语言和平台无关的。Parquet最初是由Twitter和Cloudera(由于Impala的缘故)合作开发完成并开源，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，最新的版本是1.8.1。","text":"Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Hadoop、Spark等)，被多种查询引擎支持(Hive、Impala、Drill等)，并且它是语言和平台无关的。Parquet最初是由Twitter和Cloudera(由于Impala的缘故)合作开发完成并开源，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，最新的版本是1.8.1。 1. 概述1.1 简介Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Hadoop、Spark等)，被多种查询引擎支持(Hive、Impala、Drill等)，并且它是语言和平台无关的。Parquet最初是由Twitter和Cloudera(由于Impala的缘故)合作开发完成并开源，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，最新的版本是1.8.1。 Parquet是语言无关的，而且不与任何一种数据处理框架绑定在一起，适配多种语言和组件，能够与Parquet配合的组件有： 查询引擎: Hive, Impala, Pig, Presto, Drill, Tajo, HAWQ, IBM Big SQL 计算框架: MapReduce, Spark, Cascading, Crunch, Scalding, Kite 数据模型: Avro, Thrift, Protocol Buffers, POJOs 那么Parquet是如何与这些组件协作的呢？这个可以通过下图来说明。数据从内存到Parquet文件或者反过来的过程主要由以下三个部分组成： 存储格式(storage format) parquet-format项目定义了Parquet内部的数据类型、存储格式等。 对象模型转换器(object model converters) 这部分功能由parquet-mr项目来实现，主要完成外部对象模型与Parquet内部数据类型的映射。 对象模型(object models) 对象模型可以简单理解为内存中的数据表示，Avro, Thrift, Protocol Buffers, Hive SerDe, Pig Tuple, Spark SQL InternalRow等这些都是对象模型。Parquet也提供了一个example object model 帮助大家理解。 例如parquet-mr项目里的parquet-pig项目就是负责把内存中的Pig Tuple序列化并按列存储成Parquet格式，以及反过来把Parquet文件的数据反序列化成Pig Tuple。 这里需要注意的是Avro, Thrift, Protocol Buffers都有他们自己的存储格式，但是Parquet并没有使用他们，而是使用了自己在parquet-format项目里定义的存储格式。所以如果你的应用使用了Avro等对象模型，这些数据序列化到磁盘还是使用的parquet-mr定义的转换器把他们转换成Parquet自己的存储格式。 1.2 列式存储列式存储，顾名思义就是按照列进行存储数据，把某一列的数据连续的存储，每一行中的不同列的值离散分布。列式存储技术并不新鲜，在关系数据库中都已经在使用，尤其是在针对OLAP场景下的数据存储，由于OLAP场景下的数据大部分情况下都是批量导入，基本上不需要支持单条记录的增删改操作，而查询的时候大多数都是只使用部分列进行过滤、聚合，对少数列进行计算(基本不需要select * from xx之类的查询)。 example： 以下这张表有A、B、C三个字段： A B C A1 B1 C1 A2 B2 C2 A3 B3 C3 行存储： A1 B1 C1 A2 B2 C2 A3 B3 C3 列存储 A1 A2 A3 B1 B2 B3 C1 C2 C3 列式存储可以大大提升这类查询的性能，较之于行是存储，列式存储能够带来这些优化： 查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推。 由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O。 由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效。 2. Parquet详解2.1 数据模型理解Parquet首先要理解这个列存储格式的数据模型。我们以一个下面这样的schema和数据为例来说明这个问题。 message AddressBook &#123; required string owner; repeated string ownerPhoneNumbers; repeated group contacts &#123; required string name; optional string phoneNumber; &#125;&#125; 这个schema中每条记录表示一个人的AddressBook。有且只有一个owner，owner可以有0个或者多个ownerPhoneNumbers，owner可以有0个或者多个contacts。每个contact有且只有一个name，这个contact的phoneNumber可有可无。 每个schema的结构是这样的：根叫做message，message包含多个fields。每个field包含三个属性：repetition, type, name。repetition可以是以下三种：required（出现1次），optional（出现0次或者1次），repeated（出现0次或者多次）。type可以是一个group或者一个primitive类型。 Parquet格式的数据类型不需要复杂的Map, List, Set等，而是使用repeated fields 和 groups来表示。例如List和Set可以被表示成一个repeated field，Map可以表示成一个包含有key-value 对的repeated group，而且key是required的。 List(或Set)可以用repeated field来表示： Map可以用包含key-value对且key是required的repeated group来表示： 2.2 列存储格式列存储通过将相同基本类型（primitive type）的值存储在一起来提供高效的编码和解码。为了用列存储来存储如上嵌套的数据结构，我们需要将该schema用某种方式映射到一系列的列使我们能够将记录写到列中并且能读取成原来的嵌套的数据结构。 在Parquet格式的存储中，一个schema的树结构有几个叶子节点（叶子节点都是primitive type），实际的存储中就会有多少column。 上面的schema的树结构如图所示： 上面这个schema的数据存储实际上有四个column，如下图所示： 只有字段值不能表达清楚记录的结构。给出一个repeated field的两个值，我们不知道此值是按什么‘深度’被重复的（比如，这些值是来自两个不同的记录，还是相同的记录中两个重复的值）。同样的，给出一个缺失的可选字段，我们不知道整个路径有多少字段被显示定义了。因此我们将介绍repetition level 和 definition level的概念。 example： 两条嵌套的记录和它们的schema： 将上图的两条记录用列存储表示： 上面的例子主要是想让大家对嵌套结构的列式存储有个直观的印象，包括repetition level 和 definition level的应用，接下来详细介绍repetition level 和 definition level。 2.3 Definition levelsDefinition level指明该列的路径上多少个可选field被定义了。 嵌套数据类型的特点是有些field（optional field 和 repeated field）可以是空的，也就是没有定义。如果一个field是定义的，那么它的所有的父节点都是被定义的。从根节点开始遍历，当某一个field的路径上的节点开始是空的时候我们记录下当前的深度作为这个field的Definition Level。如果一个field的definition Level等于这个field的最大definition Level就说明这个field是有数据的。对于required类型的field必须是有定义的，所以这个Definition Level是不需要的。在关系型数据中，optional类型的field被编码成0表示空和1表示非空（或者反之）。 注：definition Level是该路径上有定义的repeated field 和 optional field的个数，不包括required field，因为required field是必须有定义的。 再举个简单的例子： message ExampleDefinitionLevel &#123; optional group a &#123; required group b &#123; optional string c; &#125; &#125;&#125; 因为b是required field，所以第3行c的definition level为1而不是2（因为b是required field，所有不需计算在内）；第4行c的definition level为2而不是3（理由同上）. 2.4 Repetition levelsRepetition level指明该值在路径中哪个repeated field重复。 Repetition level是针对repeted field的。注意在图2中的Code字段。可以看到它在r1出现了3次。‘en-us’、‘en’在第一个Name中，而‘en-gb’在第三个Name中。结合了图2你肯定能理解我上一句话并知道‘en-us’、‘en’、‘en-gb’出现在r1中的具体位置，但是不看图的话呢？怎么用文字，或者说是一种定义、一种属性、一个数值，诠释清楚它们出现的位置？这就是重复深度这个概念的作用，它能用一个数字告诉我们在路径中的什么重复字段，此值重复了，以此来确定此值的位置（注意，这里的重复，特指在某个repeated类型的字段下“重复”出现的“重复”）。我们用深度0表示一个纪录的开头（虚拟的根节点），深度的计算忽略非重复字段（标签不是repeated的字段都不算在深度里）。所以在Name.Language.Code这个路径中，包含两个重复字段，Name和Language，如果在Name处重复，重复深度为1（虚拟的根节点是0，下一级就是1），在Language处重复就是2，不可能在Code处重复，它是required类型，表示有且仅有一个；同样的，在路径Links.Forward中，Links是optional的，不参与深度计算（不可能重复），Forward是repeated的，因此只有在Forward处重复时重复深度为1。现在我们从上至下扫描纪录r1。当我们遇到’en-us’，我们没看到任何重复字段，也就是说，重复深度是0。当我们遇到‘en’，字段Language重复了（在‘en-us’的路径里已经出现过一个Language），所以重复深度是2.最终，当我们遇到’en-gb‘，Name重复了（Name在前面‘en-us’和‘en’的路径里已经出现过一次，而此Name后Language只出现过一次，没有重复），所以重复深度是1。因此，r1中Code的值的重复深度是0、2、1. 要注意第二个Name在r1中没有包含任何Code值。为了确定‘en-gb’出现在第三个Name而不是第二个，我们添加一个NULL值在‘en’和‘en-gb’之间（如图3所示）。 2.5 Striping and assembly下面用AddressBook的例子来说明Striping和assembly的过程。 对于每个column的最大的Repetion Level和 Definition Level下图所示。 下面这样两条record： AddressBook &#123; owner: &quot;Julien Le Dem&quot;, ownerPhoneNumbers: &quot;555 123 4567&quot;, ownerPhoneNumbers: &quot;555 666 1337&quot;, contacts: &#123; name: &quot;Dmitriy Ryaboy&quot;, phoneNumber: &quot;555 987 6543&quot;, &#125;, contacts: &#123; name: &quot;Chris Aniszczyk&quot; &#125;&#125;AddressBook &#123; owner: &quot;A. Nonymous&quot;&#125; 以contacts.phoneNumber这一列为例，”555 987 6543”这个contacts.phoneNumber的Definition Level是最大Definition Level=2。而如果一个contact没有phoneNumber，那么它的Definition Level就是1。如果连contact都没有，那么它的Definition Level就是0。 下面我们拿掉其他三个column只看contacts.phoneNumber这个column，把上面的两条record简化成下面的样子： AddressBook &#123; contacts: &#123; phoneNumber: &quot;555 987 6543&quot; &#125; contacts: &#123; &#125;&#125;AddressBook &#123;&#125; 这两条记录的序列化过程如下图所示： 如果我们要把这个column写到磁盘上，磁盘上会写入这样的数据： 注意：NULL实际上不会被存储，如果一个column value的Definition Level小于该column最大Definition Level的话，那么就表示这是一个空值。 下面是从磁盘上读取数据并反序列化成AddressBook对象的过程： 读取第一个三元组R=0, D=2, Value=”555 987 6543” R=0 表示是一个新的record，要根据schema创建一个新的nested record直到Definition Level=2。 D=2 说明Definition Level=Max Definition Level，那么这个Value就是contacts.phoneNumber这一列的值，赋值操作contacts.phoneNumber=”555 987 6543”。 读取第二个三元组 R=1, D=1 R=1 表示不是一个新的record，是上一个record中一个新的contacts。 D=1 表示contacts定义了，但是contacts的下一个级别也就是phoneNumber没有被定义，所以创建一个空的contacts。 读取第三个三元组 R=0, D=0 R=0 表示一个新的record，根据schema创建一个新的nested record直到Definition Level=0，也就是创建一个AddressBook根节点。 可以看出在Parquet列式存储中，对于一个schema的所有叶子节点会被当成column存储，而且叶子节点一定是primitive类型的数据。对于这样一个primitive类型的数据会衍生出三个sub columns (R, D, Value)，也就是从逻辑上看除了数据本身以外会存储大量的Definition Level和Repetition Level。那么这些Definition Level和Repetition Level是否会带来额外的存储开销呢？实际上这部分额外的存储开销是可以忽略的。因为对于一个schema来说level都是有上限的，而且非repeated类型的field不需要Repetition Level，required类型的field不需要Definition Level，也可以缩短这个上限。例如对于Twitter的7层嵌套的schema来说，只需要3个bits就可以表示这两个Level了。 对于存储关系型的record，record中的元素都是非空的（NOT NULL in SQL）。Repetion Level和Definition Level都是0，所以这两个sub column就完全不需要存储了。所以在存储非嵌套类型的时候，Parquet格式也是一样高效的。 2.6 文件格式 行组(Row Group)：按照行将数据物理上划分为多个单元，每一个行组包含一定的行数。一个行组包含这个行组对应的区间内的所有列的列块。 官方建议： 更大的行组意味着更大的列块，使得能够做更大的序列IO。我们建议设置更大的行组（512MB-1GB）。因为一次可能需要读取整个行组，所以我们想让一个行组刚好在一个HDFS块中。因此，HDFS块的大小也需要被设得更大。一个最优的读设置是：1GB的行组，1GB的HDFS块，1个HDFS块放一个HDFS文件。 列块(Column Chunk)：在一个行组中每一列保存在一个列块中，行组中的所有列连续的存储在这个行组文件中。不同的列块可能使用不同的算法进行压缩。一个列块由多个页组成。 页(Page)：每一个列块划分为多个页，页是压缩和编码的单元，对数据模型来说页是透明的。在同一个列块的不同页可能使用不同的编码方式。官方建议一个页为8KB。 上图展示了一个Parquet文件的结构，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length存储了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和当前文件的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页，但是在后面的版本中增加。 2.7 映射下推(Project PushDown)说到列式存储的优势，映射下推是最突出的，它意味着在获取表中原始数据时只需要扫描查询中需要的列，由于每一列的所有值都是连续存储的，所以分区取出每一列的所有值就可以实现TableScan算子，而避免扫描整个表文件内容。 在Parquet中原生就支持映射下推，执行查询的时候可以通过Configuration传递需要读取的列的信息，这些列必须是Schema的子集，映射每次会扫描一个Row Group的数据，然后一次性得将该Row Group里所有需要的列的Cloumn Chunk都读取到内存中，每次读取一个Row Group的数据能够大大降低随机读的次数，除此之外，Parquet在读取的时候会考虑列是否连续，如果某些需要的列是存储位置是连续的，那么一次读操作就可以把多个列的数据读取到内存。 2.8 谓词下推(Predicate PushDown)在数据库之类的查询系统中最常用的优化手段就是谓词下推了，通过将一些过滤条件尽可能的在最底层执行可以减少每一层交互的数据量，从而提升性能，例如”select count(1) from A Join B on A.id = B.id where A.a &gt; 10 and B.b &lt; 100″SQL查询中，在处理Join操作之前需要首先对A和B执行TableScan操作，然后再进行Join，再执行过滤，最后计算聚合函数返回，但是如果把过滤条件A.a &gt; 10和B.b &lt; 100分别移到A表的TableScan和B表的TableScan的时候执行，可以大大降低Join操作的输入数据。 无论是行式存储还是列式存储，都可以在将过滤条件在读取一条记录之后执行以判断该记录是否需要返回给调用者，在Parquet做了更进一步的优化，优化的方法时对每一个Row Group的每一个Column Chunk在存储的时候都计算对应的统计信息，包括该Column Chunk的最大值、最小值和空值个数。通过这些统计值和该列的过滤条件可以判断该Row Group是否需要扫描。另外Parquet未来还会增加诸如Bloom Filter和Index等优化数据，更加有效的完成谓词下推。 3. 性能3.1 压缩 上图是展示了使用不同格式存储TPC-H和TPC-DS数据集中两个表数据的文件大小对比，可以看出Parquet较之于其他的二进制文件存储格式能够更有效的利用存储空间，而新版本的Parquet(2.0版本)使用了更加高效的页存储方式，进一步的提升存储空间。 3.2 查询 上图展示了Twitter在Impala中使用不同格式文件执行TPC-DS基准测试的结果，测试结果可以看出Parquet较之于其他的行式存储格式有较明显的性能提升。 上图展示了criteo公司在Hive中使用ORC和Parquet两种列式存储格式执行TPC-DS基准测试的结果，测试结果可以看出在数据存储方面，两种存储格式在都是用snappy压缩的情况下量中存储格式占用的空间相差并不大，查询的结果显示Parquet格式稍好于ORC格式，两者在功能上也都有优缺点，Parquet原生支持嵌套式数据结构，而ORC对此支持的较差，这种复杂的Schema查询也相对较差;而Parquet不支持数据的修改和ACID，但是ORC对此提供支持，但是在OLAP环境下很少会对单条数据修改，更多的则是批量导入。 4. 总结本文介绍了一种支持嵌套数据模型对的列式存储格式Parquet，作为大数据系统中OLAP查询的优化方案，它已经被多种查询引擎原生支持，并且部分高性能引擎将其作为默认的文件存储格式。通过数据编码和压缩，以及映射下推和谓词下推功能，Parquet的性能也较之其它文件格式有所提升，可以预见，随着数据模型的丰富和Ad hoc查询的需求，Parquet将会被更广泛的使用。 5. 参考 Google论文：Dremel: Interactive Analysis of Web-Scale Datasets Twitter博文：Dremel made simple with Parquet http://www.importnew.com/2617.html http://www.2cto.com/database/201605/509506.html http://www.infoq.com/cn/articles/in-depth-analysis-of-parquet-column-storage-format/","raw":null,"content":null,"categories":[{"name":"列式存储","slug":"列式存储","permalink":"http://linbingdong.com/categories/列式存储/"}],"tags":[{"name":"Parquet","slug":"Parquet","permalink":"http://linbingdong.com/tags/Parquet/"},{"name":"列式存储","slug":"列式存储","permalink":"http://linbingdong.com/tags/列式存储/"}]},{"title":"Phoenix安装配置","slug":"Phoenix安装配置","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Phoenix安装配置/","link":"","permalink":"http://linbingdong.com/2017/03/11/Phoenix安装配置/","excerpt":"介绍Phoenix安装配置的过程，记录在安装配置过程中遇到的问题及解决方案。","text":"介绍Phoenix安装配置的过程，记录在安装配置过程中遇到的问题及解决方案。 1.简介Phoenix最早是saleforce的一个开源项目，后来成为Apache基金的顶级项目 Phoenix是构建在HBase上的一个SQL层，能让我们用标准的JDBC APIs而不是HBase客户端APIs来创建表、插入数据和对HBase数据进行查询 因此Phoenix跟HBase是离不开的，Phoenix的安装也是基于HBase的。在安装Phoenix之前，请确保集群上已经安装了Hadoop集群跟HBase集群 本集群上已部署CHD5.5.1版本的Hadooop（2.6.0）和HBase（1.0.0） 各节点规划如下： 192.168.20.100 node-20-100 hdfs-master1 nn1 jn1 hmaster1192.168.20.101 node-20-101 hdfs-master2 nn2 zk1 jn2 hmaster2 Phoenix192.168.20.102 node-20-102 hdfs-slave1 dn1 zk2 jn3 hregionserver1192.168.20.103 node-20-103 hdfs-slave2 dn2 zk3 jn4 hregionserver2192.168.20.104 node-20-104 hdfs-slave3 dn3 zk4 jn5 hregionserver3192.168.20.105 node-20-105 hdfs-slave4 dn4 zk5 hregionserver4 注意：Cloudera官方并不支持Phoenix，也就是说从Phoenix官网下的预编译的包在CDH安装的HBase上根本不能运行，Phoenix官网对此也没有任何说明！！！刚开始按照Phoenix官网给出的步骤安装完Phoenix后运行报错，幸好有StackOverflow，才找到了原因，并且找到解决方案。链接如下：http://stackoverflow.com/questions/31849454/using-phoenix-with-cloudera-hbase-installed-from-repo 解决方案：需要自己从Phoenix官网下载跟HBase版本对应的Phoenix版本（Phoenix 4.x版本均支持HBase 1.0.0）的源码来编译，得到编译后的两个相关jar包。具体安装步骤如下 2.安装配置Phoenix最新版本是4.8，4.x均支持HBase 1.0.0，这里选用Phoenix 4.6.0版本 2.1下载并解压从Phoenix官网下载预编译的phoenix-4.6.0-HBase-1.0-bin.tar.gz Phoenix客户端所在的节点最好安装有ZooKeeper，方便后续操作 这里选择192.168.20.101节点作为Phoenix客户端 切换到/opt目录下：$ cd /opt wget：$ wget &#39;http://archive.apache.org/dist/phoenix/phoenix-4.6.0-HBase-1.0/bin/phoenix-4.6.0-HBase-1.0-bin.tar.gz&#39; 解压：$ tar -xzvf phoenix-4.6.0-HBase-1.0-bin.tar.gz 建立软链接：$ ln -s phoenix-4.6.0-HBase-1.0-bin phoenix 2.2编译源码如果从Phoenix官网下载4.6.0的源码来编译，需要自己修改pom.xml文件，比较麻烦。Github上已经有人把修改过pom.xml文件的源码上传了，链接如下：https://github.com/chiastic-security/phoenix-for-cloudera/tree/4.6-HBase-1.0-cdh5.5 下载该链接的源码，用maven进行编译 进入phoenix-for-cloudera-4.6-HBase-1.0-cdh5.5目录 $ mvn package -DskipTests 编译成功后显示如下： 2.3替换将编译后`phoenix-for-cloudera-4.6-HBase-1.0-cdh5.5/phoenix-assembly/target目录下的phoenix-4.6.0-cdh5.5.1-client.jar和phoenix-4.6.0-cdh5.5.1-server.jar分别替换/opt/phoenix目录下的phoenix-4.6.0-HBase-1.0-client.jar和phoenix-4.6.0-HBase-1.0-server.jar 2.4将相关jar拷贝到HBase的lib目录下拷贝phoenix-4.6.0-cdh5.5.1-server.jar到集群上每个HBase的lib目录下 $ cp phoenix-4.6.0-cdh5.5.1-server.jar /usr/lib/hbase/lib$ scp phoenix-4.6.0-cdh5.5.1-server.jar node-20-100:/usr/lib/hbase/lib/phoenix-4.6.0-cdh5.5.1-server.jar$ scp phoenix-4.6.0-cdh5.5.1-server.jar node-20-102:/usr/lib/hbase/lib/phoenix-4.6.0-cdh5.5.1-server.jar$ scp phoenix-4.6.0-cdh5.5.1-server.jar node-20-103:/usr/lib/hbase/lib/phoenix-4.6.0-cdh5.5.1-server.jar$ scp phoenix-4.6.0-cdh5.5.1-server.jar node-20-104:/usr/lib/hbase/lib/phoenix-4.6.0-cdh5.5.1-server.jar$ scp phoenix-4.6.0-cdh5.5.1-server.jar node-20-105:/usr/lib/hbase/lib/phoenix-4.6.0-cdh5.5.1-server.jar 2.5配置Phoenix客户端的CLASSPATH将phoenix-4.6.0-cdh5.5.1-client.jar添加到Phoenix客户端的CLASSPATH中，这里是192.168.20.101节点 在/etc/profile.d目录下新建phoenix.shexport CLASSPATH=.:/opt/phoenix/phoenix-4.6.0-cdh5.5.1-client.jar $ source phoenix.sh 2.6配置hbase-site.xml Master的hbase-site.xml &lt;property&gt; &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.master.loadbalancer.class&lt;/name&gt;&lt;value&gt;org.apache.phoenix.hbase.index.balancer.IndexLoadBalancer&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt;&lt;value&gt;org.apache.phoenix.hbase.index.master.IndexMasterObserver&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rpc.timeout&lt;/name&gt; &lt;value&gt;300000&lt;/value&gt;&lt;/property&gt; Region Server的hbase-site.xml &lt;property&gt; &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.region.server.rpc.scheduler.factory.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.ipc.PhoenixRpcSchedulerFactory&lt;/value&gt;&lt;description&gt;Factory to create the Phoenix RPC Scheduler that usesseparate queues for index and metadata updates&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rpc.controllerfactory.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hbase.ipc.controller.ServerRpcControllerFactory&lt;/value&gt;&lt;description&gt;Factory to create the Phoenix RPCScheduler that uses separate queues for index and metadataupdates&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.coprocessor.regionserver.classes&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hbase.regionserver.LocalIndexMerger&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rpc.timeout&lt;/name&gt; &lt;value&gt;300000&lt;/value&gt;&lt;/property&gt; 至此，Phoenix安装配置完毕 3.验证是否可用3.1进入CLI切换到/opt/phoenix/bin目录下 $ chmod 777 sqlline.py$ chmod 777 psql.py 运行 $ ./sqlline.py localhost 结果如下： 说明Phoenix安装成功 3.2在终端执行SQL脚本运行$ ./sqlline.py localhost ../examples/STOCK_SYMBOL.sql 报错： 解决： 将examples/STOCK_SYMBOL.sql里第一行-- creates stock table with single row删掉 重新运行： 3.3加载数据运行： $ psql.py localhost ../examples/web_stat.sql ../examples/web_stat.csv ../examples/web_stat_queries.sql 结果：","raw":null,"content":null,"categories":[{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/categories/Phoenix/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/tags/Phoenix/"}]},{"title":"Phoenix综述（SQL on HBase）","slug":"Phoenix文档","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Phoenix文档/","link":"","permalink":"http://linbingdong.com/2017/03/11/Phoenix文档/","excerpt":"1. Phoenix概述Phoenix最早是saleforce的一个开源项目，后来成为Apache基金的顶级项目。","text":"1. Phoenix概述Phoenix最早是saleforce的一个开源项目，后来成为Apache基金的顶级项目。 Phoenix是构建在HBase上的一个SQL层，能让我们用标准的JDBC APIs而不是HBase客户端APIs来创建表，插入数据和对HBase数据进行查询。 put the SQL back in NoSQL Phoenix完全使用Java编写，作为HBase内嵌的JDBC驱动。Phoenix查询引擎会将SQL查询转换为一个或多个HBase扫描，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。 HBase的查询工具有很多，如：Hive、Tez、Impala、Spark SQL、Phoenix等。 Phoenix通过以下方式使我们可以少写代码，并且性能比我们自己写代码更好： 将SQL编译成原生的HBase scans。 确定scan关键字的最佳开始和结束 让scan并行执行 … 使用Phoenix的公司 2. 历史演进 3.0/4.0 release ARRAY Type. 支持标准的JDBC数组类型 Sequences. 支持 CREATE/DROP SEQUENCE, NEXT VALUE FOR, CURRENT VALUE FOR也实现了 Multi-tenancy. 同一张HBase物理表上，不同的租户可以创建相互独立的视图 Views. 同一张HBase物理表上可以创建不同的视图 3.1/4.1 release Apache Pig Loader . 通过pig来处理数据时支持pig加载器来利用Phoenix的性能 Derived Tables. 允许在一个FROM子句中使用SELECT子句来定义一张衍生表 Local Indexing. 后面介绍 Tracing. 后面介绍 3.2/4.2 release Subqueries 支持在WHERE和FROM子句中的独立子查询和相关子查询 Semi/anti joins. 通过标准的[NOT] IN 和 [NOT] EXISTS关键字来支持半/反连接 Optimize foreign key joins. 通过利用跳跃扫描过滤器来优化外键连接 Statistics Collection. 通过收集表的统计信息来提高并行查询能力 3.3/4.3 release Many-to-many joins. 支持两边都太大以至于无法放进内存的连接 Map-reduce Integration. 支持Map-reduce集成 Functional Indexes. 后面介绍 4.4 release User Defined Functions. 后面介绍 4.5 release Asynchronous Index Population. 通过一个Map-reduce job，索引可以被异步创建 4.6 release Time series Optimization. 优化针对时间序列数据的查询 4.7 release Transaction Support. 后面介绍 4.8 release DISTINCT Query Optimization. 使用搜索逻辑来大幅提高 SELECT DISTINCT 和 COUNT DISTINCT的查询性能 Local Index Improvements. Reworked 后面介绍 Hive Integration. 能够在Phoenix内使用Hive来支持大表和大表之间的连接 Namespace Mapping. 将Phoenix schema映射到HBase的命名空间来增强不同schema之间的隔离性 3. 特性3.1 Transactions (beta) 事务该特性还处于beta版，并非正式版。通过集成Tephra,Phoenix可以支持ACID特性。Tephra也是Apache的一个项目,是事务管理器，它在像HBase这样的分布式数据存储上提供全局一致事务。HBase本身在行层次和区层次上支持强一致性，Tephra额外提供交叉区、交叉表的一致性来支持可扩展性。 要想让Phoenix支持事务特性，需要以下步骤： 配置客户端hbase-site.xml &lt;property&gt; &lt;name&gt;phoenix.transactions.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 配置服务端hbase-site.xml &lt;property&gt; &lt;name&gt;data.tx.snapshot.dir&lt;/name&gt; &lt;value&gt;/tmp/tephra/snapshots&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;data.tx.timeout&lt;/name&gt; &lt;value&gt;60&lt;/value&gt; &lt;description&gt; set the transaction timeout (time after which open transactions become invalid) to a reasonable value.&lt;/description&gt;&lt;/property&gt; 配置$HBASE_HOME并启动Tephra ./bin/tephra 通过以上配置，Phoenix已经支持了事务特性，但创建表的时候默认还是不支持的。如果想创建一个表支持事务特性，需要显示声明，如下： CREATE TABLE my_table (k BIGINT PRIMARY KEY, v VARCHAR) TRANSACTIONAL=true; 就是在建表语句末尾增加 TRANSACTIONAL=true。 原本存在的表也可以更改成支持事务的，需要注意的是，事务表无法改回非事务的，因此更改的时候要小心。一旦改成事务的，就改不回去了。 ALTER TABLE my_other_table SET TRANSACTIONAL=true; 3.2 User-defined functions(UDFs) 用户定义函数3.2.1 概述Phoenix从4.4.0版本开始支持用户自定义函数。 用户可以创建临时或永久的用户自定义函数。这些用户自定义函数可以像内置的create、upsert、delete一样被调用。临时函数是针对特定的会话或连接，对其他会话或连接不可见。永久函数的元信息会被存储在一张叫做SYSTEM.FUNCTION的系统表中，对任何会话或连接均可见。 3.2.2 配置 hive-site.xml &lt;property&gt; &lt;name&gt;phoenix.functions.allowUserDefinedFunctions&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.hdfs.impl&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.DistributedFileSystem&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;$&#123;hbase.tmp.dir&#125;/hbase&lt;/value&gt; &lt;description&gt;The directory shared by region servers and into which HBase persists. The URL should be &apos;fully-qualified&apos; to include the filesystem scheme. For example, to specify the HDFS directory &apos;/hbase&apos; where the HDFS instance&apos;s namenode is running at namenode.example.org on port 9000, set this value to: hdfs://namenode.example.org:9000/hbase. By default, we write to whatever $&#123;hbase.tmp.dir&#125; is set too -- usually /tmp -- so change this configuration or else all data will be lost on machine restart.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.dynamic.jars.dir&lt;/name&gt; &lt;value&gt;$&#123;hbase.rootdir&#125;/lib&lt;/value&gt; &lt;description&gt; The directory from which the custom udf jars can be loaded dynamically by the phoenix client/region server without the need to restart. However, an already loaded udf class would not be un-loaded. See HBASE-1936 for more details. &lt;/description&gt;&lt;/property&gt; 后两个配置需要跟hbse服务端的配置一致。 以上配置完后，在JDBC连接时还需要执行以下语句： Properties props = new Properties();props.setProperty(&quot;phoenix.functions.allowUserDefinedFunctions&quot;, &quot;true&quot;);Connection conn = DriverManager.getConnection(&quot;jdbc:phoenix:localhost&quot;, props); 以下是可选的配置，用于动态类加载的时候把jar包从hdfs拷贝到本地文件系统 &lt;property&gt; &lt;name&gt;hbase.local.dir&lt;/name&gt; &lt;value&gt;$&#123;hbase.tmp.dir&#125;/local/&lt;/value&gt; &lt;description&gt;Directory on the local filesystem to be used as a local storage.&lt;/description&gt;&lt;/property&gt; 3.3 Secondary Indexing 二级索引在HBase中，只有一个单一的按照字典序排序的rowKey索引，当使用rowKey来进行数据查询的时候速度较快，但是如果不使用rowKey来查询的话就会使用filter来对全表进行扫描，很大程度上降低了检索性能。而Phoenix提供了二级索引技术来应对这种使用rowKey之外的条件进行检索的场景。 Covered Indexes 只需要通过索引就能返回所要查询的数据，所以索引的列必须包含所需查询的列(SELECT的列和WHRER的列) Functional Indexes 从Phoeinx4.3以上就支持函数索引，其索引不局限于列，可以合适任意的表达式来创建索引，当在查询时用到了这些表达式时就直接返回表达式结果 Global Indexes Global indexing适用于多读少写的业务场景。使用Global indexing的话在写数据的时候会消耗大量开销，因为所有对数据表的更新操作（DELETE, UPSERT VALUES and UPSERT SELECT）,会引起索引表的更新，而索引表是分布在不同的数据节点上的，跨节点的数据传输带来了较大的性能消耗。在读数据的时候Phoenix会选择索引表来降低查询消耗的时间。在默认情况下如果想查询的字段不是索引字段的话索引表不会被使用，也就是说不会带来查询速度的提升。 Local Indexes Local indexing适用于写操作频繁的场景。与Global indexing一样，Phoenix会自动判定在进行查询的时候是否使用索引。使用Local indexing时，索引数据和数据表的数据是存放在相同的服务器中的避免了在写操作的时候往不同服务器的索引表中写索引带来的额外开销。使用Local indexing的时候即使查询的字段不是索引字段索引表也会被使用，这会带来查询速度的提升，这点跟Global indexing不同。一个数据表的所有索引数据都存储在一个单一的独立的可共享的表中。 3.4 Statistics Collection 统计信息收集 UPDATE STATISTICS可以更新某张表的统计信息，以提高查询性能 3.5 Row timestamp 时间戳 从4.6版本开始，Phoenix提供了一种将HBase原生的row timestamp映射到Phoenix列的方法。这样有利于充分利用HBase提供的针对存储文件的时间范围的各种优化，以及Phoenix内置的各种查询优化。 3.6 Paged Queries 分页查询 Phoenix支持分页查询： Row Value Constructors (RVC) OFFSET with limit 3.7 Salted Tables 散步表 如果row key是自动增长的，那么HBase的顺序写会导致region server产生数据热点的问题，Phoenix的Salted Tables技术可以解决region server的热点问题 3.8 Skip Scan 跳跃扫描 可以在范围扫描的时候提高性能 3.9 Views 视图 标准的SQL视图语法现在在Phoenix上也支持了。这使得能在同一张底层HBase物理表上创建多个虚拟表。 3.10 Multi tenancy 多租户 通过指定不同的租户连接实现数据访问的隔离 3.11 Dynamic Columns 动态列 Phoenix 1.2, specifying columns dynamically is now supported by allowing column definitions to included in parenthesis after the table in the FROM clause on a SELECT statement. Although this is not standard SQL, it is useful to surface this type of functionality to leverage the late binding ability of HBase. 3.12 Bulk CSV Data Loading 大量CSV数据加载 加载CSV数据到Phoenix表有两种方式：1. 通过psql命令以单线程的方式加载，数据量少的情况下适用。 2. 基于MapReduce的bulk load工具，适用于数据量大的情况 3.13 Query Server 查询服务器 Phoenix4.4引入的一个单独的服务器来提供thin客户端的连接 3.14 Tracing 追踪 从4.1版本开始Phoenix增加这个特性来追踪每条查询的踪迹，这使用户能够看到每一条查询或插入操作背后从客户端到HBase端执行的每一步。 3.15 Metrics 指标 Phoenix提供各种各样的指标使我们能够知道Phoenix客户端在执行不同SQL语句的时候其内部发生了什么。这些指标在客户端JVM中通过两种方式来收集： Request level metrics - collected at an individual SQL statementlevel Global metrics - collected at the client JVM level 4. 架构和组成 Phoenix架构 Phoenix在Hadoop生态系统中的位置 5. 数据存储 Phoenix将HBase的数据模型映射到关系型世界 6. 对QL的支持支持的命令如下： SELECT Example:SELECT * FROM TEST LIMIT 1000;SELECT * FROM TEST LIMIT 1000 OFFSET 100;SELECT full_name FROM SALES_PERSON WHERE ranking &gt;= 5.0 UNION ALL SELECT reviewer_name FROM CUSTOMER_REVIEW WHERE score &gt;= 8.0 UPSERT VALUES Example:UPSERT INTO TEST VALUES(&apos;foo&apos;,&apos;bar&apos;,3);UPSERT INTO TEST(NAME,ID) VALUES(&apos;foo&apos;,123); UPSERT SELECT Example:UPSERT INTO test.targetTable(col1, col2) SELECT col3, col4 FROM test.sourceTable WHERE col5 &lt; 100UPSERT INTO foo SELECT * FROM bar; DELETE Example:DELETE FROM TEST;DELETE FROM TEST WHERE ID=123;DELETE FROM TEST WHERE NAME LIKE &apos;foo%&apos;; CREATE TABLE CREATE TABLE my_schema.my_table ( id BIGINT not null primary key, date)CREATE TABLE my_table ( id INTEGER not null primary key desc, date DATE not null,m.db_utilization DECIMAL, i.db_utilization) m.DATA_BLOCK_ENCODING=&apos;DIFF&apos;CREATE TABLE stats.prod_metrics ( host char(50) not null, created_date date not null,txn_count bigint CONSTRAINT pk PRIMARY KEY (host, created_date) )CREATE TABLE IF NOT EXISTS &quot;my_case_sensitive_table&quot; ( &quot;id&quot; char(10) not null primary key, &quot;value&quot; integer) DATA_BLOCK_ENCODING=&apos;NONE&apos;,VERSIONS=5,MAX_FILESIZE=2000000 split on (?, ?, ?)CREATE TABLE IF NOT EXISTS my_schema.my_table (org_id CHAR(15), entity_id CHAR(15), payload binary(1000),CONSTRAINT pk PRIMARY KEY (org_id, entity_id) )TTL=86400 DROP TABLE Example:DROP TABLE my_schema.my_table;DROP TABLE IF EXISTS my_table;DROP TABLE my_schema.my_table CASCADE; CREATE FUNCTION Example:CREATE FUNCTION my_reverse(varchar) returns varchar as &apos;com.mypackage.MyReverseFunction&apos; using jar &apos;hdfs:/localhost:8080/hbase/lib/myjar.jar&apos;CREATE FUNCTION my_reverse(varchar) returns varchar as &apos;com.mypackage.MyReverseFunction&apos;CREATE FUNCTION my_increment(integer, integer constant defaultvalue=&apos;10&apos;) returns integer as &apos;com.mypackage.MyIncrementFunction&apos; using jar &apos;/hbase/lib/myincrement.jar&apos;CREATE TEMPORARY FUNCTION my_reverse(varchar) returns varchar as &apos;com.mypackage.MyReverseFunction&apos; using jar &apos;hdfs:/localhost:8080/hbase/lib/myjar.jar&apos; DROP FUNCTION Example:DROP FUNCTION IF EXISTS my_reverseDROP FUNCTION my_reverse CREATE VIEW Example:CREATE VIEW &quot;my_hbase_table&quot;( k VARCHAR primary key, &quot;v&quot; UNSIGNED_LONG) default_column_family=&apos;a&apos;;CREATE VIEW my_view ( new_col SMALLINT ) AS SELECT * FROM my_table WHERE k = 100;CREATE VIEW my_view_on_view AS SELECT * FROM my_view WHERE new_col &gt; 70; DROP VIEW Example:DROP VIEW my_viewDROP VIEW IF EXISTS my_schema.my_viewDROP VIEW IF EXISTS my_schema.my_view CASCADE CREATE SEQUENCE Example:CREATE SEQUENCE my_sequence;CREATE SEQUENCE my_sequence START WITH -1000CREATE SEQUENCE my_sequence INCREMENT BY 10CREATE SEQUENCE my_schema.my_sequence START 0 CACHE 10 DROP SEQUENCE Example:DROP SEQUENCE my_sequenceDROP SEQUENCE IF EXISTS my_schema.my_sequence ALTER Example:ALTER TABLE my_schema.my_table ADD d.dept_id char(10) VERSIONS=10ALTER TABLE my_table ADD dept_name char(50), parent_id char(15) null primary keyALTER TABLE my_table DROP COLUMN d.dept_id, parent_id;ALTER VIEW my_view DROP COLUMN new_col;ALTER TABLE my_table SET IMMUTABLE_ROWS=true,DISABLE_WAL=true; CREATE INDEX Example:CREATE INDEX my_idx ON sales.opportunity(last_updated_date DESC)CREATE INDEX my_idx ON log.event(created_date DESC) INCLUDE (name, payload) SALT_BUCKETS=10CREATE INDEX IF NOT EXISTS my_comp_idx ON server_metrics ( gc_time DESC, created_date DESC ) DATA_BLOCK_ENCODING=&apos;NONE&apos;,VERSIONS=?,MAX_FILESIZE=2000000 split on (?, ?, ?)CREATE INDEX my_idx ON sales.opportunity(UPPER(contact_name)) DROP INDEX Example:DROP INDEX my_idx ON sales.opportunityDROP INDEX IF EXISTS my_idx ON server_metrics ALTER INDEX Example:ALTER INDEX my_idx ON sales.opportunity DISABLEALTER INDEX IF EXISTS my_idx ON server_metrics REBUILD EXPLAIN Example:EXPLAIN SELECT NAME, COUNT(*) FROM TEST GROUP BY NAME HAVING COUNT(*) &gt; 2;EXPLAIN SELECT entity_id FROM CORE.CUSTOM_ENTITY_DATA WHERE organization_id=&apos;00D300000000XHP&apos; AND SUBSTR(entity_id,1,3) = &apos;002&apos; AND created_date &lt; CURRENT_DATE()-1; UPDATE STATISTICS Example:UPDATE STATISTICS my_tableUPDATE STATISTICS my_schema.my_table INDEXUPDATE STATISTICS my_indexUPDATE STATISTICS my_table COLUMNSUPDATE STATISTICS my_table SET phoenix.stats.guidepost.width=50000000 CREATE SCHEMA Example:CREATE SCHEMA IF NOT EXISTS my_schemaCREATE SCHEMA my_schema USE Example:USE my_schemaUSE DEFAULT DROP SCHEMA Example:DROP SCHEMA IF EXISTS my_schemaDROP SCHEMA my_schema 7. 安装部署7.1 安装预编译的Phoenix 下载并解压最新版的phoenix-[version]-bin.tar包 将phoenix-[version]-server.jar放入服务端和master节点的HBase的lib目录下 重启HBase 将phoenix-[version]-client.jar添加到所有Phoenix客户端的classpath 7.2 使用Phoenix7.2.1 命令行若要在命令行执行交互式SQL语句： 1.切换到bin目录 2.执行以下语句 $ sqlline.py localhost 若要在命令行执行SQL脚本 $ sqlline.py localhost ../examples/stock_symbol.sql 7.2.2 客户端 SQuirrel是用来连接Phoenix的客户端。 SQuirrel安装步骤如下： 1. Remove prior phoenix-[*oldversion*]-client.jar from the lib directory of SQuirrel, copy phoenix-[*newversion*]-client.jar to the lib directory (*newversion* should be compatible with the version of the phoenix server jar used with your HBase installation)2. Start SQuirrel and add new driver to SQuirrel (Drivers -&gt; New Driver)3. In Add Driver dialog box, set Name to Phoenix, and set the Example URL to jdbc:phoenix:localhost.4. Type “org.apache.phoenix.jdbc.PhoenixDriver” into the Class Name textbox and click OK to close this dialog.5. Switch to Alias tab and create the new Alias (Aliases -&gt; New Aliases)6. In the dialog box, Name: *any name*, Driver: Phoenix, User Name: *anything*, Password: *anything*7. Construct URL as follows: jdbc:phoenix: *zookeeper quorum server*. For example, to connect to a local HBase use: jdbc:phoenix:localhost8. Press Test (which should succeed if everything is setup correctly) and press OK to close.9. Now double click on your newly created Phoenix alias and click Connect. Now you are ready to run SQL queries against Phoenix. 8. 测试8.1 PherfPherf是可以通过Phoenix来进行性能和功能测试的工具。Pherf可以用来生成高度定制的数据集，并且测试SQL在这些数据集上的性能。 8.1.1 构建PherfPherf是在用maven构建Phoenix的过程中同时构建的。可以用两种不同的配置来构建： 集群（默认） This profile builds Pherf such that it can run along side an existing cluster. The dependencies are pulled from the HBase classpath. 独立 This profile builds all of Pherf’s dependencies into a single standalone jar. The deps will be pulled from the versions specified in Phoenix’s pom. 构建全部的Phoenix。包含Pherf的默认配置。 mvn clean package -DskipTests 用Pherf的独立配置来构建Phoenix。 mvn clean package -P standalone -DskipTests 8.1.2 安装用以上的Maven命令构建完Pherf后，会在该模块的目标目录下生成一个zip文件。 将该zip文件解压到合适的目录 配置env.sh文件 ./pherf.sh -h 想要在一个真正的集群上测试，运行如下命令: ./pherf.sh -drop all -l -q -z localhost -schemaFile .*user_defined_schema.sql -scenarioFile .*user_defined_scenario.xml 8.1.3 命令示例 列出所有可运行的场景文件 $./pherf.sh -listFiles 删掉全部场景文件中存在的特定的表、加载和查询数据 $./pherf.sh -drop all -l -q -z localhost 8.1.4 参数 -h Help-l Apply schema and load data-q Executes Multi-threaded query sets and write results-z [quorum] Zookeeper quorum-m Enable monitor for statistics-monitorFrequency [frequency in Ms] _Frequency at which the monitor will snopshot stats to log file.-drop [pattern] Regex drop all tables with schema name as PHERF. Example drop Event tables: -drop .(EVENT). Drop all: -drop . or -drop all-scenarioFile Regex or file name of a specific scenario file to run.-schemaFile Regex or file name of a specific schema file to run.-export Exports query results to CSV files in CSV_EXPORT directory-diff Compares results with previously exported results-hint Executes all queries with specified hint. Example SMALL-rowCountOverride-rowCountOverride [number of rows] Specify number of rows to be upserted rather than using row count specified in schema 8.1.5 为数据生成增加规则8.1.6 定义场景8.1.7 结果结果实时写入结果目录中。可以打开.jpg格式文件来实时可视化。 8.1.8 测试 Run unit tests: mvn test -DZK_QUORUM=localhostRun a specific method: mvn -Dtest=ClassName#methodName testMore to come… 8.2 性能Phoenix通过以下方法来奉行把计算带到离数据近的地方的哲学： 协处理器在服务端执行操作来最小化服务端和客户端的数据传输 定制的过滤器为了删减数据使之尽可能地靠近源数据并最小化启动代价，Phoenix使用原生的HBase APIs而不是使用Map/Reduce框架 8.2.1 Phoenix对比相近产品8.2.1.1 Phoenix vs Hive (running over HDFS and HBase) Query: select count(1) from table over 10M and 100M rows. Data is 5 narrow columns. Number of Region Servers: 4 (HBase heap: 10GB, Processor: 6 cores @ 3.3GHz Xeon) 8.2.1.2 Phoenix vs Impala (running over HBase) Query: select count(1) from table over 1M and 5M rows. Data is 3 narrow columns. Number of Region Server: 1 (Virtual Machine, HBase heap: 2GB, Processor: 2 cores @ 3.3GHz Xeon) 8.2.2 Latest Automated Performance RunLatest Automated Performance Run | Automated Performance Runs History 8.2.3 Phoenix1.2性能提升 Essential Column Family Skip Scan Salting Top-N 9. 参考资料 http://phoenix.apache.org http://phoenix.apache.org/Phoenix-in-15-minutes-or-less.html http://hadooptutorial.info/apache-phoenix-hbase-an-sql-layer-on-hbase/ http://www.phoenixframework.org/docs/resources https://en.wikipedia.org/wiki/Apache_Phoenix","raw":null,"content":null,"categories":[{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/categories/Phoenix/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/tags/Phoenix/"}]},{"title":"Phoenix查询经验总结","slug":"Phoenix查询测试经验总结","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Phoenix查询测试经验总结/","link":"","permalink":"http://linbingdong.com/2017/03/11/Phoenix查询测试经验总结/","excerpt":"适当的索引能够让极大提升查询速度，因此在Phoenix查询的测试用例中包括了对有索引跟无索引的查询性能的比较。测试过程中遇到一些问题，经过探索，得到一些结论，在此记录下来。","text":"适当的索引能够让极大提升查询速度，因此在Phoenix查询的测试用例中包括了对有索引跟无索引的查询性能的比较。测试过程中遇到一些问题，经过探索，得到一些结论，在此记录下来。 1. 背景适当的索引能够让极大提升查询速度，因此在Phoenix查询的测试用例中包括了对有索引跟无索引的查询性能的比较。测试过程中遇到一些问题，在此记录下来。 2. 问题及解决2.1. 创建索引时报错，报错如下：//创建索引语句：0: jdbc:phoenix:localhost&gt; CREATE INDEX ind_1 ON TESTINPUT(ff1);//报错：Error: ERROR 1029 (42Y88): Mutable secondary indexes must have the hbase.regionserver.wal.codec property set to org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec in the hbase-sites.xml of every region server tableName=IND_1 (state=42Y88,code=1029)java.sql.SQLException: ERROR 1029 (42Y88): Mutable secondary indexes must have the hbase.regionserver.wal.codec property set to org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec in the hbase-sites.xml of every region server tableName=IND_1 at org.apache.phoenix.exception.SQLExceptionCode$Factory$1.newException(SQLExceptionCode.java:396) at org.apache.phoenix.exception.SQLExceptionInfo.buildException(SQLExceptionInfo.java:145) at org.apache.phoenix.schema.MetaDataClient.createIndex(MetaDataClient.java:1162) at org.apache.phoenix.compile.CreateIndexCompiler$1.execute(CreateIndexCompiler.java:95) at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:322) at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:314) at org.apache.phoenix.call.CallRunner.run(CallRunner.java:53) at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation(PhoenixStatement.java:312) at org.apache.phoenix.jdbc.PhoenixStatement.execute(PhoenixStatement.java:1435) at sqlline.Commands.execute(Commands.java:822) at sqlline.Commands.sql(Commands.java:732) at sqlline.SqlLine.dispatch(SqlLine.java:808) at sqlline.SqlLine.begin(SqlLine.java:681) at sqlline.SqlLine.start(SqlLine.java:398) at sqlline.SqlLine.main(SqlLine.java:292) 原因：Phoenix支持两种索引：可变索引跟不可变索引。在可变表上建的索引是可变索引，在不可变表上建的索引是不可变索引。可变索引是指插入或删除数据的时候会同时更新索引；不可变索引适用于只写入一次不再更改的表，索引只建立一次，再插入数据不会更新索引。上面使用的语句是创建可变索引，需要在hbase-site.xml中进行相关配置使其支持可变索引（不可变索引无需另外配置，默认支持）。 解决：对HMaster和HRegionserver节点分别增加配置,然后重启HBase集群 HMaster &lt;property&gt; &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.loadbalancer.class&lt;/name&gt; &lt;value&gt;org.apache.phoenix.hbase.index.balancer.IndexLoadBalancer&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt; &lt;value&gt;org.apache.phoenix.hbase.index.master.IndexMasterObserver&lt;/value&gt;&lt;/property&gt; HRegionserver &lt;property&gt; &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.region.server.rpc.scheduler.factory.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.ipc.PhoenixRpcSchedulerFactory&lt;/value&gt; &lt;description&gt;Factory to create the Phoenix RPC Scheduler that usesseparate queues for index and metadata updates&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rpc.controllerfactory.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.ipc.controller.ServerRpcControllerFactory&lt;/value&gt; &lt;description&gt;Factory to create the Phoenix RPCScheduler that uses separate queues for index and metadataupdates&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.coprocessor.regionserver.classes&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.regionserver.LocalIndexMerger&lt;/value&gt;&lt;/property&gt; 2.2. 对10亿数据查询时，报错如下：16/11/29 10:33:50 WARN client.ScannerCallable: Ignore, probably already closedorg.apache.hadoop.hbase.regionserver.LeaseException: org.apache.hadoop.hbase.regionserver.LeaseException: lease &apos;1132&apos; does not exist at org.apache.hadoop.hbase.regionserver.Leases.removeLease(Leases.java:221) at org.apache.hadoop.hbase.regionserver.Leases.cancelLease(Leases.java:206)...org.apache.phoenix.exception.PhoenixIOException: org.apache.phoenix.exception.PhoenixIOException: Failed after attempts=36, exceptions:Tue Nov 29 10:33:50 CST 2016, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60321: row &apos;��s,d&apos; on table &apos;TEST11&apos; at region=TEST11,\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00,1479985615575.c3adb68acea8d88d223bffd3acc16c2e., hostname=node-20-105,60020,1480385981798, seqNum=1244662...Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=18173, waitTime=60001, operationTimeout=60000 expired. at org.apache.hadoop.hbase.ipc.Call.checkAndSetTimeout(Call.java:70) at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1197)... 原因： 某些查询需要很长时间才能返回结果，被HBase的超时机制杀掉了。 思路： 增大超时时间，在hbase-site.xml里增加了如下配置： &lt;property&gt; &lt;name&gt;hbase.rpc.timeout&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.client.operation.timeout&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.client.scanner.timeout.period&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;phoenix.query.timeoutMs&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;phoenix.query.keepAliveMs&lt;/name&gt; &lt;value&gt;600000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.client.ipc.pool.type&lt;/name&gt; &lt;value&gt;RoundRobinPool&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.client.ipc.pool.size&lt;/name&gt; &lt;value&gt;10&lt;/value&gt;&lt;/property&gt; 最终虽然配置生效了，但是还是报同样的错。已经将网上说的可能的配置项都配了还是无法解决超时问题。等增加了机器，查询时间变短，10亿数据的查询应该就没有超时问题了。 3. 特性 不可变索引默认支持，不需要另外配置；可变索引需要如上添加配置才能支持 创建不可变表： CREATE TABLE TABLENAME (pk long PRIMARY KEY,col1 int) IMMUTABLE_ROWS=true; 创建索引有以下几种方式： CREATE INDEX ind_name ON TABLENAME(COLUMN1);CREATE INDEX ind_name ON TABLENAME(COLUMN1,COLUMN2);CREATE INDEX ind_name ON TABLENAME(COLUMN1) INCLUDE(COLUMN2); 执行查询的时候，Phoenix查询优化器将选择合适的索引。可以使用explain plan进行查看 0: jdbc:phoenix:localhost&gt; explain select ff3,if1 from testinput where ff3 &gt;= 0.7 and ff3 &lt; 0.9 order by if1;+------------------------------------------+| PLAN |+------------------------------------------+| CLIENT 1-CHUNK PARALLEL 1-WAY RANGE SCAN OVER IND_4 [0.7] - [0.9] || SERVER SORTED BY [&quot;IF1&quot;] || CLIENT MERGE SORT |+------------------------------------------+ 除非所有查询使用的列被索引或者覆盖列，否则二级索引不会被使用 建索引的时候不要包括primary key，否则索引不会被使用；可以单独对primary key建索引 where条件里有primary key的时候会使用Range Scan，因为表本来就是按照primary key的顺序排列的 primary key在插入时是自动排序的，插入完成后primary key保持有序（如果该表只有一个分区，则全局有序；如果有多个分区，则在每个分区内部有序，并非全局有序） 对某几个（1个或多个）列建索引，则会生成一张索引表，该表由创建索引的这几个列组成，并在最后一列添加primary key列。也就是说索引表也是一张表，只不过该表列数比原表少。 索引表的第一列是有序的 upsert into一个跟之前一样的primary key，会将之前那个primary key的记录替换成新的。 phoenix虽然不支持update语句，但是可以用upsert into tablename(id,columnname) values(id,newvalue)来实现同样的功能。 local index 对应的索引表的分区跟表的分区在同一个region server上（索引表分区数必须跟表分区数一样） global index 对应的索引表的分区跟表的分区不一定在同一个region server上（索引表分区数必须跟表分区数一样） 对一张表建了多个local index，对于HBase来讲，其实只存了一张索引表。但是global index则不同。 4. 参考资料 https://github.com/forcedotcom/phoenix/wiki/Secondary-Indexing http://phoenix.apache.org/language/index.html#create_index http://blog.csdn.net/jiangshouzhuang/article/details/52387718","raw":null,"content":null,"categories":[{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/categories/Phoenix/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/tags/Phoenix/"}]},{"title":"Phoenix表和索引分区数对插入和查询性能的影响","slug":"Phoenix表和索引分区数对插入和查询性能的影响","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Phoenix表和索引分区数对插入和查询性能的影响/","link":"","permalink":"http://linbingdong.com/2017/03/11/Phoenix表和索引分区数对插入和查询性能的影响/","excerpt":"Phoenix在建表和建索引的时候可以指定SALT_BUCKETS数，即分区数，从而提高插入和查询性能。\n通过指定分区，可以将对一张表的操作分配给多个Region Server进行处理，从而提高效率。 ","text":"Phoenix在建表和建索引的时候可以指定SALT_BUCKETS数，即分区数，从而提高插入和查询性能。 通过指定分区，可以将对一张表的操作分配给多个Region Server进行处理，从而提高效率。 1. 概述1.1 HBase概述HBase由master节点和region server节点组成。在100-105集群上，100和101是master节点，102-105是region server节点。 每个region server管理很多region，每个region只会属于一个region server。一个region的大小可以自己配置（100-105集群上一个region大小为100GB）。 在HBase中创建一张表时，刚开始默认是一个region，若表越来越大，超过一个region的大小，则会split成两个region。当然也可以在建表的时候预分区几个region，如果表的大小超过了预分区的region的大小也会split。 1.2 Phoenix分区Phoenix在建表和建索引的时候可以指定SALT_BUCKETS数，即分区数，从而提高插入和查询性能。方式如下： CREATE TABLE IF NOT EXISTS test1 (pk BIGINT PRIMARY KEY,ff1 DOUBLE,sf1 VARCHAR,if1 INTEGER) SALT_BUCKETS=20; 通过指定分区，可以将对一张表的操作分配给多个Region Server进行处理，从而提高效率。 但是官网上并没有对分区数应设为多少比较合适给出建议，网上有博客说应该指定为region server总CPU核数的0.5~1倍之间。测试集群region sever每个节点40核，4个节点共160核。 1.3 目的测试并确定分区数对Phoenix插入和查询性能的影响，确定当前集群在表分区和索引分区数分别为多少的情况下性能最优，接下来Phoenix性能测试采用该最优方案。 2. 方案2.1 方案设计创建多张表，除了表和索引的分区数不同外其他条件均相同，分别执行插入和查询操作，对比插入和查询时间。 相同的条件有： 用90*2线程执行插入 用1个线程进行查询 每轮查询执行42条查询语句，重复10次 表的总记录数为1000万 表的字段数和每个字段的类型 每个表都建3个global index 示例： CREATE TABLE IF NOT EXISTS test4 (pk BIGINT PRIMARY KEY,ff1 DOUBLE,ff2 DOUBLE,sf1 VARCHAR,if1 INTEGER,if2 INTEGER,if3 INTEGER,if4 INTEGER,if5 INTEGER,if6 INTEGER) SALT_BUCKETS=40;CREATE INDEX ind_l4 ON test4(pk) SALT_BUCKETS=20;CREATE INDEX ind_l4_1 ON test4(ff1,ff2,sf1) SALT_BUCKETS=20;CREATE INDEX ind_l4_2 ON test4(if1) SALT_BUCKETS=20; 注：若只指定了表的分区数，未指定索引的分区数，则默认索引的分区数跟表分区数一样。 2.2 测试用例 用例编号 表分区数 索引分区数 插入时间 查询时间 T1 0 0 T2 12 12 T3 20 1 T4 20 20 T5 40 20 T6 40 40 T7 60 60 T8 80 12 T9 80 40 T10 80 80 T11 120 40 T12 120 120 3. 结果3.1 软硬件环境 Master服务器 IP：192.168.20.100,192.168.20.101 硬件： CPU：Intel E5-2670v3 * 2（2.3GHz、L3 Cache 25M）vCore:40 内存：16G DDR4 * 16 2133 MHz Cache 28G 硬盘：SAS硬盘 2（300G、2.5吋、10K） SAS硬盘 12（3T、2.5吋、7200转） 网卡： 曙光万兆双口光纤（含光模块） * 1 软件： Centos 7 jdk-7u65-linux-x64 Phoenix 4.6 HBase 1.0.0 Region服务器 IP：192.168.20.102, 192.168.20.103, 192.168.20.104, 192.168.20.105 硬件： CPU：Intel E5-2670v3 * 2（2.3GHz、L3 Cache 25M）vCore:40 内存：16G DDR4 * 16 2133 MHz Cache 28G 硬盘：SAS硬盘 2（300G、2.5吋、10K） SAS硬盘 12（3T、2.5吋、7200转） 网卡： 曙光万兆双口光纤（含光模块） * 1 软件： Centos 7 jdk-7u65-linux-x64 HBase 1.0.0 客户端服务器 IP：192.168.20.100,192.168.20.102 硬件： CPU：Intel E5-2670v3 * 2（2.3GHz、L3 Cache 25M）vCore:40 内存：16G DDR4 * 16 2133 MHz Cache 28G 硬盘：SAS硬盘 2（300G、2.5吋、10K） SAS硬盘 12（3T、2.5吋、7200转） 网卡： 曙光万兆双口光纤（含光模块） * 1 软件： Centos 7 jdk-7u65-linux-x64 HBase 1.0.0 Phoenix客户端 IP：192.168.20.101 硬件： CPU：Intel E5-2670v3 * 2（2.3GHz、L3 Cache 25M）vCore:40 内存：16G DDR4 * 16 2133 MHz Cache 28G 硬盘：SAS硬盘 2（300G、2.5吋、10K） SAS硬盘 12（3T、2.5吋、7200转） 网卡： 曙光万兆双口光纤（含光模块） * 1 软件： Centos 7 jdk-7u65-linux-x64 Phoenix 4.6 HBase 1.0.0 3.2 结果 用例编号 表分区数 索引分区数 插入时间 查询时间 T1 0 0 779 4490 T2 12 12 303 735 T3 20 1 203 1200 T4 20 20 319 697 T5 40 20 380 592 T6 40 40 369 531 T7 60 60 441 587 T8 80 12 384 714 T9 80 40 522 653 T10 80 80 478 623 T11 120 40 512 764 T12 120 120 526 753 插入时间和查询时间单位均为秒。查询时间为执行42个查询每个查询10次的总时间。 4. 分析通过观察3.2结果中的数据，可得出以下结论： 对比T1和其他可知，有分区相对无分区在插入和查询上都有极大的性能提升。 对比T3和T4,T8和T9可知，在一定范围内，增大索引分区数使插入变慢，查询变快。 对比T11和T12可知，当索引分区达到一定大小后，再增加分区数已经无法提升查询性能。 综合比较来看，当前集群在表分区数和索引分区数均为40时插入和查询的综合性能最好。 因此，Phoenix的性能测试中将采用表分区数和索引分区数均为40的方案。","raw":null,"content":null,"categories":[{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/categories/Phoenix/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Phoenix","slug":"Phoenix","permalink":"http://linbingdong.com/tags/Phoenix/"}]},{"title":"PostgreSQL主从流复制部署","slug":"PostgreSQL主从流复制部署","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/PostgreSQL主从流复制部署/","link":"","permalink":"http://linbingdong.com/2017/03/11/PostgreSQL主从流复制部署/","excerpt":"PostgreSQL在9.0之后引入了主从的流复制机制，所谓流复制，就是从服务器通过tcp流从主服务器中同步相应的数据。这样当主服务器数据丢失时从服务器中仍有备份。","text":"PostgreSQL在9.0之后引入了主从的流复制机制，所谓流复制，就是从服务器通过tcp流从主服务器中同步相应的数据。这样当主服务器数据丢失时从服务器中仍有备份。 192.168.20.93上部署主服务器，192.168.20.94上部署从服务器。 1. 简介PostgreSQL在9.0之后引入了主从的流复制机制，所谓流复制，就是从服务器通过tcp流从主服务器中同步相应的数据。这样当主服务器数据丢失时从服务器中仍有备份。 与基于文件日志传送相比，流复制允许保持从服务器更新。 从服务器连接主服务器，其产生的流WAL记录到从服务器， 而不需要等待主服务器写完WAL文件。 PostgreSQL流复制默认是异步的。在主服务器上提交事务和从服务器上变化可见之间有一个小的延迟，这个延迟远小于基于文件日志传送，通常1秒能完成。如果主服务器突然崩溃，可能会有少量数据丢失。 同步复制必须等主服务器和从服务器都写完WAL后才能提交事务。这样在一定程度上会增加事务的响应时间。 配置同步复制仅需要一个额外的配置步骤： synchronous_standby_names必须设置为一个非空值。synchronous_commit也必须设置为on。 这里部署的是异步的流复制。 注:主从服务器所在节点的系统、环境\u0001等最好一致。PostgreSQL版本也最好一致，否则可能会有问题。 2. 安装部署先在192.168.20.93和192.168.20.94均安装PostgreSQL。 具体安装部署步骤见：PostgreSQL单机部署（CentOS7） 2.1 主服务器主服务器为192.168.20.93 先创建一个新目录： mkdir /opt/pgsql/pg_archive 1.首先需要创建一个数据库用户进行主从同步。创建用户replica，并赋予登录和复制的权限。 postgres# CREATE ROLE replica login replication encrypted password &apos;replica&apos; 2.修改pg_hba.conf，允许replica用户来同步。 在pg_hba.conf里增加两行： host all all 192.168.20.94/32 trust #允许94连接到主服务器host replication replica 192.168.20.94/32 md5 #允许94使用replica用户来复制 这样，就设置了replica这个用户可以从192.168.20.93进行流复制请求。 注：第二个字段必须要填replication 4.修改postgresql.conf listen_addresses = &apos;*&apos; # 监听所有IParchive_mode = on # 允许归档archive_command = &apos;cp %p /opt/pgsql/pg_archive/%f&apos; # 用该命令来归档logfile segmentwal_level = hot_standby max_wal_senders = 32 # 这个设置了可以最多有几个流复制连接，差不多有几个从，就设置几个wal_keep_segments = 256 ＃ 设置流复制保留的最多的xlog数目wal_sender_timeout = 60s ＃ 设置流复制主机发送数据的超时时间max_connections = 100 # 这个设置要注意下，从库的max_connections必须要大于主库的 配置完两个文件后重启服务器。 pg_ctl stop -D /opt/pgsql/datapg_ctl start -D /opt/pgsql/data 3.测试94能否连接93数据库。在94上运行如下命令： psql -h 192.168.20.93 -U postgres 看看是否能进入数据库。若可以，则正常。 2.2 从服务器1.从主节点拷贝数据到从节点 su - postgresrm -rf /opt/pgsql/data/* #先将data目录下的数据都清空pg_basebackup -h 192.168.20.93 -U replica -D /opt/pgsql/data -X stream -P # 从93拷贝数据到94（基础备份）mkdir /opt/pgsql/pg_archive 2.配置recovery.conf 复制/usr/pgsql-9.4/share/recovery.conf.sample 到 /opt/pgsql/data/recovery.conf cp /usr/pgsql-9.4/share/recovery.conf.sample /opt/pgsql/data/recovery.conf 修改recovery.conf standby_mode = on # 说明该节点是从服务器primary_conninfo = &apos;host=192.168.20.93 port=5432 user=replica password=replica&apos; # 主服务器的信息以及连接的用户recovery_target_timeline = &apos;latest&apos; 3.配置postgresql.conf wal_level = hot_standbymax_connections = 1000 ＃ 一般查多于写的应用从库的最大连接数要比较大hot_standby = on ＃ 说明这台机器不仅仅是用于数据归档，也用于数据查询max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间wal_receiver_status_interval = 10s # 多久向主报告一次从的状态，当然从每次数据复制都会向主报告状态，这里只是设置最长的间隔时间hot_standby_feedback = on # 如果有错误的数据复制，是否向主进行反馈 配置完后重启从服务器 pg_ctl stop -D /opt/pgsql/datapg_ctl start -D /opt/pgsql/data 3. 验证是否部署成功在主节点上执行： select client_addr,sync_state from pg_stat_replication; 结果如下： postgres=# select client_addr,sync_state from pg_stat_replication; client_addr | sync_state---------------+------------ 192.168.20.94 | async(1 行记录) 说明94是从服务器，在接收流，而且是异步流复制。 此外，还可以分别在主、从节点上运行 ps aux | grep postgres 来查看进程： 主服务器（93）上： postgres 262270 0.0 0.0 337844 2832 ? Ss 10:14 0:00 postgres: wal sender process replica 192.168.20.94(13059) streaming 0/A002A88 可以看到有一个 wal sender 进程。 从服务器（94）上： postgres 569868 0.0 0.0 384604 2960 ? Ss 10:14 0:02 postgres: wal receiver process streaming 0/A002B60 可以看到有一个 wal receiver 进程。 至此，PostgreSQL主从流复制安装部署完成。 在主服务器上插入数据或删除数据，在从服务器上能看到相应的变化。从服务器上只能查询，不能插入或删除。","raw":null,"content":null,"categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/categories/PostgreSQL/"}],"tags":[{"name":"关系数据库","slug":"关系数据库","permalink":"http://linbingdong.com/tags/关系数据库/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/tags/PostgreSQL/"}]},{"title":"PostgreSQL单机部署（CentOS7）","slug":"PostgreSQL单机部署（CentOS7）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/PostgreSQL单机部署（CentOS7）/","link":"","permalink":"http://linbingdong.com/2017/03/11/PostgreSQL单机部署（CentOS7）/","excerpt":"本文介绍Contos7上用yum部署PostgreSQL9.4的过程。","text":"本文介绍Contos7上用yum部署PostgreSQL9.4的过程。 1. 安装PostgreSQL源rpm -Uvh http://yum.postgresql.org/9.4/redhat/rhel-7-x86_64/pgdg-centos94-9.4-1.noarch.rpm 2. 执行安装命令yum updateyum install postgresql94-server postgresql94-contrib 3. 验证是否安装成功执行： rpm -qa | grep postgres 结果： postgresql94-9.4.10-1PGDG.rhel7.x86_64postgresql94-server-9.4.10-1PGDG.rhel7.x86_64postgresql94-libs-9.4.10-1PGDG.rhel7.x86_64postgresql94-contrib-9.4.10-1PGDG.rhel7.x86_64 说明安装成功 4. 初始化数据库先创建数据存放目录： mkdir -p /opt/pgsql/data 赋予postgres用户该目录的权限： chown postgres /opt/pgsql/data 切换到postgres用户： su postgres 执行初始化： initdb -D /opt/pgsql/data 注： -D 后面是数据库文件存放的目录，如果不指定则默认在/var/lib/pgsql/9.4/data下 初始化的日志如下： 属于此数据库系统的文件宿主为用户 &quot;postgres&quot;.此用户也必须为服务器进程的宿主.数据库簇将使用本地化语言 &quot;zh_CN.UTF-8&quot;进行初始化.默认的数据库编码已经相应的设置为 &quot;UTF8&quot;.initdb: 无法为本地化语言环境&quot;zh_CN.UTF-8&quot;找到合适的文本搜索配置缺省的文本搜索配置将会被设置到&quot;simple&quot;禁止为数据页生成校验和.修复已存在目录 /opt/pgsql/data 的权限 ... 成功正在创建子目录 ... 成功选择默认最大联接数 (max_connections) ... 100选择默认共享缓冲区大小 (shared_buffers) ... 128MB选择动态共享内存实现 ......posix创建配置文件 ... 成功在 /opt/pgsql/data/base/1 中创建 template1 数据库 ... 成功初始化 pg_authid ... 成功初始化dependencies ... 成功创建系统视图 ... 成功正在加载系统对象描述 ...成功创建(字符集)校对规则 ... 成功创建字符集转换 ... 成功正在创建字典 ... 成功对内建对象设置权限 ... 成功创建信息模式 ... 成功正在装载PL/pgSQL服务器端编程语言...成功清理数据库 template1 ... 成功拷贝 template1 到 template0 ... 成功拷贝 template1 到 template0 ... 成功同步数据到磁盘...成功成功. 您现在可以用下面的命令运行数据库服务器: /usr/pgsql-9.4/bin/postmaster -D /opt/pgsql/data/或者 /usr/pgsql-9.4/bin/pg_ctl -D /opt/pgsql/data/ -l logfile start 5. 启动服务1.切换到postgres用户 su postgres 这个步骤同样必须以PostgreSQL用户帐户登录来做。 2.启动服务 没有-D选项，服务器将使用环境变量PGDATA命名的目录； 如果这个环境变量也没有，将导致失败。通常，最好在后台启动postgres，使用下面的 Unix shell 语法： pg_ctl -D /opt/pgsql/data/ -l logfile start 3.设置开机自动启动 在Linux系统里，要么往/etc/rc.d/rc.local或 /etc/rc.local文件里加上下面几行： /usr/local/pgsql/bin/pg_ctl start -l logfile -D /usr/local/pgsql/data 6. 创建用户PostgreSQL使用角色的概念管理数据库访问权限。 根据角色自身的设置不同，一个角色可以看做是一个数据库用户，或者一组数据库用户。 角色可以拥有数据库对象(比如表)以及可以把这些对象上的权限赋予其它角色， 以控制谁拥有访问哪些对象的权限。另外，我们也可以把一个角色的成员 权限赋予其它角色，这样就允许成员角色使用分配给另一个角色的权限。角色的概念替换了”用户”和”组”。在PostgreSQL 版本 8.1 之前，用户和组是独立类型的记录，但现在它们只是角色。 任何角色都可以是一个用户、一个组、或者两者。 数据库角色从概念上与操作系统用户是完全无关的。在实际使用中把它们对应起来可能比较方便， 但这不是必须的。数据库角色在整个数据库集群中是全局的(而不是每个库不同)。 要创建一个角色，使用 SQL 命令CREATE ROLE执行： CREATE ROLE name; name遵循 SQL 标识的规则：要么完全没有特殊字符， 要么用双引号包围(实际上你通常会给命令增加额外的选项，比如LOGIN。 下面显示更多细节)。要删除一个现有角色，使用类似的DROP ROLE命令： DROP ROLE name; 为了方便，程序createuser和dropuser 提供了对了这些 SQL 命令的封装。我们可以在 shell 命令上直接调用它们： 直接在shell里输入： createuser lbd; 这样就创建了lbd这个角色。 dropuser lbd; 这样就创建了lbd这个角色。 要检查现有角色的集合，可以检查pg_roles系统表，比如： SELECT rolname FROM pg_roles; 结果如下： postgres=# SELECT rolname FROM pg_roles; rolname---------- postgres lbd(2 行记录) psql的元命令\\du也可以用于列出现有角色。 结果如下： postgres=# \\du 角色列表 角色名称 | 属性 | 成员属于---------+----------------------------------+---------- lbd | | &#123;&#125; postgres| 超级用户, 建立角色, 建立 DB, 复制 | &#123;&#125;","raw":null,"content":null,"categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/categories/PostgreSQL/"}],"tags":[{"name":"关系数据库","slug":"关系数据库","permalink":"http://linbingdong.com/tags/关系数据库/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/tags/PostgreSQL/"}]},{"title":"Java I/O 操作示例","slug":"Java I:O 操作示例","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java I:O 操作示例/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java I:O 操作示例/","excerpt":"给出几个Java I/O 操作的示例代码。","text":"给出几个Java I/O 操作的示例代码。 创建文件或目录import java.io.File;import java.io.IOException;public class TestFileIO &#123; public static void main(String[] args) &#123; File dir = new File(\"dir1\"); dir.mkdir(); //创建目录 File file = new File(dir,\"file1\"); //目录加文件名 File file2 = new File(\"dir1/file2\"); //完整路径 try &#123; file.createNewFile(); //创建文件,若存在同名文件,不会覆盖 file2.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 删除文件import java.io.File;public class TestFileIO &#123; public static void main(String[] args) &#123; File file = new File(\"dir1/file2\"); if (file.delete())&#123; System.out.println(file.getName() + \" is deleted!\"); &#125;else &#123; System.out.println(\"File is not deleted!\"); &#125; &#125;&#125; 向文件逐行写入内容(覆盖写） FileOutputStream import java.io.*;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; File fout = new File(\"dir1/file1\"); FileOutputStream fos = new FileOutputStream(fout); BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(fos)); for (int i = 0; i &lt; 10; i++)&#123; bw.write(\"something\"); bw.newLine(); &#125; bw.close(); &#125;&#125; FileWriter import java.io.*;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; File fout = new File(\"dir1/file1\"); FileWriter fw = new FileWriter(fout); for (int i = 0; i &lt; 10; i++)&#123; fw.write(\"something\" + System.getProperty(\"line.separator\")); &#125; fw.close(); &#125;&#125; PrintWriter import java.io.*;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; File fout = new File(\"dir1/file1\"); PrintWriter pw = new PrintWriter(new FileWriter(fout)); for (int i = 0; i &lt; 10; i++)&#123; pw.println(\"something\"); &#125; pw.close(); &#125;&#125; OutputStreamWriter import java.io.*;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; File fout = new File(\"dir1/file1\"); FileOutputStream fos = new FileOutputStream(fout); OutputStreamWriter osw = new OutputStreamWriter(fos); for (int i = 0; i &lt; 10; i++) &#123; osw.write(\"something\" + System.getProperty(\"line.separator\")); &#125; osw.close(); &#125;&#125; 注：往文本文件里写内容用FileWriter即可，比较方便。但是如果要自己定义字符编号和byte-buffer大小的话就要用FileOutputStream。 PrintWriter跟FileWriter的主要区别是PrintWriter可以格式化输出。该类实现了PrintStream的所有print方法。 追加写import java.io.*;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; File fout = new File(\"dir1/file1\"); FileOutputStream fos = new FileOutputStream(fout,true); //跟覆盖写唯一的区别是这里加了个true参数。 OutputStreamWriter osw = new OutputStreamWriter(fos); for (int i = 0; i &lt; 10; i++) &#123; osw.write(\"something\" + System.getProperty(\"line.separator\")); &#125; osw.close(); &#125;&#125; 拷贝文件import java.io.*;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;public class TestFileIO &#123; public static void main(String[] args) throws IOException &#123; Path sour = Paths.get(\"dir1/file1\"); Path des = Paths.get(\"dir1/file2\"); Files.copy(sour,des); //Files.copy(a,b)。 &#125;&#125; 合并多个文件读取多个文件的内容，写入一个文件。 import java.io.*;/** * Created by lbd on 2017/1/13. */public class MergeFiles &#123; public static void main(String[] args) throws IOException &#123; String sourceFile1Path = \"dir1/file1\"; String sourceFile2Path = \"dir1/file2\"; String mergedFilePath = \"dir1/mergedFile.txt\"; File[] files = new File[2]; files[0] = new File(sourceFile1Path); files[1] = new File(sourceFile2Path); File mergedFile = new File(mergedFilePath); mergeFiles(files,mergedFile); &#125; public static void mergeFiles(File[] files,File mergedFile) throws IOException &#123; FileWriter fw = new FileWriter(mergedFile,true); BufferedWriter bw = new BufferedWriter(fw); for (File f : files)&#123; System.out.println(\"merging: \" + f.getName()); FileReader fr = new FileReader(f); BufferedReader br = new BufferedReader(fr); String aLine; while ((aLine = br.readLine()) != null)&#123; bw.write(aLine); bw.newLine(); &#125; br.close(); &#125; bw.close(); &#125;&#125; 移动文件调用的是File.renameTo()方法。 import java.io.*;public class MoveFile &#123; public static void main(String[] args) throws IOException &#123; File f1 = new File(\"dir1/file1\"); File f2 = new File(\"dir1/dir2/file3\"); //dir2目录必须存在,否则无法移动成功 f1.renameTo(f2); &#125;&#125; 对文件内容排序file1内容如下： dog cat--windows--kankanppsgame--annot be guaranteed as it is, generally speaking, --impossible to make any hard guarantees in the p--resence of unsynchr 对行进行排序，以上面的文本为例，排序后arantees in the p应该在第一行 import java.io.*;import java.util.ArrayList;import java.util.Collections;/** * Created by lbd on 2017/1/13. */public class TestJavaIO &#123; public static void main(String[] args) throws IOException &#123; File fin = new File(\"file1\"); File fout = new File(\"file2\"); String s; FileWriter fw = new FileWriter(fout); FileReader fr = new FileReader(fin); BufferedReader br = new BufferedReader(fr); BufferedWriter bw = new BufferedWriter(fw); ArrayList&lt;String&gt; al = new ArrayList&lt;&gt;(); while ((s = br.readLine()) != null )&#123; if (!s.trim().startsWith(\"-\") &amp;&amp; s.trim().length() &gt; 0)&#123; al.add(s); &#125; &#125; Collections.sort(al); for (String line : al)&#123; bw.write(line); bw.newLine(); bw.write(\"------------------------------\"); bw.newLine(); &#125; br.close(); bw.close(); &#125;&#125; file2内容如下： arantees in the p------------------------------as it is, generally speaking, ------------------------------cat------------------------------dog ------------------------------game------------------------------pps------------------------------","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"Java I/O 总结","slug":"Java I:O总结","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java I:O总结/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java I:O总结/","excerpt":"Java中I/O操作主要是指使用Java进行输入，输出操作. Java所有的I/O机制都是基于数据流进行输入输出，这些数据流表示了字符或者字节数据的流动序列。","text":"Java中I/O操作主要是指使用Java进行输入，输出操作. Java所有的I/O机制都是基于数据流进行输入输出，这些数据流表示了字符或者字节数据的流动序列。 数据流是一串连续不断的数据的集合，就象水管里的水流，在水管的一端一点一点地供水，而在水管的另一端看到的是一股连续不断的水流。数据写入程序可以是一段、一段地向数据流管道中写入数据，这些数据段会按先后顺序形成一个长的数据流。对数据读取程序来说，看不到数据流在写入时的分段情况，每次可以读取其中的任意长度的数据，但只能先读取前面的数据后，再读取后面的数据（不能随机读取）。不管写入时是将数据分多次写入，还是作为一个整体一次写入，读取时的效果都是完全一样的。 简而言之：数据流是一组有序，有起点和终点的字节的数据序列。包括输入流和输出流。 当程序需要读取数据的时候，就会建立一个通向数据源的连接，这个数据源可以是文件，内存，或是网络连接。类似的，当程序需要写入数据的时候，就会建立一个通向目的地的连接。 数据流分类： 流序列中的数据既可以是未经加工的原始二进制数据，也可以是经一定编码处理后符合某种格式规定的特定数据。因此Java中的流分为两种： 1) 字节流：数据流中最小的数据单元是字节 2) 字符流：数据流中最小的数据单元是字符， Java中的字符是Unicode编码，一个字符占用两个字节。 概览Java.io包中最重要的就是5个类和一个接口。5个类指的是File、OutputStream、InputStream、Writer、Reader；一个接口指的是Serializable。掌握了这些就掌握了Java I/O的精髓了。 Java I/O主要包括如下3层次： 流式部分——最主要的部分。如：OutputStream、InputStream、Writer、Reader等 非流式部分——如：File类、RandomAccessFile类和FileDescriptor等类 其他——文件读取部分的与安全相关的类，如：SerializablePermission类，以及与本地操作系统相关的文件系统的类，如：FileSystem类和Win32FileSystem类和WinNTFileSystem类。 主要类如下： File（文件特征与管理）：用于文件或者目录的描述信息，例如生成新目录，修改文件名，删除文件，判断文件所在路径等。 InputStream（字节流，二进制格式操作）：抽象类，基于字节的输入操作，是所有输入流的父类。定义了所有输入流都具有的共同特征。 OutputStream（字节流，二进制格式操作）：抽象类。基于字节的输出操作。是所有输出流的父类。定义了所有输出流都具有的共同特征。 Reader（字符流，文本格式操作）：抽象类，基于字符的输入操作。 Writer（字符流，文本格式操作）：抽象类，基于字符的输出操作。 RandomAccessFile（随机文件操作）：它的功能丰富，可以从文件的任意位置进行存取（输入输出）操作。 I/O流java.io包里有4个基本类：InputStream、OutputStream及Reader、Writer类，它们分别处理字节流和字符流。 其他各种各样的流都是由这4个派生出来的。 按来源/去向分类： File（文件）： FileInputStream, FileOutputStream, FileReader, FileWriter byte[]：ByteArrayInputStream, ByteArrayOutputStream Char[]: CharArrayReader, CharArrayWriter String: StringBufferInputStream, StringReader, StringWriter 网络数据流：InputStream, OutputStream, Reader, Writer InputStreamInputStream 为字节输入流，它本身为一个抽象类，必须依靠其子类实现各种功能，此抽象类是表示字节输入流的所有类的超类。 继承自InputStream 的流都是向程序中输入数据的，且数据单位为字节（8bit）； InputStream是输入字节数据用的类，所以InputStream类提供了3种重载的read方法.Inputstream类中的常用方法： public abstract int read( )：读取一个byte的数据，返回值是高位补0的int类型值。若返回值=-1说明没有读取到任何字节读取工作结束。 public int read(byte b[ ])：读取b.length个字节的数据放到b数组中。返回值是读取的字节数。该方法实际上是调用下一个方法实现的 public int read(byte b[ ], int off, int len)：从输入流中最多读取len个字节的数据，存放到偏移量为off的b数组中。 public int available( )：返回输入流中可以读取的字节数。注意：若输入阻塞，当前线程将被挂起，如果InputStream对象调用这个方法的话，它只会返回0，这个方法必须由继承InputStream类的子类对象调用才有用， public long skip(long n)：忽略输入流中的n个字节，返回值是实际忽略的字节数, 跳过一些字节来读取 public int close( ) ：使用完后，必须对我们打开的流进行关闭。 来看看几种不同的InputStream： FileInputStream把一个文件作为InputStream，实现对文件的读取操作 ByteArrayInputStream：把内存中的一个缓冲区作为InputStream使用 StringBufferInputStream：把一个String对象作为InputStream PipedInputStream：实现了pipe的概念，主要在线程中使用 SequenceInputStream：把多个InputStream合并为一个InputStream OutputStreamOutputStream提供了3个write方法来做数据的输出，这个是和InputStream是相对应的。 public void write(byte b[ ])：将参数b中的字节写到输出流。 public void write(byte b[ ], int off, int len) ：将参数b的从偏移量off开始的len个字节写到输出流。 public abstract void write(int b) ：先将int转换为byte类型，把低字节写入到输出流中。 public void flush( ) : 将数据缓冲区中数据全部输出，并清空缓冲区。 public void close( ) : 关闭输出流并释放与流相关的系统资源。 几种不同的OutputStream： ByteArrayOutputStream：把信息存入内存中的一个缓冲区中 FileOutputStream：把信息存入文件中 PipedOutputStream：实现了pipe的概念，主要在线程中使用 SequenceOutputStream：把多个OutStream合并为一个OutStream Reader和InputStream类似；Writer和OutputStream类似。 有两个需要注意的： InputStreamReader ： 从输入流读取字节，在将它们转换成字符。 BufferReader :接受Reader对象作为参数，并对其添加字符缓冲器，使用readline()方法可以读取一行。 如何选择I/O流 确定是输入还是输出输入:输入流 InputStream Reader输出:输出流 OutputStream Writer 明确操作的数据对象是否是纯文本是:字符流 Reader，Writer否:字节流 InputStream，OutputStream 明确具体的设备。 文件： 读：FileInputStream,, FileReader, 写：FileOutputStream，FileWriter 数组： byte[ ]：ByteArrayInputStream, ByteArrayOutputStream char[ ]：CharArrayReader, CharArrayWriter String： StringBufferInputStream(已过时，因为其只能用于String的每个字符都是8位的字符串), StringReader, StringWriter Socket流 键盘：用System.in（是一个InputStream对象）读取，用System.out（是一个OutoutStream对象）打印 是否需要转换流是，就使用转换流，从Stream转化为Reader、Writer：InputStreamReader，OutputStreamWriter 是否需要缓冲提高效率是就加上Buffered：BufferedInputStream, BufferedOuputStream, BufferedReader, BufferedWriter 是否需要格式化输出 示例代码 将标准输入（键盘输入）显示到标准输出（显示器），支持字符。 char ch;BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); //将字节流转为字符流，带缓冲try &#123; while ((ch = (char) in.read()) != -1)&#123; System.out.print(ch); &#125;&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 将AtomicityTest.java的内容打印到显示器 方法一：BufferedReader in = new BufferedReader(new FileReader(\"AtomicityTest.java\"));String s;try &#123; while ((s = in.readLine()) != null)&#123; System.out.println(s); &#125; in.close();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 方法二： FileReader in = new FileReader(\"AtomicityTest.java\");int b;try &#123; while ((b = in.read()) != -1)&#123; System.out.print((char)b); &#125; in.close();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 方法三：(有可能出现乱码） FileInputStream in = new FileInputStream(\"AtomicityTest.java\");int n = 50;byte[] buffer = new byte[n];try &#123; while ((in.read(buffer,0,n) != -1 &amp;&amp; n &gt; 0))&#123; System.out.print(new String(buffer)); &#125; in.close();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 将文件A的内容拷贝到文件B FileInputStream in = new FileInputStream(\"AtomicityTest.java\");FileOutputStream out = new FileOutputStream(\"copy.txt\");int b;while ((b = in.read()) != -1)&#123; out.write(b);&#125;out.flush();in.close();out.close(); 将标准输入的内容写入文件 Scanner in = new Scanner(System.in);FileWriter out = new FileWriter(\"systemIn.log\");String s;while (!(s = in.nextLine()).equals(\"Q\"))&#123; out.write(s + \"\\n\");&#125;out.flush();out.close();in.close();","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"Python日志模块示例","slug":"Python日志模块示例","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Python日志模块示例/","link":"","permalink":"http://linbingdong.com/2017/03/11/Python日志模块示例/","excerpt":"给出Python日志模块显示配置和文件配置两种方式的示例","text":"给出Python日志模块显示配置和文件配置两种方式的示例 显示配置在程序中直接调用函数来设置参数 #!/usr/bin/python# -*- coding: utf-8 -*-import logging# 创建一个loggerlogger = logging.getLogger('example')logger.setLevel(logging.DEBUG)# 创建一个输出到控制台的handlersh = logging.StreamHandler()sh.setLevel(logging.ERROR)# 创建一个输出到文件的handlerfh = logging.FileHandler('loggingtest.log')fh.setLevel(logging.INFO)# 设置输出格式fmt = logging.Formatter('%(asctime)s - %(threadName)s - [%(levelname)s] : %(message)s')# handler设置formattersh.setFormatter(fmt)fh.setFormatter(fmt)# logger添加handlerlogger.addHandler(sh)logger.addHandler(fh)# 写日志logger.debug('debug message')logger.info('info message')logger.warn('warn message')logger.error('error message')logger.critical('critical message') 文件配置通过配置文件进行配置，使用fileConfig()函数读取配置文件 配置文件 logging.conf : [loggers]keys=root,example01[logger_root]level=DEBUGhandlers=hand01,hand02[logger_example01]handlers=hand01,hand02qualname=example01propagate=0[handlers]keys=hand01,hand02[handler_hand01]class=StreamHandlerlevel=INFOformatter=form02args=(sys.stderr,)[handler_hand02]class=FileHandlerlevel=DEBUGformatter=form01args=(&apos;log.log&apos;,&apos;a&apos;)[formatters]keys=form01,form02[formatter_form01]format=%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s[formatter_form02]format=%(asctime)s - %(threadName)s - [%(levelname)s] : %(message)s 程序 LogByFile.py : #!/usr/bin/python# -*- coding: utf-8 -*-import loggingimport logging.configlogging.config.fileConfig('logging.conf')logger = logging.getLogger('example01')# 写日志logger.debug('debug message')logger.info('info message')logger.warn('warn message')logger.error('error message')logger.critical('critical message')","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/tags/Python/"}]},{"title":"Java NIO之内存映射文件——MappedByteBuffer","slug":"Java NIO之内存映射文件——MappedByteBuffer","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java NIO之内存映射文件——MappedByteBuffer/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java NIO之内存映射文件——MappedByteBuffer/","excerpt":"大多数操作系统都可以利用虚拟内存实现将一个文件或者文件的一部分”映射”到内存中。然后，这个文件就可以当作是内存数组来访问，这比传统的文件要快得多。","text":"大多数操作系统都可以利用虚拟内存实现将一个文件或者文件的一部分”映射”到内存中。然后，这个文件就可以当作是内存数组来访问，这比传统的文件要快得多。 内存映射文件的一个关键优势是操作系统负责真正的读写，即使你的程序在刚刚写入内存后就挂了，操作系统仍然会将内存中的数据写入文件系统。另外一个更突出的优势是共享内存，内存映射文件可以被多个进程同时访问，起到一种低时延共享内存的作用。 那么，如何将一个文件映射到内存呢？ 从文件中获得一个通道（channel） FileChannel channel = FileChannel.open(path,options); 这里options指定映射模式，支持的模式有三种： FileChannel.MapMode.READ_ONLY：所产生的缓冲区是只读的。 FileChannel.MapMode.READ_WRITE：所产生的缓冲区是可写的,任何修改都会在某个时刻写回到文件中。注意，其他映射同一个文件的程序可能不能立即看到这些修改，多个程序同时进行文件映射的确切行为是依赖于操作系统的。 FileChannel.MapMode.PRIVATE：所产生的缓冲区是可写的，但是任何修改对该缓冲区来说都是私有的，不会传播到文件中。 调用FileChannel的map方法 MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY,0,length); 接下来通过计算一个40MB文件的CRC32校验和来比较传统的文件输入和内存映射文件的速度。 传统的文件输入包括： 普通输入流（InputStream） 带缓冲的输入流（BufferedInputStream） 随机访问文件（RandomAccessFile） 程序如下： import java.io.*;import java.nio.MappedByteBuffer;import java.nio.channels.FileChannel;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;import java.util.zip.CRC32;/** * Created by lbd on 2017/1/11. */public class MemoryMapTest &#123; public static long checksumInputStream(Path filename) throws IOException &#123; //普通输入流 try (InputStream in = Files.newInputStream(filename)) &#123; CRC32 crc = new CRC32(); int c; while ((c = in.read()) != -1) crc.update(c); return crc.getValue(); &#125; &#125; public static long checksumBufferedInputStream(Path filename) throws IOException &#123; //带缓冲的输入流 try (BufferedInputStream in = new BufferedInputStream(Files.newInputStream(filename)))&#123; CRC32 crc = new CRC32(); int c; while ((c = in.read()) != -1) crc.update(c); return crc.getValue(); &#125; &#125; public static long checksumRandomAccessFile(Path filename) throws IOException &#123; //随机访问文件 try (RandomAccessFile file = new RandomAccessFile(filename.toFile(),\"r\"))&#123; CRC32 crc = new CRC32(); long length = file.length(); for (long p = 0; p &lt; length; p++)&#123; file.seek(p); int c = file.readByte(); crc.update(c); &#125; return crc.getValue(); &#125; &#125; public static long checksumMappedFile(Path filename) throws IOException &#123; //内存映射文件 try (FileChannel channel = FileChannel.open(filename))&#123; CRC32 crc = new CRC32(); int length = (int)channel.size(); MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY,0,length); for (int p = 0; p &lt; length; p++)&#123; int c = buffer.get(p); crc.update(c); &#125; return crc.getValue(); &#125; &#125; public static void main(String[] args) throws IOException &#123; System.out.println(\"Input Stream:\"); long start = System.currentTimeMillis(); Path filename = Paths.get(args[0]); long crcValue = checksumInputStream(filename); long end = System.currentTimeMillis(); System.out.println(Long.toHexString(crcValue)); System.out.println((end - start) + \" milliseconds\"); System.out.println(); System.out.println(\"Buffered Input Stream:\"); start = System.currentTimeMillis(); crcValue = checksumBufferedInputStream(filename); end = System.currentTimeMillis(); System.out.println(Long.toHexString(crcValue)); System.out.println((end - start) + \" milliseconds\"); System.out.println(); System.out.println(\"Random Access File:\"); start = System.currentTimeMillis(); crcValue = checksumRandomAccessFile(filename); end = System.currentTimeMillis(); System.out.println(Long.toHexString(crcValue)); System.out.println((end - start) + \" milliseconds\"); System.out.println(); System.out.println(\"Mapped File:\"); start = System.currentTimeMillis(); crcValue = checksumMappedFile(filename); end = System.currentTimeMillis(); System.out.println(Long.toHexString(crcValue)); System.out.println((end - start) + \" milliseconds\"); &#125;&#125; 输出结果如下： Input Stream:c644b1f142317 millisecondsBuffered Input Stream:c644b1f1329 millisecondsRandom Access File:c644b1f157781 millisecondsMapped File:c644b1f1207 milliseconds 可以明显看出，内存映射文件速度比普通输入流和随机访问文件快得多，比带缓冲的输入流稍微快一些。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"Python读书笔记（持续更新）","slug":"Python读书笔记（持续更新）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Python读书笔记（持续更新）/","link":"","permalink":"http://linbingdong.com/2017/03/11/Python读书笔记（持续更新）/","excerpt":"\n书籍：《Python基础教程》《Python核心编程》《Python Cookbook》《Python源码剖析》\n","text":"书籍：《Python基础教程》《Python核心编程》《Python Cookbook》《Python源码剖析》 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量。这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言 在Python中，通常用全部大写的变量名表示常量。用全部大写的变量名表示常量只是一个习惯上的用法，其实它还是一个变量 Python的整数没有大小限制，而某些语言的整数根据其存储长度是有大小限制的，例如Java对32位整数的范围限制在-2147483648-2147483647。 Python的浮点数也没有大小限制，但是超出一定范围就直接表示为inf（无限大）。 把一个变量a赋值给另一个变量b，这个操作实际上是把变量b指向变量a所指向的数据 ASCII编码是1个字节，而Unicode编码通常是2个字节。 Python里的字典{ }相当于键值对，不过一个键只能存放一个值，后放的值会覆盖前面的。删除用d.pop( );dict的key必须是不可变对象 *args是可变参数，args接收的是一个tuple； **kw是关键字参数，kw接收的是一个dict。 如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线，在Python中，实例的变量名如果以开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问， 不能直接访问name是因为Python解释器对外把name变量改成了_Studentname，所以，仍然可以通过_Studentname来访问__name变量 类中没有的属性可以在实例中动态绑定，也可调用MethodType来为实例绑定类中没有的方法。 如果我们想要限制实例的属性怎么办？比如，只允许对Student实例添加name和age属性。为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的slots变量，来限制该class实例能添加的属性 class Student(object): slots = (‘name’, ‘age’) # 用tuple定义允许绑定的属性名称使用slots要注意，slots定义的属性仅对当前类实例起作用，对继承的子类是不起作用的类可以绑定原本没定义的外部方法 Python内置的@property装饰器就是负责把一个方法变成属性调用的 整除 “//“ 双反斜杠 把小数点后面的数去掉，即使是浮点数相除 幂次方用 如2 4 = 16 大数 大于20亿 后面加L表示（转换成长整型） 如 10000000000000L 说明这是个长整型 其实Python会自动转换 所有我们不用管 直接用 甚至不用写L 十六进制以0x开头 八进制以0开头 都是数字零 In Python 3.0, print is a function, which means you need to write print(42) instead of print 42 要得到某个数的几次方 可以用pow( )函数 如pow(2,4)=16 round( )函数用来四舍五入浮点数 round(3.6788,3) = 3.679 保留三位小数 math.floor( )用来向下取浮点数 math.ceil( )用来向上取浮点数 cmath是用来处理复数的库 str( ) repr( )和反引号 raw_input( )把所有输入都当作字符串 都加上 ‘ ‘ input( ) 则数字就是数字 Python3里input跟Python2的raw_input等同 要输入一串很长的字符串 里面有单引号 双引号 甚至跨行 可以用三引号’’’ string ‘’’ 若要输出的里面有很多反斜杠 \\ 比如C:\\LBD\\LSKE\\NO 可以用r’ ——‘表示原始字符串，即忽略反斜杠的作用 不然得在每个\\前面再加一个\\ 在不想让序列被改变的情况下用元组 否则一般用列表 字符串也可以切片 [2:20:3] [20:3:-2] for a positive step size, it moves from the beginning toward the end, and for a negative step size, it moves from the end toward the beginning. None 代表什么都没有，但是占了个位置 print( )完自动换行 print(a,b,c) a b c 自动空格 列表 in 可以判断x是否在字符串或列表中 字符串不能被修改 可以转成list list（）函数用来将字符串或序列转成列表 ‘ ‘.join(iterable)可以将序列用’ ‘ 连接起来 序列必须由字符串组成 可以将字符串转成序列（方便处理），也可以把序列转成字符串 切片不改变序列本身 列表有特性：可以给某个位置赋值，删除某个位置，给切片赋值(还可以跳跃赋值，只是跳跃赋值的话提供的值数量要跟跳跃的相等） python2中range( )函数产生一个列表 python3则不行，主要用来迭代次数 可以list(range(3,9,2)来将其转为列表 ls.count( )可以得到 在列表ls中出现的次数 *可以是列表 ls.append( )，在列表末尾加一个元素，append( )一个列表，该列表成为原列表的一个元素 ls.extend( )在列表末尾加一个序列(iterable)，该序列里的元素全部成为原序列的元素 也可以通过 + 将两个列表相连，但是此时不改变原列表 列表里什么都能放，包括数字、字符串、列表、元组、字典等 而且可以同时混合放 切片x[a:b] 含左不含右 ls.index( ) 返回第一次出现的索引 ls.insert(a,* )可以在a位置插入a这个元素 x.pop( )默认将最后一个元素弹出并返回 del只移除不返回 还可以指定移除某个位置的 x.pop(1) pop( )是唯一一个既能修改列表又能返回值得列表方法 若要移除某个已知的元素 而不是某个位置的元素 用ls.remove( ) 只移除第一次出现的 后面的 * 不移除 ls.reverse( )可以将列表反转 什么都不返回 列表操作里有返回值得只有pop ls.sort( )可以对列表进行排序 不返回任何东西 只能用于列表排序 ls.sort(cmp = None,key = None,reverse = False) key用来决定用什么来排序（长度、字母表、。。）reverse决定要不要反转 元组 决定是否是元组的是逗号，有逗号就是 除了空元组，其他都有逗号 如果只有一个元素，在后面加逗号表明这是一个元组 元组用小括号（圆括号）表示 tuple( )函数可以把序列转成元组 ,元祖方法跟列表类似，少了很多 序列（sequence）包含列表、元祖、字符串 字符串 字符串 要格式化两个以上的值，需要用元祖或字典 也可以用模板字符串来对字符串进行格式化 from string import Template s = Template(&apos;A $thing must never $action.&apos;) d = &#123;&#125; d[&apos;thing&apos;] = &apos;gentleman&apos; d[&apos;action&apos;] = &apos;show his socks&apos; s.substitute(d)&apos;A gentleman must never show his socks.&apos; %-10.2f 总宽度为10 保留2位小数 左对齐（默认是右对齐） %010.2f 左边用0填充 %+5d 显示正负号（正的也要显示） ‘%-s’ %(10,’ilovezxy) 左对齐 宽度为10 号用来接收宽度或精度 find( ) 在长字符串中找某个子字符串用 s.find(‘lbd’) 返回位置（最左边的） 若无 返回-1 还可以指定起始和结束位置s.find(‘lbd’,3,10) join( ) s = (‘lbd’,’zxy’,’lxy’) ‘/‘.join(s) lbd/zxy/lxy 与split( )方法相反 将序列连接处字符串 lower( ) 返回小写字符串 title( ) ‘i love python’.title( ) f-&gt; ‘I Love Python’ 首字母大写 其他小写 string.capwords(“that’s all”) replace( ) 用来替换某个子串 ‘ldljeijkldsfe’.replace(‘a’,’b’)把所有的a都替换成b split( ) 将字符串分割成序列（列表）’/lbd/zxy/lks/‘.split(‘/‘) -&gt; [‘’, ‘lbd’, ‘zxy’, ‘lks’, ‘’] 不加参数默认用空格分割 strip( ) 去除字符串两边的空格 并将去除空格后的字符串返回 已可以去除指定字符 ‘dsfsfw’.strip(‘#@$1*e’) translate( ) table = maketrans(‘cs’,’kz’) ‘this is a incredible test’.translate(table) 需要同时替换多个字母时使用 电话号码应表示为字符串 字典 键不能重复，值可以重复 dict( ) 用来创建字典 可以用（key，value）键值对 或 name=’lbd’，age=’23’ 这样来赋值 b = dict(name = ‘zxy’,age = 18,gender = ‘female’) or items=[(‘name’,’lbd’),(‘age’,23)] d = dict(items) 为某个键赋值时 若原本字典中没这个键 则会自动将此键值对添加进去 value 可以是一个字典 里面包含多个键值对 除了有元组的格式化字符串，还有字典的格式化字符串 clear( ) dict.clear( ) 清除字典里的所有内容 列表用 del x[ : ]实现 copy（ ）dict.copy( ) 返回一份dict的拷贝（新的，不是原本那份） y=x.copy( ) 此时y和x不是指向同一个对象 更新操作互不影响 删除操作会影响 若y=x 则两个指向相同内容 操作相互影响 列表虽然没有copy这个函数 但是可以用切片[ : ]实现 y=deepcopy(x)是深拷贝，完全不影响 get( ) y.get( keyname ,’default’ ) 得到key对应的value get方法更宽松 如果不存在该键不会报错 返回default x[‘keyname’]不存在会报错 has_key( ) 判断是否存在某个key items( ) and iteritems( ) x.items( ) 将x的内容以列表返回 [(‘age’, 18), (‘name’, ‘lbd’)] iteritems( )类似 只不过会返回一个迭代器而不是列表 keys( ) and iterkeys( ) 将keys以列表的形式返回 pop( ) x.pop(key) 将key对应的value返回 并删除key-value对 popitem( ) x.popitem( ) 随机弹出（删除）一个键值对，并将其返回 setdefault(key,default) 与get(key,default)类似，只不过若key不存在 setdefault()会加入 update( ) x.update(y) update可以用y字典来更新x字典 同意的key替换成y的value 不存在的key—value加入x values( ) and itervalues( ) 以列表的形式返回所有value 一个key只能对应一个value x,y,z = 1,2,3 or x,y,z = (1,2,3) 解包 可以给多个变量同时赋值 values = (4,5,6) x,y,z = values x,y,z = z,x,y 可以三个互换 x,y = y,x if … elif …else 还可以用 2=y ==比较的是值（相等性） 5 == 5.0 is 比较的是对象(同一性） 指向相同对象才相等 is一般用在可变值里 name = input(‘please input your name: ‘) or ‘default’ 如果没有输入 则name=default x = 2 if 1&gt;2 else 3 x=3 xrange( ) 一次只产生一个数 range( )一次性把所有数都产生出来 Python3中 range( ) 会被转化成 xrange( ) d={ } for k,v in d.items( ) zip(a,b) 可以把a，b两个可迭代的按顺序合并到一起称为一对 [ (a[0],b[0]) ,…, ] 用来进行并行迭代 短的结束后即停止 for index,string in enumerate(strings): strings[index] = ‘xxx’ 用来迭代index-value对 [ x*x for x in range(10) ] -&gt;[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] [x*x for x in range(10) if x%3 == 0]-&gt;[0, 9, 36, 81] [(x,y) for x in range(3) for y in range(3)]-&gt;[(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)] 如果想让程序什么都不干，用pass 若x = [1,2,3] y = x 则del x[0] 对y有影响 del x 对y无影响（编译器检测到还有变量指向该列表，所以不会真的删除这个列表） Python编译器会自动回收不需要的东西，所以不要自己操心 exec可以用来执行字符串中的代码 exec “print ‘hello world!’” eval(‘8+3*4) 20 eval( )可以对字符串里的算式进行计算 exec and eval are both not safe scope = {‘x’:3,’y’:2} eval(‘x*y’,scope) 6 为某个函数加注释可以直接在：下一行写字符串 然后调用func.doc可以查看函数文档 doc是特殊函数属性 def print_argument(arg): print_argument(3,4,’sll’,[2,4]) (3, 4, ‘sll’, [2, 4]) arg将输入的所有参数放到元组arg里 def print_argument2(*arg): print_argument2(x=1,y=2,z=’lbd’) {‘y’: 2, ‘x’: 1, ‘z’: ‘lbd’}*arg把所有输入的参数放到字典arg里 参数必须是x=a的形式 以上两种方法都可以让用户输入任意多的参数 收集参数为元组或字典（在定义中使用 或 *） 若定义中有多个参数，调用函数时参数为arg 或 *arg 可将元组arg1或字典arg2分割为多个参数 同一个函数要么定义时用或** 要么调用时用或** 不要在定义和调用时同时用 如果有全局变量x 函数内部又有x 则后者为局部变量，不会对外面的x产生影响 若想要在函数内引用全局变量x 应声明为 global x map(str, range(10)) -&gt; [‘0’, ‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’, ‘7’, ‘8’, ‘9’]filter(lambda x:x.isalnum(),seq)num = [2,3,4,2,2,3,4,4] reduce(lambda x,y:x+y,num) -&gt;24 有函数可以调用的话就不要自己写，因为内置的一般效率更高 绑定到对象特性上面的函数称为方法（method） 多态就是不用管对象的类型，真的不同类型的对象会自动选取对应的方法 类的属性，若想变成私有 1.双下划线 此时可以用ob._classattribute来访问 2.单下划线_ 外面无法访问 Python没有真正的私有化支持 issubclass(a,b) 判断a是否b的子类 isinstance(a,b) 判断a是否b的一个实例 a.bases a类的基类 a.class a是哪个类的对象（a这个对象属于哪个类）或者用 type(a)更直接 class a(b,c) a类继承b类和c类 叫做多重继承 若b、c中有相同的某个方法，则b会重写c 所有有顺序之分 捕获异常是为了发生异常时按我们的想法来运行，而不是直接崩溃（前提是你知道此处可能会有异常） try： except： or try： except（exc1，exc2，…）：except (ZeroDivisionError,NameError,TypeError) as e: print(e) 把异常打印出来 程序继续运行 try: except: else: finally: 没有异常的时候会执行else里的内容，有异常不会,finally里的语句一定会执行，不管有没有发生异常类的构造方法 def init(self): 创建新对象是会自动执行里面的内容 __del__是析构方法，在对象被垃圾回收之前调用，自己不要去用 正常情况下，子类会重写超类的构造方法（新建子类对象是只会初始化子类的构造方法，不会初始化超类的构造方法）两种方法解决：1.调用超类构造方法的未绑定版本 2.使用super函数（现在用这个） 在调用一个实例的方法时，该方法的self参数会自动绑定到该实例上 如果直接调用类的方法，该方法就不会绑定到实例上可以用type()函数创建出class 内部也是这么执行的Hello = type(‘Hello’,(object,),dict(hello = fn)) 创建的Hello类，继承object类，里面有个hello方法，该方法与fn函数绑定 metaclass是元类 很高级 可以把类看作metaclass的实例两种方法实现新式类：1. 开头添加 metaclass = type 2.继承object类 property（）函数：屏蔽类访问器方法 如 size = property(getSize,setSize) 静态方法和类成员方法 静态方法没有self参数，可以被类直接调用 类成员方法有个类似于self参数的cls参数 除此之外还要加上装饰器 @staticmethod @classmethod 一个实现了__iter__方法的对象是可迭代的，一个实现了next方法的对象是迭代器 next()返回迭代器的下一个值，__iter__返回迭代器本身 it = iter((1,2,3,4)) iter()为内建函数 可以将可迭代对象变成迭代器 list(iter) 可以将迭代器转化成列表 g = ((i+2)**2 for i in range(2,27)) g是个生成器，可以使用g.next(） 生成器是一个包含yield关键字的函数 生成器由两部分组成：生成器的函数和生成器的迭代器 import sys sys.path.append(‘/Users/linbingdong/Desktop’) 此时可以import放在该路径下的xxx.py文件 import xxx 模块在第一次被导入时会自动执行（生成xxx.pyc文件），以后就不会 在主程序中，__name__ == __main__ 在导入的模块中 __name__ == 模块名 用作测试代码 def test(): if ‘__name__‘ == ‘__main__‘: test() import pprint pprint更加智能 可以打印的更好看 比如自动换行 查看sys.path 找到site-packages目录 将自己写的模块放入该目录 其他程序就都可以import import自己写的模块两种方法 1.放入site-packages目录 2.sys.path.append（ ） dir()函数可以查看模块包含的内容 如 import copy dir(copy) copy.all 定义了模块的公有接口 from copy import 只能导入copy.all里的内容 相当于将一些程序员不太需要的过滤掉 因此from copy import 一般已经足够了 copy.file 显示copy这个模块所在的路径 copydoc 显示copy的描述文档 sys.argv是个参数列表 os.sep 路径名中的分隔符 / os.pathsep 分割路径名（不同路径名） : os.linesep 换行符 \\n os.system(‘路径名’) 可以启动应用程序 import webbrowser webbrowser.open(‘http://www.qq.com‘) 会调用默认浏览器打开该网址 set集合 set([1,2,3,3,2,3,4]) -&gt; set([1,2,3,4]) 顺序随意 求两个集合的并集 a.union(b) or a | b 求两个集合的交集 a.intersection(b) or a &amp; b a中特有的（a中有，b中没有） a.difference(b) or a - b a、b中不共有的 a.symmetric_difference(b) or a ^ b 集合是可变的 字典中的键必须是不可变的 frozenset(b)将b集合变成不可变的 forzenset()函数创建给定集合的副本 Python没有独立的“堆”类型 有个’heapq‘模块 通过heappush(heap,n) 得到的heap列表就是堆 或者用 heapify(heap) 将heap建成堆 其实可以把可迭代对象直接看成堆 heappop(heap) 每次弹出heap中的最小数 先执行heappop()再执行heappush()等价于 heapreplace(heap,x) 返回弹出的数 返回iter的前k大数 nlargest(k,iter） 返回前k小数 nsmallest(k,iter) 双端队列 deque ‘from collections import deque’ q = deque(range(5)) deque与list的区别在于 deque可以从左端加入和弹出 q.appendleft(x) q.popleft() q.rotate(3)右移三位 q.rotate(-3)左移三位 都是循环移位 time 模块 import time time.asctime() time.localtime() time.mktime()… sleep(k) 等待k秒 random 模块 from random import * random(）返回0~1之间的浮点数 uniform(a,b) 返回a~b之间的数 randrange(a,b) 返回a~b之间的随机整数 randrange(1,b,2) 返回小于b的随机正奇数 re模块 正则表达式 re.split(‘[, ]+’,text) 将text用任意长度的逗号或空格分开","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/tags/Python/"}]},{"title":"关于Java Collections的几个常见问题","slug":"Stack Overflow上关于Java Collections的几个常见问题","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Stack Overflow上关于Java Collections的几个常见问题/","link":"","permalink":"http://linbingdong.com/2017/03/11/Stack Overflow上关于Java Collections的几个常见问题/","excerpt":"列举几个关于Java Collections的常见问题并给出答案。","text":"列举几个关于Java Collections的常见问题并给出答案。 1. 什么时候用LinkedList，什么时候用ArrayList？ArrayList是使用数组实现的list，本质上就是数组。ArrayList中的元素可以通过索引随机获取一个元素。但是如果该数组已满，当添加新元素时需要分配一个新的数组然后将原来数组的元素移动过去，需要O(n)的时间复杂度。添加或删除一个元素需要移动数组中的其他元素。这是ArrayList最大的缺点。 LinkedList是一个双向链表。因此，当需要获取list中某个元素，需要从头到尾遍历list。另一方面，在链表中添加或删除元素很快，只需要O(1)的时间复杂度。从空间上来说，在链表中一个节点需要两个额外的指针来指向它的previous和next节点。 总结： 从时间复杂度来说，如果对list增加或删除操作较多，优先用LinkedList；如果查询操作较多，优先用ArrayList。 从空间复杂度来说，LinkedList会占用较多空间。 2. 如何边遍历边移除Collection中的元素边遍历边修改Collection的唯一正确方式是使用Iterator.remove()方法，如下： Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext())&#123; // do something it.remove();&#125; 一种最常见的错误代码如下： for(Integer i : list)&#123; list.remove(i)&#125; 运行以上错误代码会报ConcurrentModificationException异常。这是因为当使用foreach(for(Integer i : list))语句时，会自动生成一个iterator来遍历该list，但同时该list正在被Iterator.remove()修改。在Java中，一般不允许一个线程在遍历collection时另一个线程在修改它。 3. 如何将List转化成int[]？很多人可能认为只需用List.toArray()即可，其实不然。List.toArray()方法只可能得到Integer[]，无法得到int[]。 最简单的方法是使用Apache Commons Lang库中的ArrayUtils。 int[] array = ArrayUtils.toPrimitive(list.toArray(new Integer[0])); 在JDK中，没有捷径。需要注意的是，不能直接使用List.toArray(),因为这样会将List转化成Integer[]而不是int[]。正确的做法如下： int[] array = new int[list.size()];for(int i = 0; i &lt; list.size(); i++)&#123; array[i] = list.get(i);&#125; 4. 如何将int[]转化成List？同上，很多人以为只需用Arrays.asList()即可，其实不然。因为不能以int[]作为该方法的参数，要的话也只能是Integer[]。 关于Arrays.asList()方法有如下特性： 1.该方法对于基本数据类型的数组支持并不好,当数组是基本数据类型时不建议使用 2.当使用asList()方法时，数组就和列表链接在一起了。当更新其中之一时，另一个将自动获得更新。因为asList获得的List实际引用的就是数组 注意:仅仅针对对象数组类型,基本数据类型数组不具备该特性。 3.asList得到的数组是的没有add和remove方法的。因为asList返回的List是Arrays中的内部类,而该类并没有定义add和remove方法。 那么如何将int[]转化成List呢？ 还是得自己实现： int[] array = &#123;1,2,3,4,5&#125;;List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();for(int i: array) &#123; list.add(i);&#125; 5. 过滤一个Collection最好的方法是什么？如过滤掉list中大于5的整数。 Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext())&#123; int i = it.next(); if(i &gt; 5) &#123; //过滤掉大于5的整数 it.remove(); &#125;&#125; 6. 将List转化成Set最简单的方法？有两种方法，取决于你怎么要怎么定义两个元素相等。第一种方法是将list放入HashSet里，该方法元素是否相等是通过它们的hashCode()来比较的。如果需要自己定义比较的方法，需要用TreeSet。 Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(list); Set&lt;Integer&gt; set = new TreeSet&lt;Integer&gt;(aComparator);set.addAll(list); 7. 如何删除ArrayList中重复的元素？如果不关心元素在ArrayList中的顺序，可以将list放入set中来删除重复元素，然后在放回list。 Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(list);list.clear();list.addAll(set); 如果关心元素在ArrayList中的顺序，可以用LinkedHashSet。 8. 有序的collectionJava里有很多方法来维持一个collection有序。有的需要实现Comparable接口，有的需要自己指定Comparator。 Collections.sort()可以用来对list排序。该排序是稳定的，并且可以保证nlog(n)的性能。 PriorityQueue提供排序的队列。PriorityQueue和Collections.sort()的区别是，PriorityQueue动态维护一个有序的队列（每添加或删除一个元素就会重新排序），但是只能获队列中的头元素。 如果collection中没有重复的元素，TreeSet是另一个选择。跟PriorityQueue一样的是，TreeSet也动态维护一个有序的集合。可以从TreeSet中获取最大和最小的元素。 总结：Collections.sort()提供一个一次排序的list。PriorityQueue和TreeSet动态维护排序的collection。 9. 拷贝list有两种方法可以用来拷贝list。一种是使用ArrayList构造器。 ArrayList&lt;Integer&gt; dstList = new ArrayList&lt;Integer&gt;(srcList); 另一种是使用Collections.copy()。 ArrayList&lt;Integer&gt; dstList = new ArrayList&lt;Integer&gt;(srcList.size());Collections.copy(dstList, srcList); 需要注意的是，使用该方法的话目标list至少跟源list长度一样长。否则会报IndexOutOfBoundsException异常。 另外有两点需要注意： 两种方法都是浅拷贝 Collections.copy()方法的两个参数必须都是list，而ArrayList方法参数只要是collection即可，因此ArrayList方法更通用。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"ZeroMQ初探","slug":"ZeroMQ初探","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/ZeroMQ初探/","link":"","permalink":"http://linbingdong.com/2017/03/11/ZeroMQ初探/","excerpt":"ZeroMQ介绍、三种模式讲解及代码示例(Java &amp;&amp; Python)。","text":"ZeroMQ介绍、三种模式讲解及代码示例(Java &amp;&amp; Python)。 概述ZeroMQ（也称为 ØMQ，0MQ 或 zmq）是一个可嵌入的网络通讯库（对 Socket 进行了封装）。 它提供了携带跨越多种传输协议（如：进程内，进程间，TCP 和多播）的原子消息的 sockets 。 有了ZeroMQ，我们可以通过发布-订阅、任务分发、和请求-回复等模式来建立 N-N 的 socket 连接。 ZeroMQ 的异步 I / O 模型为我们提供可扩展的基于异步消息处理任务的多核应用程序。 它有一系列语言API（几乎囊括所有编程语言），并能够在大多数操作系统上运行。 传统的 TCP Socket 的连接是1对1的，可以认为“1个 socket = 1个连接”，每一个线程独立维护一个 socket 。但是 ZMQ 摒弃了这种1对1的模式，ZMQ的 Socket 可以很轻松地实现1对N和N对N的连接模式，一个 ZMQ 的 socket 可以自动地维护一组连接，用户无法操作这些连接，用户只能操作套接字而不是连接本身。所以说在 ZMQ 的世界里，连接是私有的。 三种基本模型ZMQ 提供了三种基本的通信模型，分别是 Request-Reply 、Publish-Subscribe 和 Parallel Pipeline ，接下来举例说明三种模型并给出相应的代码实现。 Request-Reply（请求-回复）以 “Hello World” 为例。客户端发起请求，并等待服务端回应请求。客户端发送一个简单的 “Hello”，服务端则回应一个 “World”。可以有 N 个客户端，一个服务端，因此是 1-N 连接。 服务端代码如下： hwserver.java import org.zeromq.ZMQ;public class hwserver &#123; public static void main(String[] args) throws InterruptedException &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket responder = context.socket(ZMQ.REP); responder.bind(\"tcp://*:5555\"); while (!Thread.currentThread().isInterrupted()) &#123; byte[] request = responder.recv(0); System.out.println(\"Received\" + new String(request)); Thread.sleep(1000); String reply = \"World\"; responder.send(reply.getBytes(),0); &#125; responder.close(); context.term(); &#125;&#125; hwserver.py import timeimport zmqcontext = zmq.Context()socket = context.socket(zmq.REP)socket.bind(\"tcp://*:5555\")while True: message = socket.recv() print(\"Received request: %s\" % message) # Do some 'work' time.sleep(1) socket.send(b\"World\") 客户端代码如下： hwclient.java import org.zeromq.ZMQ;public class hwclient &#123; public static void main(String[] args) &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket requester = context.socket(ZMQ.REQ); requester.connect(\"tcp://localhost:5555\"); for (int requestNbr = 0; requestNbr != 10; requestNbr++) &#123; String request = \"Hello\"; System.out.println(\"Sending Hello\" + requestNbr); requester.send(request.getBytes(),0); byte[] reply = requester.recv(0); System.out.println(\"Reveived \" + new String(reply) + \" \" + requestNbr); &#125; requester.close(); context.term(); &#125;&#125; hwclient.py import zmqcontext = zmq.Context()print(\"Connecting to hello world server...\")socket = context.socket(zmq.REQ)socket.connect(\"tcp://localhost:5555\")for request in range(10): print(\"Sending request %s ...\" % request) socket.send(b\"Hello\") message = socket.recv() print(\"Received reply %s [ %s ]\" % (request,message)) 从以上的过程，我们可以了解到使用 ZMQ 写基本的程序的方法，需要注意的是： 服务端和客户端无论谁先启动，效果是相同的，这点不同于 Socket。 在服务端收到信息以前，程序是阻塞的，会一直等待客户端连接上来。 服务端收到信息后，会发送一个 “World” 给客户端。值得注意的是一定是客户端连接上来以后，发消息给服务端，服务端接受消息然后响应客户端，这样一问一答。 ZMQ 的通信单元是消息，它只知道消息的长度，并不关心消息格式。因此，你可以使用任何你觉得好用的数据格式，如 Xml、Protocol Buffers、Thrift、json 等等。 Publish-Subscribe（发布-订阅）下面以一个天气预报的例子来介绍该模式。 服务端不断地更新各个城市的天气，客户端可以订阅自己感兴趣（通过一个过滤器）的城市的天气信息。 服务端代码如下： wuserver.java import org.zeromq.ZMQ;import java.util.Random;public class wuserver &#123; public static void main(String[] args) &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket publisher = context.socket(ZMQ.PUB); publisher.bind(\"tcp://*:5556\"); publisher.bind(\"icp://weather\"); Random srandom = new Random(System.currentTimeMillis()); while (!Thread.currentThread().isInterrupted()) &#123; int zipcode, temperature, relhumidity; zipcode = 10000 + srandom.nextInt(10000); temperature = srandom.nextInt(215) - 80 + 1; relhumidity = srandom.nextInt(50) + 10 + 1; String update = String.format(\"%05d %d %d\", zipcode, temperature, relhumidity); &#125; publisher.close(); context.term(); &#125;&#125; wuserver.py from random import randrangeimport zmqcontext = zmq.Context()socket = context.socket(zmq.PUB)socket.bind(\"tcp://*:5556\")while True: zipcode = randrange(1, 100000) temperature = randrange(-80, 135) relhumidity = randrange(10, 60) socket.send_string(\"%i %i %i\" % (zipcode, temperature, relhumidity)) 客户端代码如下： wuclient.java import org.zeromq.ZMQ;import java.util.StringTokenizer;public class wuclient &#123; public static void main(String[] args) &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket suscriber = context.socket(ZMQ.SUB); suscriber.connect(\"tcp://localhost:5556\"); String filter = (args.length &gt; 0) ? args[0] : \"10001\"; suscriber.suscribe(filter.getBytes()); //过滤条件 int update_nbr; long total_temp = 0; for (update_nbr = 0; update_nbr &lt; 100; update_nbr++) &#123; String string = suscriber.recvStr(0).trim(); StringTokenizer sscanf = new StringTokenizer(string, \" \"); int zipcode = Integer.valueOf(sscanf.nextToken()); int temperature = Integer.valueOf(sscanf.nextToken()); int relhumidity = Integer.valueOf(sscanf.nextToken()); total_temp += temperature; &#125; System.out.println(\"Average temperature for zipcode '\" + filter + \"' was \" + (int) (total_temp / update_nbr)); suscriber.close(); context.term(); &#125;&#125; wuclient.py import sysimport zmqcontext = zmq.Context()socket = context.socket(zmq.SUB)print(\"Collecting updates from weather server...\")socket.connect(\"tcp://localhost:5556\")zip_filter = sys.argv[1] if len(sys.argv) &gt; 1 else \"10001\"if isinstance(zip_filter, bytes): zip_filter = zip_filter.decode('ascii')socket.setsockopt_string(zmq.SUBSCRIBE, zip_filter)total_temp = 0for update_nbr in range(5): string = socket.recv_string() zipcode, temperature, relhumidity = string.split() total_temp += int(temperature)print(\"Average temperature for zipcode '%s' was %dF\" % (zip_filter, total_temp / (update_nbr + 1))) 服务器端生成随机数 zipcode、temperature、relhumidity 分别代表城市代码、温度值和湿度值，然后不断地广播信息。而客户端通过设置过滤参数，接受特定城市代码的信息，最终将收集到的温度求平均值。 需要注意的是： 与 “Hello World” 例子不同的是，Socket 的类型变成 ZMQ.PUB 和 ZMQ.SUB 。 客户端需要设置一个过滤条件，接收自己感兴趣的消息。 发布者一直不断地发布新消息，如果中途有订阅者退出，其他均不受影响。当订阅者再连接上来的时候，收到的就是后来发送的消息了。这样比较晚加入的或者是中途离开的订阅者必然会丢失掉一部分信息。这是该模式的一个问题，即所谓的 “Slow joiner” 。 Parallel PipelineParallel Pipeline 处理模式如下： ventilator 分发任务到各个 worker 每个 worker 执行分配到的任务 最后由 sink 收集从 worker 发来的结果 taskvent.java import org.zeromq.ZMQ;import java.io.IOException;import java.util.Random;import java.util.StringTokenizer;public class taskvent &#123; public static void main(String[] args) throws IOException &#123; ZMQ.Context context = new ZMQ.context(1); ZMQ.Socket sender = context.socket(ZMQ.PUSH); sender.bind(\"tcp://*:5557\"); ZMQ.Socket sink = context.socket(ZMQ.PUSH); sink.connect(\"tcp://localhost:5558\"); System.out.println(\"Please enter when the workers are ready: \"); System.in.read(); System.out.println(\"Sending task to workes\\n\"); sink.send(\"0\",0); Random srandom = new Random(System.currentTimeMillis()); int task_nbr; int total_msec = 0; for (task_nbr = 0; task_nbr &lt; 100; task_nbr++) &#123; int workload; workload = srandom.nextInt(100) + 1; total_msec += workload; System.out.print(workload + \".\"); String string = String.format(\"%d\", workload); sender.send(string, 0); &#125; System.out.println(\"Total expected cost: \" + total_msec + \" msec\"); sink.close(); sender.close(); context.term(); &#125;&#125; taskvent.py import zmqimport timeimport randomtry: raw_inputexcept NameError: raw_input = inputcontext = zmq.Context()sender = context.socket(zmq.PUSH)sender.bind(\"tcp://*:5557\")sink = context.socket(zmq.PUSH)sink.connect(\"tcp://localhost:5558\")print(\"Please enter when workers are ready: \")_ = raw_input()print(\"Sending tasks to workers...\")sink.send(b'0')random.seed()total_msec = 0for task_nbr in range(100): workload = random.randint(1, 100) total_msec += workload sender.send_string(u'%i' % workload)print(\"Total expected cost: %s msec\" % total_msec)time.sleep(1) taskwork.java import org.zeromq.ZMQ;public class taskwork &#123; public static void main(String[] args) &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket receiver = context.socket(ZMQ.PULL); receiver.connect(\"tcp://localhost:5557\"); ZMQ.Socket sender = context.socket(ZMQ.PUSH); sender.connect(\"tcp://localhost:5558\"); while (!Thread.currentThread().isInterrupted()) &#123; String string = receiver.recv(0).trim(); Long mesc = Long.parseLong(string); System.out.flush(); System.out.print(string + \".\"); Sleep(mesc); sender.send(\"\".getBytes(), 0); &#125; sender.close(); receiver.close(); context.term(); &#125;&#125; taskwork.py import zmqimport timeimport syscontext = zmq.Context()receiver = context.socket(zmq.PULL)receiver.connect(\"tcp://localhost:5557\")sender = context.socket(zmq.PUSH)sender.connect(\"tcp://localhost:5558\")while True: s = receiver.recv() sys.stdout.write('.') sys.stdout.flush() time.sleep(int(s) * 0.001) sender.send(b'') tasksink.java import org.zeromq.ZMQ;public class tasksink &#123; public static void main(String[] args) &#123; ZMQ.Context context = ZMQ.context(1); ZMQ.Socket receiver = context.socket(ZMQ.PULL); receiver.bind(\"tcp://*:5558\"); String string = new String(receiver.recv(0)); long tstart = System.currentTimeMillis(); int task_nbr; int total_mesc = 0; for (task_nbr = 0; task_nbr &lt; 100; task_nbr++) &#123; string = new String(receiver.recv(0).trim()); if ((task_nbr / 10) * 10 == task_nbr) &#123; System.out.print(\":\"); &#125; else &#123; System.out.print(\".\"); &#125; &#125; long tend = System.currentTimeMillis(); System.out.println(\"\\nTotal elapsed time: \" + (tend - tstart) + \"msec\"); receiver.close(); context.term(); &#125;&#125; tasksink.py import timeimport zmqimport syscontext = zmq.Context()receiver = context.socket(zmq.PULL)receiver.bind(\"tcp://*:5558\")s = receiver.recv()tstart = time.time()for task_nbr in range(1, 100): s = receiver.recv() if task_nbr % 10 == 0: sys.stdout.write(':') else: sys.stdout.write('.') sys.stdout.flush()tend = time.time()print(\"Total elapsed time: %d msec\" % ((tend - tstart) * 1000)) 以下两点需要注意： ventilator 使用 ZMQ.PUSH 来分发任务；worker 用 ZMQ.PULL 来接收任务，用 ZMQ.PUSH 来发送结果；sink 用 ZMQ.PULL 来接收 worker 发来的结果。 ventilator 既是服务端，也是客户端（此时服务端是 sink）；worker 在两个过程中都是客户端；sink 也一直都是服务端。 参考资料 ZeroMQ官方用户指南","raw":null,"content":null,"categories":[{"name":"ZeroMQ","slug":"ZeroMQ","permalink":"http://linbingdong.com/categories/ZeroMQ/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://linbingdong.com/tags/消息队列/"},{"name":"Socket编程","slug":"Socket编程","permalink":"http://linbingdong.com/tags/Socket编程/"},{"name":"ZeroMQ","slug":"ZeroMQ","permalink":"http://linbingdong.com/tags/ZeroMQ/"}]},{"title":"Java 中定义常量的几种方法","slug":"Java 中定义常量的几种方法","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java 中定义常量的几种方法/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java 中定义常量的几种方法/","excerpt":"主要有三种：接口、类和枚举。","text":"主要有三种：接口、类和枚举。 接口： 在接口里定义域(接口中会对域自动加上 public static final ，使之成为常量) 类实现该接口即可在类中调用该常量 类： 直接用 public static final 定义常量。 枚举： 在枚举类中直接写上常量值。 示例： public class ConstTest &#123; public static void main(String[] args) &#123; Signal sg = new Signal(); System.out.println(\"interface method: \" + sg.RED); SignalClassField scf = new SignalClassField(); System.out.println(\"class method: \" + scf.RED); System.out.println(\"emun method: \" + SignalEnum.RED.toString()); &#125;&#125;//interface methodinterface SignalInterface &#123; String RED = \"InterfaceRED\"; String GREEN = \"GREEN\"; String YELLOW = \"YELLOW\";&#125;class Signal implements SignalInterface &#123;&#125;//class methodclass SignalClassField &#123; public static final String RED = \"ClassRED\"; public static final String GREEN = \"GREEN\"; public static final String YELLOW = \"YELLOW\";&#125;//enum methodenum SignalEnum &#123; RED, GREEN, YELLOW&#125; 输出： interface method: InterfaceREDclass method: ClassREDemun method: RED","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"丑数","slug":"丑数","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/丑数/","link":"","permalink":"http://linbingdong.com/2017/03/11/丑数/","excerpt":"题目描述\n把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。\n分析\n这里的因子指的是质因子。\n每个丑数等于某个比它小的丑数x2或x3或x5。根据提示中的信息，我们知道丑数可以拆分成3个子序列:\n\n1x2, 2x2, 3x2, 4x2, 5x2, 6x2, 8x2… \n1x3, 2x3, 3x3, 4x3, 5x3, 6x2, 8x2… \n1x5, 2x5, 3x5, 4x5, 5x5, 6x2, 8x2…\n\n其中1，2，3，4，5，6，8（注意，没有7）是前几个丑数。7有因子7，所以不是丑数。\n每次从三个子序列中取出当前最小的那个加入序列，直到第N个为止。\n代码:","text":"题目描述 把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 分析 这里的因子指的是质因子。 每个丑数等于某个比它小的丑数x2或x3或x5。根据提示中的信息，我们知道丑数可以拆分成3个子序列: 1x2, 2x2, 3x2, 4x2, 5x2, 6x2, 8x2… 1x3, 2x3, 3x3, 4x3, 5x3, 6x2, 8x2… 1x5, 2x5, 3x5, 4x5, 5x5, 6x2, 8x2… 其中1，2，3，4，5，6，8（注意，没有7）是前几个丑数。7有因子7，所以不是丑数。 每次从三个子序列中取出当前最小的那个加入序列，直到第N个为止。 代码: public class Solution &#123; public int GetUglyNumber_Solution(int index) &#123; if(index &lt;= 0) return 0; int[] uglynum = new int[index]; uglynum[0] = 1; int n = 0,index2 = 0,index3 = 0,index5 = 0,x2 = 0, x3 = 0, x5 = 0, min = 0; while( n + 1 &lt; index)&#123; x2 = uglynum[index2] * 2; x3 = uglynum[index3] * 3; x5 = uglynum[index5] * 5; min = Math.min(x2,Math.min(x3,x5)); if(min == x2) ++index2; else if(min == x3) ++index3; else ++index5; if(min != uglynum[n]) uglynum[++n] = min; &#125; return uglynum[index-1]; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java 关键字 static 、final 总结","slug":"Java 关键字 static 、final 总结","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java 关键字 static 、final 总结/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java 关键字 static 、final 总结/","excerpt":"static 和 final 是 Java 里两个关键字，在此对它们的用法做个总结。","text":"static 和 final 是 Java 里两个关键字，在此对它们的用法做个总结。 static被 static 修饰的域或方法属于类，独立于具体的对象。通过类名就可以直接调用，不需要实例化。访问时直接用类名.static 域和类名.static 方法即可。 static 域： 如果将域定义为 static ，每个类中只有一个这样的域。该类的所有对象都共享该 static 域。 static 方法： static 方法可以通过类名直接调用，该类的任何对象也可以调用（但不推荐）。 static 方法不能使用 this 和 super 关键字。 static 方法只能访问 static 域，不能访问实例域，因为实例域是与特定的对象相关联的。 static 方法必须被实现，而不能是 abstract 方法。 以下两种情况可以考虑使用 static 方法： 一个方法不需要访问对象状态，所需参数都是通过显示参数提供（如：Math.pow） 一个方法只需访问类的 static 域。 static 代码块： static 代码块，是在类中独立于类成员的 static 语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM 加载类时会执行这些静态的代码块，如果 static 代码块有多个，JVM 将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。所有 static 代码块都在 main 方法之前执行。 finalfinal 可以修饰域、方法和类。 final 域： 被 final 修饰的域是常量，值一旦给定就无法改变。 final 方法： 如果某个类不允许其子类覆盖某个方法，可以将该方法声明为 final 方法。 使用 final 方法有两个原因： 防止子类覆盖该方法，修改它的意义和实现。 提高效率。编译器遇到 final 方法就会使用内联机制。 final 类： final 类不能被继承。final 类中的方法自动成为 final 方法，因为不能被继承，也就不会被覆盖。 使用 final 类和 final 方法的目的都是为了确保它们不会在子类中改变语义。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"两个链表的第一个公共节点","slug":"两个链表的第一个公共节点","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/两个链表的第一个公共节点/","link":"","permalink":"http://linbingdong.com/2017/03/11/两个链表的第一个公共节点/","excerpt":"题目描述\n输入两个链表，找出它们的第一个公共结点。\n分析\n先遍历一遍分别算出两个链表的长度。算出长度差mins。较长的链表先走mins步，然后两个链表同时走。\n代码:","text":"题目描述 输入两个链表，找出它们的第一个公共结点。 分析 先遍历一遍分别算出两个链表的长度。算出长度差mins。较长的链表先走mins步，然后两个链表同时走。 代码: /*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; int count1 = 0, count2 = 0; ListNode ln1 = pHead1, ln2 = pHead2; while (ln1 != null)&#123; count1++; ln1 = ln1.next; &#125; while (ln2 != null)&#123; count2++; ln2 = ln2.next; &#125; int mins = count1 - count2; ln1 = pHead1; ln2 = pHead2; if (mins &gt; 0)&#123; while (mins &gt; 0)&#123; ln1 = ln1.next; mins--; &#125; &#125; if (mins &lt; 0)&#123; mins = -mins; while (mins &gt; 0)&#123; ln2 = ln2.next; mins--; &#125; &#125; while(ln1 != null &amp;&amp; ln1 != ln2)&#123; ln1 = ln1.next; ln2 = ln2.next; &#125; return ln1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"买苹果","slug":"买苹果","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/买苹果/","link":"","permalink":"http://linbingdong.com/2017/03/11/买苹果/","excerpt":"小易去附近的商店买苹果，奸诈的商贩使用了捆绑交易，只提供6个每袋和8个每袋的包装(包装不可拆分)。 可是小易现在只想购买恰好n个苹果，小易想购买尽量少的袋数方便携带。如果不能购买恰好n个苹果，小易将不会购买。 ","text":"小易去附近的商店买苹果，奸诈的商贩使用了捆绑交易，只提供6个每袋和8个每袋的包装(包装不可拆分)。 可是小易现在只想购买恰好n个苹果，小易想购买尽量少的袋数方便携带。如果不能购买恰好n个苹果，小易将不会购买。 输入描述: 输入一个整数n，表示小易想购买n(1 ≤ n ≤ 100)个苹果 输出描述: 输出一个整数表示最少需要购买的袋数，如果不能买恰好n个苹果则输出-1 输入例子: 20 输出例子: 3 代码: import java.util.Scanner;public class Main &#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); float n = sc.nextInt(); if (n %2 == 1 || (n &lt;= 10 &amp;&amp; n != 8 &amp;&amp; n!=6))&#123; System.out.println(-1); &#125; else&#123; System.out.println((int)Math.ceil(n/8)); &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java中Comparable与Comparator的区别","slug":"Java中Comparable与Comparator的区别","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java中Comparable与Comparator的区别/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java中Comparable与Comparator的区别/","excerpt":"相同\nComparable和Comparator都是用来实现对象的比较、排序\n要想对象比较、排序，都需要实现Comparable或Comparator接口\nComparable和Comparator都是Java的接口\n","text":"相同 Comparable和Comparator都是用来实现对象的比较、排序 要想对象比较、排序，都需要实现Comparable或Comparator接口 Comparable和Comparator都是Java的接口 区别 Comparator位于java.util包下，而Comparable位于java.lang包下 Comparable接口的实现是在类的内部（如 String、Integer已经实现了Comparable接口，自己就可以完成比较大小操作），Comparator接口的实现是在类的外部（可以理解为一个是自已完成比较，一个是外部程序实现比较） 实现Comparable接口要重写compareTo方法, 在compareTo方法里面实现比较 public class Student implements Comparable &#123; String name; int age public int compareTo(Student another) &#123; int i = 0; i = name.compareTo(another.name); if(i == 0) &#123; return age - another.age; &#125; else &#123; return i; &#125; &#125;&#125; 这时我们可以直接用 Collections.sort( StudentList ) 对其排序了.( **只需传入要排序的列表**） 实现Comparator需要重写 compare 方法 public class Student&#123; String name; int age&#125;class StudentComparator implements Comparator &#123; public int compare(Student one, Student another) &#123; int i = 0; i = one.name.compareTo(another.name); if(i == 0) &#123; return one.age - another.age; &#125; else &#123; return i; &#125; &#125;&#125; Collections.sort( StudentList , new StudentComparator()) 可以对其排序（ **不仅要传入待排序的列表，还要传入实现了Comparator的类的对象**） 总结 如果比较的方法只要用在一个类中，用该类实现Comparable接口就可以。 如果比较的方法在很多类中需要用到，就自己写个类实现Comparator接口，这样当要比较的时候把实现了Comparator接口的类传过去就可以，省得重复造轮子。这也是为什么Comparator会在java.util包下的原因。使用Comparator的优点是：1.与实体类分离 2.方便应对多变的排序规则","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"大数据基准测试工具TPCx-BB源码分析","slug":"大数据基准测试工具TPCx-BB源码分析","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/大数据基准测试工具TPCx-BB源码分析/","link":"","permalink":"http://linbingdong.com/2017/03/11/大数据基准测试工具TPCx-BB源码分析/","excerpt":"TPCx-BB是大数据基准测试工具,它通过模拟零售商的30个应用场景，执行30个查询来衡量基于Hadoop的大数据系统的包括硬件和软件的性能。其中一些场景还用到了机器学习算法（聚类、线性回归等）。为了更好地了解被测试的系统的性能，需要对TPCx-BB整个测试流程深入了解。本文详细分析了整个TPCx-BB测试工具的源码，希望能够对大家理解TPCx-BB有所帮助。","text":"TPCx-BB是大数据基准测试工具,它通过模拟零售商的30个应用场景，执行30个查询来衡量基于Hadoop的大数据系统的包括硬件和软件的性能。其中一些场景还用到了机器学习算法（聚类、线性回归等）。为了更好地了解被测试的系统的性能，需要对TPCx-BB整个测试流程深入了解。本文详细分析了整个TPCx-BB测试工具的源码，希望能够对大家理解TPCx-BB有所帮助。 代码结构主目录（$BENCH_MARK_HOME）下有： bin conf data-generator engines tools 几个子目录。 bin下有几个 module ,是执行时需要用到的脚本：bigBench、cleanLogs、logEnvInformation、runBenchmark、zipLogs等 conf下有两个配置文件：bigBench.properties 和 userSettings.conf bigBench.properties 主要设置 workload（执行的benchmarkPhases）和 power_test_0（POWER_TEST 阶段需要执行的SQL查询） 默认 workload ： workload=CLEAN_ALL,ENGINE_VALIDATION_DATA_GENERATION,ENGINE_VALIDATION_LOAD_TEST,ENGINE_VALIDATION_POWER_TEST,ENGINE_VALIDATION_RESULT_VALIDATION,CLEAN_DATA,DATA_GENERATION,BENCHMARK_START,LOAD_TEST,POWER_TEST,THROUGHPUT_TEST_1,BENCHMARK_STOP,VALIDATE_POWER_TEST,VALIDATE_THROUGHPUT_TEST_1 默认 power_test_0 ：1-30 userSetting.conf 是一些基本设置，包括JAVA environment 、default settings for benchmark（database、engine、map_tasks、scale_factor …）、HADOOP environment、HDFS config and paths、Hadoop data generation options(DFS_REPLICATION、HADOOP_JVM_ENV…) data-generator下是跟数据生成相关的脚本及配置文件。详细内容在下面介绍。 engines下是TPCx-BB支持的4种引擎：biginsights、hive、impala、spark_sql。默认引擎为hive。实际上，只有hive目录下不为空，其他三个目录下均为空，估计是现在还未完善。 tools下有两个jar包：HadoopClusterExec.jar 和 RunBigBench.jar 。其中 RunBigBench.jar 是执行TPCx-BB测试的一个非常重要的文件，大部分程序都在该jar包内。 数据生成数据生成相关程序和配置都在 data-generator 目录下。该目录下有一个 pdgf.jar 包和 config、dicts、extlib 三个子目录。 pdgf.jar是数据生成的Java程序，代码量很大。config下有两个配置文件：bigbench-generation.xml 和 bigbench-schema.xml 。 bigbench-generation.xml 主要设置生成的原始数据（不是数据库表）包含哪几张表、每张表的表名以及表输出的目录、表文件的后缀、分隔符、字符编码等。 &lt;schema name=\"default\"&gt; &lt;tables&gt; &lt;!-- not refreshed tables --&gt; &lt;!-- tables not used in benchmark, but some tables have references to them. not refreshed. Kept for legacy reasons --&gt; &lt;table name=\"income_band\"&gt;&lt;/table&gt; &lt;table name=\"reason\"&gt;&lt;/table&gt; &lt;table name=\"ship_mode\"&gt;&lt;/table&gt; &lt;table name=\"web_site\"&gt;&lt;/table&gt; &lt;!-- /tables not used in benchmark --&gt; &lt;!-- Static tables (fixed small size, generated only on node 1, skipped on others, not generated during refresh) --&gt; &lt;table name=\"date_dim\" static=\"true\"&gt;&lt;/table&gt; &lt;table name=\"time_dim\" static=\"true\"&gt;&lt;/table&gt; &lt;table name=\"customer_demographics\" static=\"true\"&gt;&lt;/table&gt; &lt;table name=\"household_demographics\" static=\"true\"&gt;&lt;/table&gt; &lt;!-- /static tables --&gt; &lt;!-- \"normal\" tables. split over all nodes. not generated during refresh --&gt; &lt;table name=\"store\"&gt;&lt;/table&gt; &lt;table name=\"warehouse\"&gt;&lt;/table&gt; &lt;table name=\"promotion\"&gt;&lt;/table&gt; &lt;table name=\"web_page\"&gt;&lt;/table&gt; &lt;!-- /\"normal\" tables.--&gt; &lt;!-- /not refreshed tables --&gt; &lt;!-- refreshed tables. Generated on all nodes. Refresh tables generate extra data during refresh (e.g. add new data to the existing tables) In \"normal\"-Phase generate table rows: [0,REFRESH_PERCENTAGE*Table.Size]; In \"refresh\"-Phase generate table rows: [REFRESH_PERCENTAGE*Table.Size+1, Table.Size] .Has effect only if $&#123;REFRESH_SYSTEM_ENABLED&#125;==1. --&gt; &lt;table name=\"customer\"&gt; &lt;scheduler name=\"DefaultScheduler\"&gt; &lt;partitioner name=\"pdgf.core.dataGenerator.scheduler.TemplatePartitioner\"&gt; &lt;prePartition&gt;&lt;![CDATA[ if($&#123;REFRESH_SYSTEM_ENABLED&#125;&gt;0)&#123; int tableID = table.getTableID(); int timeID = 0; long lastTableRow=table.getSize()-1; long rowStart; long rowStop; boolean exclude=false; long refreshRows=table.getSize()*(1.0-$&#123;REFRESH_PERCENTAGE&#125;); if($&#123;REFRESH_PHASE&#125;&gt;0)&#123; //Refresh part rowStart = lastTableRow - refreshRows +1; rowStop = lastTableRow; if(refreshRows&lt;=0)&#123; exclude=true; &#125; &#125;else&#123; //\"normal\" part rowStart = 0; rowStop = lastTableRow - refreshRows; &#125; return new pdgf.core.dataGenerator.scheduler.Partition(tableID, timeID,rowStart,rowStop,exclude); &#125;else&#123; //DEFAULT return getParentPartitioner().getDefaultPrePartition(project, table); &#125; ]]&gt;&lt;/prePartition&gt; &lt;/partitioner&gt; &lt;/scheduler&gt; &lt;/table&gt; &lt;output name=\"SplitFileOutputWrapper\"&gt; &lt;!-- DEFAULT output for all Tables, if no table specific output is specified--&gt; &lt;output name=\"CSVRowOutput\"&gt; &lt;fileTemplate&gt;&lt;![CDATA[outputDir + table.getName() +(nodeCount!=1?\"_\"+pdgf.util.StaticHelper.zeroPaddedNumber(nodeNumber,nodeCount):\"\")+ fileEnding]]&gt;&lt;/fileTemplate&gt; &lt;outputDir&gt;output/&lt;/outputDir&gt; &lt;fileEnding&gt;.dat&lt;/fileEnding&gt; &lt;delimiter&gt;|&lt;/delimiter&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;sortByRowID&gt;true&lt;/sortByRowID&gt; &lt;/output&gt; &lt;output name=\"StatisticsOutput\" active=\"1\"&gt; &lt;size&gt;$&#123;item_size&#125;&lt;/size&gt;&lt;!-- a counter per item .. initialize later--&gt; &lt;fileTemplate&gt;&lt;![CDATA[outputDir + table.getName()+\"_audit\" +(nodeCount!=1?\"_\"+pdgf.util.StaticHelper.zeroPaddedNumber(nodeNumber,nodeCount):\"\")+ fileEnding]]&gt;&lt;/fileTemplate&gt; &lt;outputDir&gt;output/&lt;/outputDir&gt; &lt;fileEnding&gt;.csv&lt;/fileEnding&gt; &lt;delimiter&gt;,&lt;/delimiter&gt; &lt;header&gt;&lt;!--\"\" + pdgf.util.Constants.DEFAULT_LINESEPARATOR--&gt; &lt;/header&gt; &lt;footer&gt;&lt;/footer&gt; bigbench-schema.xml 设置了很多参数，有跟表的规模有关的，比如每张表的大小（记录的条数）;绝大多数是跟表的字段有关的，比如时间的起始、结束、性别比例、结婚比例、指标的上下界等。还具体定义了每个字段是怎么生成的，以及限制条件。示例如下： 生成的数据大小由 SCALE_FACTOR（-f） 决定。如 -f 1，则生成的数据总大小约为1G；-f 100，则生成的数据总大小约为100G。那么SCALE_FACTOR（-f） 是怎么精确控制生成的数据的大小呢？ 原因是 SCALE_FACTOR（-f） 决定了每张表的记录数。如下，customer 表的记录数为 100000.0d * ${SF_sqrt}，即如果 -f 1 则 customer 表的记录数为 100000*sqrt(1)= 10万条 ;如果 -f 100 则 customer 表的记录数为 100000*sqrt(100)= 100万条 &lt;property name=\"$&#123;customer_size&#125;\" type=\"long\"&gt;100000.0d * $&#123;SF_sqrt&#125;&lt;/property&gt; &lt;property name=\"$&#123;DIMENSION_TABLES_START_DAY&#125;\" type=\"datetime\"&gt;2000-01-03 00:00:00&lt;/property&gt;&lt;property name=\"$&#123;DIMENSION_TABLES_END_DAY&#125;\" type=\"datetime\"&gt;2004-01-05 00:00:00&lt;/property&gt; &lt;property name=\"$&#123;gender_likelihood&#125;\" type=\"double\"&gt;0.5&lt;/property&gt;&lt;property name=\"$&#123;married_likelihood&#125;\" type=\"double\"&gt;0.3&lt;/property&gt; &lt;property name=\"$&#123;WP_LINK_MIN&#125;\" type=\"double\"&gt;2&lt;/property&gt;&lt;property name=\"$&#123;WP_LINK_MAX&#125;\" type=\"double\"&gt;25&lt;/property&gt; &lt;field name=\"d_date\" size=\"13\" type=\"CHAR\" primary=\"false\"&gt; &lt;gen_DateTime&gt; &lt;disableRng&gt;true&lt;/disableRng&gt; &lt;useFixedStepSize&gt;true&lt;/useFixedStepSize&gt; &lt;startDate&gt;$&#123;date_dim_begin_date&#125;&lt;/startDate&gt; &lt;endDate&gt;$&#123;date_dim_end_date&#125;&lt;/endDate&gt; &lt;outputFormat&gt;yyyy-MM-dd&lt;/outputFormat&gt; &lt;/gen_DateTime&gt;&lt;/field&gt; &lt;field name=\"t_time_id\" size=\"16\" type=\"CHAR\" primary=\"false\"&gt; &lt;gen_ConvertNumberToString&gt; &lt;gen_Id/&gt; &lt;size&gt;16.0&lt;/size&gt; &lt;characters&gt;ABCDEFGHIJKLMNOPQRSTUVWXYZ&lt;/characters&gt; &lt;/gen_ConvertNumberToString&gt;&lt;/field&gt; &lt;field name=\"cd_dep_employed_count\" size=\"10\" type=\"INTEGER\" primary=\"false\"&gt; &lt;gen_Null probability=\"$&#123;NULL_CHANCE&#125;\"&gt; &lt;gen_WeightedListItem filename=\"dicts/bigbench/ds-genProbabilities.txt\" list=\"dependent_count\" valueColumn=\"0\" weightColumn=\"0\" /&gt; &lt;/gen_Null&gt; &lt;/field&gt; dicts下有city.dict、country.dict、male.dict、female.dict、state.dict、mail_provider.dict等字典文件，表里每一条记录的各个字段应该是从这些字典里生成的。 extlib下是引用的外部程序jar包。有 lucene-core-4.9.0.jar、commons-net-3.3.jar、xml-apis.jar和log4j-1.2.15.jar等 总结： pdgf.jar根据bigbench-generation.xml 和 bigbench-schema.xml两个文件里的配置（表名、字段名、表的记录条数、每个字段生成的规则），从 dicts 目录下对应的 .dict文件获取表中每一条记录、每个字段的值，生成原始数据。 customer 表里的某条记录如下： 0 AAAAAAAAAAAAAAAA 1824793 3203 2555 28776 14690 Ms. Marisa Harrington N 17 4 1988 UNITED ARAB EMIRATES RRCyuY3XfE3a Marisa.Harrington@lawyer.com gdMmGdU9 如果执行 TPCx-BB 测试时指定 -f 1（SCALE_FACTOR = 1） 则最终生成的原始数据总大小约为 1G(977M+8.6M) [root@node-20-100 ~]# hdfs dfs -du -h /user/root/benchmarks/bigbench/data12.7 M 38.0 M /user/root/benchmarks/bigbench/data/customer5.1 M 15.4 M /user/root/benchmarks/bigbench/data/customer_address74.2 M 222.5 M /user/root/benchmarks/bigbench/data/customer_demographics14.7 M 44.0 M /user/root/benchmarks/bigbench/data/date_dim151.5 K 454.4 K /user/root/benchmarks/bigbench/data/household_demographics327 981 /user/root/benchmarks/bigbench/data/income_band405.3 M 1.2 G /user/root/benchmarks/bigbench/data/inventory6.5 M 19.5 M /user/root/benchmarks/bigbench/data/item4.0 M 12.0 M /user/root/benchmarks/bigbench/data/item_marketprices53.7 M 161.2 M /user/root/benchmarks/bigbench/data/product_reviews45.3 K 135.9 K /user/root/benchmarks/bigbench/data/promotion3.0 K 9.1 K /user/root/benchmarks/bigbench/data/reason1.2 K 3.6 K /user/root/benchmarks/bigbench/data/ship_mode3.3 K 9.9 K /user/root/benchmarks/bigbench/data/store4.1 M 12.4 M /user/root/benchmarks/bigbench/data/store_returns88.5 M 265.4 M /user/root/benchmarks/bigbench/data/store_sales4.9 M 14.6 M /user/root/benchmarks/bigbench/data/time_dim584 1.7 K /user/root/benchmarks/bigbench/data/warehouse170.4 M 511.3 M /user/root/benchmarks/bigbench/data/web_clickstreams7.9 K 23.6 K /user/root/benchmarks/bigbench/data/web_page5.1 M 15.4 M /user/root/benchmarks/bigbench/data/web_returns127.6 M 382.8 M /user/root/benchmarks/bigbench/data/web_sales8.6 K 25.9 K /user/root/benchmarks/bigbench/data/web_site 执行流程要执行TPCx-BB测试，首先需要切换到TPCx-BB源程序的目录下，然后进入bin目录，执行以下语句： ./bigBench runBenchmark -f 1 -m 8 -s 2 -j 5 其中，-f、-m、-s、-j都是参数，用户可根据集群的性能以及自己的需求来设置。如果不指定，则使用默认值，默认值在 conf 目录下的 userSetting.conf 文件指定，如下： export BIG_BENCH_DEFAULT_DATABASE=\"bigbench\"export BIG_BENCH_DEFAULT_ENGINE=\"hive\"export BIG_BENCH_DEFAULT_MAP_TASKS=\"80\"export BIG_BENCH_DEFAULT_SCALE_FACTOR=\"1000\"export BIG_BENCH_DEFAULT_NUMBER_OF_PARALLEL_STREAMS=\"2\"export BIG_BENCH_DEFAULT_BENCHMARK_PHASE=\"run_query\" 默认 MAP_TASKS 为 80（-m 80）、SCALE_FACTOR 为 1000（-f 1000）、NUMBER_OF_PARALLEL_STREAMS 为 2（-s 2）。 所有可选参数及其意义如下： General options:-d 使用的数据库 (默认: $BIG_BENCH_DEFAULT_DATABASE -&gt; bigbench)-e 使用的引擎 (默认: $BIG_BENCH_DEFAULT_ENGINE -&gt; hive)-f 数据集的规模因子（scale factor） (默认: $BIG_BENCH_DEFAULT_SCALE_FACTOR -&gt; 1000)-h 显示帮助-m 数据生成的`map tasks`数 (default: $BIG_BENCH_DEFAULT_MAP_TASKS)\"-s 并行的`stream`数 (默认: $BIG_BENCH_DEFAULT_NUMBER_OF_PARALLEL_STREAMS -&gt; 2)Driver specific options:-a 伪装模式执行-b 执行期间将调用的bash脚本在标准输出中打印出来-i 指定需要执行的阶段 (详情见$BIG_BENCH_CONF_DIR/bigBench.properties)-j 指定需要执行的查询 (默认：1-30共30个查询均执行)\"-U 解锁专家模式 若指定了-U,即解锁了专家模式，则： echo \"EXPERT MODE ACTIVE\"echo \"WARNING - INTERNAL USE ONLY:\"echo \"Only set manually if you know what you are doing!\"echo \"Ignoring them is probably the best solution\" echo \"Running individual modules:\"echo \"Usage: `basename $0` module [options]\"-D 指定需要debug的查询部分. 大部分查询都只有一个单独的部分-p 需要执行的benchmark phase (默认: $BIG_BENCH_DEFAULT_BENCHMARK_PHASE -&gt; run_query)\"-q 指定需要执行哪个查询-t 指定执行查询时的stream数-v metastore population的sql脚本 (默认: $&#123;USER_POPULATE_FILE:-\"$BIG_BENCH_POPULATION_DIR/hiveCreateLoad.sql\"&#125;)\"-w metastore refresh的sql脚本 (默认: $&#123;USER_REFRESH_FILE:-\"$BIG_BENCH_REFRESH_DIR/hiveRefreshCreateLoad.sql\"&#125;)\"-y 含额外的用户自定义查询参数的文件 (global: $BIG_BENCH_ENGINE_CONF_DIR/queryParameters.sql)\"-z 含额外的用户自定义引擎设置的文件 (global: $BIG_BENCH_ENGINE_CONF_DIR/engineSettings.sql)\"List of available modules: $BIG_BENCH_ENGINE_BIN_DIR 回到刚刚执行TPCx-BB测试的语句： ./bigBench runBenchmark -f 1 -m 8 -s 2 -j 5 bigBenchbigBench是主脚本，runBenchmark是module。 bigBench 里设置了很多环境变量，因为后面调用 runBigBench.jar 的时候需要在Java程序里读取这些环境变量。 bigBench 前面都是在做一些基本工作，如设置环境变量、解析用户输入参数、赋予文件权限、设置路径等等。到最后一步调用 runBenchmark 的 runModule() 方法： 1.设置基本路径 export BIG_BENCH_VERSION=\"1.0\"export BIG_BENCH_BIN_DIR=\"$BIG_BENCH_HOME/bin\"export BIG_BENCH_CONF_DIR=\"$BIG_BENCH_HOME/conf\"export BIG_BENCH_DATA_GENERATOR_DIR=\"$BIG_BENCH_HOME/data-generator\"export BIG_BENCH_TOOLS_DIR=\"$BIG_BENCH_HOME/tools\"export BIG_BENCH_LOGS_DIR=\"$BIG_BENCH_HOME/logs\" 2.指定 core-site.xml 和 hdfs-site.xml 的路径 数据生成时要用到Hadoop集群，生成在hdfs上 export BIG_BENCH_DATAGEN_CORE_SITE=\"$BIG_BENCH_HADOOP_CONF/core-site.xml\"export BIG_BENCH_DATAGEN_HDFS_SITE=\"$BIG_BENCH_HADOOP_CONF/hdfs-site.xml\" 3.赋予整个包下所有可执行文件权限（.sh/.jar/.py） find \"$BIG_BENCH_HOME\" -name '*.sh' -exec chmod 755 &#123;&#125; +find \"$BIG_BENCH_HOME\" -name '*.jar' -exec chmod 755 &#123;&#125; +find \"$BIG_BENCH_HOME\" -name '*.py' -exec chmod 755 &#123;&#125; + 4.设置 userSetting.conf 的路径并 source USER_SETTINGS=\"$BIG_BENCH_CONF_DIR/userSettings.conf\"if [ ! -f \"$USER_SETTINGS\" ]then echo \"User settings file $USER_SETTINGS not found\" exit 1else source \"$USER_SETTINGS\"fi 5.解析输入参数和选项并根据选项的内容作设置 第一个参数必须是module_name 如果没有输入参数或者第一个参数以”-“开头，说明用户没有输入需要运行的module。 if [[ $# -eq 0 || \"`echo \"$1\" | cut -c1`\" = \"-\" ]]then export MODULE_NAME=\"\" SHOW_HELP=\"1\"else export MODULE_NAME=\"$1\" shiftfiexport LIST_OF_USER_OPTIONS=\"$@\" 解析用户输入的参数 根据用户输入的参数来设置环境变量 while getopts \":d:D:e:f:hm:p:q:s:t:Uv:w:y:z:abi:j:\" OPT; do case \"$OPT\" in # script options d) #echo \"-d was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_DATABASE=\"$OPTARG\" ;; D) #echo \"-D was triggered, Parameter: $OPTARG\" &gt;&amp;2 DEBUG_QUERY_PART=\"$OPTARG\" ;; e) #echo \"-e was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_ENGINE=\"$OPTARG\" ;; f) #echo \"-f was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_SCALE_FACTOR=\"$OPTARG\" ;; h) #echo \"-h was triggered, Parameter: $OPTARG\" &gt;&amp;2 SHOW_HELP=\"1\" ;; m) #echo \"-m was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_MAP_TASKS=\"$OPTARG\" ;; p) #echo \"-p was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_BENCHMARK_PHASE=\"$OPTARG\" ;; q) #echo \"-q was triggered, Parameter: $OPTARG\" &gt;&amp;2 QUERY_NUMBER=\"$OPTARG\" ;; s) #echo \"-t was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_NUMBER_OF_PARALLEL_STREAMS=\"$OPTARG\" ;; t) #echo \"-s was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_STREAM_NUMBER=\"$OPTARG\" ;; U) #echo \"-U was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_EXPERT_MODE=\"1\" ;; v) #echo \"-v was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_POPULATE_FILE=\"$OPTARG\" ;; w) #echo \"-w was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_REFRESH_FILE=\"$OPTARG\" ;; y) #echo \"-y was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_QUERY_PARAMS_FILE=\"$OPTARG\" ;; z) #echo \"-z was triggered, Parameter: $OPTARG\" &gt;&amp;2 USER_ENGINE_SETTINGS_FILE=\"$OPTARG\" ;; # driver options a) #echo \"-a was triggered, Parameter: $OPTARG\" &gt;&amp;2 export USER_PRETEND_MODE=\"1\" ;; b) #echo \"-b was triggered, Parameter: $OPTARG\" &gt;&amp;2 export USER_PRINT_STD_OUT=\"1\" ;; i) #echo \"-i was triggered, Parameter: $OPTARG\" &gt;&amp;2 export USER_DRIVER_WORKLOAD=\"$OPTARG\" ;; j) #echo \"-j was triggered, Parameter: $OPTARG\" &gt;&amp;2 export USER_DRIVER_QUERIES_TO_RUN=\"$OPTARG\" ;; \\?) echo \"Invalid option: -$OPTARG\" &gt;&amp;2 exit 1 ;; :) echo \"Option -$OPTARG requires an argument.\" &gt;&amp;2 exit 1 ;; esacdone 6.设置全局变量 如果用户指定了某个参数的值，则采用该值，否则使用默认值。 export BIG_BENCH_EXPERT_MODE=\"$&#123;USER_EXPERT_MODE:-\"0\"&#125;\"export SHOW_HELP=\"$&#123;SHOW_HELP:-\"0\"&#125;\"export BIG_BENCH_DATABASE=\"$&#123;USER_DATABASE:-\"$BIG_BENCH_DEFAULT_DATABASE\"&#125;\"export BIG_BENCH_ENGINE=\"$&#123;USER_ENGINE:-\"$BIG_BENCH_DEFAULT_ENGINE\"&#125;\"export BIG_BENCH_MAP_TASKS=\"$&#123;USER_MAP_TASKS:-\"$BIG_BENCH_DEFAULT_MAP_TASKS\"&#125;\"export BIG_BENCH_SCALE_FACTOR=\"$&#123;USER_SCALE_FACTOR:-\"$BIG_BENCH_DEFAULT_SCALE_FACTOR\"&#125;\"export BIG_BENCH_NUMBER_OF_PARALLEL_STREAMS=\"$&#123;USER_NUMBER_OF_PARALLEL_STREAMS:-\"$BIG_BENCH_DEFAULT_NUMBER_OF_PARALLEL_STREAMS\"&#125;\"export BIG_BENCH_BENCHMARK_PHASE=\"$&#123;USER_BENCHMARK_PHASE:-\"$BIG_BENCH_DEFAULT_BENCHMARK_PHASE\"&#125;\"export BIG_BENCH_STREAM_NUMBER=\"$&#123;USER_STREAM_NUMBER:-\"0\"&#125;\"export BIG_BENCH_ENGINE_DIR=\"$BIG_BENCH_HOME/engines/$BIG_BENCH_ENGINE\"export BIG_BENCH_ENGINE_CONF_DIR=\"$BIG_BENCH_ENGINE_DIR/conf\" 7.检测 -s -m -f -j的选项是否为数字 if [ -n \"`echo \"$BIG_BENCH_MAP_TASKS\" | sed -e 's/[0-9]*//g'`\" ]then echo \"$BIG_BENCH_MAP_TASKS is not a number\"fiif [ -n \"`echo \"$BIG_BENCH_SCALE_FACTOR\" | sed -e 's/[0-9]*//g'`\" ]then echo \"$BIG_BENCH_SCALE_FACTOR is not a number\"fiif [ -n \"`echo \"$BIG_BENCH_NUMBER_OF_PARALLEL_STREAMS\" | sed -e 's/[0-9]*//g'`\" ]then echo \"$BIG_BENCH_NUMBER_OF_PARALLEL_STREAMS is not a number\"fiif [ -n \"`echo \"$BIG_BENCH_STREAM_NUMBER\" | sed -e 's/[0-9]*//g'`\" ]then echo \"$BIG_BENCH_STREAM_NUMBER is not a number\"fi 8.检查引擎是否存在 if [ ! -d \"$BIG_BENCH_ENGINE_DIR\" ]then echo \"Engine directory $BIG_BENCH_ENGINE_DIR not found. Aborting script...\" exit 1fiif [ ! -d \"$BIG_BENCH_ENGINE_CONF_DIR\" ]then echo \"Engine configuration directory $BIG_BENCH_ENGINE_CONF_DIR not found. Aborting script...\" exit 1fi 9.设置 engineSetting.conf 路径并 source ENGINE_SETTINGS=\"$BIG_BENCH_ENGINE_CONF_DIR/engineSettings.conf\"if [ ! -f \"$ENGINE_SETTINGS\" ]then echo \"Engine settings file $ENGINE_SETTINGS not found\" exit 1else source \"$ENGINE_SETTINGS\"fi 10.检查module是否存在 当输入某个module时，系统会先到$BIG_BENCH_ENGINE_BIN_DIR/目录下去找该module是否存在，如果存在，就source &quot;$MODULE&quot;；如果该目录下不存在指定的module，再到export MODULE=&quot;$BIG_BENCH_BIN_DIR/&quot;目录下找该module，如果存在，就source &quot;$MODULE&quot;；否则，输出Module $MODULE not found, aborting script. export MODULE=\"$BIG_BENCH_ENGINE_BIN_DIR/$MODULE_NAME\"if [ -f \"$MODULE\" ]then source \"$MODULE\"else export MODULE=\"$BIG_BENCH_BIN_DIR/$MODULE_NAME\"if [ -f \"$MODULE\" ]then source \"$MODULE\"else echo \"Module $MODULE not found, aborting script.\" exit 1fifi 11.检查module里的runModule（）、helpModule ( )、runEngineCmd()方法是否有定义 MODULE_RUN_METHOD=\"runModule\"if ! declare -F \"$MODULE_RUN_METHOD\" &gt; /dev/null 2&gt;&amp;1then echo \"$MODULE_RUN_METHOD was not implemented, aborting script\" exit 1fi 12.运行module 如果module是runBenchmark，执行runCmdWithErrorCheck &quot;$MODULE_RUN_METHOD&quot;也就是runCmdWithErrorCheck runModule（） 由上可以看出，bigBench脚本主要执行一些如设置环境变量、赋予权限、检查并解析输入参数等基础工作，最终调用runBenchmark的runModule()方法继续往下执行。 runBenchmark接下来看看runBenchmark脚本。 runBenchmark里有两个函数：helpModule ()和runModule ()。 helpModule ()就是显示帮助。 runModule ()是运行runBenchmark模块时真正调用的函数。该函数主要做四件事： 清除之前生成的日志 调用RunBigBench.jar来执行 logEnvInformation 将日志文件夹打包成zip 源码如下： runModule () &#123; #check input parameters if [ \"$BIG_BENCH_NUMBER_OF_PARALLEL_STREAMS\" -le 0 ] then echo \"The number of parallel streams -s must be greater than 0\" return 1 fi \"$&#123;BIG_BENCH_BIN_DIR&#125;/bigBench\" cleanLogs -U $LIST_OF_USER_OPTIONS \"$BIG_BENCH_JAVA\" -jar \"$&#123;BIG_BENCH_TOOLS_DIR&#125;/RunBigBench.jar\" \"$&#123;BIG_BENCH_BIN_DIR&#125;/bigBench\" logEnvInformation -U $LIST_OF_USER_OPTIONS \"$&#123;BIG_BENCH_BIN_DIR&#125;/bigBench\" zipLogs -U $LIST_OF_USER_OPTIONS return $?&#125; 相当于运行runBenchmark模块时又调用了cleanLogs、logEnvInformation、zipLogs三个模块以及RunBigBench.jar。其中RunBigBench.jar是TCPx-BB测试执行的核心代码，用Java语言编写。接下来分析RunBigBench.jar源码。 runModule()runModule()函数用来执行某个module。我们已知，执行某个module需要切换到主目录下的bin目录，然后执行： ./bigBench module_name arguments 在runModule()函数里，cmdLine用来生成如上命令。 ArrayList cmdLine = new ArrayList();cmdLine.add(\"bash\");cmdLine.add(this.runScript);cmdLine.add(benchmarkPhase.getRunModule());cmdLine.addAll(arguments); 其中，this.runScript为： this.runScript = (String)env.get(\"BIG_BENCH_BIN_DIR\") + \"/bigBench\"; benchmarkPhase.getRunModule()用来获得需要执行的module。 arguments为用户输入的参数。 至此，cmdLine为： bash $BIG_BENCH_BIN_DIR/bigBench module_name arguments 那么，怎么让系统执行该bash命令呢？答案是调用runCmd()方法。 boolean successful = this.runCmd(this.homeDir, benchmarkPhase.isPrintStdOut(), (String[])cmdLine.toArray(new String[0])); 接下来介绍rumCmd()方法 runCmd()runCmd()方法通过ProcessBuilder来创建一个操作系统进程，并用该进程执行以上的bash命令。 ProcessBuilder还可以设置工作目录和环境。 ProcessBuilder pb = new ProcessBuilder(command);pb.directory(new File(workingDirectory));Process p = null;---p = pb.start(); getQueryList()getQueryList()用来获得需要执行的查询列表。从$BIG_BENCH_LOGS_DIR/bigBench.properties文件中读取。与$BIG_BENCH_HOME/conf/bigBench.properties内容一致。 bigBench.properties里power_test_0=1-30规定了powter_test_0阶段需要执行的查询及其顺序。 可以用区间如 5-12 或者单个数字如 21 表示，中间用 , 隔开。 power_test_0=28-25,2-5,10,22,30 表示powter_test_0阶段需要执行的查询及其顺序为：25,26,27,28,2,3,4,5,10,22,30 如果想让30个查询按顺序执行，则： power_test_0=1-30 获得查询列表的源码如下： private List&lt;Integer&gt; getQueryList(BigBench.BenchmarkPhase benchmarkPhase, int streamNumber) &#123; String SHUFFLED_NAME_PATTERN = \"shuffledQueryList\"; BigBench.BenchmarkPhase queryOrderBasicPhase = BigBench.BenchmarkPhase.POWER_TEST; String propertyKey = benchmarkPhase.getQueryListProperty(streamNumber); boolean queryOrderCached = benchmarkPhase.isQueryOrderCached(); if(queryOrderCached &amp;&amp; this.queryListCache.containsKey(propertyKey)) &#123; return new ArrayList((Collection)this.queryListCache.get(propertyKey)); &#125; else &#123; Object queryList; String basicPhaseNamePattern; if(!this.properties.containsKey(propertyKey)) &#123; if(benchmarkPhase.isQueryOrderRandom()) &#123; if(!this.queryListCache.containsKey(\"shuffledQueryList\")) &#123; basicPhaseNamePattern = queryOrderBasicPhase.getQueryListProperty(0); if(!this.properties.containsKey(basicPhaseNamePattern)) &#123; throw new IllegalArgumentException(\"Property \" + basicPhaseNamePattern + \" is not defined, but is the basis for shuffling the query list.\"); &#125; this.queryListCache.put(\"shuffledQueryList\", this.getQueryList(queryOrderBasicPhase, 0)); &#125; queryList = (List)this.queryListCache.get(\"shuffledQueryList\"); this.shuffleList((List)queryList, this.rnd); &#125; else &#123; queryList = this.getQueryList(queryOrderBasicPhase, 0); &#125; &#125; else &#123; queryList = new ArrayList(); String[] var11; int var10 = (var11 = this.properties.getProperty(propertyKey).split(\",\")).length; label65: for(int var9 = 0; var9 &lt; var10; ++var9) &#123; basicPhaseNamePattern = var11[var9]; String[] queryRange = basicPhaseNamePattern.trim().split(\"-\"); switch(queryRange.length) &#123; case 1: ((List)queryList).add(Integer.valueOf(Integer.parseInt(queryRange[0].trim()))); break; case 2: int startQuery = Integer.parseInt(queryRange[0]); int endQuery = Integer.parseInt(queryRange[1]); int i; if(startQuery &gt; endQuery) &#123; i = startQuery; while(true) &#123; if(i &lt; endQuery) &#123; continue label65; &#125; ((List)queryList).add(Integer.valueOf(i)); --i; &#125; &#125; else &#123; i = startQuery; while(true) &#123; if(i &gt; endQuery) &#123; continue label65; &#125; ((List)queryList).add(Integer.valueOf(i)); ++i; &#125; &#125; default: throw new IllegalArgumentException(\"Query numbers must be in the form X or X-Y, comma separated.\"); &#125; &#125; &#125; if(queryOrderCached) &#123; this.queryListCache.put(propertyKey, new ArrayList((Collection)queryList)); &#125; return new ArrayList((Collection)queryList); &#125;&#125; parseEnvironment()parseEnvironment()读取系统的环境变量并解析。 Map env = System.getenv();this.version = (String)env.get(\"BIG_BENCH_VERSION\");this.homeDir = (String)env.get(\"BIG_BENCH_HOME\");this.confDir = (String)env.get(\"BIG_BENCH_CONF_DIR\");this.runScript = (String)env.get(\"BIG_BENCH_BIN_DIR\") + \"/bigBench\";this.datagenDir = (String)env.get(\"BIG_BENCH_DATA_GENERATOR_DIR\");this.logDir = (String)env.get(\"BIG_BENCH_LOGS_DIR\");this.dataGenLogFile = (String)env.get(\"BIG_BENCH_DATAGEN_STAGE_LOG\");this.loadLogFile = (String)env.get(\"BIG_BENCH_LOADING_STAGE_LOG\");this.engine = (String)env.get(\"BIG_BENCH_ENGINE\");this.database = (String)env.get(\"BIG_BENCH_DATABASE\");this.mapTasks = (String)env.get(\"BIG_BENCH_MAP_TASKS\");this.numberOfParallelStreams = Integer.parseInt((String)env.get(\"BIG_BENCH_NUMBER_OF_PARALLEL_STREAMS\"));this.scaleFactor = Long.parseLong((String)env.get(\"BIG_BENCH_SCALE_FACTOR\"));this.stopAfterFailure = ((String)env.get(\"BIG_BENCH_STOP_AFTER_FAILURE\")).equals(\"1\"); 并自动在用户指定的参数后面加上 -U (解锁专家模式) this.userArguments.add(\"-U\"); 如果用户指定了 PRETEND_MODE、PRINT_STD_OUT、WORKLOAD、QUERIES_TO_RUN，则以用户指定的参数为准，否则使用默认值。 if(env.containsKey(\"USER_PRETEND_MODE\")) &#123; this.properties.setProperty(\"pretend_mode\", (String)env.get(\"USER_PRETEND_MODE\"));&#125;if(env.containsKey(\"USER_PRINT_STD_OUT\")) &#123; this.properties.setProperty(\"show_command_stdout\", (String)env.get(\"USER_PRINT_STD_OUT\"));&#125;if(env.containsKey(\"USER_DRIVER_WORKLOAD\")) &#123; this.properties.setProperty(\"workload\", (String)env.get(\"USER_DRIVER_WORKLOAD\"));&#125;if(env.containsKey(\"USER_DRIVER_QUERIES_TO_RUN\")) &#123; this.properties.setProperty(BigBench.BenchmarkPhase.POWER_TEST.getQueryListProperty(0), (String)env.get(\"USER_DRIVER_QUERIES_TO_RUN\"));&#125; 读取 workload 并赋值 benchmarkPhases。如果 workload 里不包含 BENCHMARK_START 和 BENCHMARK_STOP，自动在 benchmarkPhases 的首位和末位分别加上 BENCHMARK_START 和 BENCHMARK_STOP。 this.benchmarkPhases = new ArrayList();Iterator var7 = Arrays.asList(this.properties.getProperty(\"workload\").split(\",\")).iterator(); while(var7.hasNext()) &#123; String benchmarkPhase = (String)var7.next(); this.benchmarkPhases.add(BigBench.BenchmarkPhase.valueOf(benchmarkPhase.trim()));&#125; if(!this.benchmarkPhases.contains(BigBench.BenchmarkPhase.BENCHMARK_START)) &#123; this.benchmarkPhases.add(0, BigBench.BenchmarkPhase.BENCHMARK_START);&#125; if(!this.benchmarkPhases.contains(BigBench.BenchmarkPhase.BENCHMARK_STOP)) &#123; this.benchmarkPhases.add(BigBench.BenchmarkPhase.BENCHMARK_STOP);&#125; run()run() 方法是 RunBigBench.jar 里核心的方法。所有的执行都是通过 run() 方法调用的。比如 runQueries()、runModule()、generateData()等。runQueries()、runModule()、generateData() 又通过调用 runCmd() 方法来创建操作系统进程，执行bash命令，调用bash脚本。 run() 方法里通过一个 while 循环来逐一执行 workload 里的每一个 benchmarkPhase。 不同的 benchmarkPhase 会调用 runQueries()、runModule()、generateData()…中的不同方法。 try &#123;long e = 0L;this.log.finer(\"Benchmark phases: \" + this.benchmarkPhases);Iterator startCheckpoint = this.benchmarkPhases.iterator();long throughputStart;while(startCheckpoint.hasNext()) &#123; BigBench.BenchmarkPhase children = (BigBench.BenchmarkPhase)startCheckpoint.next(); if(children.isPhaseDone()) &#123; this.log.info(\"The phase \" + children.name() + \" was already performed earlier. Skipping this phase\"); &#125; else &#123; try &#123; switch($SWITCH_TABLE$io$bigdatabenchmark$v1$driver$BigBench$BenchmarkPhase()[children.ordinal()]) &#123; case 1: case 20: throw new IllegalArgumentException(\"The value \" + children.name() + \" is only used internally.\"); case 2: this.log.info(children.getConsoleMessage()); e = System.currentTimeMillis(); break; case 3: if(!BigBench.BenchmarkPhase.BENCHMARK_START.isPhaseDone()) &#123; throw new IllegalArgumentException(\"Error: Cannot stop the benchmark before starting it\"); &#125; throughputStart = System.currentTimeMillis(); this.log.info(String.format(\"%-55s finished. Time: %25s\", new Object[]&#123;children.getConsoleMessage(), BigBench.Helper.formatTime(throughputStart - e)&#125;)); this.logTreeRoot.setCheckpoint(new BigBench.Checkpoint(BigBench.BenchmarkPhase.BENCHMARK, -1L, -1L, e, throughputStart, this.logTreeRoot.isSuccessful())); break; case 4: case 15: case 18: case 22: case 27: case 28: case 29: this.runModule(children, this.userArguments); break; case 5: case 10: case 11: this.runQueries(children, 1, validationArguments); break; case 6: case 9: this.runModule(children, validationArguments); break; case 7: this.generateData(children, false, validationArguments); break; case 8: this.generateData(children, true, validationArguments); break; case 12: case 19: case 24: this.runQueries(children, 1, this.userArguments); break; case 13: case 14: case 21: case 23: case 25: case 26: this.runQueries(children, this.numberOfParallelStreams, this.userArguments); break; case 16: this.generateData(children, false, this.userArguments); break; case 17: this.generateData(children, true, this.userArguments); &#125; children.setPhaseDone(true); &#125; catch (IOException var21) &#123; this.log.info(\"==============\\nBenchmark run terminated\\nReason: An error occured while running a command in phase \" + children + \"\\n==============\"); var21.printStackTrace(); if(this.stopAfterFailure || children.mustSucceed()) &#123; break; &#125; &#125; &#125;&#125; 这里的 case 1-29 并不是 1-29 条查询，而是枚举类型里的 1-29 个 benmarkPhase 。如下所示： private static enum BenchmarkPhase &#123;BENCHMARK((String)null, \"benchmark\", false, false, false, false, \"BigBench benchmark\"),BENCHMARK_START((String)null, \"benchmark_start\", false, false, false, false, \"BigBench benchmark: Start\"),BENCHMARK_STOP((String)null, \"benchmark_stop\", false, false, false, false, \"BigBench benchmark: Stop\"),CLEAN_ALL(\"cleanAll\", \"clean_all\", false, false, false, false, \"BigBench clean all\"),ENGINE_VALIDATION_CLEAN_POWER_TEST(\"cleanQuery\", \"engine_validation_power_test\", false, false, false, false, \"BigBench engine validation: Clean power test queries\"),ENGINE_VALIDATION_CLEAN_LOAD_TEST(\"cleanMetastore\", \"engine_validation_metastore\", false, false, false, false, \"BigBench engine validation: Clean metastore\"),ENGINE_VALIDATION_CLEAN_DATA(\"cleanData\", \"engine_validation_data\", false, false, false, false, \"BigBench engine validation: Clean data\"),ENGINE_VALIDATION_DATA_GENERATION(\"dataGen\", \"engine_validation_data\", false, false, false, true, \"BigBench engine validation: Data generation\"),ENGINE_VALIDATION_LOAD_TEST(\"populateMetastore\", \"engine_validation_metastore\", false, false, false, true, \"BigBench engine validation: Populate metastore\"),ENGINE_VALIDATION_POWER_TEST(\"runQuery\", \"engine_validation_power_test\", false, false, false, false, \"BigBench engine validation: Power test\"),ENGINE_VALIDATION_RESULT_VALIDATION(\"validateQuery\", \"engine_validation_power_test\", false, false, true, false, \"BigBench engine validation: Check all query results\"),CLEAN_POWER_TEST(\"cleanQuery\", \"power_test\", false, false, false, false, \"BigBench clean: Clean power test queries\"),CLEAN_THROUGHPUT_TEST_1(\"cleanQuery\", \"throughput_test_1\", false, false, false, false, \"BigBench clean: Clean first throughput test queries\"),CLEAN_THROUGHPUT_TEST_2(\"cleanQuery\", \"throughput_test_2\", false, false, false, false, \"BigBench clean: Clean second throughput test queries\"),CLEAN_LOAD_TEST(\"cleanMetastore\", \"metastore\", false, false, false, false, \"BigBench clean: Load test\"),CLEAN_DATA(\"cleanData\", \"data\", false, false, false, false, \"BigBench clean: Data\"),DATA_GENERATION(\"dataGen\", \"data\", false, false, false, true, \"BigBench preparation: Data generation\"),LOAD_TEST(\"populateMetastore\", \"metastore\", false, false, false, true, \"BigBench phase 1: Load test\"),POWER_TEST(\"runQuery\", \"power_test\", false, true, false, false, \"BigBench phase 2: Power test\"),THROUGHPUT_TEST((String)null, \"throughput_test\", false, false, false, false, \"BigBench phase 3: Throughput test\"),THROUGHPUT_TEST_1(\"runQuery\", \"throughput_test_1\", true, true, false, false, \"BigBench phase 3: First throughput test run\"),THROUGHPUT_TEST_REFRESH(\"refreshMetastore\", \"throughput_test_refresh\", false, false, false, false, \"BigBench phase 3: Throughput test data refresh\"),THROUGHPUT_TEST_2(\"runQuery\", \"throughput_test_2\", true, true, false, false, \"BigBench phase 3: Second throughput test run\"),VALIDATE_POWER_TEST(\"validateQuery\", \"power_test\", false, false, true, false, \"BigBench validation: Power test results\"),VALIDATE_THROUGHPUT_TEST_1(\"validateQuery\", \"throughput_test_1\", false, false, true, false, \"BigBench validation: First throughput test results\"),VALIDATE_THROUGHPUT_TEST_2(\"validateQuery\", \"throughput_test_2\", false, false, true, false, \"BigBench validation: Second throughput test results\"),SHOW_TIMES(\"showTimes\", \"show_times\", false, false, true, false, \"BigBench: show query times\"),SHOW_ERRORS(\"showErrors\", \"show_errors\", false, false, true, false, \"BigBench: show query errors\"),SHOW_VALIDATION(\"showValidation\", \"show_validation\", false, false, true, false, \"BigBench: show query validation results\");private String runModule;private String namePattern;private boolean queryOrderRandom;private boolean queryOrderCached;private boolean printStdOut;private boolean mustSucceed;private String consoleMessage;private boolean phaseDone;private BenchmarkPhase(String runModule, String namePattern, boolean queryOrderRandom, boolean queryOrderCached, boolean printStdOut, boolean mustSucceed, String consoleMessage) &#123; this.runModule = runModule; this.namePattern = namePattern; this.queryOrderRandom = queryOrderRandom; this.queryOrderCached = queryOrderCached; this.printStdOut = printStdOut; this.mustSucceed = mustSucceed; this.consoleMessage = consoleMessage; this.phaseDone = false;&#125; 3对应 BENCHMARK_STOP，4对应 CLEAN_ALL,29对应 SHOW_VALIDATION，依此类推… 可以看出： CLEAN_ALL、CLEAN_LOAD_TEST、LOAD_TEST、THROUGHPUT_TEST_REFRESH、SHOW_TIMES、SHOW_ERRORS、SHOW_VALIDATION等benchmarkPhases调用的是 this.runModule(children, this.userArguments); 方法是 runModule ，参数是 this.userArguments。 ENGINE_VALIDATION_CLEAN_POWER_TEST、ENGINE_VALIDATION_POWER_TEST、ENGINE_VALIDATION_RESULT_VALIDATION 调用的是 this.runQueries(children, 1, validationArguments); 方法是 runQueries ，参数是 1(stream number) 和 validationArguments。 ENGINE_VALIDATION_CLEAN_LOAD_TEST 和 ENGINE_VALIDATION_LOAD_TEST 调用的是 this.runModule(children, validationArguments); ENGINE_VALIDATION_CLEAN_DATA 调用的是 this.generateData(children, false, validationArguments); ENGINE_VALIDATION_DATA_GENERATION 调用的是 this.generateData(children, true, validationArguments); CLEAN_POWER_TEST、POWER_TEST、VALIDATE_POWER_TEST 调用的是 this.runQueries(children, 1, this.userArguments); CLEAN_THROUGHPUT_TEST_1``CLEAN_THROUGHPUT_TEST_2``THROUGHPUT_TEST_1``THROUGHPUT_TEST_2``VALIDATE_THROUGHPUT_TEST_1 VALIDATE_THROUGHPUT_TEST_2 调用的是 this.runQueries(children, this.numberOfParallelStreams, this.userArguments); CLEAN_DATA 调用的是 this.generateData(children, false, this.userArguments); DATA_GENERATION 调用的是 this.generateData(children, true, this.userArguments); 总结一下以上的方法调用可以发现： 跟 ENGINE_VALIDATION 相关的benchmarkPhase用的参数都是 validationArguments。其余用的是 userArguments 跟 POWER_TEST 相关的都是调用 runQueries() 方法，因为 POWER_TEST 就是执行SQL查询 跟 CLEAN_DATA DATA_GENERATION 相关的都是调用 generateData() 方法 跟 LOAD_TEST SHOW 相关的都是调用 runModule() 方法 benchmarkPhase 和 module 对应关系具体每个 benchmarkPhase 跟 module（执行的脚本）的对应关系如下： CLEAN_ALL -&gt; \"cleanAll\"ENGINE_VALIDATION_CLEAN_POWER_TEST -&gt; \"cleanQuery\"ENGINE_VALIDATION_CLEAN_LOAD_TEST -&gt; \"cleanMetastore\",ENGINE_VALIDATION_CLEAN_DATA -&gt; \"cleanData\"ENGINE_VALIDATION_DATA_GENERATION -&gt; \"dataGen\"ENGINE_VALIDATION_LOAD_TEST -&gt; \"populateMetastore\"ENGINE_VALIDATION_POWER_TEST -&gt; \"runQuery\"ENGINE_VALIDATION_RESULT_VALIDATION -&gt; \"validateQuery\"CLEAN_POWER_TEST -&gt; \"cleanQuery\"CLEAN_THROUGHPUT_TEST_1 -&gt; \"cleanQuery\"CLEAN_THROUGHPUT_TEST_2 -&gt; \"cleanQuery\"CLEAN_LOAD_TEST -&gt; \"cleanMetastore\"CLEAN_DATA -&gt; \"cleanData\"DATA_GENERATION -&gt; \"dataGen\"LOAD_TEST -&gt; \"populateMetastore\"POWER_TEST -&gt; \"runQuery\"THROUGHPUT_TEST -&gt; (String)nullTHROUGHPUT_TEST_1 -&gt; \"runQuery\"THROUGHPUT_TEST_REFRESH -&gt; \"refreshMetastore\"THROUGHPUT_TEST_2 -&gt; \"runQuery\"VALIDATE_POWER_TEST -&gt; \"validateQuery\"VALIDATE_THROUGHPUT_TEST_1 -&gt; \"validateQuery\"VALIDATE_THROUGHPUT_TEST_2 -&gt; \"validateQuery\"SHOW_TIMES -&gt; \"showTimes\"SHOW_ERRORS -&gt; \"showErrors\"SHOW_VALIDATION -&gt; \"showValidation\" 当执行某个 benchmarkPhase 时会去调用如上该 benchmarkPhase 对应的 module （脚本位于 $BENCH_MARK_HOME/engines/hive/bin 目录下） cmdLine.add(benchmarkPhase.getRunModule()); 程序调用流程 接下来介绍每个module的功能 modulecleanAll1. DROP DATABASE 2. 删除hdfs上的源数据 echo \"dropping database (with all tables)\"runCmdWithErrorCheck runEngineCmd -e \"DROP DATABASE IF EXISTS $BIG_BENCH_DATABASE CASCADE;\"echo \"cleaning $&#123;BIG_BENCH_HDFS_ABSOLUTE_HOME&#125;\"hadoop fs -rm -r -f -skipTrash \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_HOME&#125;\" cleanQuery1. 删除对应的 Query 生成的临时表 2. 删除对应的 Query 生成的结果表 runCmdWithErrorCheck runEngineCmd -e \"DROP TABLE IF EXISTS $TEMP_TABLE1; DROP TABLE IF EXISTS $TEMP_TABLE2; DROP TABLE IF EXISTS $RESULT_TABLE;\"return $? cleanMetastore1. 调用 `dropTables.sql` 将23张表依次DROP echo \"cleaning metastore tables\"runCmdWithErrorCheck runEngineCmd -f \"$BIG_BENCH_CLEAN_METASTORE_FILE\" export BIG_BENCH_CLEAN_METASTORE_FILE=\"$BIG_BENCH_CLEAN_DIR/dropTables.sql\" dropTables.sql 将23张表依次DROP,源码如下： DROP TABLE IF EXISTS $&#123;hiveconf:customerTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:customerAddressTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:customerDemographicsTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:dateTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:householdDemographicsTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:incomeTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:itemTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:promotionTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:reasonTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:shipModeTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:storeTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:timeTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:warehouseTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:webSiteTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:webPageTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:inventoryTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:storeSalesTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:storeReturnsTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:webSalesTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:webReturnsTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:marketPricesTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:clickstreamsTableName&#125;;DROP TABLE IF EXISTS $&#123;hiveconf:reviewsTableName&#125;; cleanData1. 删除hdfs上 /user/root/benchmarks/bigbench/data 目录 2. 删除hdfs上 /user/root/benchmarks/bigbench/data_refresh 目录 echo \"cleaning $&#123;BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR&#125;\"hadoop fs -rm -r -f -skipTrash \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR&#125;\"echo \"cleaning $&#123;BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;\"hadoop fs -rm -r -f -skipTrash \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;\"``` ### dataGen 1. 创建目录 /user/root/benchmarks/bigbench/data 并赋予权限 2. 创建目录 /user/root/benchmarks/bigbench/data_refresh 并赋予权限 3. 调用 HadoopClusterExec.jar 和 pdgf.jar 生成 base data 到 /user/root/benchmarks/bigbench/data 目录下 4. 调用 HadoopClusterExec.jar 和 pdgf.jar 生成 refresh data 到 /user/root/benchmarks/bigbench/data_refresh 目录下创建目录 /user/root/benchmarks/bigbench/data 并赋予权限```bashrunCmdWithErrorCheck hadoop fs -mkdir -p \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR&#125;\"runCmdWithErrorCheck hadoop fs -chmod 777 \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR&#125;\" 创建目录 /user/root/benchmarks/bigbench/data_refresh 并赋予权限 runCmdWithErrorCheck hadoop fs -mkdir -p \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;\"runCmdWithErrorCheck hadoop fs -chmod 777 \"$&#123;BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;\" 调用 HadoopClusterExec.jar 和 pdgf.jar 生成 base data runCmdWithErrorCheck hadoop jar \"$&#123;BIG_BENCH_TOOLS_DIR&#125;/HadoopClusterExec.jar\" -archives \"$&#123;PDGF_ARCHIVE_PATH&#125;\" $&#123;BIG_BENCH_DATAGEN_HADOOP_EXEC_DEBUG&#125; -taskFailOnNonZeroReturnValue -execCWD \"$&#123;PDGF_DISTRIBUTED_NODE_DIR&#125;\" $&#123;HadoopClusterExecOptions&#125; -exec $&#123;BIG_BENCH_DATAGEN_HADOOP_JVM_ENV&#125; -cp \"$&#123;HADOOP_CP&#125;:pdgf.jar\" $&#123;PDGF_CLUSTER_CONF&#125; pdgf.Controller -nc HadoopClusterExec.tasks -nn HadoopClusterExec.taskNumber -ns -c -sp REFRESH_PHASE 0 -o \"'$&#123;BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR&#125;/'+table.getName()+'/'\" $&#123;BIG_BENCH_DATAGEN_HADOOP_OPTIONS&#125; -s $&#123;BIG_BENCH_DATAGEN_TABLES&#125; $&#123;PDGF_OPTIONS&#125; \"$@\" 2&gt;&amp;1 | tee -a \"$BIG_BENCH_DATAGEN_STAGE_LOG\" 2&gt;&amp;1 调用 HadoopClusterExec.jar 和 pdgf.jar 生成 refresh data runCmdWithErrorCheck hadoop jar \"$&#123;BIG_BENCH_TOOLS_DIR&#125;/HadoopClusterExec.jar\" -archives \"$&#123;PDGF_ARCHIVE_PATH&#125;\" $&#123;BIG_BENCH_DATAGEN_HADOOP_EXEC_DEBUG&#125; -taskFailOnNonZeroReturnValue -execCWD \"$&#123;PDGF_DISTRIBUTED_NODE_DIR&#125;\" $&#123;HadoopClusterExecOptions&#125; -exec $&#123;BIG_BENCH_DATAGEN_HADOOP_JVM_ENV&#125; -cp \"$&#123;HADOOP_CP&#125;:pdgf.jar\" $&#123;PDGF_CLUSTER_CONF&#125; pdgf.Controller -nc HadoopClusterExec.tasks -nn HadoopClusterExec.taskNumber -ns -c -sp REFRESH_PHASE 1 -o \"'$&#123;BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;/'+table.getName()+'/'\" $&#123;BIG_BENCH_DATAGEN_HADOOP_OPTIONS&#125; -s $&#123;BIG_BENCH_DATAGEN_TABLES&#125; $&#123;PDGF_OPTIONS&#125; \"$@\" 2&gt;&amp;1 | tee -a \"$BIG_BENCH_DATAGEN_STAGE_LOG\" 2&gt;&amp;1 populateMetastore 该过程是真正的创建数据库表的过程。建表的过程调用的是 $BENCH_MARK_HOME/engines/hive/population/ 目录下的 hiveCreateLoad.sql ,通过该sql文件来建数据库表。 从 /user/root/benchmarks/bigbench/data 路径下读取 .dat 的原始数据，生成 TEXTFILE 格式的外部临时表 用 select * from 临时表 来创建最终的 ORC 格式的数据库表 删除外部临时表。 从 /user/root/benchmarks/bigbench/data 路径下读取 .dat 的原始数据，生成 TEXTFILE 格式的外部临时表 DROP TABLE IF EXISTS $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125;;CREATE EXTERNAL TABLE $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125; ( c_customer_sk bigint --not null , c_customer_id string --not null , c_current_cdemo_sk bigint , c_current_hdemo_sk bigint , c_current_addr_sk bigint , c_first_shipto_date_sk bigint , c_first_sales_date_sk bigint , c_salutation string , c_first_name string , c_last_name string , c_preferred_cust_flag string , c_birth_day int , c_birth_month int , c_birth_year int , c_birth_country string , c_login string , c_email_address string , c_last_review_date string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '$&#123;hiveconf:fieldDelimiter&#125;' STORED AS TEXTFILE LOCATION '$&#123;hiveconf:hdfsDataPath&#125;/$&#123;hiveconf:customerTableName&#125;'; 用 select * from 临时表 来创建最终的 ORC 格式的数据库表 DROP TABLE IF EXISTS $&#123;hiveconf:customerTableName&#125;;CREATE TABLE $&#123;hiveconf:customerTableName&#125;STORED AS $&#123;hiveconf:tableFormat&#125;ASSELECT * FROM $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125;; 删除外部临时表 DROP TABLE $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125;; 总结下执行以下 TPCx-BB 测试命令代码的执行步骤: ./bigBench runBenchmark -f 1 -m 8 -s 2 -j 5 runQuery1. runQuery 调用每个query下的 run.sh 里的 `query_run_main_method()` 方法 2. `query_run_main_method()` 调用 `runEngineCmd` 来执行query脚本（qxx.sql） runQuery 调用每个query下的 run.sh 里的 query_run_main_method() 方法 QUERY_MAIN_METHOD=\"query_run_main_method\"-----------------------------------------\"$QUERY_MAIN_METHOD\" 2&gt;&amp;1 | tee -a \"$LOG_FILE_NAME\" 2&gt;&amp;1 query_run_main_method() 调用 runEngineCmd 来执行query脚本（qxx.sql） query_run_main_method () &#123; QUERY_SCRIPT=\"$QUERY_DIR/$QUERY_NAME.sql\" if [ ! -r \"$QUERY_SCRIPT\" ] then echo \"SQL file $QUERY_SCRIPT can not be read.\" exit 1 fi runCmdWithErrorCheck runEngineCmd -f \"$QUERY_SCRIPT\" return $?&#125; 一般情况下 query_run_main_method () 方法只是执行对应的query脚本，但是像 q05、q20… 这些查询，用到了机器学习算法，所以在执行对应的query脚本后会把生成的结果表作为输入，然后调用执行机器学习算法（如聚类、逻辑回归）的jar包继续执行，得到最终的结果。 runEngineCmd () &#123; if addInitScriptsToParams then \"$BINARY\" \"$&#123;BINARY_PARAMS[@]&#125;\" \"$&#123;INIT_PARAMS[@]&#125;\" \"$@\" else return 1 fi&#125;BINARY=\"/usr/bin/hive\"BINARY_PARAMS+=(--hiveconf BENCHMARK_PHASE=$BIG_BENCH_BENCHMARK_PHASE --hiveconf STREAM_NUMBER=$BIG_BENCH_STREAM_NUMBER --hiveconf QUERY_NAME=$QUERY_NAME --hiveconf QUERY_DIR=$QUERY_DIR --hiveconf RESULT_TABLE=$RESULT_TABLE --hiveconf RESULT_DIR=$RESULT_DIR --hiveconf TEMP_TABLE=$TEMP_TABLE --hiveconf TEMP_DIR=$TEMP_DIR --hiveconf TABLE_PREFIX=$TABLE_PREFIX)INIT_PARAMS=(-i \"$BIG_BENCH_QUERY_PARAMS_FILE\" -i \"$BIG_BENCH_ENGINE_SETTINGS_FILE\")INIT_PARAMS+=(-i \"$LOCAL_QUERY_ENGINE_SETTINGS_FILE\")if [ -n \"$USER_QUERY_PARAMS_FILE\" ]thenif [ -r \"$USER_QUERY_PARAMS_FILE\" ]then echo \"User defined query parameter file found. Adding $USER_QUERY_PARAMS_FILE to hive init.\" INIT_PARAMS+=(-i \"$USER_QUERY_PARAMS_FILE\")else echo \"User query parameter file $USER_QUERY_PARAMS_FILE can not be read.\" return 1fifiif [ -n \"$USER_ENGINE_SETTINGS_FILE\" ]thenif [ -r \"$USER_ENGINE_SETTINGS_FILE\" ]then echo \"User defined engine settings file found. Adding $USER_ENGINE_SETTINGS_FILE to hive init.\" INIT_PARAMS+=(-i \"$USER_ENGINE_SETTINGS_FILE\")else echo \"User hive settings file $USER_ENGINE_SETTINGS_FILE can not be read.\" return 1fifireturn 0 validateQuery1. 调用每个query下的 run.sh 里的 `query_run_validate_method()` 方法 2. `query_run_validate_method()` 比较 `$BENCH_MARK_HOME/engines/hive/queries/qxx/results/qxx-result` 和hdfs上 `/user/root/benchmarks/bigbench/queryResults/qxx_hive_${BIG_BENCH_BENCHMARK_PHASE}_${BIG_BENCH_STREAM_NUMBER}_result` 两个文件，如果一样，则验证通过，否则验证失败。 if diff -q \"$VALIDATION_RESULTS_FILENAME\" &lt;(hadoop fs -cat \"$RESULT_DIR/*\")then echo \"Validation of $VALIDATION_RESULTS_FILENAME passed: Query returned correct results\"else echo \"Validation of $VALIDATION_RESULTS_FILENAME failed: Query returned incorrect results\" VALIDATION_PASSED=\"0\"fi SF为1时(-f 1)，用上面的方法比较，SF不为1（&gt;1）时,只要hdfs上的结果表中行数大于等于1即验证通过 if [ `hadoop fs -cat \"$RESULT_DIR/*\" | head -n 10 | wc -l` -ge 1 ]then echo \"Validation passed: Query returned results\"else echo \"Validation failed: Query did not return results\" return 1fi refreshMetastore1. 调用 `$BENCH_MARK_HOME/engines/hive/refresh/` 目录下的 `hiveRefreshCreateLoad.sql` 脚本 2. `hiveRefreshCreateLoad.sql` 将hdfs上 `/user/root/benchmarks/bigbench/data_refresh/` 目录下每个表数据插入外部临时表 3. 外部临时表再将每个表的数据插入Hive数据库对应的表中 hiveRefreshCreateLoad.sql 将hdfs上 /user/root/benchmarks/bigbench/data_refresh/ 目录下每个表数据插入外部临时表 DROP TABLE IF EXISTS $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125;;CREATE EXTERNAL TABLE $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125; ( c_customer_sk bigint --not null , c_customer_id string --not null , c_current_cdemo_sk bigint , c_current_hdemo_sk bigint , c_current_addr_sk bigint , c_first_shipto_date_sk bigint , c_first_sales_date_sk bigint , c_salutation string , c_first_name string , c_last_name string , c_preferred_cust_flag string , c_birth_day int , c_birth_month int , c_birth_year int , c_birth_country string , c_login string , c_email_address string , c_last_review_date string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '$&#123;hiveconf:fieldDelimiter&#125;' STORED AS TEXTFILE LOCATION '$&#123;hiveconf:hdfsDataPath&#125;/$&#123;hiveconf:customerTableName&#125;';set hdfsDataPath=$&#123;env:BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR&#125;;``` 外部临时表再将每个表的数据插入Hive数据库对应的表中```sqlINSERT INTO TABLE $&#123;hiveconf:customerTableName&#125;SELECT * FROM $&#123;hiveconf:customerTableName&#125;$&#123;hiveconf:temporaryTableSuffix&#125;; 附录在测试之前会先用PDGF（并行数据生成框架）生成数据。指定Scale Factor为1（1GB），生成以下共23张表。以下是每张表的建表语句及每张表里的某一条记录。 23张表hive&gt; show tables;OKcustomercustomer_addresscustomer_demographicsdate_dimhousehold_demographicsincome_bandinventoryitemitem_marketpricesproduct_reviewspromotionreasonship_modestorestore_returnsstore_salestime_dimwarehouseweb_clickstreamsweb_pageweb_returnsweb_salesweb_siteTime taken: 0.017 seconds, Fetched: 23 row(s) customer （99000行）4.03MB建表语句： hive&gt; show create table customer;OKCREATE TABLE `customer`( `c_customer_sk` bigint, `c_customer_id` string, `c_current_cdemo_sk` bigint, `c_current_hdemo_sk` bigint, `c_current_addr_sk` bigint, `c_first_shipto_date_sk` bigint, `c_first_sales_date_sk` bigint, `c_salutation` string, `c_first_name` string, `c_last_name` string, `c_preferred_cust_flag` string, `c_birth_day` int, `c_birth_month` int, `c_birth_year` int, `c_birth_country` string, `c_login` string, `c_email_address` string, `c_last_review_date` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/customer\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'99000\\', \\'rawDataSize\\'=\\'88084062\\', \\'totalSize\\'=\\'4221267\\', \\'transient_lastDdlTime\\'=\\'1473167154\\')Time taken: 0.116 seconds, Fetched: 34 row(s) 某一行： 0 AAAAAAAAAAAAAAAA 1824793 3203 2555 28776 14690 Ms. Marisa Harrington N 17 4 1988 UNITED ARAB EMIRATES RRCyuY3XfE3a Marisa.Harrington@lawyer.com gdMmGdU9 customer_address（49500行） 0.92MB建表语句： hive&gt; show create table customer_address;OKCREATE TABLE `customer_address`( `ca_address_sk` bigint, `ca_address_id` string, `ca_street_number` string, `ca_street_name` string, `ca_street_type` string, `ca_suite_number` string, `ca_city` string, `ca_county` string, `ca_state` string, `ca_zip` string, `ca_country` string, `ca_gmt_offset` decimal(5,2), `ca_location_type` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/customer_address\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'49500\\', \\'rawDataSize\\'=\\'55836000\\', \\'totalSize\\'=\\'966548\\', \\'transient_lastDdlTime\\'=\\'1473167160\\')Time taken: 0.043 seconds, Fetched: 29 row(s) 某一行： 6187 AAAAAAAAAAAAAJDZ 536 6th Lake Drive UKL8bE5C Lowell Brule County SD 18464 United States -6 apartment customer_demographics (19200800行）6.84MB建表语句： hive&gt; show create table customer_demographics;OKCREATE TABLE `customer_demographics`( `cd_demo_sk` bigint, `cd_gender` string, `cd_marital_status` string, `cd_education_status` string, `cd_purchase_estimate` int, `cd_credit_rating` string, `cd_dep_count` int, `cd_dep_employed_count` int, `cd_dep_college_count` int)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/customer_demographics\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'1\\', \\'numRows\\'=\\'1920800\\', \\'rawDataSize\\'=\\'718371044\\', \\'totalSize\\'=\\'7167503\\', \\'transient_lastDdlTime\\'=\\'1473167169\\') 某一行： 0 F U Primary 6000 Good 0 5 0 date_dim （109573行） 1.67MB建表语句： hive&gt; show create table date_dim;OKCREATE TABLE `date_dim`( `d_date_sk` bigint, `d_date_id` string, `d_date` string, `d_month_seq` int, `d_week_seq` int, `d_quarter_seq` int, `d_year` int, `d_dow` int, `d_moy` int, `d_dom` int, `d_qoy` int, `d_fy_year` int, `d_fy_quarter_seq` int, `d_fy_week_seq` int, `d_day_name` string, `d_quarter_name` string, `d_holiday` string, `d_weekend` string, `d_following_holiday` string, `d_first_dom` int, `d_last_dom` int, `d_same_day_ly` int, `d_same_day_lq` int, `d_current_day` string, `d_current_week` string, `d_current_month` string, `d_current_quarter` string, `d_current_year` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/date_dim\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'1\\', \\'numRows\\'=\\'109573\\', \\'rawDataSize\\'=\\'123050479\\', \\'totalSize\\'=\\'1748707\\', \\'transient_lastDdlTime\\'=\\'1473167172\\') 某一行： 0 AAAAAAAAAAAAAAAA 1900-01-01 0 0 0 1900 1 1 1 1 1900 0 0 Monday 1900Q1 Y N N 2448812 2458802 2472542 2420941 N N NN N household_demographics （7200行） 14.31KB建表语句： hive&gt; show create table household_demographics;OKCREATE TABLE `household_demographics`( `hd_demo_sk` bigint, `hd_income_band_sk` bigint, `hd_buy_potential` string, `hd_dep_count` int, `hd_vehicle_count` int)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/household_demographics\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'1\\', \\'numRows\\'=\\'7200\\', \\'rawDataSize\\'=\\'835168\\', \\'totalSize\\'=\\'14655\\', \\'transient_lastDdlTime\\'=\\'1473167173\\') 某一行： 0 3 1001-5000 0 0 income_band （20行） 754B建表语句： hive&gt; show create table income_band;OKCREATE TABLE `income_band`( `ib_income_band_sk` bigint, `ib_lower_bound` int, `ib_upper_bound` int)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/income_band\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'20\\', \\'rawDataSize\\'=\\'320\\', \\'totalSize\\'=\\'754\\', \\'transient_lastDdlTime\\'=\\'1473167179\\')Time taken: 0.032 seconds, Fetched: 19 row(s) 某一行： 0 1 10000 inventory （23255100行） 34.55MB建表语句： hive&gt; show create table inventory;OKCREATE TABLE `inventory`( `inv_date_sk` bigint, `inv_item_sk` bigint, `inv_warehouse_sk` bigint, `inv_quantity_on_hand` int)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/inventory\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'3\\', \\'numRows\\'=\\'23255100\\', \\'rawDataSize\\'=\\'651118804\\', \\'totalSize\\'=\\'36234106\\', \\'transient_lastDdlTime\\'=\\'1473167235\\')Time taken: 0.031 seconds, Fetched: 20 row(s) 某一行： 36890 0 0 503 item （17820行） 2.36MB建表语句： hive&gt; show create table item;OKCREATE TABLE `item`( `i_item_sk` bigint, `i_item_id` string, `i_rec_start_date` string, `i_rec_end_date` string, `i_item_desc` string, `i_current_price` decimal(7,2), `i_wholesale_cost` decimal(7,2), `i_brand_id` int, `i_brand` string, `i_class_id` int, `i_class` string, `i_category_id` int, `i_category` strong, `i_manufact_id` int, `i_manufact` string, `i_size` string, `i_formulation` string, `i_color` string, `i_units` string, `i_container` string, `i_manager_id` int, `i_product_name` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/item\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'1\\', \\'numRows\\'=\\'17820\\', \\'rawDataSize\\'=\\'31238428\\', \\'totalSize\\'=\\'2472973\\', \\'transient_lastDdlTime\\'=\\'1473167181\\') 某一行： 0 AAAAAAAAAAAAAAAA 2000-01-14 quickly even dinos beneath the frays must have to boost boldly careful bold escapades: stealthily even forges over the dependencies integrate always past the quiet sly decoys-- notornis sol 72.29 64.96 3898712 71TS7NSbvH1YbdiQMG6ttBHKAljiNoIRB 1 Fan Shop 9 Sports &amp; Outdoors 995 2VOxvrIWwlJQTSk6 small 99Ee1r6uFbZSSClAX3 dodger Oz Unknown 18 8m9n5Q7T33DNWidoA6nWlg6ydmpA1SKOoOJLXiLVb item_marketprices （89100行） 0.63MB建表语句： hive&gt; show create table item_marketprices;OKCREATE TABLE `item_marketprices`( `imp_sk` bigint, `imp_item_sk` bigint, `imp_competitor` string, `imp_competitor_price` decimal(7,2), `imp_start_date` bigint, `imp_end_date` bigint)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/item_marketprices\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'89100\\', \\'rawDataSize\\'=\\'21736912\\', \\'totalSize\\'=\\'657024\\', \\'transient_lastDdlTime\\'=\\'1473167275\\') 某一行： 5 4737 AAAAAAAAAAAAAAIN 66.4 36890 36958 product_reviews （89991行） 24.36MB建表语句： hive&gt; show create table product_reviews;OKCREATE TABLE `product_reviews`( `pr_review_sk` bigint, `pr_review_date` string, `pr_review_time` string, `pr_review_rating` int, `pr_item_sk` bigint, `pr_user_sk` bigint, `pr_order_sk` bigint, `pr_review_content` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/product_reviews\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'89991\\', \\'rawDataSize\\'=\\'79597043\\', \\'totalSize\\'=\\'25546821\\', \\'transient_lastDdlTime\\'=\\'1473167305\\') 某一行： 4 2004-02-25 21:43:07 1 3683 88783 41241 Had to offset the praise handed down by so many years is probably the result of some sin committed (obviously so grievous don\\&apos;t &quot;get&quot; it. Why all the original artwork by Stephen Gammel. promotion （300行） 15.83KB建表语句： hive&gt; show create table promotion;OKCREATE TABLE `promotion`( `p_promo_sk` bigint, `p_promo_id` string, `p_start_date_sk` bigint, `p_end_date_sk` bigint, `p_item_sk` bigint, `p_cost` decimal(15,2), `p_response_target` int, `p_promo_name` string, `p_channel_dmail` string, `p_channel_email` string, `p_channel_catalog` string, `p_channel_tv` string, `p_channel_radio` string, `p_channel_press` string, `p_channel_event` string, `p_channel_demo` string, `p_channel_details` string, `p_purpose` string, `p_discount_active` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/promotion\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'300\\', \\'rawDataSize\\'=\\'404926\\', \\'totalSize\\'=\\'16204\\', \\'transient_lastDdlTime\\'=\\'1473167186\\') 某一行： 7 AAAAAAAAAAAAAAAH 94455 108529 13511 427.76 1 bar YN Y N N N N N blithe grouches past the blithe quick epitaphs print rut Unknown N reason （35行） 3.17KB建表语句: hive&gt; show create table reason;OKCREATE TABLE `reason`( `r_reason_sk` bigint, `r_reason_id` string, `r_reason_desc` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/reason\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'35\\', \\'rawDataSize\\'=\\'9027\\', \\'totalSize\\'=\\'3240\\', \\'transient_lastDdlTime\\'=\\'1473167190\\') 某一行： 5 uy busily sly excuses hang: slow braids to the daring somas was toward the epitaphs-- gifts betw ship_mode （20行） 2.93KB建表语句： hive&gt; show create table ship_mode;OKCREATE TABLE `ship_mode`( `sm_ship_mode_sk` bigint, `sm_ship_mode_id` string, `sm_type` string, `sm_code` string, `sm_carrier` strong, `sm_contract` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/ship_mode\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'20\\', \\'rawDataSize\\'=\\'9576\\', \\'totalSize\\'=\\'3001\\', \\'transient_lastDdlTime\\'=\\'1473167196\\') 某一行： 12 wGyozLRZ3uL iCTZsMlNzsQ cBRc FlWM9v tm0ehuQ2 store （12行） 8.03KB建表语句： hive&gt; show create table store;OKCREATE TABLE `store`( `s_store_sk` bigint, `s_store_id` string, `s_rec_start_date` string, `s_rec_end_date` string, `s_closed_date_sk` bigint, `s_store_name` string, `s_number_employees` int, `s_floor_space` int, `s_hours` string, `s_manager` string, `s_market_id` int, `s_geography_class` string, `s_market_desc` string, `s_market_manager` string, `s_division_id` int, `s_division_name` string, `s_company_id` int, `s_company_name` string, `s_street_number` string, `s_street_name` string, `s_street_type` string, `s_suite_number` string, `s_city` string, `s_county` string, `s_state` string, `s_zip` string, `s_country` string, `s_gmt_offset` decimal(5,2), `s_tax_precentage` decimal(5,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/store\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'12\\', \\'rawDataSize\\'=\\'25962\\', \\'totalSize\\'=\\'8214\\', \\'transient_lastDdlTime\\'=\\'1473167201\\') 某一行： 10 AAAAAAAAAAAAAAAK 2000-11-01 6235 Avalon 254 6468537 8AM-12AM Michael Barlow 6 Unknown final sly gifts by the even final dependencies x-ray under the fluffy Barry Shaw 1 Unknown1Unknown 993 Mill Pkwy aQV Cold Springs Cumberland County TN 95692 United States -5 0.03 store_returns (37902行） 1.19MB建表语句： hive&gt; show create table store_returns;OKCREATE TABLE `store_returns`( `sr_returned_date_sk` bigint, `sr_return_time_sk` bigint, `sr_item_sk` bigint, `sr_customer_sk` bigint, `sr_cdemo_sk` bigint, `sr_hdemo_sk` bigint, `sr_addr_sk` bigint, `sr_store_sk` bigint, `sr_reason_sk` bigint, `sr_ticket_number` bigint, `sr_return_quantity` int, `sr_return_amt` decimal(7,2), `sr_return_tax` decimal(7,2), `sr_return_amt_inc_tax` decimal(7,2), `sr_fee` decimal(7,2), `sr_return_ship_cost` decimal(7,2), `sr_refunded_cash` decimal(7,2), `sr_reversed_charge` decimal(7,2), `sr_store_credit` decimal(7,2), `sr_net_loss` decimal(7,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/store_returns\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'37902\\', \\'rawDataSize\\'=\\'41388272\\', \\'totalSize\\'=\\'1250563\\', \\'transient_lastDdlTime\\'=\\'1473167251\\') 某一行： 37375 38182 11520 7640 242073 6754 25731 2 22 20293 33 1990.89 119.45 2110.34 34.14 2433.41 477.81 559.84 953.24 2672.31 store_sales （667579行） 23.49MB建表语句： hive&gt; show create table store_sales;OKCREATE TABLE `store_sales`( `ss_sold_date_sk` bigint, `ss_sold_time_sk` bigint, `ss_item_sk` bigint, `ss_customer_sk` bigint, `ss_cdemo_sk` bigint, `ss_hdemo_sk` bigint, `ss_addr_sk` bigint, `ss_store_sk` bigint, `ss_promo_sk` bigint, `ss_ticket_number` bigint, `ss_quantity` int, `ss_wholesale_cost` decimal(7,2), `ss_list_price` decimal(7,2), `ss_sales_price` decimal(7,2), `ss_ext_discount_amt` decimal(7,2), `ss_ext_sales_price` decimal(7,2), `ss_ext_wholesale_cost` decimal(7,2), `ss_ext_list_price` decimal(7,2), `ss_ext_tax` decimal(7,2), `ss_coupon_amt` decimal(7,2), `ss_net_paid` decimal(7,2), `ss_net_paid_inc_tax` decimal(7,2), `ss_net_profit` decimal(7,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/store_sales\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'667579\\', \\'rawDataSize\\'=\\'953293700\\', \\'totalSize\\'=\\'24629162\\', \\'transient_lastDdlTime\\'=\\'1473167245\\') 某一行： 37115 20244 16481 98676 1211207 5239 37107 9 38 11138 93 56.47 82.45 36.28 4293.81 3374.04 5251.71 7667.85 101.22 0 3374.04 3475.26 -1877.67 time_dim （86400行） 219.49KB建表语句： hive&gt; show create table time_dim;OKCREATE TABLE `time_dim`( `t_time_sk` bigint, `t_time_id` string, `t_time` int, `t_hour` int, `t_minute` int, `t_second` int, `t_am_pm` string, `t_shift` string, `t_sub_shift` string, `t_meal_time` string)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/time_dim\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'1\\', \\'numRows\\'=\\'86400\\', \\'rawDataSize\\'=\\'41040000\\', \\'totalSize\\'=\\'224757\\', \\'transient_lastDdlTime\\'=\\'1473167202\\') 某一行： 2 AAAAAAAAAAAAAAAC 2 0 0 2 AM third night warehouse （5行） 1.94KB建表语句: hive&gt; show create table warehouse;OKCREATE TABLE `warehouse`( `w_warehouse_sk` bigint, `w_warehouse_id` string, `w_warehouse_name` string, `w_warehouse_sq_ft` int, `w_street_number` string, `w_street_name` string, `w_street_type` string, `w_suite_number` string, `w_city` string, `w_county` string, `w_state` string, `w_zip` string, `w_country` string, `w_gmt_offset` decimal(5,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/warehouse\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'5\\', \\'rawDataSize\\'=\\'5695\\', \\'totalSize\\'=\\'1980\\', \\'transient_lastDdlTime\\'=\\'1473167204\\') 某一行： 1 AAAAAAAAAAAAAAAB frets would sleep 845707 181 9th 13thCourt kQ Sherwood Forest Teton County WY 87891 United States -7 web_clickstreams （6770550行） 34.11MB建表语句： hive&gt; show create table web_clickstreams;OKCREATE TABLE `web_clickstreams`( `wcs_click_date_sk` bigint, `wcs_click_time_sk` bigint, `wcs_sales_sk` bigint, `wcs_item_sk` bigint, `wcs_web_page_sk` bigint, `wcs_user_sk` bigint)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/web_clickstreams\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'6770550\\', \\'rawDataSize\\'=\\'253337416\\', \\'totalSize\\'=\\'35768476\\', \\'transient_lastDdlTime\\'=\\'1473167298\\') 某一行： 36890 27089 NULL 15465 47 NULL web_page （60行） 6.81KB建表语句： hive&gt; show create table web_page;OKCREATE TABLE `web_page`( `wp_web_page_sk` bigint, `wp_web_page_id` string, `wp_rec_start_date` string, `wp_rec_end_date` string, `wp_creation_date_sk` bigint, `wp_access_date_sk` bigint, `wp_autogen_flag` string, `wp_customer_sk` bigint, `wp_url` string, `wp_type` string, `wp_char_count` int, `wp_link_count` int, `wp_image_count` int, `wp_max_ad_count` int)ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/web_page\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'60\\', \\'rawDataSize\\'=\\'38763\\', \\'totalSize\\'=\\'6969\\', \\'transient_lastDdlTime\\'=\\'1473167215\\') 某一行： 24 AAAAAAAAAAAAAAAY 2000-12-19 38819 69008 0 44446 http://www.C8jdri37RmtbDNeFnXjmYbyBPzeO4WWK9pVYP6xtBJbaQ5yIj4s.com feedback 4340 23 5 2 web_returns （38487行） 1.40MB建表语句： hive&gt; show create table web_returns;OKCREATE TABLE `web_returns`( `wr_returned_date_sk` bigint, `wr_returned_time_sk` bigint, `wr_item_sk` bigint, `wr_refunded_customer_sk` bigint, `wr_refunded_cdemo_sk` bigint, `wr_refunded_hdemo_sk` bigint, `wr_refunded_addr_sk` bigint, `wr_returning_customer_sk` bigint, `wr_returning_cdemo_sk` bigint, `wr_returning_hdemo_sk` bigint, `wr_returning_addr_sk` bigint, `wr_web_page_sk` bigint, `wr_reason_sk` bigint, `wr_order_number` bigint, `wr_return_quantity` int, `wr_return_amt` decimal(7,2), `wr_return_tax` decimal(7,2), `wr_return_amt_inc_tax` decimal(7,2), `wr_fee` decimal(7,2), `wr_return_ship_cost` decimal(7,2), `wr_refunded_cash` decimal(7,2), `wr_reversed_charge` decimal(7,2), `wr_account_credit` decimal(7,2), `wr_net_loss` decimal(7,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/web_returns\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'38487\\', \\'rawDataSize\\'=\\'43257220\\', \\'totalSize\\'=\\'1471571\\', \\'transient_lastDdlTime\\'=\\'1473167269\\') 某一行： 38952 68126 9590 52948 893223 2020 6942 52948 893223 2020 6942 32 13 63444 33 626.0125.04 651.05 18.74 958.4 244.14 286.4 95.47 1008.48 web_sales （668052行） 32.99MB建表语句： hive&gt; show create table web_sales;OKCREATE TABLE `web_sales`( `ws_sold_date_sk` bigint, `ws_sold_time_sk` bigint, `ws_ship_date_sk` bigint, `ws_item_sk` bigint, `ws_bill_customer_sk` bigint, `ws_bill_cdemo_sk` bigint, `ws_bill_hdemo_sk` bigint, `ws_bill_addr_sk` bigint, `ws_ship_customer_sk` bigint, `ws_ship_cdemo_sk` bigint, `ws_ship_hdemo_sk` bigint, `ws_ship_addr_sk` bigint, `ws_web_page_sk` bigint, `ws_web_site_sk` bigint, `ws_ship_mode_sk` bigint, `ws_warehouse_sk` bigint, `ws_promo_sk` bigint, `ws_order_number` bigint, `ws_quantity` int, `ws_wholesale_cost` decimal(7,2), `ws_list_price` decimal(7,2), `ws_sales_price` decimal(7,2), `ws_ext_discount_amt` decimal(7,2), `ws_ext_sales_price` decimal(7,2), `ws_ext_wholesale_cost` decimal(7,2), `ws_ext_list_price` decimal(7,2), `ws_ext_tax` decimal(7,2), `ws_coupon_amt` decimal(7,2), `ws_ext_ship_cost` decimal(7,2), `ws_net_paid` decimal(7,2), `ws_net_paid_inc_tax` decimal(7,2), `ws_net_paid_inc_ship` decimal(7,2), `ws_net_paid_inc_ship_tax` decimal(7,2), `ws_net_profit` decimal(7,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/web_sales\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'668052\\', \\'rawDataSize\\'=\\'1221174888\\', \\'totalSize\\'=\\'34585166\\', \\'transient_lastDdlTime\\'=\\'1473167263\\') 某一行： 36890 26789 36993 794 85457 380790 2436 42649 29934 1583844 5251 525 2 14 1 3 120 0 93 32.62 81.22 59.29 2039.49 5513.97 3033.66 7553.46 330.84 0 1661.76 5513.97 5844.81 7175.73 7506.57 2480.31 web_site （30行）10.31KB建表语句： hive&gt; show create table web_site;OKCREATE TABLE `web_site`( `web_site_sk` bigint, `web_site_id` string, `web_rec_start_date` string, `web_rec_end_date` string, `web_name` string, `web_open_date_sk` bigint, `web_close_date_sk` bigint, `web_class` string, `web_manager` string, `web_mkt_id` int, `web_mkt_class` string, `web_mkt_desc` string, `web_market_manager` string, `web_company_id` int, `web_company_name` string, `web_street_number` string, `web_street_name` string, `web_street_type` string, `web_suite_number` string, `web_city` string, `web_county` string, `web_state` string, `web_zip` string, `web_country` string, `web_gmt_offset` decimal(5,2), `web_tax_percentage` decimal(5,2))ROW FORMAT SERDE \\'org.apache.hadoop.hive.ql.io.orc.OrcSerde\\'STORED AS INPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\\'OUTPUTFORMAT \\'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\\'LOCATION \\'hdfs://mycluster/usr/hive/warehouse/bigbench.db/web_site\\'TBLPROPERTIES ( \\'COLUMN_STATS_ACCURATE\\'=\\'true\\', \\'numFiles\\'=\\'2\\', \\'numRows\\'=\\'30\\', \\'rawDataSize\\'=\\'62832\\', \\'totalSize\\'=\\'10554\\', \\'transient_lastDdlTime\\'=\\'1473167210\\') 某一行： 2 AAAAAAAAAAAAAAAC 2002-07-17 site_0 16450 91500 Unknown Gregory George 1 sheaves despite the quietly sly asymp thin enticing frets except the sometimes final courts might promise blithe dino Frank Hernandez 1 ese 17 5th Ave EbDxJVL Georgetown Guadalupe County TX 75435 United States -6 0.01","raw":null,"content":null,"categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://linbingdong.com/categories/源码分析/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"TPCx-BB","slug":"TPCx-BB","permalink":"http://linbingdong.com/tags/TPCx-BB/"},{"name":"基准测试","slug":"基准测试","permalink":"http://linbingdong.com/tags/基准测试/"}]},{"title":"分布式一致性算法：Raft 算法（Raft 论文翻译）","slug":"分布式一致性算法：Raft 算法（Raft 论文翻译）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/分布式一致性算法：Raft 算法（Raft 论文翻译）/","link":"","permalink":"http://linbingdong.com/2017/03/11/分布式一致性算法：Raft 算法（Raft 论文翻译）/","excerpt":"Raft 算法是可以用来替代 Paxos 算法的分布式一致性算法，而且 raft 算法比 Paxos 算法更易懂且更容易实现。本文对 raft 论文进行翻译，希望能有助于读者更方便地理解 raft 的思想。如果对 Paxos 算法感兴趣，可以看我的另一篇文章：分布式系列文章——Paxos算法原理与推导","text":"Raft 算法是可以用来替代 Paxos 算法的分布式一致性算法，而且 raft 算法比 Paxos 算法更易懂且更容易实现。本文对 raft 论文进行翻译，希望能有助于读者更方便地理解 raft 的思想。如果对 Paxos 算法感兴趣，可以看我的另一篇文章：分布式系列文章——Paxos算法原理与推导 摘要Raft 是用来管理复制日志（replicated log）的一致性协议。它跟 multi-Paxos 作用相同，效率也相当，但是它的组织结构跟 Paxos 不同。这使得 Raft 比 Paxos 更容易理解并且更容易在工程实践中实现。为了使 Raft 协议更易懂，Raft 将一致性的关键元素分开，如 leader 选举、日志复制和安全性，并且它实施更强的一致性以减少必须考虑的状态的数量。用户研究的结果表明，Raft 比 Paxos 更容易学习。 Raft 还包括一个用于变更集群成员的新机制，它使用重叠的大多数（overlapping majorities）来保证安全性。 1 介绍一致性算法允许多台机器作为一个集群协同工作，并且在其中的某几台机器出故障时集群仍然能正常工作。 正因为如此，一致性算法在建立可靠的大规模软件系统方面发挥了关键作用。 在过去十年中，Paxos [15,16] 主导了关于一致性算法的讨论：大多数一致性的实现都是基于 Paxos 或受其影响，Paxos 已成为用于教授学生一致性相关知识的主要工具。 不幸的是，Paxos 实在是太难以理解，尽管许多人一直在努力尝试使其更易懂。 此外，其架构需要复杂的改变来支持实际系统。 结果是，系统开发者和学生都在与 Paxos 斗争。 在我们自己与 Paxos 斗争之后，我们开始着手寻找一个新的一致性算法，可以为系统开发和教学提供更好的基础。 我们的方法是不寻常的，因为我们的主要目标是可理解性：我们可以为实际系统定义一个一致性算法，并以比 Paxos 更容易学习的方式描述它吗？在该算法的设计过程中，重要的不仅是如何让该算法起作用，还有清晰地知道该算法为什么会起作用。 这项工作的结果是一个称为 Raft 的一致性算法。 在设计 Raft 时，我们使用了特定的技术来提高可理解性，包括分解（Raft 分离 leader 选举，日志复制和安全）和状态空间减少（相对于 Paxos ，Raft 减少了不确定性程度和服务器之间彼此不一致的方式 ）。 一项针对两个大学的 43 名学生的用户研究表明，Raft 比 Paxos 更容易理解：在学习两种算法后，其中 33 名学生能够更好地回答关于 Raft 的问题。 Raft 在许多方面类似于现有的一致性算法（尤其是 Oki 和 Liskov 的 Viewstamped Replication [29,22]），但它有几个新特性： Strong leader：在 Raft 中，日志条目（log entries）只从 leader 流向其他服务器。 这简化了复制日志的管理，使得 raft 更容易理解。 Leader 选举：Raft 使用随机计时器进行 leader 选举。 这只需在任何一致性算法都需要的心跳（heartbeats）上增加少量机制，同时能够简单快速地解决冲突。 成员变更：Raft 使用了一种新的联合一致性方法，其中两个不同配置的大多数在过渡期间重叠。 这允许集群在配置更改期间继续正常运行。 我们认为，Raft 优于 Paxos 和其他一致性算法，不仅在教学方面，在工程实现方面也是。 它比其他算法更简单且更易于理解; 它被描述得十分详细足以满足实际系统的需要; 它有多个开源实现，并被多家公司使用; 它的安全性已被正式规定和验证; 它的效率与其他算法相当。 本文的剩余部分介绍了复制状态机问题（第 2 节），讨论了 Paxos 的优点和缺点（第3节），描述了我们实现易理解性的方法（第 4 节），提出了 Raft 一致性算法（第 5-8 节），评估 Raft（第 9 节），并讨论了相关工作（第 10 节）。 2 复制状态机一致性算法是在复制状态机[37]的背景下产生的。 在这种方法中，一组服务器上的状态机计算相同状态的相同副本，并且即使某些服务器宕机，也可以继续运行。 复制状态机用于解决分布式系统中的各种容错问题。 例如，具有单个 leader 的大规模系统，如 GFS [8]，HDFS [38] 和 RAMCloud [33] ，通常使用单独的复制状态机来进行 leader 选举和存储 leader 崩溃后重新选举需要的配置信息。Chubby [2] 和 ZooKeeper [11] 都是复制状态机。 复制状态机通常使用复制日志实现，如图 1 所示。每个服务器存储一个包含一系列命令的日志，其状态机按顺序执行日志中的命令。 每个日志中命令都相同并且顺序也一样，因此每个状态机处理相同的命令序列。 这样就能得到相同的状态和相同的输出序列。 一致性算法的工作就是保证复制日志的一致性。 每台服务器上的一致性模块接收来自客户端的命令，并将它们添加到其日志中。 它与其他服务器上的一致性模块通信，以确保每个日志最终以相同的顺序包含相同的命令，即使有一些服务器失败。 一旦命令被正确复制，每个服务器上的状态机按日志顺序处理它们，并将输出返回给客户端。 这样就形成了高可用的复制状态机。 实际系统中的一致性算法通常具有以下属性： 它们确保在所有非拜占庭条件下（包括网络延迟，分区和数据包丢失，重复和乱序）的安全性（不会返回不正确的结果）。 只要任何大多数（过半）服务器都可以运行，并且可以相互通信和与客户通信，一致性算法就可用。 因此，五台服务器的典型集群可以容忍任何两台服务器的故障。 假设服务器突然宕机，它们可以稍后从状态恢复并重新加入群集。 它们不依赖于时序来确保日志的一致性：错误的时钟和极端消息延迟在最坏的情况下会导致可用性问题（译者注：言外之意是可以保证一致性）。 在通常情况下，只要集群的大部分（过半服务器）已经响应了单轮远程过程调用，命令就可以完成; 少数（一半以下）慢服务器不会影响整个系统性能。 3 Paxos 存在的问题在过去十年里，Leslie Lamport 的 Paxos 协议[15]几乎成为一致性的同义词：它是课堂上教授最多的一致性协议，并且大多数一致性的实现也以它为起点。 Paxos 首先定义了能够在单个决策（例如单个复制日志条目）上达成一致的协议。 我们将这个子集称为 single-decree Paxos。 然后 Paxos 组合该协议的多个实例以促进一系列决策，例如日志（multi-Paxos）。 Paxos能够确保安全性和活性，并且支持集群成员的变更。它的正确性已被证明，并且在正常情况下是高效的。 不幸的是，Paxos 有两个显著的缺点。 第一个缺点是 Paxos 非常难以理解。 Paxos 的描述晦涩难懂，臭名昭著（译者注：《The Part-time Parliament》比较晦涩难懂，但是《Paxos Made Simple》就比较容易理解）; 很少有人成功地理解它，即使能理解也必须付出巨大的努力。 因此，已有几个尝试用更简单的方式来描述 Paxos [16,20,21] 。 这些描述集中在 single-degree Paxos ，但它们仍然具有挑战性。 在对 NSDI 2012 参会者的非正式调查中，我们发现很少有人喜欢 Paxos ，即使是经验丰富的研究人员。 我们自己也跟 Paxos 进行了艰苦的斗争; 我们也无法完全理解整个协议，直到阅读了几个更简单的描述和自己设计替代 Paxos 的协议，整个过程花了将近一年。 Paxos 晦涩难懂的原因是作者选择了single-degree Paxos作为基础。Single-decree Paxos 分成两个阶段，这两个阶段没有简单直观的说明，并且不能被单独理解。因此，很难理解为什么该算法能起作用。Multi-Paxos 的合成规则又增加了许多复杂性。我们相信，对多个决定（日志而不是单个日志条目）达成一致的总体问题可以用其他更直接和更明显的方式进行分解。 Paxos的第二个问题是它不能为构建实际的实现提供良好的基础。 一个原因是没有针对 multi-Paxos 的广泛同意的算法。 Lamport的描述主要是关于 single-decree Paxos; 他描述了 multi-Paxos 的可能方法，但缺少许多细节。 已经有几个尝试来具体化和优化 Paxos ，例如[26]，[39]和[13]，但这些彼此各不相同并且跟 Lamport 描述的也不同。 像Chubby [4] 这样的系统已经实现了类 Paxos（Paxos-like）算法，但大多数情况下，它们的细节并没有公布。 此外，Paxos 的架构对于构建实际系统来说是一个糟糕的设计，这是 single-decree 分解的另一个结果。 例如，独立地选择日志条目集合，然后再将它们合并到顺序日志中几乎没有任何好处，这只会增加复杂性。 围绕日志设计系统是更简单和有效的方法，新日志条目按照约束顺序地添加到日志中。 Paxos 的做法适用于只需要做一次决策的情况，如果需要做一系列决策，更简单和快速的方法是先选择一个 leader ，然后让该 leader 协调这些决策。 因此，实际的系统跟 Paxos 相差很大。几乎所有的实现都是从 Paxos 开始，然后发现很多实现上的难题，接着就开发了一种和 Paxos 完全不一样的架构。这样既费时又容易出错，而且 Paxos 本身晦涩难懂使得该问题更加严重。Paxos 的公式可能可以很好地证明它的正确性，但是现实的系统和 Paxos 差别是如此之大，以至于这些证明并没有什么太大的价值。下面来自 Chubby 作者的评论非常典型： 在Paxos算法描述和实现现实系统之间有着巨大的鸿沟。最终的系统往往建立在一个还未被证明的协议之上。 由于以上问题，我们得出的结论是 Paxos 算法没有为系统实践和教学提供一个良好的基础。考虑到一致性问题在大规模软件系统中的重要性，我们决定尝试设计一个能够替代 Paxos 并且具有更好特性的一致性算法。Raft算法就是这次实验的结果。 4 为可理解性而设计在设计 Raft 算法过程中我们有几个目标：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在典型的应用条件下是可用的；并且在正常情况下是高效的。但是我们最重要的目标也是最大的挑战是可理解性。它必须保证能够被大多数人容易地理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行扩展。 在设计 Raft 算法的时候，很多情况下我们需要在多个备选方案中进行选择。在这种情况下，我们基于可理解性来评估备选方案：解释各个备选方案的难道有多大（例如，Raft 的状态空间有多复杂，是否有微妙的含义）？对于一个读者而言，完全理解这个方案和含义是否容易？ 我们意识到这样的分析具有高度的主观性；但是我们使用了两种通用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能，我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成 leader 选举，日志复制，安全性和成员变更几个部分。 我们使用的第二个方法是通过减少状态的数量来简化状态空间，使得系统更加连贯并且尽可能消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了使日志之间不一致的方式。尽管在大多数情况下我们都试图去消除不确定性，但是在某些情况下不确定性可以提高可理解性。特别是，随机化方法虽然引入了不确定性，但是他们往往能够通过使用相近的方法处理可能的选择来减少状态空间。我们使用随机化来简化 Raft 中的 leader 选举算法。 5 Raft 一致性算法Raft 是一种用来管理第 2 节中描述的复制日志的算法。图 2 是该算法的浓缩，可用作参考，图 3 列举了该算法的一些关键特性。图中的这些内容将在剩下的章节中逐一介绍。 Raft 通过首先选举一个 distinguished leader，然后让它全权负责管理复制日志来实现一致性。Leader 从客户端接收日志条目，把日志条目复制到其他服务器上，并且在保证安全性的时候通知其他服务器将日志条目应用到他们的状态机中。拥有一个 leader 大大简化了对复制日志的管理。例如，leader 可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都是从 leader 流向其他服务器。leader 可能宕机，也可能和其他服务器断开连接，这时一个新的 leader 会被选举出来。 通过选举一个 leader 的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题将会在接下来的子章节中进行讨论： Leader 选举：当前的 leader 宕机时，一个新的 leader 必须被选举出来。（5.2 节） 日志复制：Leader 必须从客户端接收日志条目然后复制到集群中的其他节点，并且强制要求其他节点的日志和自己的保持一致。 安全性：Raft 中安全性的关键是图 3 中状态机的安全性：如果有任何的服务器节点已经应用了一个特定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一条不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；该解决方案在选举机制（5.2 节）上增加了额外的限制。 在展示一致性算法之后，本章节将讨论可用性的一些问题以及时序在系统中的作用。 5.1 Raft 基础一个 Raft 集群包含若干个服务器节点；通常是 5 个，这样的系统可以容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于这三个状态之一：leader、follower 或者 candidate 。在正常情况下，集群中只有一个 leader 并且其他的节点全部都是 follower 。Follower 都是被动的：他们不会发送任何请求，只是简单的响应来自 leader 和 candidate 的请求。Leader 处理所有的客户端请求（如果一个客户端和 follower 通信，follower 会将请求重定向给 leader）。第三种状态，candidate ，是用来选举一个新的 leader（章节 5.2）。图 4 展示了这些状态和他们之间的转换关系；这些转换关系在接下来会进行讨论。 Raft 把时间分割成任意长度的任期（term），如图 5 所示。任期用连续的整数标记。每一段任期从一次选举开始，一个或者多个 candidate 尝试成为 leader 。如果一个 candidate 赢得选举，然后他就在该任期剩下的时间里充当 leader 。在某些情况下，一次选举无法选出 leader 。在这种情况下，这一任期会以没有 leader 结束；一个新的任期（包含一次新的选举）会很快重新开始。Raft 保证了在任意一个任期内，最多只有一个 leader 。 不同的服务器节点观察到的任期转换的次数可能不同，在某些情况下，一个服务器节点可能没有看到 leader 选举过程或者甚至整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，这使得服务器节点可以发现一些过期的信息比如过时的 leader 。每一个服务器节点存储一个当前任期号，该编号随着时间单调递增。服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他的小，该服务器会将自己的任期号更新为较大的那个值。如果一个 candidate 或者 leader 发现自己的任期号过期了，它会立即回到 follower 状态。如果一个节点接收到一个包含过期的任期号的请求，它会直接拒绝这个请求。 Raft 算法中服务器节点之间使用 RPC 进行通信，并且基本的一致性算法只需要两种类型的 RPC。请求投票（RequestVote） RPC 由 candidate 在选举期间发起（章节 5.2），追加条目（AppendEntries）RPC 由 leader 发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPC 来获得最佳的性能。 5.2 Leader 选举Raft 使用一种心跳机制来触发 leader 选举。当服务器程序启动时，他们都是 follower 。一个服务器节点只要能从 leader 或 candidate 处接收到有效的 RPC 就一直保持 follower 状态。Leader 周期性地向所有 follower 发送心跳（不包含日志条目的 AppendEntries RPC）来维持自己的地位。如果一个 follower 在一段选举超时时间内没有接收到任何消息，它就假设系统中没有可用的 leader ，然后开始进行选举以选出新的 leader 。 要开始一次选举过程，follower 先增加自己的当前任期号并且转换到 candidate 状态。然后投票给自己并且并行地向集群中的其他服务器节点发送 RequestVote RPC（让其他服务器节点投票给它）。Candidate 会一直保持当前状态直到以下三件事情之一发生：(a) 它自己赢得了这次的选举（收到过半的投票），(b) 其他的服务器节点成为 leader ，(c) 一段时间之后没有任何获胜者。这些结果会在下面的章节里分别讨论。 当一个 candidate 获得集群中过半服务器节点针对同一个任期的投票，它就赢得了这次选举并成为 leader 。对于同一个任期，每个服务器节点只会投给一个 candidate ，按照先来先服务（first-come-first-served）的原则（注意：5.4 节在投票上增加了额外的限制）。要求获得过半投票的规则确保了最多只有一个 candidate 赢得此次选举（图 3 中的选举安全性）。一旦 candidate 赢得选举，就立即成为 leader 。然后它会向其他的服务器节点发送心跳消息来确定自己的地位并阻止新的选举。 在等待投票期间，candidate 可能会收到另一个声称自己是 leader 的服务器节点发来的 AppendEntries RPC 。如果这个 leader 的任期号（包含在RPC中）不小于 candidate 当前的任期号，那么 candidate 会承认该 leader 的合法地位并回到 follower 状态。 如果 RPC 中的任期号比自己的小，那么 candidate 就会拒绝这次的 RPC 并且继续保持 candidate 状态。 第三种可能的结果是 candidate 既没有赢得选举也没有输：如果有多个 follower 同时成为 candidate ，那么选票可能会被瓜分以至于没有 candidate 赢得过半的投票。当这种情况发生时，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，如果没有其他机制的话，该情况可能会无限重复。 Raft 算法使用随机选举超时时间的方法来确保很少发生选票瓜分的情况，就算发生也能很快地解决。为了阻止选票一开始就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后该服务器赢得选举并在其他服务器超时之前发送心跳。同样的机制被用来解决选票被瓜分的情况。每个 candidate 在开始一次选举的时候会重置一个随机的选举超时时间，然后一直等待直到选举超时；这样减小了在新的选举中再次发生选票瓜分情况的可能性。9.3 节展示了该方案能够快速地选出一个 leader 。 选举的例子可以很好地展示可理解性是如何指导我们选择设计方案的。起初我们打算使用一种等级系统（ranking system）：每一个 candidate 都被赋予一个唯一的等级（rank），等级用来在竞争的 candidate 之间进行选择。如果一个 candidate 发现另一个 candidate 拥有更高的等级，它就会回到 follower 状态，这样高等级的 candidate 能够更加容易地赢得下一次选举。但是我们发现这种方法在可用性方面会有一下小问题。我们对该算法进行了多次调整，但是每次调整之后都会有新的小问题。最终我们认为随机重试的方法更加显然且易于理解。 5.3 日志复制Leader 一旦被选举出来，就开始为客户端请求提供服务。客户端的每一个请求都包含一条将被复制状态机执行的指令。Leader 把该指令作为一个新的条目追加到日志中去，然后并行的发起 AppendEntries RPC 给其他的服务器，让它们复制该条目。当该条目被安全地复制（下面会介绍），leader 会应用该条目到它的状态机中（状态机执行该指令）然后把执行的结果返回给客户端。如果 follower 崩溃或者运行缓慢，或者网络丢包，leader 会不断地重试 AppendEntries RPC（即使已经回复了客户端）直到所有的 follower 最终都存储了所有的日志条目。 日志以图 6 展示的方式组织。每个日志条目存储一条状态机指令和 leader 收到该指令时的任期号。任期号用来检测多个日志副本之间的不一致情况，同时也用来保证图 3 中的某些性质。每个日志条目都有一个整数索引值来表明它在日志中的位置。 Leader 决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为已提交的。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。一旦创建该日志条目的 leader 将它复制到过半的服务器上，该日志条目就会被提交（例如在图 6 中的条目 7）。同时，leader 日志中该日志条目之前的所有日志条目也都会被提交，包括由其他 leader 创建的条目。5.4 节讨论在 leader 变更之后应用该规则的一些细节，并且证明了这种提交的规则是安全的。Leader 追踪将会被提交的日志条目的最大索引，未来的所有 AppendEntries RPC 都会包含该索引，这样其他的服务器才能最终知道哪些日志条目需要被提交。Follower 一旦知道某个日志条目已经被提交就会将该日志条目应用到自己的本地状态机中（按照日志的顺序）。 我们设计了 Raft 日志机制来维持不同服务器之间日志高层次的一致性。这么做不仅简化了系统的行为也使得系统行为更加可预测，同时该机制也是保证安全性的重要组成部分。Raft 维护着以下特性，这些同时也构成了图 3 中的日志匹配特性： 如果不同日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。 如果不同日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也都相同。 Leader 在特定的任期号内的一个日志索引处最多创建一个日志条目，同时日志条目在日志中的位置也从来不会改变。该点保证了上面的第一条特性。第二个特性是由 AppendEntries RPC 执行一个简单的一致性检查所保证的。在发送 AppendEntries RPC 的时候，leader 会将前一个日志条目的索引位置和任期号包含在里面。如果 follower 在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝该新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足 Log Matching Property（日志匹配特性） 的，然后一致性检查保证了日志扩展时的日志匹配特性。因此，每当 AppendEntries RPC 返回成功时，leader 就知道 follower 的日志一定和自己相同（从第一个日志条目到最新条目）。 正常操作期间，leader 和 follower 的日志保持一致，所以 AppendEntries RPC 的一致性检查从来不会失败。然而，leader 崩溃的情况会使日志处于不一致的状态（老的 leader 可能还没有完全复制它日志里的所有条目）。这种不一致会在一系列的 leader 和 follower 崩溃的情况下加剧。图 7 展示了在什么情况下 follower 的日志可能和新的 leader 的日志不同。Follower 可能缺少一些在新 leader 中有的日志条目，也可能拥有一些新 leader 没有的日志条目，或者同时发生。缺失或多出日志条目的情况可能会涉及到多个任期。 图 7：当一个 leader 成功当选时（最上面那条日志），follower 可能是（a-f）中的任何情况。每一个盒子表示一个日志条目；里面的数字表示任期号。Follower 可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能这样发生，f 对应的服务器在任期 2 的时候是 leader ，追加了一些日志条目到自己的日志中，一条都还没提交（commit）就崩溃了；该服务器很快重启，在任期 3 重新被选为 leader，又追加了一些日志条目到自己的日志中；在这些任期 2 和任期 3 中的日志都还没被提交之前，该服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。 在 Raft 算法中，leader 通过强制 follower 复制它的日志来解决不一致的问题。这意味着 follower 中跟 leader 冲突的日志条目会被 leader 的日志条目覆盖。5.4 节会证明通过增加一个限制可以保证安全性。 要使得 follower 的日志跟自己一致，leader 必须找到两者达成一致的最大的日志条目（索引最大），删除 follower 日志中从那个点之后的所有日志条目，并且将自己从那个点之后的所有日志条目发送给 follower 。所有的这些操作都发生在对 AppendEntries RPCs 中一致性检查的回复中。Leader 针对每一个 follower 都维护了一个 nextIndex ，表示 leader 要发送给 follower 的下一个日志条目的索引。当选出一个新 leader 时，该 leader 将所有 nextIndex 的值都初始化为自己最后一个日志条目的 index 加1（图 7 中的 11）。如果 follower 的日志和 leader 的不一致，那么下一次 AppendEntries RPC 中的一致性检查就会失败。在被 follower 拒绝之后，leaer 就会减小 nextIndex 值并重试 AppendEntries RPC 。最终 nextIndex 会在某个位置使得 leader 和 follower 的日志达成一致。此时，AppendEntries RPC 就会成功，将 follower 中跟 leader 冲突的日志条目全部删除然后追加 leader 中的日志条目（如果有需要追加的日志条目的话）。一旦 AppendEntries RPC 成功，follower 的日志就和 leader 一致，并且在该任期接下来的时间里保持一致。 如果想要的话，该协议可以被优化来减少被拒绝的 AppendEntries RPC 的个数。例如，当拒绝一个 AppendEntries RPC 的请求的时候，follower 可以包含冲突条目的任期号和自己存储的那个任期的第一个 index 。借助这些信息，leader 可以跳过那个任期内所有冲突的日志条目来减小 nextIndex；这样就变成每个有冲突日志条目的任期需要一个 AppendEntries RPC 而不是每个条目一次。在实践中，我们认为这种优化是没有必要的，因为失败不经常发生并且也不可能有很多不一致的日志条目。 通过这种机制，leader 在当权之后就不需要任何特殊的操作来使日志恢复到一致状态。Leader 只需要进行正常的操作，然后日志就能在回复 AppendEntries 一致性检查失败的时候自动趋于一致。Leader 从来不会覆盖或者删除自己的日志条目（图 3 的 Leader Append-Only 属性）。 这样的日志复制机制展示了第 2 节中描述的一致性特性：只要过半的服务器能正常运行，Raft 就能够接受，复制并应用新的日志条目；在正常情况下，新的日志条目可以在一个 RPC 来回中被复制给集群中的过半机器；并且单个运行慢的 follower 不会影响整体的性能。 5.4 安全性前面的章节里描述了 Raft 算法是如何进行 leader 选举和日志复制的。然而，到目前为止描述的机制并不能充分地保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个 follower 可能会进入不可用状态，在此期间，leader 可能提交了若干的日志条目，然后这个 follower 可能会被选举为 leader 并且用新的日志条目覆盖这些日志条目；结果，不同的状态机可能会执行不同的指令序列。 这节通过对 leader 选举增加一个限制来完善 Raft 算法。这一限制保证了对于给定的任意任期号， leader 都包含了之前各个任期所有被提交的日志条目（图 3 中的 Leader Completeness 性质）。有了这一 leader 选举的限制，我们也使得提交规则更加清晰。最后，我们展示了对于 Leader Completeness 性质的简要证明并且说明该性质是如何领导复制状态机执行正确的行为的。 5.4.1 选举限制在任何基于 leader 的一致性算法中，leader 最终都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication[22]，一开始并没有包含所有已经提交的日志条目的服务器也可能被选为 leader 。这种算法包含一些额外的机制来识别丢失的日志条目并将它们传送给新的 leader ，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证新 leader 在当选时就包含了之前所有任期号中已经提交的日志条目，不需要再传送这些日志条目给新 leader 。这意味着日志条目的传送是单向的，只从 leader 到 follower，并且 leader 从不会覆盖本地日志中已经存在的条目。 Raft 使用投票的方式来阻止 candidate 赢得选举除非该 candidate 包含了所有已经提交的日志条目。候选人为了赢得选举必须与集群中的过半节点通信，这意味着至少其中一个服务器节点包含了所有已提交的日志条目。如果 candidate 的日志至少和过半的服务器节点一样新（接下来会精确地定义“新”），那么他一定包含了所有已经提交的日志条目。RequestVote RPC 执行了这样的限制： RPC 中包含了 candidate 的日志信息，如果投票者自己的日志比 candidate 的还新，它会拒绝掉该投票请求。 Raft 通过比较两份日志中最后一条日志条目的索引值和任期号来定义谁的日志比较新。如果两份日志最后条目的任期号不同，那么任期号大的日志更新。如果两份日志最后条目的任期号相同，那么日志较长的那个更新。 5.4.2 提交之前任期内的日志条目如同 5.3 节描述的那样，一旦当前任期内的某个日志条目已经存储到过半的服务器节点上，leader 就知道该日志条目已经被提交了。如果某个 leader 在提交某个日志条目之前崩溃了，以后的 leader 会试图完成该日志条目的复制。然而，如果是之前任期内的某个日志条目已经存储到过半的服务器节点上，leader 也无法立即断定该日志条目已经被提交了。图 8 展示了一种情况，一个已经被存储到过半节点上的老日志条目，仍然有可能会被未来的 leader 覆盖掉。 图 8：如图的时间序列展示了为什么 leader 无法判断老的任期号内的日志是否已经被提交。在 (a) 中，S1 是 leader ，部分地复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 中通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，继续复制日志。此时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。但是，在崩溃之前，如果 S1 在自己的任期里复制了日志条目到大多数机器上，如 (e) 中，然后这个条目就会被提交（S5 就不可能选举成功）。 在这种情况下，之前的所有日志也被提交了。 为了消除图 8 中描述的问题，Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目。只有 leader 当前任期内的日志条目才通过计算副本数目的方式来提交；一旦当前任期的某个日志条目以这种方式被提交，那么由于日志匹配特性，之前的所有日志条目也都会被间接地提交。在某些情况下，领导人可以安全地断定一个老的日志条目已经被提交（例如，如果该条目已经存储到所有服务器上），但是 Raft 为了简化问题使用了一种更加保守的方法。 Raft 会在提交规则上增加额外的复杂性是因为当 leader 复制之前任期内的日志条目时，这些日志条目都保留原来的任期号。在其他的一致性算法中，如果一个新的 leader 要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 的做法使得更加容易推导出（reason about）日志条目，因为他们自始至终都使用同一个任期号。另外，和其他的算法相比，Raft 中的新 leader 只需要发送更少的日志条目（其他算法中必须在它们被提交之前发送更多的冗余日志条目来给它们重新编号）。 5.4.3 安全性论证在给出了完整的 Raft 算法之后，我们现在可以更加精确的讨论 leader 完整性特性（Leader Completeness Prop-erty）（这一讨论基于 9.2 节的安全性证明）。我们假设 leader 完整性特性是不满足的，然后我们推出矛盾来。假设任期 T 的 leader（leader T）在任期内提交了一个日志条目，但是该日志条目没有被存储到未来某些任期的 leader 中。假设 U 是大于 T 的没有存储该日志条目的最小任期号。 图 9：如果 S1 （任期 T 的 leader）在它的任期里提交了一个新的日志条目，然后 S5 在之后的任期 U 里被选举为 leader ，那么肯定至少会有一个节点，如 S3，既接收了来自 S1 的日志条目，也给 S5 投票了。 U 一定在刚成为 leader 的时候就没有那条被提交的日志条目了（leader 从不会删除或者覆盖任何条目）。 Leader T 复制该日志条目给集群中的过半节点，同时，leader U 从集群中的过半节点赢得了选票。因此，至少有一个节点（投票者）同时接受了来自 leader T 的日志条目和给 leader U 投票了，如图 9。该投票者是产生矛盾的关键。 该投票者必须在给 leader U 投票之前先接受了从 leader T 发来的已经被提交的日志条目；否则它就会拒绝来自 leader T 的 AppendEntries 请求（因为此时它的任期号会比 T 大）。 该投票者在给 leader U 投票时依然保有这该日志条目，因为任何 U 、T 之间的 leader 都包含该日志条目（根据上述的假设），leader 从不会删除条目，并且 follower 只有跟 leader 冲突的时候才会删除条目。 该投票者把自己选票投给 leader U 时，leader U 的日志必须至少和投票者的一样新。这就导致了以下两个矛盾之一。 首先，如果该投票者和 leader U 的最后一个日志条目的任期号相同，那么 leader U 的日志至少和该投票者的一样长，所以 leader U 的日志一定包含该投票者日志中的所有日志条目。这是一个矛盾，因为该投票者包含了该已被提交的日志条目，但是在上述的假设里，leader U 是不包含的。 否则，leader U 的最后一个日志条目的任期号就必须比该投票者的大了。此外，该任期号也比 T 大，因为该投票者的最后一个日志条目的任期号至少和 T 一样大（它包含了来自任期 T 的已提交的日志）。创建了 leader U 最后一个日志条目的之前的 leader 一定已经包含了该已被提交的日志条目（根据上述假设，leader U 是第一个不包含该日志条目的 leader）。所以，根据日志匹配特性，leader U 一定也包含该已被提交的日志条目，这里产生了矛盾。 因此，所有比 T 大的任期的 leader 一定都包含了任期 T 中提交的所有日志条目。 日志匹配特性保证了未来的 leader 也会包含被间接提交的日志条目，例如图 8 (d) 中的索引 2。 通过 Leader 完整性特性，我们就能证明图 3 中的状态机安全特性，即如果某个服务器已经将某个给定的索引处的日志条目应用到自己的状态机里了，那么其他的服务器就不会在相同的索引处应用一个不同的日志条目。在一个服务器应用一个日志条目到自己的状态机中时，它的日志和 leader 的日志从开始到该日志条目都相同，并且该日志条目必须被提交。现在考虑如下最小任期号：某服务器在该任期号中某个特定的索引处应用了一个日志条目；日志完整性特性保证拥有更高任期号的 leader 会存储相同的日志条目，所以之后任期里服务器应用该索引处的日志条目也会是相同的值。因此，状态机安全特性是成立的。 最后，Raft 要求服务器按照日志索引顺序应用日志条目。再加上状态机安全特性，这就意味着所有的服务器都会按照相同的顺序应用相同的日志条目到自己的状态机中。 5.5 Follower 和 candidate 崩溃到目前为止，我们只关注了 leader 崩溃的情况。Follower 和 candidate 崩溃后的处理方式比 leader 崩溃要简单的多，并且两者的处理方式是相同的。如果 follower 或者 candidate 崩溃了，那么后续发送给他们的 RequestVote 和 AppendEntries RPCs 都会失败。Raft 通过无限的重试来处理这种失败；如果崩溃的机器重启了，那么这些 RPC 就会成功地完成。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在它重启之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样的重试不会造成任何伤害。例如，一个 follower 如果收到 AppendEntries 请求但是它的日志中已经包含了这些日志条目，它就会直接忽略这个新的请求中的这些日志条目。 5.6 定时（timing）和可用性Raft 的要求之一就是安全性不能依赖定时：整个系统不能因为某些事件运行得比预期快一点或者慢一点就产生错误的结果。但是，可用性（系统能够及时响应客户端）不可避免的要依赖于定时。例如，当有服务器崩溃时，消息交换的时间就会比正常情况下长，candidate 将不会等待太长的时间来赢得选举；没有一个稳定的 leader ，Raft 将无法工作。 Leader 选举是 Raft 中定时最为关键的方面。 只要整个系统满足下面的时间要求，Raft 就可以选举出并维持一个稳定的 leader： 广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF） 在这个不等式中，广播时间指的是一个服务器并行地发送 RPCs 给集群中所有的其他服务器并接收到响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举超时时间；平均故障间隔时间就是对于一台服务器而言，两次故障间隔时间的平均值。广播时间必须比选举超时时间小一个量级，这样 leader 才能够可靠地发送心跳消息来阻止 follower 开始进入选举状态；再加上随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间需要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定地运行。当 leader 崩溃后，整个系统会有大约选举超时时间不可用；我们希望该情况在整个时间里只占一小部分。 广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化地保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒之间，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的要求。 6 集群成员变更到目前为止，我们都假设集群的配置（参与一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔会改变集群的配置的，例如替换那些宕机的机器或者改变复制程度。尽管可以通过使整个集群下线，更新所有配置，然后重启整个集群的方式来实现，但是在更改期间集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定将配置变更自动化并将其纳入到 Raft 一致性算法中来。 为了使配置变更机制能够安全，在转换的过程中不能够存在任何时间点使得同一个任期里可能选出两个 leader 。不幸的是，任何服务器直接从旧的配置转换到新的配置的方案都是不安全的。一次性自动地转换所有服务器是不可能的，所以在转换期间整个集群可能划分成两个独立的大多数（见图 10）。 图 10：直接从一种配置转到另一种配置是不安全的，因为各个机器会在不同的时候进行转换。在这个例子中，集群从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，同一个任期里两个不同的 leader 会被选出。一个获得旧配置里过半机器的投票，一个获得新配置里过半机器的投票。 为了保证安全性，配置变更必须采用一种两阶段方法。目前有很多种两阶段的实现。例如，有些系统（比如，[22]）在第一阶段停掉旧的配置所以不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为联合一致（joint consensus）；一旦联合一致已经被提交了，那么系统就切换到新的配置上。联合一致结合了老配置和新配置： 日志条目被复制给集群中新、老配置的所有服务器。 新、旧配置的服务器都可以成为 leader 。 达成一致（针对选举和提交）需要分别在两种配置上获得过半的支持。 联合一致允许独立的服务器在不妥协安全性的前提下，在不同的时刻进行配置转换过程。此外，联合一致允许集群在配置变更期间依然响应客户端请求。 集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置变更过程。当一个 leader 接收到一个改变配置从 C-old 到 C-new 的请求，它就为联合一致将该配置（图中的 C-old,new）存储为一个日志条目，并以前面描述的方式复制该条目。一旦某个服务器将该新配置日志条目增加到自己的日志中，它就会用该配置来做出未来所有的决策（服务器总是使用它日志中最新的配置，无论该配置日志是否已经被提交）。这就意味着 leader 会使用 C-old,new 的规则来决定 C-old,new 的日志条目是什么时候被提交的。如果 leader 崩溃了，新 leader 可能是在 C-old 配置也可能是在 C-old,new 配置下选出来的，这取决于赢得选举的 candidate 是否已经接收到了 C-old,new 配置。在任何情况下， C-new 在这一时期都不能做出单方面决定。 一旦 C-old,new 被提交，那么 C-old 和 C-new 都不能在没有得到对方认可的情况下做出决定，并且 leader 完整性特性保证了只有拥有 C-old,new 日志条目的服务器才能被选举为 leader 。现在 leader 创建一个描述 C-new 配置的日志条目并复制到集群其他节点就是安全的了。此外，新的配置被服务器收到后就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新配置的服务器就可以被关闭了。如图 11 所示，任何时刻 C-old 和 C-new 都不能单方面做出决定；这保证了安全性。 在关于配置变更还有三个问题需要解决。第一个问题是，新的服务器开始时可能没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，它们需要一段时间来更新来赶上其他服务器，这段它们无法提交新的日志条目。为了避免因此而造成的系统短时间的不可用，Raft 在配置变更前引入了一个额外的阶段，在该阶段，新的服务器以没有投票权身份加入到集群中来（leader 也复制日志给它们，但是考虑过半的时候不用考虑它们）。一旦该新的服务器追赶上了集群中的其他机器，配置变更就可以按上面描述的方式进行。 第二个问题是，集群的 leader 可能不是新配置中的一员。在这种情况下，leader 一旦提交了 C-new 日志条目就会退位（回到 follower 状态）。这意味着有这样的一段时间（leader 提交 C-new 期间），leader 管理着一个不包括自己的集群；它复制着日志但不把自己算在过半里面。Leader 转换发生在 C-new 被提交的时候，因为这是新配置可以独立运转的最早时刻（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。 第三个问题是，那些被移除的服务器（不在 C-new 中）可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，它们就会进行新的选举过程。它们会发送带有新任期号的 RequestVote RPCs ，这样会导致当前的 leader 回到 follower 状态。新的 leader 最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致系统可用性很差。 为了防止这种问题，当服务器认为当前 leader 存在时，服务器会忽略RequestVote RPCs 。特别的，当服务器在最小选举超时时间内收到一个 RequestVote RPC，它不会更新任期号或者投票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待最小选举超时时间。相反，这有利于避免被移除的服务器的扰乱：如果 leader 能够发送心跳给集群，那它就不会被更大的任期号废黜。 7 日志压缩Raft 的日志在正常操作中随着包含更多的客户端请求不断地增长，但是在实际的系统中，日志不能无限制地增长。随着日志越来越长，它会占用越来越多的空间，并且需要花更多的时间来回放。如果没有一定的机制来清除日志中积累的过期的信息，最终就会带来可用性问题。 快照技术是日志压缩最简单的方法。在快照技术中，整个当前系统的状态都以快照的形式持久化到稳定的存储中，该时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。 增量压缩方法，例如日志清理或者日志结构合并树（log-structured merge trees，LSM 树），都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，它们先选择一个积累了大量已经被删除或者被覆盖的对象的数据区域，然后重写该区域还活着的对象，之后释放该区域。和快照技术相比，它们需要大量额外的机制和复杂性，快照技术通过操作整个数据集来简化该问题。状态机可以用和快照技术相同的接口来实现 LSM 树，但是日志清除方法就需要修改 Raft 了。 一台服务器用一个新快照替代了它日志中已经提交了的条目（索引 1 到 5），该快照只存储了当前的状态（变量 x 和 y 的值）。快照的 last included index 和 last included term 被保存来定位日志中条目 6 之前的快照 图 12 展示了 Raft 中快照的基本思想。每个服务器独立地创建快照，快照只包括自己日志中已经被提交的条目。主要的工作是状态机将自己的状态写入快照中。Raft 快照中也包含了少量的元数据：the last included index 指的是最后一个被快照取代的日志条目的索引值（状态机最后应用的日志条目），the last included term 是该条目的任期号。保留这些元数据是为了支持快照后第一个条目的 AppendEntries 一致性检查，因为该条目需要之前的索引值和任期号。为了支持集群成员变更（第 6 节），快照中也包括日志中最新的配置作为 last included index 。一旦服务器完成写快照，他就可以删除 last included index 之前的所有日志条目，包括之前的快照。 尽管通常服务器都是独立地创建快照，但是 leader 必须偶尔发送快照给一些落后的跟随者。这通常发生在 leader 已经丢弃了需要发送给 follower 的下一条日志条目的时候。幸运的是这种情况在常规操作中是不可能的：一个与 leader 保持同步的 follower 通常都会有该日志条目。然而一个例外的运行缓慢的 follower 或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让该 follower 更新到最新的状态的方式就是通过网络把快照发送给它。 Leader 使用 InstallSnapshot RPC 来发送快照给太落后的 follower ；见图 13。当 follower 收到带有这种 RPC 的快照时，它必须决定如何处理已经存在的日志条目。通常该快照会包含接收者日志中没有的信息。在这种情况下，follower 丢弃它所有的日志；这些会被该快照所取代，并且可能一些没有提交的条目会和该快照产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目仍然有用并保留。 这种快照的方式违反了 Raft 的 strong leader 原则，因为 follower 可以在不知道 leader 状态的情况下创建快照。但是我们认为这种违背是合乎情理的。Leader 的存在，是为了防止在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，因此没有决策会冲突。数据依然只能从 leader 流到 follower ，只是 follower 可以重新组织它们的数据了。 我们考虑过一种可替代的基于 leader 的快照方案，在该方案中，只有leader 会创建快照，然后 leader 会发送它的快照给所有的 follower 。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照过程。每个 follower 都已经拥有了创建自己的快照所需要的信息，而且很显然，follower 从本地的状态中创建快照远比通过网络接收别人发来的要来得经济。第二，leader 的实现会更加复杂。例如，leader 发送快照给 follower 的同时也要并行地将新的日志条目发送给它们，这样才不会阻塞新的客户端请求。 还有两个问题会影响快照的性能。首先，服务器必须决定什么时候创建快照。如果快照创建过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，就要承担耗尽存储容量的风险，同时也增加了重启时日志回放的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置得显著大于期望的快照的大小，那么快照的磁盘带宽负载就会很小。 第二个性能问题就是写入快照需要花费一段时间，并且我们不希望它影响到正常的操作。解决方案是通过写时复制的技术，这样新的更新就可以在不影响正在写的快照的情况下被接收。例如，具有泛函数据结构的状态机天然支持这样的功能。另外，操作系统对写时复制技术的支持（如 Linux 上的 fork）可以被用来创建整个状态机的内存快照（我们的实现用的就是这种方法）。 8 客户端交互本节介绍客户端如何和 Raft 进行交互，包括客户端如何找到 leader 和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。 Raft 的客户端发送所有的请求给 leader 。当客户端第一次启动的时候，它会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是 leader ，那么该服务器会拒绝客户端的请求并且提供关于它最近接收到的领导人的信息（AppendEntries 请求包含了 leader 的网络地址）。如果 leader 已经崩溃了，客户端请求就会超时；客户端之后会再次随机挑选服务器进行重试。 我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在它的调用和回复之间）。但是，如上述，Raft 可能执行同一条命令多次：例如，如果 leader 在提交了该日志条目之后，响应客户端之前崩溃了，那么客户端会和新的 leader 重试这条指令，导致这条命令被再次执行。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每个客户端已经处理的最新的序列号以及相关联的回复。如果接收到一条指令，该指令的序列号已经被执行过了，就立即返回结果，而不重新执行该请求。 只读的操作可以直接处理而不需要记录日志。但是，如果不采取任何其他措施，这么做可能会有返回过时数据（stale data）的风险，因为 leader 响应客户端请求时可能已经被新的 leader 替代了，但是它还不知道自己已经不是最新的 leader 了。线性化的读操作肯定不会返回过时数据，Raft 需要使用两个额外的预防措施来在不使用日志的情况下保证这一点。首先，leader 必须有关于哪些日志条目被提交了的最新信息。Leader 完整性特性保证了 leader 一定拥有所有已经被提交的日志条目，但是在它任期开始的时候，它可能不知道哪些是已经被提交的。为了知道这些信息，它需要在它的任期里提交一个日志条目。Raft 通过让 leader 在任期开始的时候提交一个空的没有任何操作的日志条目到日志中来处理该问题。第二，leader 在处理只读请求之前必须检查自己是否已经被替代了（如果一个更新的 leader 被选举出来了，它的信息就是过时的了）。Raft 通过让 leader 在响应只读请求之前，先和集群中的过半节点交换一次心跳信息来处理该问题。另一种可选的方案，leader 可以依赖心跳机制来实现一种租约的形式，但是这种方法依赖 timing 来保证安全性（假设时间误差是有界的）。 参考资料 [1] BOLOSKY, W. J., BRADSHAW, D., HAAGENS, R. B., KUSTERS, N. P., AND LI, P. Paxos replicated state machines as the basis of a high-performance data store. In Proc. NSDI’11, USENIX Conference on Networked Systems Design and Implementation (2011), USENIX, pp. 141–154. [2] BURROWS, M. The Chubby lock service for loosely- coupled distributed systems. In Proc. OSDI’06, Sympo- sium on Operating Systems Design and Implementation (2006), USENIX, pp. 335–350. [3] CAMARGOS, L. J., SCHMIDT, R. M., AND PEDONE, F. Multicoordinated Paxos. In Proc. PODC’07, ACM Sym- posium on Principles of Distributed Computing (2007), ACM, pp. 316–317. [4] CHANDRA, T. D., GRIESEMER, R., AND REDSTONE, J. Paxos made live: an engineering perspective. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 398–407. [5] CHANG, F., DEAN, J., GHEMAWAT, S., HSIEH, W. C., WALLACH, D. A., BURROWS, M., CHANDRA, T., FIKES, A., AND GRUBER, R. E. Bigtable: a distributed storage system for structured data. In Proc. OSDI’06, USENIX Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 205–218. [6] CORBETT, J. C., DEAN, J., EPSTEIN, M., FIKES, A., FROST, C., FURMAN, J. J., GHEMAWAT, S., GUBAREV, A., HEISER, C., HOCHSCHILD, P., HSIEH, W., KAN- THAK, S., KOGAN, E., LI, H., LLOYD, A., MELNIK, S., MWAURA, D., NAGLE, D., QUINLAN, S., RAO, R., ROLIG, L., SAITO, Y., SZYMANIAK, M., TAYLOR, C., WANG, R., AND WOODFORD, D. Spanner: Google’s globally-distributed database. In Proc. OSDI’12, USENIX Conference on Operating Systems Design and Implemen- tation (2012), USENIX, pp. 251–264. [7] COUSINEAU, D., DOLIGEZ, D., LAMPORT, L., MERZ, S., RICKETTS, D., AND VANZETTO, H. TLA+ proofs. In Proc. FM’12, Symposium on Formal Methods (2012), D. Giannakopoulou and D. Me ́ry, Eds., vol. 7436 of Lec- ture Notes in Computer Science, Springer, pp. 147–154. [8] GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The Google file system. In Proc. SOSP’03, ACM Symposium on Operating Systems Principles (2003), ACM, pp. 29–43. [9] GRAY,C.,ANDCHERITON,D.Leases:Anefficientfault- tolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Ssymposium on Operating Systems Principles (1989), pp. 202–210. [10] HERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. ACM Trans- actions on Programming Languages and Systems 12 (July 1990), 463–492. [11] HUNT, P., KONAR, M., JUNQUEIRA, F. P., AND REED, B. ZooKeeper: wait-free coordination for internet-scale systems. In Proc ATC’10, USENIX Annual Technical Con- ference (2010), USENIX, pp. 145–158. [12] JUNQUEIRA, F. P., REED, B. C., AND SERAFINI, M. Zab: High-performance broadcast for primary-backup sys- tems. In Proc. DSN’11, IEEE/IFIP Int’l Conf. on Depend- able Systems &amp; Networks (2011), IEEE Computer Society, pp. 245–256. [13] KIRSCH, J., AND AMIR, Y. Paxos for system builders. Tech. Rep. CNDS-2008-2, Johns Hopkins University, 2008. [14] LAMPORT, L. Time, clocks, and the ordering of events in a distributed system. Commununications of the ACM 21, 7 (July 1978), 558–565. [15] LAMPORT, L. The part-time parliament. ACM Transac- tions on Computer Systems 16, 2 (May 1998), 133–169. [16] LAMPORT, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25. [17] LAMPORT, L. Specifying Systems, The TLA+ Language and Tools for Hardware and Software Engineers. Addison- Wesley, 2002. [18] LAMPORT, L. Generalized consensus and Paxos. Tech. Rep. MSR-TR-2005-33, Microsoft Research, 2005. [19] LAMPORT, L. Fast paxos. Distributed Computing 19, 2 (2006), 79–103. [20] LAMPSON, B. W. How to build a highly available system using consensus. In Distributed Algorithms, O. Baboaglu and K. Marzullo, Eds. Springer-Verlag, 1996, pp. 1–17. [21] LAMPSON, B. W. The ABCD’s of Paxos. In Proc. PODC’01, ACM Symposium on Principles of Distributed Computing (2001), ACM, pp. 13–13. [22] LISKOV, B., AND COWLING, J. Viewstamped replica- tion revisited. Tech. Rep. MIT-CSAIL-TR-2012-021, MIT, July 2012.17 [23] LogCabin source code. logcabin/logcabin.http://github.com/ [24] LORCH, J. R., ADYA, A., BOLOSKY, W. J., CHAIKEN, R., DOUCEUR, J. R., AND HOWELL, J. The SMART way to migrate replicated stateful services. In Proc. Eu- roSys’06, ACM SIGOPS/EuroSys European Conference on Computer Systems (2006), ACM, pp. 103–115. [25] MAO, Y., JUNQUEIRA, F. P., AND MARZULLO, K. Mencius: building efficient replicated state machines forWANs. In Proc. OSDI’08, USENIX Conference on Operating Systems Design and Implementation (2008), USENIX, pp. 369–384. [26] MAZIE` RES, D. Paxos made practical.//www.scs.stanford.edu/ ̃dm/home/ papers/paxos.pdf, Jan. 2007. [27] MORARU, I., ANDERSEN, D. G., AND KAMINSKY, M. There is more consensus in egalitarian parliaments. In Proc. SOSP’13, ACM Symposium on Operating System Principles (2013), ACM. [28] Raft user study. http://ramcloud.stanford. edu/ ̃ongaro/userstudy/. [29] OKI, B. M., AND LISKOV, B. H. Viewstamped replication: A new primary copy method to support highly-available distributed systems. In Proc. PODC’88, ACM Symposium on Principles of Distributed Computing (1988), ACM, pp. 8–17. [30] O’NEIL, P., CHENG, E., GAWLICK, D., AND ONEIL, E. The log-structured merge-tree (LSM-tree). Acta Informat- ica 33, 4 (1996), 351–385. [31] ONGARO, D. Consensus: Bridging Theory and Practice. PhD thesis, Stanford University, 2014 (work in progress).http://ramcloud.stanford.edu/ ̃ongaro/ thesis.pdf. [32] ONGARO, D., AND OUSTERHOUT, J. In search of an understandable consensus algorithm. In Proc ATC’14, USENIX Annual Technical Conference (2014), USENIX. [33] OUSTERHOUT, J., AGRAWAL, P., ERICKSON, D., KOZYRAKIS, C., LEVERICH, J., MAZIE`RES, D., MI- TRA, S., NARAYANAN, A., ONGARO, D., PARULKAR, G., ROSENBLUM, M., RUMBLE, S. M., STRATMANN, E., AND STUTSMAN, R. The case for RAMCloud. Com- munications of the ACM 54 (July 2011), 121–130. [34] Raft consensus algorithm website. http://raftconsensus.github.io. [35] REED, B. Personal communications, May 17, 2013. [36] ROSENBLUM, M., AND OUSTERHOUT, J. K. The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10 (February 1992), 26–52. [37] SCHNEIDER, F. B. Implementing fault-tolerant services using the state machine approach: a tutorial. ACM Com- puting Surveys 22, 4 (Dec. 1990), 299–319. [38] SHVACHKO, K., KUANG, H., RADIA, S., AND CHANSLER, R. The Hadoop distributed file system. In Proc. MSST’10, Symposium on Mass Storage Sys- tems and Technologies (2010), IEEE Computer Society, pp. 1–10. [39] VAN RENESSE, R. Paxos made moderately complex. Tech. rep., Cornell University, 2012. Raft 网站","raw":null,"content":null,"categories":[{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/categories/分布式一致性算法/"},{"name":"Raft","slug":"分布式一致性算法/Raft","permalink":"http://linbingdong.com/categories/分布式一致性算法/Raft/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"},{"name":"论文翻译","slug":"论文翻译","permalink":"http://linbingdong.com/tags/论文翻译/"},{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/tags/分布式一致性算法/"},{"name":"Raft","slug":"Raft","permalink":"http://linbingdong.com/tags/Raft/"}]},{"title":"Git常用命令","slug":"Git常用命令","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Git常用命令/","link":"","permalink":"http://linbingdong.com/2017/03/11/Git常用命令/","excerpt":"记录 Git 常用的命令。","text":"记录 Git 常用的命令。 命令 说明 git init 初始化git仓库 git add filename 将文件添加到暂存区 git commit -m “blablabla…” 提交到本地仓库 git push origin master 将本地master分支推到远程 git status 查看那些文件被修改过 git diff 查看修改内容 git reset –hard HEAD^ 回到某个版本 （HEAD表示当前版本（已commit的最新版本），HEAD^表示上一个版本，HEAD^^表示上上个版本，依此类推） git log –oneline 查看提交历史（–oneline 简洁地打印提交历史） git reflog 查看命令历史，包括commit和reset等 git diff HEAD – readme.txt 查看工作区和版本库里最新版本的区别 git checkout – filename 撤销工作区中对该文件的修改 让该文件回到最近一次 commit 或 add 时的状态 git rm filename 从版本库中删除文件 git reset HEAD filename 把暂存区对该文件的修改撤销掉（unstage），重新放回工作区 git branch 查看分支 git branch branchname 创建分支 git checkout branchname 切换分支 git checkout -b branchname 创建并切换分支 git merge branchname 将分支合并到当前分支 git branch -d branchname 删除分支 git log –graph –oneline 分支合并图 git merge –no-ff -m “describe something” dev 跟dev合并，不使用ff，然后提交 git stash 把工作现场“储存”起来，等以后恢复现场再继续工作 git stash list 查看“储存”的工作现场 git stash pop 恢复工作现场并把stash内容删除 相当于 git stash apply stash@{0};git stash drop stash@{0} git branch -D branchname 将没有被merge过的分支强制删除 git remote 查看远程仓库信息 git remote -v 显示更详细的远程仓库信息 git push origin master 把本地该分支推送到远程库对应的远程分支上。如果推送失败，先用 git pull 拉取最新的再 git push git checkout -b brahch-name origin/branch-name 在本地创建和远程分支对应的分支 git branch –set-upstream branch-name origin/branch-name 建立本地分支和远程分支的关联 git tag v1.0 打上v1.0标签，默认打在最新提交的commit上 git tag 查看所有标签 git tag v0.9 9c4ef20 为 9c4ef20 这次commit打上v0.9标签 git show v0.9 查看标签（显示具体的commit内容） git tag -a -m “blablabla…” 可以指定标签信息 git tag -d v0.1 删除v0.1标签 git push origin v1.0 推送v1.0标签到远程 ，对应github上的一个release git push origin –tags 推送本地所有标签到远程 git tag -d v0.9 ; git push origin :refs/tags/v0.9 删除远程v0.9标签 git config –global color.ui true 设置让git显示颜色 git add -f xxx.pyc 强制添加被忽略的文件 git check-ignore -v xxx.pyc 查看该文件是被哪一条规则忽略的 git config –global alias.st status 设置status的别名为st 如果要忽略某些文件（比如.pyc文件），可以通过添加.gitignore文件来实现（写上 *.pyc）。.gitignore文件也需要 add 和 commit。 常用别名： git config –global alias.ci commit git config –global alias.st status git config –global alias.br branch git config –global alias.unstage ‘reset HEAD’ git config –global alias.last ‘log -1’ git config –global alias.lg “log –color –graph –pretty=format:’%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit” 如果想从版本库里删除某个文件： rm filename git rm filename git commit 在本地新建一个仓库 git init 初始化本地仓库 git remote add origin git@github.com:linbingdong/blog.git 关联一个远程库 git push -u origin master 第一次推送master分支的所有内容","raw":null,"content":null,"categories":[{"name":"编程工具","slug":"编程工具","permalink":"http://linbingdong.com/categories/编程工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://linbingdong.com/tags/Git/"}]},{"title":"二维数组中的查找","slug":"二维数组中的查找","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/二维数组中的查找/","link":"","permalink":"http://linbingdong.com/2017/03/11/二维数组中的查找/","excerpt":"在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n分析\n从左下角元素开始，若比target大，则上移；若比target小，则右移。如果移出边界还未找到，说明没有target。\n代码:","text":"在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 分析 从左下角元素开始，若比target大，则上移；若比target小，则右移。如果移出边界还未找到，说明没有target。 代码: public class Solution &#123; public boolean Find(int target, int [][] array) &#123; int y = 0; int x = array.length - 1; while(x &gt;= 0 &amp;&amp; y &lt; array[0].length)&#123; if(target &gt; array[x][y]) y++; else if(target &lt; array[x][y]) x--; else return true; &#125; return false; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"链表中环的入口节点","slug":"链表中环的入口","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/链表中环的入口/","link":"","permalink":"http://linbingdong.com/2017/03/11/链表中环的入口/","excerpt":"题目描述\n一个链表中包含环，请找出该链表的环的入口节点。\n分析\n两种思路\n思路一：创建一个set，依次往set里添加节点。第二次到环的入口节点时，由于重复了，无法添加成功，返回该节点。\n思路二：两个指针。具体分析见代码注释。\n代码:","text":"题目描述 一个链表中包含环，请找出该链表的环的入口节点。 分析 两种思路 思路一：创建一个set，依次往set里添加节点。第二次到环的入口节点时，由于重复了，无法添加成功，返回该节点。 思路二：两个指针。具体分析见代码注释。 代码: 用HashSet（取巧） import java.util.*;public class Solution &#123; public ListNode EntryNodeOfLoop(ListNode pHead)&#123; if (pHead == null) return null; ListNode p = pHead; HashSet&lt;ListNode&gt; set = new HashSet&lt;ListNode&gt;(); while (p != null)&#123; if (!set.add(p)) return p; p = p.next; &#125; return null; &#125;&#125; 两个指针（巧妙） public class Solution &#123; public ListNode EntryNodeOfLoop(ListNode pHead)&#123; if (pHead == null || pHead.next == null) return null; ListNode p1 = pHead, p2 = pHead; while (p2 != null)&#123; p1 = p1.next; //p1每次走一步 p2 = p2.next.next; //p2每次走两步 if (p1 == p2)&#123; //第一次相遇，此时p2刚好比p1多走一个环的长度，又因为p2走的距离是p1的两倍，所以p1刚好走了一个环的距离 p1 = pHead; //p1回到头节点，p2不动。此时p1，p2刚好相差一个环的距离 while (p1 != p2)&#123; //p1、p2每次都只走一步，下次相遇必定在环的入口节点 p1 = p1.next; p2 = p2.next; &#125; return p1; &#125; &#125; return null; &#125; &#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"从尾到头打印链表","slug":"从尾到头打印链表","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/从尾到头打印链表/","link":"","permalink":"http://linbingdong.com/2017/03/11/从尾到头打印链表/","excerpt":"输入一个链表，从尾到头打印链表每个节点的值。\n分析\n将每个node的值一次放入栈中。新建一个list，将出栈元素依次加入该list中。\n代码:","text":"输入一个链表，从尾到头打印链表每个节点的值。 分析 将每个node的值一次放入栈中。新建一个list，将出栈元素依次加入该list中。 代码: /*** public class ListNode &#123;* int val;* ListNode next = null;** ListNode(int val) &#123;* this.val = val;* &#125;* &#125;**/import java.util.Stack;import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); while(listNode != null)&#123; stack.push(listNode.val); listNode = listNode.next; &#125; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); while(!stack.isEmpty()) list.add(stack.pop()); return list; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"优雅的点","slug":"优雅的点","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/优雅的点/","link":"","permalink":"http://linbingdong.com/2017/03/11/优雅的点/","excerpt":"小易有一个圆心在坐标原点的圆，小易知道圆的半径的平方。小易认为在圆上的点而且横纵坐标都是整数的点是优雅的，小易现在想寻找一个算法计算出优雅的点的个数，请你来帮帮他。例如：半径的平方如果为25优雅的点就有：(+/-3, +/-4), (+/-4, +/-3), (0, +/-5) (+/-5, 0)，一共12个点。 \n输入描述:\n输入为一个整数，即为圆半径的平方,范围在32位int范围内。\n输出描述:\n输出为一个整数，即为优雅的点的个数\n输入例子:\n25\n输出例子:\n12\n代码:","text":"小易有一个圆心在坐标原点的圆，小易知道圆的半径的平方。小易认为在圆上的点而且横纵坐标都是整数的点是优雅的，小易现在想寻找一个算法计算出优雅的点的个数，请你来帮帮他。例如：半径的平方如果为25优雅的点就有：(+/-3, +/-4), (+/-4, +/-3), (0, +/-5) (+/-5, 0)，一共12个点。 输入描述: 输入为一个整数，即为圆半径的平方,范围在32位int范围内。 输出描述: 输出为一个整数，即为优雅的点的个数 输入例子: 25 输出例子: 12 代码: import java.util.Scanner; /** * Created by lbd on 2016/10/29. */public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int rSquare = sc.nextInt(); int count = 0; double r = Math.sqrt(rSquare); for (int i = 0; i &lt; r; i++)&#123; double j = Math.sqrt(rSquare - i*i); if ((int)j == j)&#123; count++; &#125; &#125; System.out.println(count&lt;&lt;2); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"关于Java Map的几个常见问题","slug":"关于Java Map的几个常见问题","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/关于Java Map的几个常见问题/","link":"","permalink":"http://linbingdong.com/2017/03/11/关于Java Map的几个常见问题/","excerpt":"列举几个关于Java Map的常见问题并给出答案。","text":"列举几个关于Java Map的常见问题并给出答案。 1. 将Map转化成ListMap接口提供了三种collection：key set,value set 和 key-value set，每一种都可以转成List。如下： //mapHashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;();map.put(1,10);map.put(2,20);map.put(3,30);//key listArrayList&lt;Integer&gt; keyList = new ArrayList&lt;&gt;(map.keySet());//value listArrayList&lt;Integer&gt; valueList = new ArrayList&lt;&gt;(map.values());//key-value listArrayList&lt;Map.Entry&lt;Integer,Integer&gt;&gt; entryList = new ArrayList&lt;&gt;(map.entrySet()); 2. 迭代Map最高效的遍历map的每个entry的方法如下： for (Map.Entry entry : map.entrySet())&#123; int key = (int) entry.getKey(); int value = (int) entry.getValue();&#125; 也可以使用iterator，特别是JDK 1.5之前。 Iterator itr = map.entrySet().iterator();while(itr.hasNext())&#123; Map.Entry entry = itr.next(); int key = (int) entry.getKey(); int value = (int) entry.getValue();&#125; 3. 根据key对map进行排序可以将Map.Entry放入一个list，然后自己实现Comparator来对list排序。 ArrayList&lt;Map.Entry&lt;Integer,Integer&gt;&gt; list = new ArrayList&lt;&gt;(map.entrySet());Collections.sort(list, new Comparator&lt;Map.Entry&lt;Integer, Integer&gt;&gt;() &#123; @Override public int compare(Map.Entry&lt;Integer, Integer&gt; e1, Map.Entry&lt;Integer, Integer&gt; e2) &#123; return e1.getKey().compareTo(e2.getKey()); &#125;&#125;); 可以使用SortedMap。SortedMap的一个实现类是TreeMap。TreeMap的构造器可以接受一个Comparator参数。如下： SortedMap&lt;Integer,Integer&gt; sortedMap = new TreeMap&lt;&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer k1, Integer k2) &#123; return k1.compareTo(k2); &#125;&#125;);sortedMap.putAll(map); 注：TreeMap默认对key进行排序。 4. 根据value对map进行排序ArrayList&lt;Map.Entry&lt;Integer,Integer&gt;&gt; list = new ArrayList&lt;&gt;(map.entrySet());Collections.sort(list, new Comparator&lt;Map.Entry&lt;Integer, Integer&gt;&gt;() &#123; @Override public int compare(Map.Entry&lt;Integer, Integer&gt; e1, Map.Entry&lt;Integer, Integer&gt; e2) &#123; return e1.getValue().compareTo(e2.getValue()); &#125;&#125;); 如果map中的value不重复，可以通过反转key-value对为value-key对来用上面的3中的TreeMap方法对其排序。该方法不推荐。 5. 初始化一个不可变Map正确的做法： public class Test&#123; private static Map&lt;Integer,Integer&gt; map1 = new HashMap&lt;&gt;(); static &#123; map1.put(8,9); map1.put(88,99); map1 = Collections.unmodifiableMap(map1); &#125;&#125; 错误的做法： public class Test&#123; private static final Map&lt;Integer,Integer&gt; map1 = new HashMap&lt;&gt;(); static &#123; map1.put(8,9); map1.put(88,99); &#125;&#125; 加了final只能确保不能 map1 = new，但是可以修改map1中的元素。 6. HashMap、TreeMap和HashTable的区别Map接口有三个比较重要的实现类，分别是HashMap、TreeMap和HashTable。 TreeMap是有序的，HashMap和HashTable是无序的。 Hashtable的方法是同步的，HashMap的方法不是同步的。这是两者最主要的区别。 这就意味着Hashtable是线程安全的，HashMap不是线程安全的。HashMap效率较高，Hashtable效率较低。如果对同步性或与遗留代码的兼容性没有任何要求，建议使用HashMap。查看Hashtable的源代码就可以发现，除构造函数外，Hashtable的所有 public 方法声明中都有 synchronized关键字，而HashMap的源码中则没有。 Hashtable不允许null值，HashMap允许null值（key和value都允许） 父类不同：Hashtable的父类是Dictionary，HashMap的父类是AbstractMap Hashtable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 | HashMap | Hashtable | TreeMap-------------------------------------------------------iteration order | no | no | yesnull key-value | yes-yes | no-no | no-yessynchronized | no | yes | notime performance | O(1) | O(1) | O(log n)implementation | buckets | buckets | red-black tree 7. 创建一个空的Map如果希望该map为不可变的，则： map = Collections.emptyMap(); 否则： map = new HashMap();","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"关于Java字符串的几个常见问题","slug":"关于Java字符串的几个常见问题","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/关于Java字符串的几个常见问题/","link":"","permalink":"http://linbingdong.com/2017/03/11/关于Java字符串的几个常见问题/","excerpt":"列举几个关于Java字符串的常见问题并给出答案。","text":"列举几个关于Java字符串的常见问题并给出答案。 1. 如何比较两个字符串？用”==”还是”equals”? “==”对比的是引用是否相同（是否同一个对象） “equals”对比的是值是否相同 除非想要比较两个字符串是否是同一个对象，否则应该一直使用”equals”。 2. 为什么对安全性敏感的信息更喜欢用char[]而不是String来存储？因为String是不可变对象，这就意味着只要String被创建，它们就会一直存在直到被垃圾回收器收集。因此，用String保存的信息安全性会降低。 3. 在switch语句中可以使用字符串吗？从Java7开始，可以在switch语句中使用字符串。 switch (aString) &#123; case \"a\": value = 1; break; case \"b\": value = 2; break;&#125; 4. 如何将字符串转为int？int n = Integer.parseInt(\"10\"); 虽然很简单，但是使用频率很高。 5. 如何用空格切分字符串？String[] strArray = aString.split(\"\\\\s+\"); 6. substring()方法会创建一个新字符串吗？从Java7开始，substring()方法会创建一个新的char数组，而不是使用已经存在的。 在Java6中，substring()方法不会创建一个新的char数组，如果想创建新的，可以用以下代码： str.substring(m,n) + \"\"; 7. String vs StringBuilder vs StringBufferString是不可变的，StringBuilder和StringBuffer都是可变的。 StringBuffer是同步的，线程安全的，效率低。 StringBuilder是非同步的，非线程安全，效率比StringBuffer高。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"全球分布式数据库：Google Spanner（论文翻译）","slug":"全球分布式数据库：Google Spanner（论文翻译）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/全球分布式数据库：Google Spanner（论文翻译）/","link":"","permalink":"http://linbingdong.com/2017/03/11/全球分布式数据库：Google Spanner（论文翻译）/","excerpt":"本文由厦门大学计算机系教师林子雨翻译，翻译质量很高，本人只对极少数翻译得不太恰当的地方进行了修改。\n【摘要】Spanner 是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个把数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。本文描述了 Spanner 的架构、特性、不同设计决策的背后机理和一个新的时间 API，这个 API 可以暴露时钟的不确定性。这个 API 及其实现，对于支持外部一致性和许多强大特性而言，是非常重要的，这些强大特性包括:非阻塞的读、不采用锁机制的只读事务、原子模式变更。","text":"本文由厦门大学计算机系教师林子雨翻译，翻译质量很高，本人只对极少数翻译得不太恰当的地方进行了修改。 【摘要】Spanner 是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个把数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。本文描述了 Spanner 的架构、特性、不同设计决策的背后机理和一个新的时间 API，这个 API 可以暴露时钟的不确定性。这个 API 及其实现，对于支持外部一致性和许多强大特性而言，是非常重要的，这些强大特性包括:非阻塞的读、不采用锁机制的只读事务、原子模式变更。 【关键词】Google Spanner, Bigtable, distributed database 1 介绍Spanner 是一个可扩展的、全球分布式的数据库，是在谷歌公司设计、开发和部署的。 在最高抽象层面，Spanner 就是一个数据库，把数据分片存储在许多 Paxos[21]状态机上，这些机器位于遍布全球的数据中心内。复制技术可以用来服务于全球可用性和地理局部性。客户端会自动在副本之间进行失败恢复。随着数据的变化和服务器的变化，Spanner 会自动把数据进行重新分片，从而有效应对负载变化和处理失败。Spanner 被设计成可以扩展到几百万个机器节点，跨越成百上千个数据中心，具备几万亿数据库行的规模。 应用可以借助于 Spanner 来实现高可用性，通过在一个洲的内部和跨越不同的洲之间复制数据，保证即使面对大范围的自然灾害时数据依然可用。我们最初的客户是 F1[35]，一个谷歌广告后台的重新编程实现。F1 使用了跨越美国的 5 个副本。绝大多数其他应用很可能会在属于同一个地理范围内的 3-5 个数据中心内放置数据副本，采用相对独立的失败模式。也就是说，许多应用都会首先选择低延迟，而不是高可用性，只要系统能够从 1-2 个数据中心失败中恢复过来。 Spanner 的主要工作，就是管理跨越多个数据中心的数据副本，但是，在我们的分布式系统体系架构之上设计和实现重要的数据库特性方面，我们也花费了大量的时间。尽管有许多项目可以很好地使用 BigTable[9]，我们也不断收到来自客户的抱怨，客户反映 BigTable 无法应用到一些特定类型的应用上面，比如具备复杂可变的模式，或者对于在大范围内分布的多个副本数据具有较高的一致性要求。其他研究人员也提出了类似的抱怨[37]。谷歌的许多应用已经选择使用 Megastore[5]，主要是因为它的半关系数据模型和对同步复制的支持，尽管 Megastore 具备较差的写操作吞吐量。由于上述多个方面的因素，Spanner 已经从一个类似 BigTable 的单一版本的键值存储，演化成为一个具有时间属性的多版本的数据库。数据被存储到模式化的、半关系的表中，数据被版本化，每个版本都会自动以提交时间作为时间戳，旧版本的数据会更容易被垃圾回收。应用可以读取旧版本的数据。Spanner 支持通用的事务，提供了基于 SQL 的查询语言。 作为一个全球分布式数据库，Spanner 提供了几个有趣的特性:第一，在数据的副本配置方面，应用可以在一个很细的粒度上进行动态控制。应用可以详细规定，哪些数据中心包含哪些数据，数据距离用户有多远(控制用户读取数据的延迟)，不同数据副本之间距离有多远(控制写操作的延迟)，以及需要维护多少个副本(控制可用性和读操作性能)。数据也可以被动态和透明地在数据中心之间进行移动，从而平衡不同数据中心内资源的使用。第二， Spanner 有两个重要的特性，很难在一个分布式数据库上实现，即 Spanner 提供了读和写操作的外部一致性，以及在一个时间戳下面的跨越数据库的全球一致性的读操作。这些特性使得 Spanner 可以支持一致的备份、一致的 MapReduce 执行[12]和原子模式变更，所有都是在全球范围内实现，即使存在正在处理中的事务也可以。 之所以可以支持这些特性，是因为 Spanner 可以为事务分配全球范围内有意义的提交时间戳，即使事务可能是分布式的。这些时间戳反映了事务序列化的顺序。除此以外，这些序列化的顺序满足了外部一致性的要求:如果一个事务 T1 在另一个事务 T2 开始之前就已经提交了，那么，T1 的时间戳就要比 T2 的时间戳小。Spanner 是第一个可以在全球范围内提供这种保证的系统。 实现这种特性的关键技术就是一个新的 TrueTime API 及其实现。这个 API 可以直接暴露时钟不确定性，Spanner 时间戳的保证就是取决于这个 API 实现的界限。如果这个不确定性很大，Spanner 就降低速度来等待这个大的不确定性结束。谷歌的簇管理器软件提供了一个 TrueTime API 的实现。这种实现可以保持较小的不确定性(通常小于 10ms)，主要是借助于现代时钟参考值(比如 GPS 和原子钟)。 第 2 部分描述了 Spanner 实现的结构、特性集和工程方面的决策;第 3 部分介绍我们的新的 TrueTime API，并且描述了它的实现;第 4 部分描述了 Spanner 如何使用 TrueTime 来实现外部一致性的分布式事务、不用锁机制的只读事务和原子模式更新。第 5 部分提供了测试 Spanner 性能和 TrueTime 行为的测试基准，并讨论了 F1 的经验。第 6、7 和 8 部分讨论了相关工作，并给出总结。 2 实现本部分内容描述了 Spanner 的结构和背后的实现机理，然后描述了目录抽象，它被用来管理副本和局部性，并介绍了数据的转移单位。最后，将讨论我们的数据模型，从而说明为什么 Spanner 看起来更加像一个关系数据库，而不是一个键值数据库;还会讨论应用如何可以控制数据的局部性。 一个 Spanner 部署称为一个 universe。假设 Spanner 在全球范围内管理数据，那么，将会只有可数的、运行中的 universe。我们当前正在运行一个测试用的 universe，一个部署/线上用的 universe 和一个只用于线上应用的 universe。 Spanner 被组织成许多个 zone 的集合，每个 zone 都大概像一个 BigTable 服务器的部署。 zone 是管理部署的基本单元。zone 的集合也是数据可以被复制到的位置的集合。当新的数据中心加入服务，或者老的数据中心被关闭时，zone 可以被加入到一个运行的系统中，或者从中移除。zone 也是物理隔离的单元，在一个数据中心中，可能有一个或者多个 zone， 例如，当属于不同应用的数据必须被分区存储到同一个数据中心的不同服务器集合中时，一个数据中心就会有多个 zone 。 图 1 显示了在一个 Spanner 的 universe 中的服务器。一个 zone 包括一个 zonemaster， 和一百至几千个 spanserver。Zonemaster 把数据分配给 spanserver，spanserver 把数据提供给客户端。客户端使用每个 zone 上面的 location proxy 来定位可以为自己提供数据的 spanserver。Universe master 和 placement driver，当前都只有一个。Universe master 主要是一个控制台，它显示了关于 zone 的各种状态信息，可以用于相互之间的调试。Placement driver 会周期性地与 spanserver 进行交互，来发现那些需要被转移的数据，或者是为了满足新的副本约束条件，或者是为了进行负载均衡。 2.1 Spanserver 软件栈本部分内容主要关注 spanserver 实现，来解释复制和分布式事务是如何被架构到我们的基于 BigTable 的实现之上的。图 2 显示了软件栈。在底部，每个 spanserver 负载管理 100-1000 个称为 tablet 的数据结构的实例。一个 tablet 就类似于 BigTable 中的 tablet，也实现了下面的映射: (key:string, timestamp:int64)-&gt;string 与 BigTable 不同的是，Spanner 会把时间戳分配给数据，这种非常重要的方式，使得 Spanner 更像一个多版本数据库，而不是一个键值存储。一个 tablet 的状态是存储在类似于 B-树的文件集合和写前(write-ahead)的日志中，所有这些都会被保存到一个分布式的文件系统中，这个分布式文件系统被称为 Colossus，它继承自 Google File System。 为了支持复制，每个 spanserver 会在每个 tablet 上面实现一个单个的 Paxos 状态机。一个之前实现的Spanner 可以支持在每个 tablet 上面实现多个 Paxos 状态机器，它可以允许更加灵活的复制配置，但是，这种设计过于复杂，被我们舍弃了。每个状态机器都会在相应的 tablet 中保存自己的元数据和日志。我们的 Paxos 实现支持长寿命的领导者（采用基于时间的领导者租约），时间通常在 0 到 10 秒之间。当前的 Spanner 实现中，会对每个 Paxos 写操作进行两次记录:一次是写入到 tablet 日志中，一次是写入到 Paxos 日志中。这种做法只是权宜之计，我们以后会进行完善。我们在 Paxos 实现上采用了管道化的方式，从而可以在存在广域网延迟时改进 Spanner 的吞吐量，但是，Paxos 会把写操作按照顺序的方式执行。 Paxos 状态机是用来实现一系列被一致性复制的映射。每个副本的键值映射状态，都会被保存到相应的 tablet 中。写操作必须在领导者上初始化 Paxos 协议，读操作可以直接从底层的任何副本的 tablet 中访问状态信息，只要这个副本足够新。副本的集合被称为一个 Paxos group。 对于每个是领导者的副本而言，每个 spanserver 会实现一个锁表来实现并发控制。这个锁表包含了两阶段锁机制的状态:它把键的值域映射到锁状态上面。注意，采用一个长寿命的 Paxos 领导者，对于有效管理锁表而言是非常关键的。在 BigTable 和 Spanner 中，我们都专门为长事务做了设计，比如，对于报表操作，可能要持续几分钟，当存在冲突时，采用乐观并发控制机制会表现出很差的性能。对于那些需要同步的操作，比如事务型的读操作，需要获得锁表中的锁，而其他类型的操作则可以不理会锁表。 对于每个扮演领导者角色的副本，每个 spanserver 也会实施一个事务管理器来支持分布式事务。这个事务管理器被用来实现一个 participant leader，该组内的其他副本则是作为 participant slaves。如果一个事务只包含一个 Paxos 组(对于许多事务而言都是如此)，它就可以绕过事务管理器，因为锁表和 Paxos 二者一起可以保证事务性。如果一个事务包含了多 于一个 Paxos 组，那些组的领导者之间会彼此协调合作完成两阶段提交。其中一个参与者组，会被选为协调者，该组的 participant leader 被称为 coordinator leader，该组的 participant slaves 被称为 coordinator slaves。每个事务管理器的状态，会被保存到底层的 Paxos 组。 2.2 目录和放置在一系列键值映射的上层，Spanner 实现支持一个被称为“目录”的桶抽象，也就是包含公共前缀的连续键的集合。(选择“目录”作为名称，主要是由于历史沿袭的考虑，实际 上更好的名称应该是“桶”)。我们会在第 2.3 节解释前缀的源头。对目录的支持，可以让应用通过选择合适的键来控制数据的局部性。 一个目录是数据放置的基本单元。属于一个目录的所有数据，都具有相同的副本配置。 当数据在不同的 Paxos 组之间进行移动时，会一个目录一个目录地转移，如图 3 所示。Spanner 可能会移动一个目录从而减轻一个 Paxos 组的负担，也可能会把那些被频繁地一起访问的目录都放置到同一个组中，或者会把一个目录转移到距离访问者更近的地方。当客户端操作正在进行时，也可以进行目录的转移。我们可以预期在几秒内转移 50MB 的目录。 一个 Paxos 组可以包含多个目录，这意味着一个 Spanner tablet 是不同于一个 BigTable tablet 的。一个 Spanner tablet 没有必要是一个行空间内按照词典顺序连续的分区，相反，它可以是行空间内的多个分区。我们做出这个决定，是因为这样做可以让多个被频繁一起访问的目录被整合到一起。 Movedir 是一个后台任务，用来在不同的 Paxos 组之间转移目录[14]。Movedir 也用来为 Paxos 组增加和删除副本[25]，因为 Spanner 目前还不支持在一个 Paxos 内部进行配置的变更。 Movedir 并不是作为一个事务来实现，这样可以避免在一个块数据转移过程中阻塞正在进行的读操作和写操作。相反，Movedir 会注册一个事实(fact)，表明它要转移数据，然后在后台运行转移数据。当它几乎快要转移完指定数量的数据时，就会启动一个事务来自动转移那部分数据，并且为两个 Paxos 组更新元数据。 一个目录也是一个应用可以指定的地理复制属性(即放置策略)的最小单元。我们的放置规范语言的设计，把管理复制的配置这个任务单独分离出来。管理员需要控制两个维度: 副本的数量和类型，以及这些副本的地理放置属性。他们在这两个维度里面创建了一个命名 选项的菜单。通过为每个数据库或单独的目录增加这些命名选项的组合，一个应用就可以控制数据的复制。例如，一个应用可能会在自己的目录里存储每个终端用户的数据，这就有可能使得用户 A 的数据在欧洲有三个副本，用户 B 的数据在北美有 5 个副本。 为了表达的清晰性，我们已经做了尽量简化。事实上，当一个目录变得太大时，Spanner 会把它分片存储。每个分片可能会被保存到不同的 Paxos 组上(因此就意味着来自不同的服 务器)。Movedir 在不同组之间转移的是分片，而不是转移整个目录。 2.3 数据模型Spanner 会把下面的数据特性集合暴露给应用:基于模式化的半关系表的数据模型，查询语言和通用事务。支持这些特性的动机，是受到许多因素驱动的。需要支持模式化的半关系表是由 Megastore[5]的普及来支持的。在谷歌内部至少有 300 个应用使用 Megastore(尽 管它具有相对低的性能)，因为它的数据模型要比 BigTable 简单，更易于管理，并且支持在跨数据中心层面进行同步复制。BigTable 只可以支持跨数据中心的最终事务一致性。使用 Megastore 的著名的谷歌应用是 Gmail,Picasa,Calendar,Android Market, AppEngine。在 Spanner 中需要支持 SQL 类型的查询语言，也很显然是非常必要的，因为 Dremel[28]作为交互式分析工具已经非常普及。最后，在 BigTable 中跨行事务的缺乏来导致了用户频繁的抱怨; Percolator[32]的开发就是用来部分解决这个问题的。一些作者都在抱怨，通用的两阶段提交的代价过于昂贵，因为它会带来可用性问题和性能问题[9][10][19]。我们认为，最好让应用 程序开发人员来处理由于过度使用事务引起的性能问题，而不是总是围绕着“缺少事务”进 行编程。在 Paxos 上运行两阶段提交弱化了可用性问题。 应用的数据模型是架构在被目录桶装的键值映射层之上。一个应用会在一个 universe 中创建一个或者多个数据库。每个数据库可以包含无限数量的模式化的表。每个表都和关系数据库表类似，具备行、列和版本值。我们不会详细介绍 Spanner 的查询语言，它看起来很像 SQL，只是做了一些扩展。 Spanner 的数据模型不是纯粹关系型的，它的行必须有名称。更准确地说，每个表都需 要有包含一个或多个主键列的排序集合。这种需求，让 Spanner 看起来仍然有点像键值存储: 主键形成了一个行的名称，每个表都定义了从主键列到非主键列的映射。当一个行存在时，必须要求已经给行的一些键定义了一些值(即使是 NULL)。采用这种结构是很有用的，因为这可以让应用通过选择键来控制数据的局部性。 图 4 包含了一个 Spanner 模式的实例，它是以每个用户和每个相册为基础存储图片元数据。这个模式语言和 Megastore 的类似，同时增加了额外的要求，即每个 Spanner 数据库必 须被客户端分割成一个或多个表的层次结构(hierarchy)。客户端应用会使用 INTERLEAVE IN 语句在数据库模式中声明这个层次结构。这个层次结构上面的表，是一个目录表。目录表中的每行都具有键 K，和子孙表中的所有以 K 开始(以字典顺序排序)的行一起，构成了一个目录。ON DELETE CASCADE 意味着，如果删除目录中的一个行，也会级联删除所有相关的子孙行。这个图也解释了这个实例数据库的交织层次(interleaved layout)，例如 Albums(2,1) 代表了来自 Albums 表的、对应于 user_id=2 和 album_id=1 的行。这种表的交织层次形成目录，是非常重要的，因为它允许客户端来描述存在于多个表之间的位置关系，这对于一个分片的分布式数据库的性能而言是很重要的。没有它的话，Spanner 就无法知道最重要的位置关系。 本部分内容描述 TrueTime API，并大概给出它的实现方法。我们把大量细节内容放在另一篇论文中，我们的目标是展示这种 API 的力量。表 1 列出了 API 的方法。TrueTime 会显式地把时间表达成 TTinterval，这是一个时间区间，具有有界限的时间不确定性(不像其他 的标准时间接口，没有为客户端提供―不确定性‖这种概念)。TTinterval 区间的端点是 TTstamp 类型。TT.now()方法会返回一个 TTinterval，它可以保证包含 TT.now()方法在调用时的绝对 时间。这个时间和具备闰秒涂抹(leap-second smearing)的 UNIX 时间一样。把即时误差边 界定义为 ε,平均误差边界为ε。TT.after()和 TT.before()方法是针对 TT.now()的便捷的包装器。 表示一个事件 e 的绝对时间，可以利用函数 tabs(e)。如果用更加形式化的术语，TrueTime 可以保证，对于一个调用 tt=TT.now()，有 tt.earliest≤tabs(enow)≤tt.latest，其中， enow 是调用的事件。 在底层，TrueTime 使用的时间是 GPS 和原子钟。TrueTime 使用两种类型的时间，是因为它们有不同的失败模式。GPS 参考时间的弱点是天线和接收器失效、局部电磁干扰和相关失败(比如设计上的缺陷导致无法正确处理闰秒和电子欺骗)，以及 GPS 系统运行中断。原子钟也会失效，不过失效的方式和 GPS 无关，不同原子钟之间的失效也没有彼此关联。 由于存在频率误差，在经过很长的时间以后，原子钟都会产生明显误差。 TrueTime 是由每个数据中心上面的许多 time master 机器和每台机器上的一个 timeslave daemon 来共同实现的。大多数 master 都有具备专用天线的 GPS 接收器，这些 master 在物理上是相互隔离的，这样可以减少天线失效、电磁干扰和电子欺骗的影响。剩余的 master (我们称为 Armageddon master)则配备了原子钟。一个原子钟并不是很昂贵:一个 Armageddon master 的花费和一个 GPS master 的花费是同一个数量级的。所有 master 的时间 参考值都会进行彼此校对。每个 master 也会交叉检查时间参考值和本地时间的比值，如果二者差别太大，就会把自己驱逐出去。在同步期间，Armageddon master 会表现出一个逐渐增加的时间不确定性，这是由保守应用的最差时钟漂移引起的。GPS master 表现出的时间不确定性几乎接近于 0。 每个 daemon 会从许多 master[29]中收集投票，获得时间参考值，从而减少误差。被选中的 master 中，有些 master 是 GPS master，是从附近的数据中心获得的，剩余的 GPS master 是从远处的数据中心获得的;还有一些是 Armageddon master。Daemon 会使用一个 Marzullo 算法[27]的变种，来探测和拒绝欺骗，并且把本地时钟同步到非撒谎 master 的时间参考值。 为了免受较差的本地时钟的影响，我们会根据组件规范和运行环境确定一个界限，如果机器的本地时钟误差频繁超出这个界限，这个机器就会被驱逐出去。 在同步期间，一个 daemon 会表现出逐渐增加的时间不确定性。ε 是从保守应用的最差 时钟漂移中得到的。ε 也取决于 time master 的不确定性，以及与 time master 之间的通讯延迟。在我们的线上应用环境中，ε 通常是一个关于时间的锯齿形函数。在每个投票间隔中， ε 会在 1 到 7ms 之间变化。因此，在大多数情况下，ε的值是 4ms。Daemon 的投票间隔，在当前是 30 秒，当前使用的时钟漂移比率是 200 微秒/秒，二者一起意味着 0 到 6ms 的锯齿形边界。剩余的 1ms 主要来自到 time master 的通讯延迟。在失败的时候，超过这个锯齿形边界也是有可能的。例如，偶尔的 time master 不确定性，可能会引起整个数据中心范围内的 ε 值的增加。类似的，过载的机器或者网络连接，都会导致 ε 值偶尔地局部增大。 4 并发控制本部分内容描述 TrueTime 如何可以用来保证并发控制的正确性，以及这些属性如何用来实现一些关键特性，比如外部一致性的事务、无锁机制的只读事务、针对历史数据的非阻塞读。这些特性可以保证，在时间戳为 t 的时刻的数据库读操作，一定只能看到在 t 时刻之 前已经提交的事务。 进一步说，把 Spanner 客户端的写操作和 Paxos 看到的写操作这二者进行区分，是非常重要的，我们把 Paxos 看到的写操作称为 Paxos 写操作。例如，两阶段提交会为准备提交阶段生成一个 Paxos 写操作，这时不会有相应的客户端写操作。 4.1 时间戳管理表 2 列出了 Spanner 支持的操作的类型。Spanner 可以支持读写事务、只读事务(预先声明的快照隔离事务)和快照读。独立写操作，会被当成读写事务来执行。非快照独立读操作，会被当成只读事务来执行。二者都是在内部进行 retry，客户端不用进行这种 retry loop。 一个只读事务具备快照隔离的性能优势[6]。一个只读事务必须事先被声明不会包含任何写操作，它并不是一个简单的不包含写操作的读写事务。在一个只读事务中的读操作，在执行时会采用一个系统选择的时间戳，不包含锁机制，因此，后面到达的写操作不会被阻塞。 在一个只读事务中的读操作，可以到任何足够新的副本上去执行(见第 4.1.3 节)。 一个快照读操作，是针对历史数据的读取，执行过程中，不需要锁机制。一个客户端可以为快照读确定一个时间戳，或者提供一个时间范围让 Spanner 来自动选择时间戳。不管是 哪种情况，快照读操作都可以在任何具有足够新的副本上执行。 对于只读事务和快照读而言，一旦已经选定一个时间戳，那么，提交就是不可避免的，除非在那个时间点的数据已经被垃圾回收了。因此，客户端不必在 retry loop 中缓存结果。 当一个服务器失效的时候，客户端就可以使用同样的时间戳和当前的读位置，在另外一个服务器上继续执行读操作。 4.1.1 Paxos 领导者租约Spanner 的 Paxos 实现中使用了时间化的租约，来实现长时间的领导者地位(默认是 10秒)。一个潜在的领导者会发起请求，请求时间化的租约投票，在收到指定数量的投票后，这个领导者就可以确定自己拥有了一个租约。一个副本在成功完成一个写操作后，会隐式地延期自己的租约。对于一个领导者而言，如果它的租约快要到期了，就要显示地请求租约延期。另一个领导者的租约有个时间区间，这个时间区间的起点就是这个领导者获得指定数量的投票那一刻，时间区间的终点就是这个领导者失去指定数量的投票的那一刻(因为有些投 票已经过期了)。Spanner 依赖于下面这些“不连贯性”:对于每个 Paxos 组，每个 Paxos 领 导者的租约时间区间，是和其他领导者的时间区间完全隔离的。附录 A 显示了如何强制实现这些不连贯性。 Spanner 实现允许一个 Paxos 领导者通过把 slave 从租约投票中释放出来这种方式，实现领导者的退位。为了保持这种彼此隔离的不连贯性，Spanner 会对什么时候退位做出限制。把 smax 定义为一个领导者可以使用的最大的时间戳。在退位之前，一个领导者必须等到 TT.after(smax)是真。 4.1.2 为读写事务分配时间戳事务读和写采用两段锁协议。当所有的锁都已经获得以后，在任何锁被释放之前，就可以给事务分配时间戳。对于一个给定的事务，Spanner 会为事务分配时间戳，这个时间戳是 Paxos 分配给 Paxos 写操作的，它代表了事务提交的时间。 Spanner 依赖下面这些单调性:在每个 Paxos 组内，Spanner 会以单调增加的顺序给每个 Paxos 写操作分配时间戳，即使在跨越多个领导者时也是如此。一个单个的领导者副本，可以很容易地以单调增加的方式分配时间戳。在多个领导者之间就会强制实现彼此隔离的不连 贯:一个领导者必须只能分配属于它自己租约时间区间内的时间戳。要注意到，一旦一个时间戳 s 被分配，smax 就会被增加到 s，从而保证彼此隔离性(不连贯性)。 Spanner 也会实现下面的外部一致性:如果一个事务 T2 在事务 T1 提交以后开始执行， 那么，事务 T2 的时间戳一定比事务 T1 的时间戳大。对于一个事务 Ti 而言，定义开始和提交事件eistart和eicommit，事务提交时间为si。对外部一致性的要求就变成了:tabs(e1commit )&lt;tabs(e2start ) s1&lt;s2。执行事务的协议和分配时间戳的协议，遵守两条规则，二者一起保证外部一致性。对于一个写操作 Ti 而言，担任协调者的领导者发出的提交请求的事件为eiserver 。 Start. 为一个事务 Ti 担任协调者的领导者分配一个提交时间戳 si，不会小于 TT.now().latest 的值，TT.now().latest的值是在esierver事件之后计算得到的。要注意，担任参与者的领导者， 在这里不起作用。第 4.2.1 节描述了这些担任参与者的领导者是如何参与下一条规则的实现的。 Commit Wait. 担任协调者的领导者，必须确保客户端不能看到任何被 Ti 提交的数据，直到 TT.after(si)为真。提交等待，就是要确保 si 会比 Ti 的绝对提交时间小。提交等待的实现在 4.2.1 节中描述。证明如下: 4.1.3 在某个时间戳下的读操作第 4.1.2 节中描述的单调性，使得 Spanner 可以正确地确定一个副本是否足够新，从而能够满足一个读操作的要求。每个副本都会跟踪记录一个值，这个值被称为安全时间 tsafe，它是一个副本最近更新后的最大时间戳。如果一个读操作的时间戳是 t，当满足 t&lt;=tsafe 时， 这个副本就可以被这个读操作读取。 。。。 4.1.4 为只读事务分配时间戳一个只读事务分成两个阶段执行:分配一个时间戳 sread[8]，然后当成 sread 时刻的快照读来执行事务读操作。快照读可以在任何足够新的副本上面执行。 在一个事务开始后的任意时刻，可以简单地分配 sread=TT.now().latest，通过第 4.1.2 节中描述过的类似的方式来维护外部一致性。但是，对于时间戳 sread 而言，如果 tsafe 没有增加到足够大，可能需要对 sread 时刻的读操作进行阻塞。除此以外还要注意，选择一个 sread 的值可 能也会增加 smax 的值，从而保证不连贯性。为了减少阻塞的概率，Spanner 应该分配可以保持外部一致性的最老的时间戳。第 4.2.2 节描述了如何选择这种时间戳。 4.2 细节这部分内容介绍一些读写操作和只读操作的实践细节，以及用来实现原子模式变更的特定事务的实现方法。然后，描述一些基本模式的细化。 4.2.1 读写事务就像 Bigtable 一样，发生在一个事务中的写操作会在客户端进行缓存，直到提交。由此导致的结果是，在一个事务中的读操作，不会看到这个事务的写操作的结果。这种设计在 Spanner 中可以很好地工作，因为一个读操作可以返回任何数据读的时间戳，未提交的写操作还没有被分配时间戳。 在读写事务内部的读操作，使用伤停等待(wound-wait)[33]来避免死锁。客户端对位于合适组内的领导者副本发起读操作，需要首先获得读锁，然后读取最新的数据。当一个客户端事务保持活跃的时候，它会发送“保持活跃”信息，防止那些参与的领导者让该事务过时。当一个客户端已经完成了所有的读操作，并且缓冲了所有的写操作，它就开始两阶段提交。客户端选择一个协调者组，并且发送一个提交信息给每个参与的、具有协调者标识的领导者，并发送提交信息给任何缓冲的写操作。让客户端发起两阶段提交操作，可以避免在大范围连接内发送两次数据。 一个参与其中的、扮演非协调者角色的领导者，首先需要获得写锁。然后，它会选择一 个预备时间戳，这个时间戳应该比之前分配给其他事务的任何时间戳都要大(这样可以保持 单调性)，并且通过 Paxos 把准备提交记录写入日志。然后，每个参与者就把自己的准备时 间戳通知给协调者。 扮演协调者的领导者，也会首先获得写锁，但是，会跳过准备阶段。在从所有其他的、扮演参与者的领导者那里获得信息后，它就会为整个事务选择一个时间戳。这个提交时间戳 s 必须大于或等于所有的准备时间戳(这是为了满足第 4.1.3 节讨论的限制条件)，在协调者收到它的提交信息时，s 应该大于 TT.now().latest，并且 s 应该大于这个领导者为之前的其他 所有事务分配的时间戳(再次指出，这样做是为了满足单调性)。这个扮演协调者的领导者，就会通过 Paxos 在日志中写入一个提交记录(或者当等待其他参与者发生超时就在日志中写 入终止记录)。 在允许任何协调者副本去提交记录之前，扮演协调者的领导者会一直等待到 TT.after(s)， 从而可以保证遵循第 4.1.2 节中描述的提交等待规则。因为，扮演协调者的领导者会根据 TT.now().latest 来选择 s，而且必须等待直到那个时间戳可以确保成为过去，预期的等待时间 至少是 2*ε。这种等待时间通常会和 Paxos 通信时间发生重叠。在提交等待之后，协调者就会发送一个提交时间戳给客户端和所有其他参与的领导者。每个参与的领导者会通过 Paxos 把事务结果写入日志。所有的参与者会在同一个时间戳进行提交，然后释放锁。 4.2.2 只读事务分配一个时间戳需要一个协商阶段，这个协商发生在所有参与到该读操作中的 Paxos 组之间。由此导致的结果是，Spanner 需要为每个只读事务提供一个 scope 表达式，它可以指出整个事务需要读取哪些键。对于单独的查询，Spanner 可以自动计算出 scope。 如果 scope 的值是由单个 Paxos 组来提供的，那么，客户端就会给那个组的领导者发起一个只读事务(当前的 Spanner 实现中，只会为 Paxos leader 中的只读事务选择一个时间戳)， 为那个领导者分配 sread 并且执行读操作。对于一个单个位置的读操作，Spanner 通常会比 TT.now().latest 做得更好。我们把 LastTS()定义为在 Paxos 组中最后提交的写操作的时间戳。如果没有准备提交的事务，这个分配到的时间戳 sread=LastTS()就很容易满足外部一致性要求: 这个事务将可以看见最后一个写操作的结果，然后排队排在它之后。 如果 scope 的值是由多个 Paxos 组来提供的，就会有几种选择。最复杂的选择就是，和所有组的领导者进行一轮沟通，大家根据 LastTS()进行协商得到 sread。Spanner 当前实现了一个更加简单的选择。这个选择可以避免一轮协商，让读操作在 sread=TT.now().latest 时刻去 执行(这可能会等待安全时间的增加)。这个事务中的所有读操作，可以被发送到任何足够 新的副本上执行。 4.2.3 模式变更事务TrueTime 允许 Spanner 支持原子模式变更。使用一个标准的事务是不可行的，因为参与者的数量(即数据库中组的数量)可能达到几百万个。Bigtable 可以支持在一个数据中心内进行原子模式变更，但是，这个操作会阻塞所有其他操作。 一个 Spanner 模式变更事务通常是一个标准事务的、非阻塞的变种。首先，它会显式地分配一个未来的时间戳，这个时间戳会在准备阶段进行注册。由此，跨越几千个服务器的模式变更，可以在不打扰其他并发活动的前提下完成。其次，读操作和写操作，它们都是隐式地依赖于模式，它们都会和任何注册的模式变更时间戳t保持同步:当它们的时间戳小于 t 时， 读写操作就执行到时刻 t;当它们的时间戳大于时刻 t 时，读写操作就必须阻塞，在模式变更事务后面进行等待。如果没有 TrueTime，那么定义模式变更发生在 t 时刻，就变得毫无意义。 5. 实验分析我们对 Spanner 性能进行了测试，包括复制、事务和可用性。然后，我们提供了一些关于 TrueTime 的实验数据，并且提供了我们的第一个用例——F1。 5.1 微测试基准表 3 给出了一用于 Spanner 的微测试基准(microbenchmark)。这些测试是在分时机器上实现的:每个 spanserver 采用 4GB 内存和四核 CPU(AMD Barcelona 2200MHz)。客户端运行在单独的机器上。每个 zone 都包含一个 spanserver。客户端和 zone 都放在一个数据中心集合内，它们之间的网络距离不会超过 1ms。这种布局是很普通的，许多数据并不需要把数 据分散存储到全球各地)。测试数据库具有 50 个 Paxos 组和 2500 个目录。操作都是独立的 4KB 大小的读和写。All reads were served out of memory after a compaction，从而使得我们只需要衡量 Spanner 调用栈的开销。此外，还会进行一轮读操作，来预热任何位置的缓存。 对于延迟实验而言，客户端会发起足够少量的操作，从而避免在服务器中发生排队。从 1 个副本的实验中，提交等待大约是 5ms，Paxos 延迟大约是 9ms。随着副本数量的增加， 延迟大约保持不变，只具有很少的标准差，因为在一个组的副本内，Paxos 会并行执行。随着副本数量的增加，获得指定投票数量的延迟对一个 slave 副本的慢速度不会很敏感。 对于吞吐量的实验而言，客户端发起足够数量的操作，从而使得 CPU 处理能力达到饱和。快照读操作可以在任何足够新的副本上进行，因此，快照读的吞吐量会随着副本的数量增加而线性增加。单个读的只读事务，只会在领导者上执行，因为，时间戳分配必须发生在领导者上。只读事务吞吐量会随着副本数量的增加而增加，因为有效的 spanserver 的数量会增加:在这个实验的设置中，spanserver 的数量和副本的数量相同，领导者会被随机分配到不同的 zone。写操作的吞吐量也会从这种实验设置中获得收益(副本从 3 变到 5 时写操作吞吐量增加了，就能够说明这点)，但是，随着副本数量的增加，每个写操作执行时需要完 成的工作量也会线性增加，这就会抵消前面的收益。 表 4 显示了两阶段提交可以扩展到合理数量的参与者:它是对一系列实验的总结，这些实验运行在 3 个 zone 上，每个 zone 具有 25 个 spanserver。扩展到 50 个参与者，无论在平均值还是第 99 个百分位方面，都是合理的。在 100 个参与者的情形下，延迟开发明显增加。 5.2 可用性图 5 显示了在多个数据中心运行 Spanner 时的可用性方面的收益。它显示了三个吞吐量实验的结果，并且存在数据中心失败的情形，所有三个实验结果都被重叠放置到一个时间轴 上。测试用的 universe 包含 5 个 zone Zi，每个 zone 都拥有 25 个 spanserver。测试数据库被 分片成 1250 个 Paxos 组，100 个客户端不断地发送非快照读操作，累积速率是每秒 50K 个读操作。所有领导者都会被显式地放置到 Z1。每个测试进行 5 秒钟以后，一个 zone 中的所有服务器都会被“杀死”:non-leader 杀掉 Z2，leader-hard 杀掉 Z1，leader-soft 杀掉 Z1，但是，它会首先通知所有服务器它们将要交出领导权。 杀掉 Z2 对于读操作吞吐量没有影响。杀掉 Z1，给领导者一些时间来把领导权交给另一个 zone 时，会产生一个小的影响:吞吐量会下降，不是很明显，大概下降 3-4%。另一方面，没有预警就杀掉 Z1 有一个明显的影响:完成率几乎下降到 0。随着领导者被重新选择，系统的吞吐量会增加到大约每秒 100K 个读操作，主要是由于我们的实验设置:系统中有额外的能力，当找不到领导者时操作会排队。由此导致的结果是，系统的吞吐量会增加直到到达 系统恒定的速率。 我们可以看看把 Paxos 领导者租约设置为 10ms 的效果。当我们杀掉这个 zone，对于这 个组的领导者租约的过期时间，会均匀地分布到接下来的 10 秒钟内。来自一个死亡的领导者的每个租约一旦过期，就会选择一个新的领导者。大约在杀死时间过去 10 秒钟以后，所有的组都会有领导者，吞吐量就恢复了。短的租约时间会降低服务器死亡对于可用性的影响， 但是，需要更多的更新租约的网络通讯开销。我们正在设计和实现一种机制，它可以在领导者失效的时候，让 slave 释放 Paxos 领导者租约。 5.3 TrueTime关于 TrueTime，必须回答两个问题: ε 是否就是时钟不确定性的边界? ε 会变得多糟糕? 对于第一个问题，最严峻的问题就是，如果一个局部的时钟漂移大于 200us/sec，那就会破坏 TrueTime 的假设。我们的机器统计数据显示，坏的 CPU 的出现概率要比坏的时钟出现概率大 6 倍。也就是说，与更加严峻的硬件问题相比，时钟问题是很少见的。由此，我们也相信，TrueTime 的实现和 Spanner 其他软件组件一样，具有很好的可靠性，值得信任。 图 6 显示了 TrueTime 数据，是从几千个 spanserver 中收集的，这些 spanserver 跨越了多 个数据中心，距离 2200 公里以上。图中描述了 ε 的第 90 个、99 个和 99.9 个百分位的情况， 是在对 timemaster 进行投票后立即对 timeslave daemon 进行样本抽样的。这些抽样数据没有考虑由于时钟不确定性带来的 ε 值的锯齿，因此测量的是 timemaster 不确定性(通常是 0) 再加上通讯延迟。 图 6 中的数据显示了，在决定 ε 的基本值方面的上述两个问题，通常都不会是个问题。 但是，可能会存在明显的拖尾延迟问题，那会引起更高的 ε 值。图中，3 月 30 日拖尾延迟的降低，是因为网络的改进，减少了瞬间网络连接的拥堵。在 4 月 13 日 ε 的值增加了，持续了大约 1 个小时，主要是因为例行维护时关闭了两个 time master。我们会继续调研并且消除引起 TrueTime 突变的因素。 5.4 F1Spanner 在 2011 年早期开始进行在线负载测试，它是作为谷歌广告后台 F1[35]的重新实现的一部分。这个后台最开始是基于 MySQL 数据库，在许多方面都采用手工数据分区。未 经压缩的数据可以达到几十 TB，虽然这对于许多 NoSQL 实例而言数据量是很小的，但是， 对于采用数据分区的 MySQL 而言，数据量是非常大的。MySQL 的数据分片机制，会把每个客户和所有相关的数据分配给一个固定的分区。这种布局方式，可以支持针对单个客户的 索引构建和复杂查询处理，但是，需要了解一些商业知识来设计分区。随着客户数量的增长， 对数据进行重新分区，代价是很大的。最近一次的重新分区，花费了两年的时间，为了降低风险，在多个团队之间进行了大量的合作和测试。这种操作太复杂了，无法常常执行，由此导致的结果是，团队必须限制 MySQL 数据库的增长，方法是，把一些数据存储在外部的 Bigtable 中，这就会牺牲事务和查询所有数据的能力。 F1 团队选择使用 Spanner 有几个方面的原因。首先，Spanner 不需要手工分区。其次， Spanner 提供了同步复制和自动失败恢复。在采用 MySQL 的 master-slave 复制方法时，很难进行失败恢复，会有数据丢失和当机的风险。再次，F1 需要强壮的事务语义，这使得使用 其他 NoSQL 系统是不实际的。应用语义需要跨越任意数据的事务和一致性读。F1 团队也需要在他们的数据上构建二级索引(因为 Spanner 没有提供对二级索引的自动支持)，也有能力使用 Spanner 事务来实现他们自己的一致性全球索引。 所有应用写操作，现在都是默认从 F1 发送到 Spanner。而不是发送到基于 MySQL 的应 用栈。F1 在美国的西岸有两个副本，在东岸有三个副本。这种副本位置的选择，是为了避免发生自然灾害时出现服务停止问题，也是出于前端应用的位置的考虑。实际上，Spanner 的失败自动恢复，几乎是不可见的。在过去的几个月中，尽管有不在计划内的机群失效，但是，F1 团队最需要做的工作仍然是更新他们的数据库模式，来告诉 Spanner 在哪里放置 Paxos 领导者，从而使得它们尽量靠近应用前端。 Spanner 时间戳语义，使得它对于 F1 而言，可以高效地维护从数据库状态计算得到的、放在内存中的数据结构。F1 会为所有变更都维护一个逻辑历史日志，它会作为每个事务的 一部分写入到 Spanner。F1 会得到某个时间戳下的数据的完整快照，来初始化它的数据结构， 然后根据数据的增量变化来更新这个数据结构。 表 5 显示了 F1 中每个目录的分片数量的分布情况。每个目录通常对应于 F1 上的应用栈中的一个用户。绝大多数目录(同时意味着绝大多数用户)都只会包含一个分片，这就意味着，对于这些用户数据的读和写操作只会发生在一个服务器上。多于 100 个分片的目录，是那些包含 F1 二级索引的表:对这些表的多个分片进行写操作，是极其不寻常的。F1 团队也只是在以事务的方式进行未经优化的批量数据加载时，才会碰到这种情形。 表 6 显示了从 F1 服务器来测量的 Spanner 操作的延迟。在东海岸数据中心的副本，在 选择 Paxos 领导者方面会获得更高的优先级。表 6 中的数据是从这些数据中心的 F1 服务器 上测量得到的。写操作延迟分布上存在较大的标准差，是由于锁冲突引起的肥尾效应(fat tail)。在读操作延迟分布上存在更大的标准差，部分是因为 Paxos 领导者跨越了两个数据中心，只有其中的一个是采用了固态盘的机器。此外，测试内容还包括系统中的每个针对两个 数据中心的读操作:字节读操作的平均值和标准差分别是 1.6KB 和 119KB。 6. 相关工作Megastore[5]和 DynamoDB[3]已经提供了跨越多个数据中心的一致性复制。DynamoDB 提供了键值存储接口，只能在一个 region 内部进行复制。Spanner 和 Megastore 一样，都提供了半关系数据模型，甚至采用了类似的模式语言。Megastore 无法活动高性能。Megastore 是架构在 Bigtable 之上，这带来了很高的通讯代价。Megastore 也不支持长寿命的领导者， 多个副本可能会发起写操作。来自不同副本的写操作，在 Paxos 协议下一定会发生冲突，即使他们不会发生逻辑冲突:会严重影响吞吐量，在一个 Paxos 组内每秒钟只能执行几个写操作。Spanner 提供了更高的性能，通用的事务和外部一致性。 Pavlo 等人[31]对数据库和 MapReduce[12]的性能进行了比较。他们指出了几个努力的方向，可以在分布式键值存储之上充分利用数据库的功能[1][4][7][41]，二者可以实现充分的融合。我们比较赞同这个结论，并且认为集成多个层是具有优势的:把复制和并发控制集成起来，可以减少 Spanner 中的提交等待代价。 在一个采用了复制的存储上面实现事务，可以至少追述到 Gifford 的论文[16]。Scatter[17] 是一个最近的基于 DHT 的键值存储，可以在一致性复制上面实现事务。Spanner 则要比 Scatter 在更高的层次上提供接口。Gray 和 Lamport[18]描述了一个基于 Paxos 的非阻塞的提交协议，他们的协议会比两阶段提交协议带来更多的代价，而两阶段提交协议在大范围分布 式的组中的代价会进一步恶化。Walter[36]提供了一个快照隔离的变种，但是无法跨越数据中心。相反，我们的只读事务提供了一个更加自然的语义，因为我们对于所有的操作都支持外部语义。 最近，在减少或者消除锁开销方面已经有大量的研究工作。Calvin[40]消除了并发控制: 它会重新分配时间戳，然后以时间戳的顺序执行事务。HStore[39]和 Granola[11]都支持自己的事务类型划分方法，有些事务类型可以避免锁机制。但是，这些系统都无法提供外部一致性。Spanner 通过提供快照隔离，解决了冲突问题。 VoltDB[42]是一个分片的内存数据库，可以支持在大范围区域内进行主从复制，支持灾难恢复，但是没有提供通用的复制配置方法。它是一个被称为 NewSQL 的实例，这是实现 可扩展的 SQL[38]的强大的市场推动力。许多商业化的数据库都可以支持历史数据读取，比如 Marklogic[26]和 Oracle’ Total Recall[30]。Lomet 和 Li[24]对于这种时间数据库描述了一种 实现策略。 Faresite 给出了与一个受信任的时钟参考值相关的时钟不确定性的边界13:Farsite 中的服务器租约的方式，和 Spanner 中维护 Paxos 租约的方式 相同。在之前的工作中[2][23]，宽松同步时钟已经被用来进行并发控制。我们已经展示了 TrueTime 可以从 Paxos 状态机集合中推导出全球时间。 7. 未来的工作在过去一年的大部分时间里，我们都是 F1 团队一起工作，把谷歌的广告后台从 MySQL 迁移到 Spanner。我们正在积极改进它的监控和支撑工具，同时在优化性能。此外，我们已经开展了大量工作来改进备份恢复系统的功能和性能。我们当前正在实现 Spanner 模式语言，自动维护二级索引和自动基于负载的分区。在未来，我们会调研更多的特性。以最优化的方式并行执行读操作，是我们追求的有价值的策略，但是，初级阶段的实验表明，实现这个目标比较艰难。此外，我们计划最终可以支持直接变更 Paxos 配置[22]34]。 我们希望许多应用都可以跨越数据中心进行复制，并且这些数据中心彼此靠近。 TrueTime ε 可能会明显影响性能。把 ε 值降低到 1ms 以内，并不存在不可克服的障碍。 Time-master-query 间隔可以继续减少，Time-master-query 延迟应该随着网络的改进而减少， 或者通过采用分时技术来避免延迟。 最后，还有许多有待改进的方面。尽管 Spanner 在节点数量上是可扩展的，但是与节点相关的数据结构在复杂的 SQL 查询上的性能相对较差，因为，它们是被设计成服务于简单的键值访问的。来自数据库文献的算法和数据结构，可以极大改进单个节点的性能。另外，根据客户端负载的变化，在数据中心之间自动转移数据，已经成为我们的一个目标，但是，为了有效实现这个目标，我们必须具备在数据中心之间自动、协调地转移客户端应用进程的能力。转移进程会带来更加困难的问题——如何在数据中心之间管理和分配资源。 8. 总结总的来说，Spanner 对来自两个研究群体的概念进行了结合和扩充:一个是数据库研究群体，包括熟悉易用的半关系接口，事务和基于 SQL 的查询语言;另一个是系统研究群体，包括可扩展性，自动分区，容错，一致性复制，外部一致性和大范围分布。自从 Spanner 概念成形，我们花费了 5 年以上的时间来完成当前版本的设计和实现。花费这么长的时间，一部分原因在于我们慢慢意识到，Spanner 不应该仅仅解决全球复制的命名空间问题，而且也应该关注 Bigtable 中所丢失的数据库特性。 我们的设计中一个亮点特性就是 TrueTime。我们已经表明，在时间 API 中明确给出时钟不确定性，可以以更加强壮的时间语义来构建分布式系统。此外，因为底层的系统在时钟不确定性上采用更加严格的边界，实现更强壮的时间语义的代价就会减少。作为一个研究群体，我们在设计分布式算法时，不再依赖于弱同步的时钟和较弱的时间 API。 致谢许多人帮助改进了这篇论文:Jon Howell，Atul Adya, Fay Chang, Frank Dabek, Sean Dorward, Bob Gruber, David Held, Nick Kline, Alex Thomson, and Joel Wein. 我们的管理层对于我们的工作和论文发表都非常支持:Aristotle Balogh, Bill Coughran, Urs H ̈olzle, Doron Meyer, Cos Nicolaou, Kathy Polizzi, Sridhar Ramaswany, and Shivakumar Venkataraman. 我们的工作是在Bigtable和Megastore团队的工作基础之上开展的。F1团队，尤其是Jeff Shute ，和我们一起工作，开发了数据模型，跟踪性能和纠正漏洞。Platforms团队，尤其是Luiz Barroso 和Bob Felderman，帮助我们一起实现了TrueTime。最后，许多谷歌员工都曾经在我们的团队工作过，包括Ken Ashcraft, Paul Cychosz, Krzysztof Ostrowski, Amir Voskoboynik, Matthew Weaver, Theo Vassilakis, and Eric Veach; or have joined our team recently: Nathan Bales, Adam Beberg, Vadim Borisov, Ken Chen, Brian Cooper, Cian Cullinan, Robert-Jan Huijsman, Milind Joshi, Andrey Khorlin, Dawid Kuroczko, Laramie Leavitt, Eric Li, Mike Mammarella, Sunil Mushran, Simon Nielsen, Ovidiu Platon, Ananth Shrinivas, Vadim Suvorov, and Marcel van der Holst. 参考文献[1] Azza Abouzeid et al. ―HadoopDB: an architectural hybrid of MapReduce and DBMS technologies for analytical workloads‖. Proc. of VLDB. 2009, pp. 922–933. [2] A. Adya et al. ―Efficient optimistic concurrency control using loosely synchronized clocks‖. Proc. of SIGMOD. 1995, pp. 23–34. [3] Amazon. Amazon DynamoDB. 2012. [4] Michael Armbrust et al. ―PIQL: Success-Tolerant Query Processing in the Cloud‖. Proc. of VLDB. 2011, pp. 181–192. [5] Jason Baker et al. ―Megastore: Providing Scalable, Highly Available Storage for Interactive Services‖. Proc. of CIDR. 2011, pp. 223–234. [6] Hal Berenson et al. ―A critique of ANSI SQL isolation levels‖. Proc. of SIGMOD. 1995, pp. 1–10. [7] Matthias Brantner et al. ―Building a database on S3‖. Proc. of SIGMOD. 2008, pp. 251–264. [7] Matthias Brantner et al. ―Building a database on S3‖. Proc. of SIGMOD. 2008, pp. 251–264. [8] A. Chan and R. Gray. ―Implementing Distributed Read-Only Transactions‖. IEEE TOSE SE-11.2 (Feb. 1985), pp. 205–212. [9] Fay Chang et al. ―Bigtable: A Distributed Storage System for Structured Data‖. ACM TOCS 26.2 (June 2008), 4:1–4:26. [10] Brian F. Cooper et al. ―PNUTS: Yahoo!’s hosted data serving platform‖. Proc. of VLDB. 2008, pp. 1277–1288. [11] James Cowling and Barbara Liskov. ―Granola: Low-Overhead Distributed Transaction Coordination‖. Proc. of USENIX ATC. 2012, pp. 223–236. [12] Jeffrey Dean and Sanjay Ghemawat. ―MapReduce: a flexible data processing tool‖. CACM 53.1 (Jan. 2010), pp. 72–77. [13] John Douceur and Jon Howell. Scalable Byzantine-Fault-Quantifying Clock Synchronization. Tech. rep. MSR-TR-2003-67. MS Research, 2003. [14] John R. Douceur and Jon Howell. ―Distributed directory service in the Farsite file system‖. Proc. of OSDI. 2006, pp. 321–334. [15] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. ―The Google file system‖. Proc. of SOSP. Dec. 2003, pp. 29–43. [16] David K. Gifford. Information Storage in a Decentralized Computer System. Tech. rep. CSL-81-8. PhD dissertation. Xerox PARC, July 1982. [17] Lisa Glendenning et al. ―Scalable consistency in Scatter‖. Proc. of SOSP. 2011. [18] Jim Gray and Leslie Lamport. ―Consensus on transaction commit‖. ACM TODS 31.1 (Mar. 2006), pp. 133–160. [19] Pat Helland. ―Life beyond Distributed Transactions: an Apostate’s Opinion‖. Proc. of CIDR. 2007, pp. 132–141. [20] Maurice P. Herlihy and Jeannette M. Wing. ―Linearizability: a correctness condition forconcurrent objects‖. ACM TOPLAS 12.3 (July 1990), pp. 463–492. [21] Leslie Lamport. ―The part-time parliament‖. ACM TOCS 16.2 (May 1998), pp. 133–169. [22] Leslie Lamport, Dahlia Malkhi, and Lidong Zhou. ―Reconfiguring a state machine‖. SIGACT News 41.1 (Mar. 2010), pp. 63–73. [23] Barbara Liskov. ―Practical uses of synchronized clocks in distributed systems‖. Distrib. Comput. 6.4 (July 1993), pp. 211–219. [24] David B. Lomet and Feifei Li. ―Improving Transaction-Time DBMS Performance and Functionality‖. Proc. of ICDE (2009), pp. 581–591. [25] Jacob R. Lorch et al. ―The SMART way to migrate replicated stateful services‖. Proc. of EuroSys. 2006, pp. 103–115. [26] MarkLogic. MarkLogic 5 Product Documentation. 2012. [27] Keith Marzullo and Susan Owicki. ―Maintaining the time in a distributed system‖. Proc. of PODC. 1983, pp. 295–305. [28] Sergey Melnik et al. ―Dremel: Interactive Analysis of Web-Scale Datasets‖. Proc. of VLDB. 2010, pp. 330–339. [29] D.L. Mills. Time synchronization in DCNET hosts. Internet Project Report IEN–173. COMSAT Laboratories, Feb. 1981. [30] Oracle. Oracle Total Recall. 2012. [31] Andrew Pavlo et al. ―A comparison of approaches to large-scale data analysis‖. Proc. of SIGMOD. 2009, pp. 165–178. [32] Daniel Peng and Frank Dabek. ―Large-scale incremental processing using distributed transactions and notifications‖. Proc. of OSDI. 2010, pp. 1–15. [33] Daniel J. Rosenkrantz, Richard E. Stearns, and Philip M. Lewis II. ―System level concurrency control for distributed database systems‖. ACM TODS 3.2 (June 1978), pp. 178–198. [34] Alexander Shraer et al. ―Dynamic Reconfiguration of Primary/Backup Clusters‖. Proc. ofSENIX ATC. 2012, pp. 425–438. [35] Jeff Shute et al. ―F1—The Fault-Tolerant Distributed RDBMS Supporting Google’s Ad Business‖. Proc. of SIGMOD. May 2012, pp. 777–778. [36] Yair Sovran et al. ―Transactional storage for geo-replicated systems‖. Proc. of SOSP. 2011, pp. 385–400. [37] Michael Stonebraker. Why Enterprises Are Uninterested in NoSQL. 2010. [38] Michael Stonebraker. Six SQL Urban Myths. 2010. [39] Michael Stonebraker et al. ―The end of an architectural era: (it’s time for a complete rewrite)‖. Proc. of VLDB. 2007, pp. 1150–1160. [40] Alexander Thomson et al. ―Calvin: Fast Distributed Transactions for Partitioned Database Systems‖. Proc. of SIGMOD.2012, pp. 1–12. [41] Ashish Thusoo et al. ―Hive — A Petabyte Scale Data Warehouse Using Hadoop‖. Proc. of ICDE. 2010, pp. 996–1005. [42] VoltDB. VoltDB Resources. 2012.","raw":null,"content":null,"categories":[{"name":"分布式数据库","slug":"分布式数据库","permalink":"http://linbingdong.com/categories/分布式数据库/"},{"name":"Google Spanner","slug":"分布式数据库/Google-Spanner","permalink":"http://linbingdong.com/categories/分布式数据库/Google-Spanner/"}],"tags":[{"name":"分布式数据库","slug":"分布式数据库","permalink":"http://linbingdong.com/tags/分布式数据库/"},{"name":"Spanner","slug":"Spanner","permalink":"http://linbingdong.com/tags/Spanner/"},{"name":"论文翻译","slug":"论文翻译","permalink":"http://linbingdong.com/tags/论文翻译/"}]},{"title":"分布式系列文章——Paxos算法原理与推导(PPT)","slug":"分布式系列文章——Paxos算法原理与推导(PPT)","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/分布式系列文章——Paxos算法原理与推导(PPT)/","link":"","permalink":"http://linbingdong.com/2017/03/11/分布式系列文章——Paxos算法原理与推导(PPT)/","excerpt":"之前在公司内部分享了Paxos算法的原理和推导过程，现将PPT分享给大家，有疑问欢迎随时交流讨论。","text":"之前在公司内部分享了Paxos算法的原理和推导过程，现将PPT分享给大家，有疑问欢迎随时交流讨论。","raw":null,"content":null,"categories":[{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/categories/分布式一致性算法/"},{"name":"Paxos","slug":"分布式一致性算法/Paxos","permalink":"http://linbingdong.com/categories/分布式一致性算法/Paxos/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"},{"name":"Paxos","slug":"Paxos","permalink":"http://linbingdong.com/tags/Paxos/"},{"name":"分布式一致性算法","slug":"分布式一致性算法","permalink":"http://linbingdong.com/tags/分布式一致性算法/"}]},{"title":"Java中System.arraycopy()和Arrays.copyOf()的区别","slug":"Java中System.arraycopy()和Arrays.copyOf()的区别","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java中System.arraycopy()和Arrays.copyOf()的区别/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java中System.arraycopy()和Arrays.copyOf()的区别/","excerpt":"先看看System.arraycopy()的声明：\npublic static native void arraycopy(Object src,int srcPos, Object dest, int destPos,int length);`\n","text":"先看看System.arraycopy()的声明： public static native void arraycopy(Object src,int srcPos, Object dest, int destPos,int length);` src - 源数组。srcPos - 源数组中的起始位置。dest - 目标数组。destPos - 目标数据中的起始位置。length - 要复制的数组元素的数量。 该方法用了native关键字，说明调用的是其他语言写的底层函数。 再看Arrays.copyOf() public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) { @SuppressWarnings(&quot;unchecked&quot;) T[] copy = ((Object)newType == (Object)Object[].class)?(T[]) new Object[newLength]:(T[]) Array.newInstance(newType.getComponentType(), newLength);System.arraycopy(original,0, copy,0, Math.min(original.length, newLength)); return copy; } 该方法对应不同的数据类型都有各自的重载方法original - 要复制的数组newLength - 要返回的副本的长度newType - 要返回的副本的类型仔细观察发现，copyOf()内部调用了System.arraycopy()方法 区别在于： arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，调用arraycopy()将original内容复制到copy中去，并且长度为newLength。返回copy; 即将原数组拷贝到一个长度为newLength的新数组中，并返回该数组。 总结Array.copyOf()可以看作是受限的System.arraycopy(),它主要是用来将原数组全部拷贝到一个新长度的数组，适用于数组扩容。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"分布式系列文章——从ACID到CAP/BASE","slug":"分布式系列文章——从ACID到CAP:BASE","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/分布式系列文章——从ACID到CAP:BASE/","link":"","permalink":"http://linbingdong.com/2017/03/11/分布式系列文章——从ACID到CAP:BASE/","excerpt":"本文先介绍传统关系数据库中事务的ACID特性，再介绍分布式系统中的经典理论——CAP定理和BASE理论。","text":"本文先介绍传统关系数据库中事务的ACID特性，再介绍分布式系统中的经典理论——CAP定理和BASE理论。 事务事务的定义： 事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元（Unit），狭义上的事务特指数据库事务。 事务的作用： 当多个应用程序并发访问数据库时，事务可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作相互干扰。 事务为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持数据一致性的方法。 事务具有四个特性，分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）,简称为事务的ACID特性。 ACID原子性事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，要么全部执行，要么全部不执行。 任何一项操作失败都将导致整个事务失败，同时其他已经被执行的操作都将被撤销并回滚。只有所有的操作全部成功，整个事务才算是成功完成。 一致性事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行前后，数据库都必须处于一致性状态。换句话说，事务的执行结果必须是使数据库从一个一致性状态转变到另一个一致性状态。 举个例子 银行的转账操作就是一个事务。假设A和B原来账户都有100元。此时A转账给B50元，转账结束后，应该是A账户减去50元变成50元，B账户增加50元变成150元。A、B的账户总和还是200元。转账前后，数据库就是从一个一致性状态（A100元，B100元，A、B共200元）转变到另一个一致性状态（A50元，B150元，A、B共200元）。假设转账结束后只扣了A账户，没有增加B账户，这时数据库就处于不一致的状态。 隔离性事务的隔离性是指在并发环境中，并发的事务是相互隔离的，事务之间互不干扰。 在标准的SQL规范中，定义的4个事务隔离级别，不同隔离级别对事务的处理不同。4个隔离级别分别是：未授权读取、授权读取、可重复读取和串行化。 下表展示了不同隔离级别下事务访问数据的差异 隔离级别 脏读 可重复读 幻读 未授权读取 存在 不可以 存在 授权读取 不存在 不可以 存在 可重复读取 不存在 可以 存在 串行化 不存在 可以 不存在 以上4个级别的隔离性依次增强，分别解决不同的问题。事务隔离级别越高，就越能保证数据的完整性和一致性，但同时对并发性能的影响也越大。 通常，对于绝大多数的应用来说，可以优先考虑将数据库系统的隔离级别设置为授权读取，这能够在避免脏读的同时保证较好的并发性能。尽管这种事务隔离级别会导致不可重复读、幻读和第二类丢失更新等并发问题，但较为科学的做法是在可能出现这类问题的个别场合中，由应用程序主动采用悲观锁或乐观锁来进行事务控制。 持久性事务的持久性又称为永久性，是指一个事务一旦提交，对数据库中对应数据的状态变更就应该是永久性的。即使发生系统崩溃或机器宕机等故障，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束时的状态。 分布式事务事务在分布式计算领域也得到了广泛的应用。在单机数据库中，我们很容易能够实现一套满足ACID特性的事务处理系统，但是在分布式数据库中，数据分散在各台不同的机器上，如何对这些数据进行分布式事务处理具有非常大的挑战。 分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。通常一个分布式事务会涉及对多个数据源或业务系统的操作。 举个例子来说明分布式事务。一个最典型的分布式事务场景是跨行的转账操作。该操作涉及调用两个异地的银行服务。其中一个是本地银行提供的取款服务，另一个是目标银行提供的存款服务，这两个服务本身是无状态且相互独立的，共同构成了一个完整的分布式事务。取款和存款两个步骤要么都执行，要么都不执行。否则，如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么必须回滚到取款之前的状态，否则就会导致数据不一致。 从上面的例子可以看出，一个分布式事务可以看作是由多个分布式操作序列组成的，例如上面例子中的取款服务和存款服务，通常可以把这一系列分布式的操作序列称为子事务。由于分布式事务中，各个子事务的执行是分布式的，因此要实现一种能够保证ACID特性的分布式事务处理系统就显得格外复杂。 CAP定理CAP定理： 一个分布式系统不可能同时满足一致性（C:Consistency）、可用性（A:Availability）和分区容错性（P:Partition tolerance）这三个基本要求，最多只能满足其中的两项。 一致性在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性（这点跟ACID中的一致性含义不同）。 对于一个将数据副本分布在不同节点上的分布式系统来说，如果对第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是更新前的数据（称为脏数据），这就是典型的分布式数据不一致情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都能读取到最新的值，那么这样的系统就被认为具有强一致性（或严格的一致性）。 可用性可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。 『有限的时间内』是一个在系统设计之初就设定好的运行指标，不同的系统会有很大的差别。比如对于一个在线搜索引擎来说，通常在0.5秒内需要给出用户搜索关键词对应的检索结果。而对应Hive来说，一次正常的查询时间可能在20秒到30秒之间。 『返回结果』是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出对请求的处理结果，及成功或失败，而不是一个让用户感到困惑的返回结果。 让我们再来看看上面提到的在线搜索引擎的例子，如果用户输入指定的搜索关键词后，返回的结果是一个系统错误，比如”OutOfMemoryErroe”或”System Has Crashed”等提示语，那么我们认为此时系统是不可用的。 分区容错性分区容错性要求一个分布式系统需要具备如下特性：分布式系统在遇到任何网络分区故障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。 网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络等）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。 以上就是对CAP定理中一致性、可用性和分区容错性的讲解。 既然一个分布式系统无法同时满足上述三个要求，而只能满足其中的两项，因此在对CAP定理应用时，我们就需要抛弃其中的一项，下表是抛弃CAP中任意一项特性的场景说明。 CAP 说明 放弃P 如果希望能够避免系统出现分区容错性问题，一种较为简单的做法是将所有的数据（或者仅仅是哪些与事务相关的数据）都放在一个分布式节点上。这样做虽然无法100%保证系统不会出错，但至少不会碰到由于网络分区带来的负面影响。但同时需要注意的是，放弃P的同时也就意味着放弃了系统的可扩展性 放弃A 一旦系统遇到网络分区或其他故障或为了保证一致性时，放弃可用性，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供正常的服务，即不可用 放弃C 这里所说的放弃一致性，实际上指的是放弃数据的强一致性，而保留数据的最终一致性。这样的系统无法保证数据保持实时的一致性，但是能够承诺的是，数据最终会达到一个一致的状态。 需要明确的一点是：对于一个分布式系统而言，分区容错性可以说是一个最基本的要求。因为既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓的分布式系统了，因此必然出现子网络。而对于分布式系统而言，网络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。因此系统架构师往往需要把精力花在如何根据业务特点在C（一致性）和A（可用性）之间寻求平衡。 BASE理论BASE是Basically Available(基本可用）、Soft state(软状态）和Eventually consistent(最终一致性）三个短语的简写。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方法来使系统达到最终一致性。接下来，我们着重对BASE中的三要素进行讲解。 基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用。一下就是两个”基本可用”的例子。 响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。 功能上的损失：正常情况下，在一个电子商务网站（比如淘宝）上购物，消费者几乎能够顺利地完成每一笔订单。但在一些节日大促购物高峰的时候（比如双十一、双十二），由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面，如下： 软状态软状态是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同的数据副本之间进行数据同步的过程存在延时。 最终一致性最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据到达一致状态的时间延迟，取决于网络延迟、系统负载和数据复制方案设计等因素。 在实际工程实践中，最终一致性存在一下五类主要变种。 因果一致性(Causal consistency) 读己之所写(Read your writes) 会话一致性(Session consistency) 单调读一致性(Monotonic read consistency) 单调写一致性(Monotonic write consistency) 以上就是最终一致性的五种常见的变种，在实际系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性特性的分布式系统。事实上，最终一致性并不是只有那些大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中（比如MySQL和PostgreSQL），大多都会采用同步或异步方式来实现主备数据复制技术。在同步方式中，数据的复制过程通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短。如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的数据将是旧的，因此就出现了数据不一致的情况。当然，无论是采用多次重试还是人为数据订正，关系型数据库还是能够保证最终数据达到一致，这就是系统提供最终一致性保证的经典案例。 参考资料 《从Paxos到ZooKeeper——分布式一致性原理与实践》","raw":null,"content":null,"categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/categories/分布式系统/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"}]},{"title":"分布式系列文章——分布式系统的特点及问题","slug":"分布式系列文章——分布式系统的特点及问题","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/分布式系列文章——分布式系统的特点及问题/","link":"","permalink":"http://linbingdong.com/2017/03/11/分布式系列文章——分布式系统的特点及问题/","excerpt":"随着数据量越来越大，计算机需要处理的业务越来越复杂，单机已经无法满足需求。一个有效的解决方案是把众多廉价的计算机整合起来，共同提供服务，这就是分布式系统。接下来介绍分布式系统的定义、特点，以及分布式环境中存在的问题和挑战。","text":"随着数据量越来越大，计算机需要处理的业务越来越复杂，单机已经无法满足需求。一个有效的解决方案是把众多廉价的计算机整合起来，共同提供服务，这就是分布式系统。接下来介绍分布式系统的定义、特点，以及分布式环境中存在的问题和挑战。 分布式系统定义在《分布式系统概念与设计》一书中，对分布式系统做了 如下定义： 分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。 也就是说一个分布式系统中的计算机在空间部署上可以是随意分布的，这些计算机可能被放在不同的机柜上，也可能在不同的机房中，甚至分布在不同的城市。这些计算机之间通过网络来通信。 分布式的特点分布式系统有如下体征： 分布性分布式系统中的多台计算机在空间上随意分步。当然，机器的分布情况也会随时变动。 对等性分布式系统中的计算机没有主/从之分，既没有控制整个系统的主机，也没有被控制的从机，组成分布式系统的所有计算机节点都是对等的。 并发性一个分布式系统中的多个节点，可能会并发地操作一些共享的资源，比如数据库或分布式存储等。如何准确并高效地协调分布式并发操作也成为了分布式系统架构与设计中最大的挑战。 缺乏全局时钟在分布式系统中，很难定义两个事件究竟谁先谁后，原因就是分布式系统缺乏一个全局的时钟控制序列。 故障总是会发生组成分布式系统的所有计算机，都有可能发生任何形式的故障。实践表明，在分布式系统中，计算机发生故障是比较常见的。因此，在分布式系统设计时，必须考虑到该问题。 分布式环境的各种问题分布式系统体系结构从其出现之初就伴随着诸多的难题和挑战，本节介绍分布式系统中的一些典型的问题。 通信异常分布式系统中个计算机之间是通过网络进行通信的。由于网络本身的不可靠性，每次网络通信都会伴随着网络不可用的风险。即使分布式系统各节点之间的网络通信能够正常进行，其延时也会远远大于单机操作。在分布式系统中，消息延时和消息丢失非常普遍。 网络分区当网络发生异常情况，可能导致分布式系统中某些节点之间能够正常通信，而某些节点之间无法通信——该现象就是网络分区，就是俗称的『脑裂』。当网络分区出现时，分布式系统就会出现局部小集群，小集群内计算机可以相互通信，小集群之间计算机无法通信。这就对分布式一致性提出了非常大的挑战。 三态因为在分布式系统中，网络可能会出现各式各样的问题，因此分布式系统的每一次请求和响应，存在特有的『三态』概念，即成功、失败与超时。在传统的单机系统中，应用程序在调用一个函数之后，能够得到一个非常明确的相应：成功或失败。而在分布式系统中，由于网络是不可靠的，当网络出现异常的情况下，就可能出现超时现象，发生消息丢失现象。 节点故障节点故障是分布式环境下一个比较常见的问题，指的是组成分布式系统的服务器节点出现宕机或『僵死』现象。通常根据经验来说，每个节点都有可能出现故障，并且每天都在发生。","raw":null,"content":null,"categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/categories/分布式系统/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://linbingdong.com/tags/分布式系统/"}]},{"title":"删除链表中重复的节点!","slug":"删除链表中重复的节点","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/删除链表中重复的节点/","link":"","permalink":"http://linbingdong.com/2017/03/11/删除链表中重复的节点/","excerpt":"题目描述\n在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5；链表1-&gt;1-&gt;1-&gt;2-&gt;3 , 处理后为2-&gt;3。\n分析\n可以用递归，也可以用迭代法。\n代码:","text":"题目描述 在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5；链表1-&gt;1-&gt;1-&gt;2-&gt;3 , 处理后为2-&gt;3。 分析 可以用递归，也可以用迭代法。 代码: 递归版 /* public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode deleteDuplication(ListNode pHead)&#123; if (pHead == null || pHead.next == null) return pHead; ListNode p = pHead.next; if (pHead.val == p.val)&#123; while(p != null &amp;&amp; p.val == pHead.val) p = p.next; return deleteDuplication(p); &#125;else&#123; pHead.next = deleteDuplication(pHead.next); return pHead; &#125; &#125;&#125; 迭代版 /* public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode deleteDuplication(ListNode pHead)&#123; ListNode root = new ListNode(-1); root.next = pHead; ListNode pre = root; ListNode cur = pHead; while (cur != null &amp;&amp; cur.next != null)&#123; if (cur.val == cur.next.val)&#123; while (cur.next != null &amp;&amp; cur.val == cur.next.val)&#123; cur = cur.next; &#125; pre.next = cur.next; &#125;else&#123; pre.next = cur; pre = pre.next; &#125; cur = cur.next; &#125; return root.next; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"反转链表","slug":"反转链表","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/反转链表/","link":"","permalink":"http://linbingdong.com/2017/03/11/反转链表/","excerpt":"题目描述\n输入一个链表，反转链表后，输出链表的所有元素。\n分析\n用头插法。\n代码:","text":"题目描述 输入一个链表，反转链表后，输出链表的所有元素。 分析 用头插法。 代码: /*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if (head == null) return null; ListNode h = new ListNode(-1); h = head; ListNode p = new ListNode(-1); p.val = h.val; while (h.next != null)&#123; h = h.next; ListNode q = new ListNode(-1); q.val = h.val; q.next = p; p = q; &#125; return p; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"合并两个有序的链表","slug":"合并两个有序的链表","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/合并两个有序的链表/","link":"","permalink":"http://linbingdong.com/2017/03/11/合并两个有序的链表/","excerpt":"题目描述\n输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。\n分析\n可以用递归，也可以不用递归\n代码:","text":"题目描述 输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 分析 可以用递归，也可以不用递归 代码: 非递归版 /*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; ListNode head = new ListNode(-1); ListNode head2 = head; ListNode p = list1; ListNode q = list2; while (p != null || q != null)&#123; if (p == null)&#123; head2.next = q; return head.next; &#125; if (q == null)&#123; head2.next = p; return head.next; &#125; if (p.val &lt; q.val)&#123; head2.next = p; p = p.next; &#125;else &#123; head2.next = q; q = q.next; &#125; head2 = head2.next; &#125; return head.next; &#125;&#125; 递归版 public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; if (list1 == null) return list2; if (list2 == null) return list1; if (list1.val &lt; list2.val)&#123; list1.next = Merge(list1.next,list2); return list1; &#125;else&#123; list2.next = Merge(list1,list2.next); return list2; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"和为S的两个数字","slug":"和为S的两个数字","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/和为S的两个数字/","link":"","permalink":"http://linbingdong.com/2017/03/11/和为S的两个数字/","excerpt":"题目描述\n输入一个递增排序的数组和一个数字S，在数组中查找两个数，是的他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 \n分析\n数组本来就排序好了，很简单。两个指针，刚开始i在最左边，j在最右边。如果两数想加小于S，i++;如果两数想加大于S，j–;\n代码:","text":"题目描述 输入一个递增排序的数组和一个数字S，在数组中查找两个数，是的他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 分析 数组本来就排序好了，很简单。两个指针，刚开始i在最左边，j在最右边。如果两数想加小于S，i++;如果两数想加大于S，j–; 代码: import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; FindNumbersWithSum(int [] array,int sum) &#123; int i = 0, j = array.length - 1; ArrayList&lt;Integer&gt; al = new ArrayList&lt;Integer&gt;(); while (i &lt; j)&#123; if (array[i] + array[j] == sum)&#123; al.add(array[i]); al.add(array[j]); return al; &#125;else if (array[i] + array[j] &lt; sum)&#123; i++; &#125;else &#123; j--; &#125; &#125; return al; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java中wait、sleep和yield的区别","slug":"Java中wait、sleep和yield的区别","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java中wait、sleep和yield的区别/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java中wait、sleep和yield的区别/","excerpt":"","text":"Java中wait、sleep的区别或者Java中sleep、yield的区别是Java面试或者多线程面试中最常问的问题之一。首先，一个最明显的区别是：wait是Object类的方法，sleep和yield是Thread类的静态方法。 本质上，wait方法是用来让线程等待某个条件，进入该条件的等待集中。而sleep和yield方法是用来让线程让出CPU时间，把CPU交给线程调度器，使得其他线程能获得CPU时间。 接下来详细比较三个方法。 wait常用的wait方法有wait( )和wait(long timeout) wait( )方法导致当前线程进入等待状态直到它被通知（其他线程调用notify或notifyAll方法。notify/notifyAll方法解除等待线程的阻塞状态）。 wait(long timeout) 方法导致当前线程进入等待状态直到它被通知或者经过指定的时间。 wait( )后，线程会释放掉它所占有的对象的锁，从而使线程所在对象中的其它synchronized数据可被别的线程使用。 wait方法只能在一个同步方法中调用。如果当前线程不是对象锁的持有者，该方法抛出一个IllegalMonitorStateException异常。 sleepThread.sleep(long millis),必须带有一个时间参数。 sleep(long millis)使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会被执行。 sleep(long millis)可能使任意优先级的其他线程得到执行机会。 sleep(long millis)不会释放锁。 调用sleep方法的线程在唤醒之后不保证能获取到CPU，它会先进入就绪态，与其他线程竞争CPU。 yieldyield方法没有参数。 yield方法使当前线程让出CPU，但让出的时间是不可设定的。 yield方法也不会释放锁。 yield只能把CPU让给相同优先级的其他线程，而不会把CPU给更高或更低优先级的其他线程。若此时没有其他线程跟它在有一个优先级，则该线程继续获得CPU时间，因此可能某线程刚调用yield方法又马上被执行。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"和为S的连续正数序列","slug":"和为S的连续正数序列","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/和为S的连续正数序列/","link":"","permalink":"http://linbingdong.com/2017/03/11/和为S的连续正数序列/","excerpt":"题目描述\n小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck! \n输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序。\n分析\n思路一：两个for循环即可。\n思路二：用两个数字begin和end分别表示序列的最大值和最小值，首先将begin初始化为1，end初始化为2.如果从begin到end的和大于s，我们就从序列中去掉较小的值(即增大begin),相反，只需要增大end。终止条件为：begin &gt; sum / 2. \n代码:","text":"题目描述 小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck! 输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序。 分析 思路一：两个for循环即可。 思路二：用两个数字begin和end分别表示序列的最大值和最小值，首先将begin初始化为1，end初始化为2.如果从begin到end的和大于s，我们就从序列中去掉较小的值(即增大begin),相反，只需要增大end。终止条件为：begin &gt; sum / 2. 代码: 最直接的思路 import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; FindContinuousSequence(int sum) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; list = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); for (int i = 1; i &lt;= sum / 2; i++)&#123; int temp = 0; for (int j = i; j &lt;= sum / 2 + 1; j++)&#123; temp += j; if (temp == sum)&#123; ArrayList&lt;Integer&gt; al = new ArrayList&lt;Integer&gt;(); for (int x = i; x &lt;= j; x++)&#123; al.add(x); &#125; list.add(al); &#125; if (temp &gt; sum) break; &#125; &#125; return list; &#125;&#125; 更巧妙的解法 import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; FindContinuousSequence(int sum) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; list = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if (sum &lt; 3) return list; int begin = 1; int end = 2; int temp = 3; while (begin &lt;= sum /2)&#123; while (temp &lt; sum) temp += ++end; if (temp == sum)&#123; ArrayList&lt;Integer&gt; al = new ArrayList&lt;Integer&gt;(); for (int i = begin; i &lt;= end; i++)&#123; al.add(i); &#125; list.add(al); &#125; temp -= begin++; &#125; return list; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"回文序列","slug":"回文序列","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/回文序列/","link":"","permalink":"http://linbingdong.com/2017/03/11/回文序列/","excerpt":"如果一个数字序列逆置之后跟原序列是一样的就称这样的数字序列为回文序列。例如：{1, 2, 1}, {15, 78, 78, 15} , {112} 是回文序列,{1, 2, 2}, {15, 78, 87, 51} ,{112, 2, 11} 不是回文序列。现在给出一个数字序列，允许使用一种转换操作：选择任意两个相邻的数，然后从序列移除这两个数，并用这两个数字的和插入到这两个数之前的位置(只插入一个和)。现在对于所给序列要求出最少需要多少次操作可以将其变成回文序列。\n输入描述:\n输入为两行，第一行为序列长度n ( 1 ≤ n ≤ 50)第二行为序列中的n个整数item[i]  (1 ≤ iteam[i] ≤ 1000)，以空格分隔。\n输出描述:\n输出一个数，表示最少需要的转换次数\n输入例子:\n41 1 1 3\n输出例子:\n2\n代码:","text":"如果一个数字序列逆置之后跟原序列是一样的就称这样的数字序列为回文序列。例如：{1, 2, 1}, {15, 78, 78, 15} , {112} 是回文序列,{1, 2, 2}, {15, 78, 87, 51} ,{112, 2, 11} 不是回文序列。现在给出一个数字序列，允许使用一种转换操作：选择任意两个相邻的数，然后从序列移除这两个数，并用这两个数字的和插入到这两个数之前的位置(只插入一个和)。现在对于所给序列要求出最少需要多少次操作可以将其变成回文序列。 输入描述: 输入为两行，第一行为序列长度n ( 1 ≤ n ≤ 50)第二行为序列中的n个整数item[i] (1 ≤ iteam[i] ≤ 1000)，以空格分隔。 输出描述: 输出一个数，表示最少需要的转换次数 输入例子: 41 1 1 3 输出例子: 2 代码: import java.util.Scanner; /** * Created by lbd on 2016/10/29. */public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); while (sc.hasNext())&#123; int n = sc.nextInt(); int[] inputArray = new int[n]; int times = 0; for (int i = 0;i &lt; n;i++)&#123; inputArray[i] = sc.nextInt(); &#125; int head = 0; int tail = n-1; while (head &lt; tail)&#123; if (inputArray[head] &lt; inputArray[tail])&#123; inputArray[++head] += inputArray[head-1]; times++; &#125; else if (inputArray[head] &gt; inputArray[tail])&#123; inputArray[--tail] += inputArray[tail+1]; times++; &#125; else &#123; head++; tail--; &#125; &#125; System.out.println(times); &#125; sc.close(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java中四种引用","slug":"Java中四种引用","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java中四种引用/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java中四种引用/","excerpt":"\n为了使能更加灵活地控制对象的生命周期。从JDK 1.2版本开始，把对象的引用分为4种级别。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。\n","text":"为了使能更加灵活地控制对象的生命周期。从JDK 1.2版本开始，把对象的引用分为4种级别。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 强引用（StrongReference）强引用是级别最高，也是最常用的引用。拥有强引用的对象绝不会被垃圾回收器回收。 软引用（SoftReference）如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。 弱引用（WeakReference）只具有弱引用的对象拥有更短暂的生命周期。在执行gc的时候会被回收。 虚引用（PhantomReference）“虚引用”顾名思义，就是形同虚设，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。仅用于在发生gc时接收一个系统通知。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"字符串查找算法总结（暴力匹配、KMP 算法、Boyer-Moore 算法和 Sunday 算法）","slug":"字符串匹配之暴力匹配 && KMP","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/字符串匹配之暴力匹配 && KMP/","link":"","permalink":"http://linbingdong.com/2017/03/11/字符串匹配之暴力匹配 && KMP/","excerpt":"字符串匹配是字符串的一种基本操作：给定一个长度为 M 的文本和一个长度为 N 的模式串，在文本中找到一个和该模式相符的子字符串，并返回该字字符串在文本中的位置。","text":"字符串匹配是字符串的一种基本操作：给定一个长度为 M 的文本和一个长度为 N 的模式串，在文本中找到一个和该模式相符的子字符串，并返回该字字符串在文本中的位置。 KMP 算法，全称是 Knuth-Morris-Pratt 算法，以三个发明者命名，开头的那个K就是著名科学家 Donald Knuth 。KMP 算法的关键是求 next 数组。next 数组的长度为模式串的长度。next 数组中每个值代表模式串中当前字符前面的字符串中，有多大长度的相同前缀后缀。 Boyer-Moore 算法在实际应用中比 KMP 算法效率高，据说各种文本编辑器的”查找”功能（Ctrl+F），包括 linux 里的 grep 命令，都是采用 Boyer-Moore 算法。该算法有“坏字符”和“好后缀”两个概念。主要特点是字符串从后往前匹配。 Sunday 算法跟 KMP 算法一样，是从前往后匹配。在匹配失败时，关注文本串中参加匹配的最末位字符的下一位字符，如果该字符不在模式串中，则整个模式串移动到该字符之后。如果该字符在模式串中，将模式串右移使对应的字符对齐。 关于这几种算法的详细介绍，可参考该博客。 下面分别给出暴力匹配、KMP 算法、Boyer-Moore 算法和 Sunday 算法的 Java 实现。 暴力匹配：public static int forceSearch(String txt, String pat) &#123; int M = txt.length(); int N = pat.length(); for (int i = 0; i &lt;= M - N; i++) &#123; int j; for (j = 0; j &lt; N; j++) &#123; if (txt.charAt(i + j) != pat.charAt(j)) break; &#125; if (j == N) return i; &#125; return -1;&#125; KMP 算法：public class KMP &#123; public static int KMPSearch(String txt, String pat, int[] next) &#123; int M = txt.length(); int N = pat.length(); int i = 0; int j = 0; while (i &lt; M &amp;&amp; j &lt; N) &#123; if (j == -1 || txt.charAt(i) == pat.charAt(j)) &#123; i++; j++; &#125; else &#123; j = next[j]; &#125; &#125; if (j == N) return i - j; else return -1; &#125; public static void getNext(String pat, int[] next) &#123; int N = pat.length(); next[0] = -1; int k = -1; int j = 0; while (j &lt; N - 1) &#123; if (k == -1 || pat.charAt(j) == pat.charAt(k)) &#123; ++k; ++j; next[j] = k; &#125; else k = next[k]; &#125; &#125; public static void main(String[] args) &#123; String txt = \"BBC ABCDAB CDABABCDABCDABDE\"; String pat = \"ABCDABD\"; int[] next = new int[pat.length()]; getNext(pat, next); System.out.println(KMPSearch(txt, pat, next)); &#125;&#125; Boyer-Moore 算法public class BoyerMoore &#123; public static void getRight(String pat, int[] right) &#123; for (int i = 0; i &lt; 256; i++)&#123; right[i] = -1; &#125; for (int i = 0; i &lt; pat.length(); i++) &#123; right[pat.charAt(i)] = i; &#125; &#125; public static int BoyerMooreSearch(String txt, String pat, int[] right) &#123; int M = txt.length(); int N = pat.length(); int skip; for (int i = 0; i &lt;= M - N; i += skip) &#123; skip = 0; for (int j = N - 1; j &gt;= 0; j--) &#123; if (pat.charAt(j) != txt.charAt(i + j)) &#123; skip = j - right[txt.charAt(i + j)]; if (skip &lt; 1)&#123; skip = 1; &#125; break; &#125; &#125; if (skip == 0) return i; &#125; return -1; &#125; public static void main(String[] args) &#123; String txt = \"BBC ABCDAB AACDABABCDABCDABDE\"; String pat = \"ABCDABD\"; int[] right = new int[256]; getRight(pat,right); System.out.println(BoyerMooreSearch(txt, pat, right)); &#125;&#125; Sunday算法public class Sunday &#123; public static int getIndex(String pat, Character c) &#123; for (int i = pat.length() - 1; i &gt;= 0; i--) &#123; if (pat.charAt(i) == c) return i; &#125; return -1; &#125; public static int SundaySearch(String txt, String pat) &#123; int M = txt.length(); int N = pat.length(); int i, j; int skip = -1; for (i = 0; i &lt;= M - N; i += skip) &#123; for (j = 0; j &lt; N; j++) &#123; if (txt.charAt(i + j) != pat.charAt(j))&#123; if (i == M - N) break; skip = N - getIndex(pat, txt.charAt(i + N)); break; &#125; &#125; if (j == N) return i; &#125; return -1; &#125; public static void main(String[] args) &#123; String txt = \"BBC ABCDAB AACDABABCDABCDABD\"; String pat = \"ABCDABD\"; System.out.println(SundaySearch(txt, pat)); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"算法","slug":"数据结构与算法/算法","permalink":"http://linbingdong.com/categories/数据结构与算法/算法/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"算法","slug":"算法","permalink":"http://linbingdong.com/tags/算法/"},{"name":"KMP","slug":"KMP","permalink":"http://linbingdong.com/tags/KMP/"},{"name":"Boyer-Moore","slug":"Boyer-Moore","permalink":"http://linbingdong.com/tags/Boyer-Moore/"}]},{"title":"字符流中第一个不重复的字符","slug":"字符流中第一个不重复的字符","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/字符流中第一个不重复的字符/","link":"","permalink":"http://linbingdong.com/2017/03/11/字符流中第一个不重复的字符/","excerpt":"题目描述\n请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个字符“google”时，第一个只出现一次的字符是”l”。 \n分析\n创建一个长度为128的数组charArr[]。用字符的ASCII码作为数组的下标，字符在字符流中的位置作为值。刚开始数组初始化为-1。若该字符未出现过，即charArr[ch] == -1，则令charArr[ch] = index(字符在字符流中的位置)，否则令charArr[ch] = -2。最后只要扫描整个数组，并从中找出最小的大于等于0的值对应的字符即可。\n代码:","text":"题目描述 请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个字符“google”时，第一个只出现一次的字符是”l”。 分析 创建一个长度为128的数组charArr[]。用字符的ASCII码作为数组的下标，字符在字符流中的位置作为值。刚开始数组初始化为-1。若该字符未出现过，即charArr[ch] == -1，则令charArr[ch] = index(字符在字符流中的位置)，否则令charArr[ch] = -2。最后只要扫描整个数组，并从中找出最小的大于等于0的值对应的字符即可。 代码: import java.util.*;public class Solution &#123; int[] charArr = new int[128]; int index = 0; public Solution()&#123; Arrays.fill(charArr,-1); &#125; //Insert one char from stringstream public void Insert(char ch)&#123; if(charArr[ch] == -1) charArr[ch] = index; else charArr[ch] = -2; index++; &#125; //return the first appearence once char in current stringstream public char FirstAppearingOnce()&#123; char ch = '\\0'; int minIndex = Integer.MAX_VALUE; for(int i = 0; i &lt; 128; i++)&#123; if(charArr[i] &gt;= 0 &amp;&amp; charArr[i] &lt; minIndex)&#123; ch = (char)i; minIndex = charArr[i]; &#125; &#125; return ch == '\\0' ? '#' : ch; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"链表中倒数第k个节点","slug":"链表中倒数第k个节点","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/链表中倒数第k个节点/","link":"","permalink":"http://linbingdong.com/2017/03/11/链表中倒数第k个节点/","excerpt":"题目描述\n输入一个链表，输出该链表中倒数第k个结点。\n分析\n两个节点p和q，刚开始都指向头结点。q先走k-1步，然后p、q一起走。当q走到尾节点时，p刚好在倒数第k个结点。\n代码:","text":"题目描述 输入一个链表，输出该链表中倒数第k个结点。 分析 两个节点p和q，刚开始都指向头结点。q先走k-1步，然后p、q一起走。当q走到尾节点时，p刚好在倒数第k个结点。 代码: /*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; if (head == null || k &lt; 1) return null; ListNode p = head,q = head; while (k &gt; 1)&#123; if (q.next != null)&#123; q = q.next; k--; &#125;else&#123; return null; &#125; &#125; while(q.next != null)&#123; p = p.next; q = q.next; &#125; return p; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"左旋转字符串","slug":"左旋转字符串","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/左旋转字符串/","link":"","permalink":"http://linbingdong.com/2017/03/11/左旋转字符串/","excerpt":"题目描述\n汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！\n分析\n确实很简单，一行代码搞定它！\n代码:","text":"题目描述 汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 分析 确实很简单，一行代码搞定它！ 代码: public class Solution &#123; public String LeftRotateString(String str,int n) &#123; return (str.length() &lt; n) ? str : (str.substring(n,str.length()) + str.substring(0,n)); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"PostgreSQL综合","slug":"学习PostgreSQL不可错过的一篇文章","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/学习PostgreSQL不可错过的一篇文章/","link":"","permalink":"http://linbingdong.com/2017/03/11/学习PostgreSQL不可错过的一篇文章/","excerpt":"PostgreSQL是以加州大学伯克利分校计算机系开发的 POSTGRES, Version 4.2为基础的对象关系型数据库管理系统(ORDBMS)。POSTGRES开创的许多概念在很久以后才出现在商业数据库中。","text":"PostgreSQL是以加州大学伯克利分校计算机系开发的 POSTGRES, Version 4.2为基础的对象关系型数据库管理系统(ORDBMS)。POSTGRES开创的许多概念在很久以后才出现在商业数据库中。 1. 简介PostgreSQL是以加州大学伯克利分校计算机系开发的 POSTGRES, Version 4.2为基础的对象关系型数据库管理系统(ORDBMS)。POSTGRES开创的许多概念在很久以后才出现在商业数据库中。 PostgreSQL支持大部分SQL标准并且提供了许多其它现代特性： 复杂查询 外键 触发器 可更新的视图 事务完整性 多版本并发控制 另外，PostgreSQL可以用许多方法进行扩展，比如通过增加新的： 数据类型 函数 操作符 聚合函数 索引方法 过程语言 经过二十几年的发展，PostgreSQL 是目前世界上最先进的开源数据库系统。 2. 体系基本概念PostgreSQL使用常见的客户端/服务器 的模式。一次PostgreSQL会话由下列相关的进程(程序)组成： 服务器进程 它管理数据库文件，接受来自客户端应用与数据库的连接，并且代表客 户端在数据库上执行操作。数据库服务器程序叫postgres。 客户端应用 客户端应用可能本身就是多种多样的：它们可以是一个字符界面的工具，也可以是一个图形界面的应用， 或者是一个通过访问数据库来显示网页的 web 服务器，或者是一个特殊的数据库管理工具。一些客户端应用是和PostgreSQL发布一起提供的，但绝大部分是用户开发的。 PostgreSQL服务器可以处理来自客户端的多个并发连接。 因此，它为每个连接启动(“forks”)一个新的进程。从这个时候开始，客户端和新服务器进程就不再经过最初的postgres进程进行通讯。因此，主服务器总是在运行，等待客户端连接，而客户端及其相关联的服务器进程则是起起停停。 3. 基本使用3.1 常用命令\\l 列出所有数据库 或者： SELECT datname FROM pg_database;\\du 列出所有角色/用户 或者： SELECT rolname FROM pg_roles;\\q 退出数据库\\d 列出当前数据库里的所有表\\dt 列出当前数据库里的所有资料表\\c dbname 切换数据库\\dx 显示安装的插件\\x 切换横向竖向显示show &lt;参数名&gt; 查看该参数的值 3.2 建表CREATE TABLE weather ( city varchar(80), temp_lo int, -- low temperature temp_hi int, -- high temperature prcp real, -- precipitation date date); 3.3 从文本加载数据先在/tmp下创建mydb.txt,内容如下： &apos;shanghai&apos; 20 30 0.07 &apos;2011-11-11&apos;&apos;chengdu&apos; 2 45 0.9 &apos;2008-09-08&apos;&apos;shanghai&apos; 20 30 0.07 &apos;2011-11-11&apos;&apos;chengdu&apos; 2 45 0.9 &apos;2008-09-08&apos; 将mydb.txt里的内容导入weather表中： COPY weather FROM &apos;/tmp/mydb.txt&apos; delimiter &apos; &apos;; --delimiter指定分隔符，txt文件默认分隔符是&apos;\\t&apos;,CSV文件默认分隔符是&apos;,&apos; 此时查看weather表中的数据： select * from weather; 结果： mydb=# select * from weather; city | tmp_lo | tmp_hi | prcp | date------------+--------+--------+------+------------ &apos;shanghai&apos; | 20 | 30 | 0.07 | 2011-11-11 &apos;chengdu&apos; | 2 | 45 | 0.9 | 2008-09-08 &apos;shanghai&apos; | 20 | 30 | 0.07 | 2011-11-11 &apos;chengdu&apos; | 2 | 45 | 0.9 | 2008-09-08(4 行记录) 4. 单机部署在192.168.20.93和192.168.20.94上分别部署了单机版的PostgreSQL。 4.1 安装PostgreSQL源rpm -Uvh http://yum.postgresql.org/9.4/redhat/rhel-7-x86_64/pgdg-centos94-9.4-1.noarch.rpm 4.2 执行安装命令yum updateyum install postgresql94-server postgresql94-contrib 4.3 验证是否安装成功执行： rpm -qa | grep postgres 结果： postgresql94-9.4.10-1PGDG.rhel7.x86_64postgresql94-server-9.4.10-1PGDG.rhel7.x86_64postgresql94-libs-9.4.10-1PGDG.rhel7.x86_64postgresql94-contrib-9.4.10-1PGDG.rhel7.x86_64 说明安装成功 4.4 初始化数据库先创建数据存放目录： mkdir -p /opt/pgsql/data 赋予postgres用户该目录的权限： chown postgres /opt/pgsql/data 切换到postgres用户： su postgres 执行初始化： initdb -D /opt/pgsql/data 注： -D 后面是数据库文件存放的目录，如果不指定则默认在/var/lib/pgsql/9.4/data下 初始化的日志如下： 属于此数据库系统的文件宿主为用户 &quot;postgres&quot;.此用户也必须为服务器进程的宿主.数据库簇将使用本地化语言 &quot;zh_CN.UTF-8&quot;进行初始化.默认的数据库编码已经相应的设置为 &quot;UTF8&quot;.initdb: 无法为本地化语言环境&quot;zh_CN.UTF-8&quot;找到合适的文本搜索配置缺省的文本搜索配置将会被设置到&quot;simple&quot;禁止为数据页生成校验和.修复已存在目录 /opt/pgsql/data 的权限 ... 成功正在创建子目录 ... 成功选择默认最大联接数 (max_connections) ... 100选择默认共享缓冲区大小 (shared_buffers) ... 128MB选择动态共享内存实现 ......posix创建配置文件 ... 成功在 /opt/pgsql/data/base/1 中创建 template1 数据库 ... 成功初始化 pg_authid ... 成功初始化dependencies ... 成功创建系统视图 ... 成功正在加载系统对象描述 ...成功创建(字符集)校对规则 ... 成功创建字符集转换 ... 成功正在创建字典 ... 成功对内建对象设置权限 ... 成功创建信息模式 ... 成功正在装载PL/pgSQL服务器端编程语言...成功清理数据库 template1 ... 成功拷贝 template1 到 template0 ... 成功拷贝 template1 到 template0 ... 成功同步数据到磁盘...成功成功. 您现在可以用下面的命令运行数据库服务器: /usr/pgsql-9.4/bin/postmaster -D /opt/pgsql/data/或者 /usr/pgsql-9.4/bin/pg_ctl -D /opt/pgsql/data/ -l logfile start 4.5 启动服务1.切换到postgres用户 su postgres 因为启动服务同样必须以PostgreSQL用户帐户登录来做。 2.启动服务 没有-D选项，服务器将使用环境变量PGDATA命名的目录； 如果这个环境变量也没有，将导致失败。通常，最好在后台启动postgres，使用下面的 Unix shell 语法： pg_ctl -D /opt/pgsql/data/ -l logfile start 3.设置开机自动启动 在Linux系统里，要么往/etc/rc.d/rc.local或 /etc/rc.local文件里加上下面几行： /usr/local/pgsql/bin/pg_ctl start -l logfile -D /usr/local/pgsql/data 4.6 创建用户PostgreSQL使用角色的概念管理数据库访问权限。 根据角色自身的设置不同，一个角色可以看做是一个数据库用户，或者一组数据库用户。 角色可以拥有数据库对象(比如表)以及可以把这些对象上的权限赋予其它角色， 以控制谁拥有访问哪些对象的权限。另外，我们也可以把一个角色的成员 权限赋予其它角色，这样就允许成员角色使用分配给另一个角色的权限。角色的概念替换了”用户”和”组”。在PostgreSQL 版本 8.1 之前，用户和组是独立类型的记录，但现在它们只是角色。 任何角色都可以是一个用户、一个组、或者两者。 数据库角色从概念上与操作系统用户是完全无关的。在实际使用中把它们对应起来可能比较方便， 但这不是必须的。数据库角色在整个数据库集群中是全局的(而不是每个库不同)。 要创建一个角色，使用 SQL 命令CREATE ROLE执行： CREATE ROLE name; name遵循 SQL 标识的规则：要么完全没有特殊字符， 要么用双引号包围(实际上你通常会给命令增加额外的选项，比如LOGIN。 下面显示更多细节)。要删除一个现有角色，使用类似的DROP ROLE命令： DROP ROLE name; 为了方便，程序createuser和dropuser 提供了对了这些 SQL 命令的封装。我们可以在 shell 命令上直接调用它们： 直接在shell里输入： createuser lbd; 这样就创建了lbd这个角色。 dropuser lbd; 这样就创建了lbd这个角色。 要检查现有角色的集合，可以检查pg_roles系统表，比如： SELECT rolname FROM pg_roles; 结果如下： postgres=# SELECT rolname FROM pg_roles; rolname---------- postgres lbd(2 行记录) psql的元命令\\du也可以用于列出现有角色。 结果如下： postgres=# \\du 角色列表 角色名称 | 属性 | 成员属于---------+----------------------------------+---------- lbd | | &#123;&#125; postgres| 超级用户, 建立角色, 建立 DB, 复制 | &#123;&#125; 5. 主从流复制部署192.168.20.93上部署主服务器，192.168.20.94上部署从服务器。 5.1 简介postgres在9.0之后引入了主从的流复制机制，所谓流复制，就是从服务器通过tcp流从主服务器中同步相应的数据。这样当主服务器数据丢失时从服务器中仍有备份。 与基于文件日志传送相比，流复制允许保持从服务器更新。 从服务器连接主服务器，其产生的流WAL记录到从服务器， 而不需要等待主服务器写完WAL文件。 PostgreSQL流复制默认是异步的。在主服务器上提交事务和从服务器上变化可见之间有一个小的延迟，这个延迟远小于基于文件日志传送，通常1秒能完成。如果主服务器突然崩溃，可能会有少量数据丢失。 同步复制必须等主服务器和从服务器都写完WAL后才能提交事务。这样在一定程度上会增加事务的响应时间。 配置同步复制仅需要一个额外的配置步骤： synchronous_standby_names必须设置为一个非空值。synchronous_commit也必须设置为on。 这里部署的是异步的流复制。 注:主从服务器所在节点的系统、环境\u0001等最好一致。PostgreSQL版本也最好一致，否则可能会有问题。 5.2 安装部署先在192.168.20.93和192.168.20.94均安装PostgreSQL。 具体安装部署步骤见上一节：单机部署 5.2.1 主服务器主服务器为192.168.20.93 先创建一个新目录： mkdir /opt/pgsql/pg_archive 1.首先需要创建一个数据库用户进行主从同步。创建用户replica，并赋予登录和复制的权限。 postgres# CREATE ROLE replica login replication encrypted password &apos;replica&apos; 2.修改pg_hba.conf，允许replica用户来同步。 在pg_hba.conf里增加两行： host all all 192.168.20.94/32 trust #允许94连接到主服务器host replication replica 192.168.20.94/32 md5 #允许94使用replica用户来复制 这样，就设置了replica这个用户可以从192.168.20.93进行流复制请求。 注：第二个字段必须要填replication 4.修改postgresql.conf listen_addresses = &apos;*&apos; # 监听所有IParchive_mode = on # 允许归档archive_command = &apos;cp %p /opt/pgsql/pg_archive/%f&apos; # 用该命令来归档logfile segmentwal_level = hot_standby max_wal_senders = 32 # 这个设置了可以最多有几个流复制连接，差不多有几个从，就设置几个wal_keep_segments = 256 ＃ 设置流复制保留的最多的xlog数目wal_sender_timeout = 60s ＃ 设置流复制主机发送数据的超时时间max_connections = 100 # 这个设置要注意下，从库的max_connections必须要大于主库的 配置完两个文件后重启服务器。 pg_ctl stop -D /opt/pgsql/datapg_ctl start -D /opt/pgsql/data 3.测试94能否连接93数据库。在94上运行如下命令： psql -h 192.168.20.93 -U postgres 看看是否能进入数据库。若可以，则正常。 5.2.2 从服务器1.从主节点拷贝数据到从节点 su - postgresrm -rf /opt/pgsql/data/* #先将data目录下的数据都清空pg_basebackup -h 192.168.20.93 -U replica -D /opt/pgsql/data -X stream -P # 从93拷贝数据到94（基础备份）mkdir /opt/pgsql/pg_archive 2.配置recovery.conf 复制/usr/pgsql-9.4/share/recovery.conf.sample 到 /opt/pgsql/data/recovery.conf cp /usr/pgsql-9.4/share/recovery.conf.sample /opt/pgsql/data/recovery.conf 修改recovery.conf standby_mode = on # 说明该节点是从服务器primary_conninfo = &apos;host=192.168.20.93 port=5432 user=replica password=replica&apos; # 主服务器的信息以及连接的用户recovery_target_timeline = &apos;latest&apos; 3.配置postgresql.conf wal_level = hot_standbymax_connections = 1000 ＃ 一般查多于写的应用从库的最大连接数要比较大hot_standby = on ＃ 说明这台机器不仅仅是用于数据归档，也用于数据查询max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间wal_receiver_status_interval = 10s # 多久向主报告一次从的状态，当然从每次数据复制都会向主报告状态，这里只是设置最长的间隔时间hot_standby_feedback = on # 如果有错误的数据复制，是否向主进行反馈 配置完后重启从服务器 pg_ctl stop -D /opt/pgsql/datapg_ctl start -D /opt/pgsql/data 5.3 验证是否部署成功在主节点上执行： select client_addr,sync_state from pg_stat_replication; 结果如下： postgres=# select client_addr,sync_state from pg_stat_replication; client_addr | sync_state---------------+------------ 192.168.20.94 | async(1 行记录) 说明94是从服务器，在接收流，而且是异步流复制。 此外，还可以分别在主、从节点上运行 ps aux | grep postgres 来查看进程： 主服务器（93）上： postgres 262270 0.0 0.0 337844 2832 ? Ss 10:14 0:00 postgres: wal sender process replica 192.168.20.94(13059) streaming 0/A002A88 可以看到有一个 wal sender 进程。 从服务器（94）上： postgres 569868 0.0 0.0 384604 2960 ? Ss 10:14 0:02 postgres: wal receiver process streaming 0/A002B60 可以看到有一个 wal receiver 进程。 至此，PostgreSQL主从流复制安装部署完成。 在主服务器上插入数据或删除数据，在从服务器上能看到相应的变化。从服务器上只能查询，不能插入或删除。 6. 主要配置1. 连接相关listen_addresses = &apos;*&apos; 数据库用来监听客户端连接的IP地址，*表示监听所有IP。port = 5432 数据库监听户端连接的TCP端口。默认值是5432。max_connections = 100 允许客户端的最大连接数，默认是100，足够了。superuser_reserved_connections = 3 为超级用户保留的连接数，默认为3。2. 资源使用shared_buffers = 128MB 可以被PostgreSQL用于缓存数据的内存大小。大的shared_buffers需要大的checkpoint_segments,同时需要申请更多的System V共享内存资源.这个值不需要设的太大, 因为PostgreSQL还依赖操作系统的cache来提高读性能。另外, 写操作频繁的数据库这个设太大反而会增加checkpoint压力(除非你使用了SSD或者IOPS能力很好的存储).work_mem = 4MB 内部排序和哈希操作可使用的工作内存大小。maintenance_work_mem = 64MB 这里定义的内存只是在CREATE INDEX, VACUUM等时用到。这个值越大, VACUUM, CREATE INDEX的操作越快, 当然大到一定程度瓶颈就不在内存了, 可能是CPU例如创建索引.这个值是一个操作的内存使用上限, 而不是一次性分配出去的. 并且需要注意如果开启了autovacuum, 最大可能有autovacuum_max_workers*maintenance_work_mem的内存被系统消耗掉.3. WALwal_level = hot_standby 如果需要做数据库WAL日志备份的话至少需要设置成archive级别, 如果需要做hot_standby那么需要设置成hot_standby。hot_standby意味着WAL记录得更详细, 如果没有打算做hot_standby设置得越低性能越好。fsync = on 强制把数据同步更新到磁盘wal_buffers = -1 默认是-1 根据shared_buffers的设置自动调整shared_buffers*3% .最大限制是XLOG的segment_size.checkpoint_segments = 3 多少个xlog file产生后开始checkpoint操作。建议设置为shared_buffers除以单个XLOG文件的大小。checkpoint_timeout = 5min 这个和checkpoint_segments的效果是一样的, 只是触发的条件是时间条件。archive_mode = on 允许归档。archive_command = &apos;cp %p /opt/pgsql/pg_archive/%f&apos; 归档调用的命令。4. 主从复制## postgresql.confmax_wal_senders = 32 最大的wal sender进程数。hot_standby = on 在从服务器上设置为 on ，则该服务器也可用作查询。max_standby_streaming_delay = 30s 数据流备份的最大延迟时间。wal_receiver_status_interval = 10s 多久向主报告一次从的状态，当然从每次数据复制都会向主报告状态，这里只是设置最长的间隔时间。hot_standby_feedback = on 如果有错误的数据复制，是否向主进行反馈。## recovery.conf（只有从服务器需要配置）standby_mode = on 说明该节点是从服务器primary_conninfo = &apos;host=192.168.20.93 port=5432 user=replica password=replica&apos; 主服务器的信息以及连接的用户recovery_target_timeline = &apos;latest&apos;5. 内核资源max_files_per_process = 1000 设定每个数据库进程能够打开的文件的数目。默认值是1000。shared_preload_libraries = &apos;&apos; 设置数据库在启动时要加载的操作系统共享库文件。如果有多个库文件，名字用逗号分开。如果数据库在启动时未找到shared_preload_libraries指定的某个库文件，数据库将无法启动。默认值为空串。6. AUTOVACUUM参数autovacuum = on 是否打开数据库的自动垃圾收集功能。默认值是on。如果autovacuum被设为on，参数track_counts也要被设为on，自动垃圾收集才能正常工作。注意，即使这个参数被设为off，如果事务ID回绕即将发生，数据库会自动启动一个垃圾收集操作。这个参数只能在文件postgresql.conf中被设置。log_autovacuum_min_duration = -1 单位是毫秒。如果它的值为0，所有的垃圾搜集操作都会被记录在数据库运行日志中，如果它的值是-1，所有的垃圾收集操作都不会被记录在数据库运行日志中。如果把它的值设为250毫秒，只要自动垃圾搜集发出的VACUUM和ANALYZE命令的执行时间超过250毫秒，VACUUM和ANALYZE命令的相关信息就会被记录在数据库运行日志中。默认值是-1。autovacuum_max_workers = 3 设置能同时运行的最大的自动垃圾收集工作进程的数目。默认值是3。autovacuum_naptime = 1min 设置自动垃圾收集控制进程的睡眠时间。autovacuum_vacuum_threshold = 50 设置触发垃圾收集操作的阈值。默认值是50。只有一个表上被删除或更新的记录的数目超过了autovacuum_vacuum_threshold的值，才会对这个表执行垃圾收集操作。7. 文件位置data_directory = &apos;/opt/pgsql/data&apos; 数据存放位置，初始化时可以指定，也可以在这里修改。hba_file = &apos;/opt/pgsql/data/pg_hba.conf&apos; 主从复制配置文件pg_hba.conf的路径ident_file = /opt/pgsql/data/pg_ident.conf&apos; 配置文件pg_ident.conf的路径8. 编码lc_messages = &apos;zh_CN.UTF-8&apos; 系统错误信息的语言环境lc_monetary = &apos;zh_CN.UTF-8&apos; 货币格式的语言环境lc_numeric = &apos;zh_CN.UTF-8&apos; 数字的语言环境lc_time = &apos;zh_CN.UTF-8&apos; 时间的语言环境 7. 插件（扩展）PostgreSQL的contrib/目录和extension/目录附带包含若干插件的源代码。 在附录 F中被描述。其它插件是独立开发的， 比如PostGIS。 甚至PostgreSQL的复制方案也是在外部开发的。 比如 Slony-I 是一个流行的主/从复制方案，它就是独立在核心项目之外开发的。 PostgreSQL的插件主要用来提供新的用户自定义函数，操作符，或类型。 若要使用插件，需要在数据库系统中注册新的SQL对象。（如果该插件没有在contrib或extension目录下，需要先自己安装，或者在编译源码的时候指定。） 在PostgreSQL 9.1和以后版本，这是通过执行 CREATE EXTENSION命令来实现。 CREATE EXTENSION module_name 此命令必须由数据库管理员运行。如想在某个数据库中使用该插件，则必须在该数据库中运行如上命令。另外， 在数据库template1中运行它，这样在随后创建的数据库中也可使用该插件。 具体插件的安装使用请参考下一节：PostGIS插件安装与使用 8. PostGIS插件安装与使用8.1 简介PostGIS是对象关系型数据库PostgreSQL的一个插件，PostGIS提供如下空间信息服务功能：空间对象、空间索引、空间操作函数和空间操作符。同时，PostGIS遵循OpenGIS的规范。 PostGIS支持所有的空间数据类型，这些类型包括：点（POINT）、线（LINESTRING）、多边形（POLYGON）、多点 （MULTIPOINT）、多线（MULTILINESTRING）、多多边形（MULTIPOLYGON）和集合对象集 （GEOMETRYCOLLECTION）等。PostGIS支持所有的对象表达方法，比如WKT和WKB。 PostGIS支持所有的数据存取和构造方法，如GeomFromText()、AsBinary()，以及GeometryN()等。 PostGIS提供简单的空间分析函数（如Area和Length）同时也提供其他一些具有复杂分析功能的函数，比如Distance。 PostGIS提供了对于元数据的支持，如GEOMETRY_COLUMNS和SPATIAL_REF_SYS，同时，PostGIS也提供了相应的支持函数，如AddGeometryColumn和DropGeometryColumn。 PostGIS提供了一系列的二元谓词（如Contains、Within、Overlaps和Touches）用于检测空间对象之间的空间关系，同时返回布尔值来表征对象之间符合这个关系。 PostGIS提供了空间操作符（如Union和Difference）用于空间数据操作。比如，Union操作符融合多边形之间的边界。两个交迭的多边形通过Union运算就会形成一个新的多边形，这个新的多边形的边界为两个多边形中最大边界。 PostGIS还提供以下功能： 数据库坐标变换 数据库中的几何类型可以通过Transform函数从一种投影系变换到另一种投影系中。在OpenGIS中的几何类型都将SRID作为自身结构的一部分，但不知什么原因，在OpenGIS的SFSQL规范中，并没有引入Transform。 球体长度运算 存储在普通地理坐标系中的集合类型如果不进行坐标变换是无法进行程度运算的，OpenGIS所提供的坐标变换使得积累类型的程度计算变成可能。 三维的几何类型 SFSQL规范只是针对二维集合类型。OpenGIS提供了对三维集合类型的支持，具体是利用输入的集合类型维数来决定输出的表现方式。例如，即便 所有几何对象内部都以三维形式存储，纯粹的二维交叉点通常还是以二维的形式返回。此外，还提供几何对象在不同维度间转换的功能。 空间聚集函数 在数据库中，聚集函数是一个执行某一属性列所有数据操作的函数。比如Sum和Average，Sum是求某一关系属性列的数据总和，Average 则是求取某一关系属性列的数据平均值。与此对应，空间聚集函数也是执行相同的操作，不过操作的对象是空间数据。例如聚集函数Extent返回一系列要素中 的最大的包裹矩形框，如“SELECT EXTENT(GEOM) FROM ROADS”这条SQL语句的执行结果是返回ROADS这个数据表中所有的包裹矩形框。 栅格数据类型 PostGIS通过一种新的数据类型片，提供对于大的栅格数据对象的存储。片由以下几个部分组成：包裹矩形框、SRID、类型和一个字节序列。通过 将片的大小控制在数据库页值（32×32）以下，使得快速的随即访问变成可能。一般大的图片也是通过将其切成32×32像素的片然后再存储在数据库中的。 8.2 部署8.2.1 安装PostGIS yum install postgis2_94 # 因为安装的PostgreSQL版本为9.4，所以是postgis2_94 注： 需要PostgreSQL9.1以上版本才支持PostGIS. 8.2.2 使PostGIS可用想要在PostgreSQL中使用PostGIS插件，安装只是第一步。每个数据库想要使用PostGIS必须先在该数据库中使PostGIS可用。假设我们想在gisdb这个数据库中使用PostGIS,先进入gisdb数据库，执行以下步骤： gisdb=# CREATE EXTENSION postgis;gisdb=# CREATE EXTENSION postgis_topology; 8.2.3 查看是否安装成功 在gisdb数据库中输入\\du，查看已安装的插件 gisdb=# \\dx 已安装扩展列表 名称 | 版本 | 架构模式 | 描述------------------+-------+------------+--------------------------------------------------------------------- plpgsql | 1.0 | pg_catalog | PL/pgSQL procedural language postgis | 2.1.8 | public | PostGIS geometry, geography, and raster spatial types and functions postgis_topology | 2.1.8 | topology | PostGIS topology spatial types and functions(3 行记录) 可以看到已经安装了postgis和postgis_topology。 8.3 使用8.3.1 创建空间数据表首先建立一个常规的表格存储有关城市（cities）的信息。这个表格有两栏，一个是 ID 编号，一个是城市名： gisdb=# CREATE TABLE cities (id int4, name varchar(50)); 现在添加一个空间列用于存储城市的位置。习惯上这个列叫做 the_geom。它记录了数据为什么类型（点、线、面）、有几维（这里是二维）以及空间坐标系统。此处使用 EPSG:4326 坐标系统： gisdb=# SELECT AddGeometryColumn (&apos;cities&apos;, &apos;the_geom&apos;, 4326, &apos;POINT&apos;, 2); 完成后，查询 cities 表单应当显示这个新栏目。同时页面将显示当前表达没有记录（0 rows）。 gisdb=# select * from cities; id | name | the_geom----+-----------------+----------------------------------------------------（0行记录） 为添加记录，需要使用 SQL 命令。对于空间列，使用 PostGIS 的 ST_GeomFromText可以将文本转化为坐标与参考系号的记录： gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (1,ST_GeomFromText(&apos;POINT(-0.1257 51.508)&apos;,4326),&apos;London, England&apos;);gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (2,ST_GeomFromText(&apos;POINT(-81.233 42.983)&apos;,4326),&apos;London, Ontario&apos;);gisdb=# INSERT INTO cities (id, the_geom, name) VALUES (3,ST_GeomFromText(&apos;POINT(27.91162491 -33.01529)&apos;,4326),&apos;East London,SA&apos;); 当然，这样的输入方式难以操作。其它方式可以更快的输入数据。就目前来说，表格内已经有了一些城市数据，可以先进行查询等操作。 8.3.2 简单查询标准的 SQL 操作都可以用于 PostGIS 表： gisdb=# SELECT * FROM cities; id | name | the_geom----+-----------------+---------------------------------------------------- 1 | London, England | 0101000020E6100000BBB88D06F016C0BF1B2FDD2406C14940 2 | London, Ontario | 0101000020E6100000F4FDD478E94E54C0E7FBA9F1D27D4540 3 | East London,SA | 0101000020E610000040AB064060E93B4059FAD005F58140C0(3 行记录) 这里的坐标是无法阅读的 16 进制格式。要以 WKT 文本显示，使用 ST_AsText(the_geom) 或ST_AsEwkt(the_geom) 函数。也可以使用 ST_X(the_geom) 和 ST_Y(the_geom) 显示一个维度的坐标： gisdb=# SELECT id, ST_AsText(the_geom), ST_AsEwkt(the_geom), ST_X(the_geom), ST_Y(the_geom) FROM cities; id | st_astext | st_asewkt | st_x | st_y----+------------------------------+----------------------------------------+-------------+----------- 1 | POINT(-0.1257 51.508) | SRID=4326;POINT(-0.1257 51.508) | -0.1257 | 51.508 2 | POINT(-81.233 42.983) | SRID=4326;POINT(-81.233 42.983) | -81.233 | 42.983 3 | POINT(27.91162491 -33.01529) | SRID=4326;POINT(27.91162491 -33.01529) | 27.91162491 | -33.01529(3 行记录) 8.3.3 空间查询PostGIS 为 PostgreSQL 扩展了许多空间操作功能。以上已经涉及了转换空间坐标格式的 ST_GeomFromText 。多数空间操作以 ST（spatial type）开头，在 PostGIS 文档相应章节有罗列。这里回答一个具体的问题：上面三个城市相互的距离是多少？查询语句怎么写？ gisdb=# SELECT p1.name,p2.name,ST_Distance_Sphere(p1.the_geom,p2.the_geom) FROM cities AS p1, cities AS p2 WHERE p1.id &gt; p2.id; name | name | st_distance_sphere-----------------+-----------------+-------------------- London, Ontario | London, England | 5875787.03777356 East London,SA | London, England | 9789680.59961472 East London,SA | London, Ontario | 13892208.6782928(3 行记录) 输出显示了距离数据。注意 ‘WHERE’ 部分防止了输出城市到自身的距离（0）或者两个城市不同排列的距离数据（London, England 到 London, Ontario 和 London, Ontario 到 London, England 的距离是一样的）。 9. 参考资料 https://www.postgresql.org/ http://www.postgres.cn/docs/9.4/index.html http://www.cnblogs.com/yjf512/p/4499547.html https://yq.aliyun.com/articles/63183?spm=5176.100240.searchblog.173.aJC9Fo https://yq.aliyun.com/articles/214?spm=5176.100240.searchblog.66.iduww3 http://postgis.net/install/ http://www.cnblogs.com/zhaowenzhong/p/5667434.html http://wiki.clusterlabs.org/wiki/PgSQL_Replicated_Cluster?spm=5176.100239.blogcont64841.22.H7WZ3U","raw":null,"content":null,"categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/categories/PostgreSQL/"}],"tags":[{"name":"关系数据库","slug":"关系数据库","permalink":"http://linbingdong.com/tags/关系数据库/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://linbingdong.com/tags/PostgreSQL/"}]},{"title":"跳台阶","slug":"跳台阶","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/跳台阶/","link":"","permalink":"http://linbingdong.com/2017/03/11/跳台阶/","excerpt":"一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n分析\n其实这题跟斐波那契数列那题一模一样。这里用递归搞定就好。\n代码:","text":"一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 分析 其实这题跟斐波那契数列那题一模一样。这里用递归搞定就好。 代码: public class Solution &#123; public int JumpFloor(int target) &#123; if(target &lt;= 2) return target; return JumpFloor(target - 1) + JumpFloor(target - 2); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"调整数组顺序使奇数在偶数前面（相对位置不变）","slug":"调整数组顺序使奇数在偶数前面（相对位置不变）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/调整数组顺序使奇数在偶数前面（相对位置不变）/","link":"","permalink":"http://linbingdong.com/2017/03/11/调整数组顺序使奇数在偶数前面（相对位置不变）/","excerpt":"题目描述\n输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。\n分析\n新建一个数组，对原数组做两个for循环。第一次将奇数写入新数组，第二次将偶数写入新数组。最后将新数组拷贝到原数组。\n代码:","text":"题目描述 输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 分析 新建一个数组，对原数组做两个for循环。第一次将奇数写入新数组，第二次将偶数写入新数组。最后将新数组拷贝到原数组。 代码: public class Solution &#123; public void reOrderArray(int [] array) &#123; int len = array.length; int j = 0; int[] arr = new int[len]; for(int i = 0; i &lt; len; i++)&#123; if(array[i] % 2 == 1)&#123; arr[j++] = array[i]; &#125; &#125; for(int i = 0; i &lt; len; i++)&#123; if(array[i] % 2 == 0)&#123; arr[j++] = array[i]; &#125; &#125; System.arraycopy(arr,0,array,0,len); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Hadoop YARN介绍","slug":"Hadoop YARN介绍","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Hadoop YARN介绍/","link":"","permalink":"http://linbingdong.com/2017/03/11/Hadoop YARN介绍/","excerpt":"YARN是Hadoop集群的资源管理系统。Hadoop2.0对MapReduce框架做了彻底的设计重构。YARN的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源管理器ResourceManager和每个应用程序特有的ApplicationMaster。其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。","text":"YARN是Hadoop集群的资源管理系统。Hadoop2.0对MapReduce框架做了彻底的设计重构。YARN的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源管理器ResourceManager和每个应用程序特有的ApplicationMaster。其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。 YARN产生背景MRv1的局限YARN是在MRv1基础上演化而来的，它克服了MRv1中的各种局限性。在正式介绍YARN之前，先了解下MRv1的一些局限性，主要有以下几个方面： 扩展性差。在MRv1中，JobTracker同时兼备了资源管理和作业控制两个功能，这成为系统的一个最大瓶颈，严重制约了Hadoop集群扩展性。 可靠性差。MRv1采用了master/slave结构，其中，master存在单点故障问题，一旦它出现故障将导致整个集群不可用。 资源利用率低。MRv1采用了基于槽位的资源分配模型，槽位是一种粗粒度的资源划分单位，通常一个任务不会用完槽位对应的资源，且其他任务也无法使用这些空闲资源。此外，Hadoop将槽位分为Map Slot和Reduce Slot两种，且不允许它们之间共享，常常会导致一种槽位资源紧张而另外一种闲置（比如一个作业刚刚提交时，只会运行Map Task，此时Reduce Slot闲置）。 无法支持多种计算框架。随着互联网高速发展，MapReduce这种基于磁盘的离线计算框架已经不能满足应用要求，从而出现了一些新的计算框架，包括内存计算框架、流式计算框架和迭代式计算框架等，而MRv1不能支持多种计算框架并存。 为了克服以上几个缺点，Apache开始尝试对Hadoop进行升级改造，进而诞生了更加先进的下一代MapReduce计算框架MRv2。正是由于MRv2将资源管理功能抽象成了一个独立的通用系统YARN，直接导致下一代MapReduce的核心从单一的计算框架MapReduce转移为通用的资源管理系统YARN。 集群资源统一管理随着互联网的高速发展，新的计算框架不断出现，从支持离线处理的MapReduce，到支持在线处理的Storm，从迭代式计算框架Spark到流式处理框架S4，各种框架各有所长，各自解决了某一类应用问题。这时候就需要一个组件对同一个集群上的不同计算框架进行资源的统一管理。 相比于“一种计算框架一个集群”的模式，共享集群的模式存在多种好处： 资源利用率高。如果每个框架一个集群，可能在某段时间内，有些计算框架的集群资源紧张，而另外一些集群资源空闲。共享集群模式则通过多种框架共享资源，使得集群中的资源得到更加充分的利用。 运维成本低。如果采用“一个框架一个集群”的模式，则可能需要多个管理员管理这些集群，进而增加运维成本，而共享模式通常需要少数管理员即可完成多个框架的统一管理。 数据共享。随着数据量的暴增，跨集群间的数据移动不仅需花费更长的时间，且硬件成本也会大大增加，而共享集群模式可让多种框架共享数据和硬件资源，将大大减小数据移动带来的成本。 YARN基本设计思想MRv1主要由编程模型、数据处理引擎（由Map Task和Reduce Task组成）和运行时环境三部分组成。为了保证编程模型的向后兼容性，MRv2重用了MRv1中的编程模型和数据处理引擎，但运行时环境被完全重写。 MRv1的运行时环境主要由两类服务组成，分别是JobTracker和TaskTracker。其中，JobTracker负责资源管理和作业控制。TaskTracker负责单个节点的资源管理和任务执行。 MRv1将资源管理和应用程序管理两部分混杂在一起，使得它在扩展性、容错性和多框架支持等方面存在明显缺陷。 而MRv2则通过将资源管理和应用程序管理两部分剥离开，分别由ResourceManager和ApplicationMaster负责，其中ResourceManager专管资源管理和调度，而ApplicationMaster则负责与具体应用程序相关的任务切分、任务调度和容错等，具体如下图所示。 YARN基本架构YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源管理器ResourceManager和每个应用程序特有的ApplicationMaster。其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。 YARN总体上仍然是Master/Slave结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。 下图描述了YARN的基本组成结构，YARN主要由ResourceManager、NodeManager、ApplicationMaster（图中给出了MapReduce和MPI两种计算框架的ApplicationMaster，分别为MR AppMstr和MPI AppMstr）和Container等几个组件构成。 接下来对YARN里几个重要的组件一一介绍。 1. ResourceManager(RM)RM是一个全局的资源管理器,负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。 （1）调度器（分配Container） 调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。 （2）应用程序管理器 应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。 2. ApplicationMaster（AM）用户提交的每个应用程序均包含一个AM，主要功能包括： 与RM调度器协商以获取资源（以Container表示） 将得到的任务进一步分配给内部的任务 与NM通信以启动/停止任务 监控所有任务运行状态，并在任务失败时重新为任务申请资源以重启任务 3. NodeManager（NM）NM是每个节点上的资源和任务管理器。一方面，它定时地向RM汇报本节点的资源使用情况和Container运行状态；另一方面，它接受并处理来自AM的Container启动/停止等各种请求。 4. ContainerContainer是YARN中的资源抽象，它封装了某个节点上的多维资源，如CPU、内存、磁盘、网络等。当AM向RM申请资源时，RM向AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。Container是一个动态资源划分单位，是根据应用程序的需求自动生成的。目前，YARN仅支持CPU和内存两种资源。 YARN工作流程运行在YARN上的应用程序主要分为两类：短应用程序和长应用程序。其中，短应用程序是指一定时间内可运行完成并正常退出的应用程序，如MapReduce作业、Spark DAG作业等。长应用程序是指不出意外，永不终止运行的应用程序，通常是一些服务，比如Storm Service（包括Nimbus和Supervisor两类服务），HBase Service（包括HMaster和RegionServer两类服务）等，而它们本身作为一种框架提供编程接口供用户使用。尽管这两类应用程序作业不同，一类直接运行数据处理程序，一类用于部署服务（服务之上再运行数据处理程序），但运行在YARN上的流程是相同的。 当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：第一阶段是启动ApplicationMaster。第二阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。具体如下： 用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。 ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。 ApplicationMaster首先向ResourceManager注册，这样用户就可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。 ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。 一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。 NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。 各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。 应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。","raw":null,"content":null,"categories":[{"name":"YARN","slug":"YARN","permalink":"http://linbingdong.com/categories/YARN/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"YARN","slug":"YARN","permalink":"http://linbingdong.com/tags/YARN/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://linbingdong.com/tags/Hadoop/"},{"name":"资源管理","slug":"资源管理","permalink":"http://linbingdong.com/tags/资源管理/"}]},{"title":"设计模式-观察者模式","slug":"设计模式-观察者模式","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/设计模式-观察者模式/","link":"","permalink":"http://linbingdong.com/2017/03/11/设计模式-观察者模式/","excerpt":"观察者模式又叫发布/订阅模式。","text":"观察者模式又叫发布/订阅模式。 定义观察者模式定义了对象之间的一对多依赖，使得当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。观察者模式又叫发布/订阅模式。 角色 抽象主题（Subject）：它把所有观察者对象的引用保存到一个列表里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象。 具体主题（ConcreteSubject）：将有关状态存入具体观察者对象；在具体主题内部状态改变时，给所有登记过的观察者发出通知。 抽象观察者（Observer）：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。 具体观察者（ConcreteObserver）：实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题状态协调。 类图 示例以猎头-求职者为例。猎头是主题，求职者是观察者。 Subject 接口 public interface Subject &#123; public void registerObserver(Observer o); public void removeObserver(Observer o); public void notifyAllObservers();&#125; Observer 接口 public interface Observer &#123; public void update(Subject s);&#125; HeadHunter 类实现 Subject 接口 import java.util.LinkedList;public class HeadHunter implements Subject &#123; private LinkedList&lt;Observer&gt; userList; private LinkedList&lt;String&gt; jobs; public HeadHunter() &#123; userList = new LinkedList&lt;Observer&gt;(); jobs = new LinkedList&lt;String&gt;(); &#125; @Override public void registerObserver(Observer o) &#123; userList.add(o); &#125; @Override public void removeObserver(Observer o) &#123; userList.remove(o); &#125; @Override public void notifyAllObservers() &#123; for (Observer o: userList) &#123; o.update(this); &#125; &#125; public void addJob(String job) &#123; jobs.add(job); notifyAllObservers(); &#125; public LinkedList&lt;String&gt; getJobs() &#123; return jobs; &#125; public String toString() &#123; return jobs.toString(); &#125;&#125; JobSeeker 类实现 Observer 接口 public class JobSeeker implements Observer &#123; private String name; public JobSeeker(String name) &#123; this.name = name; &#125; @Override public void update(Subject s) &#123; System.out.println(this.name + \" got notified!\"); System.out.println(s); &#125;&#125; 测试 public class Main &#123; public static void main(String[] args) &#123; HeadHunter hh = new HeadHunter(); JobSeeker lbd = new JobSeeker(\"lbd\"); JobSeeker lbx = new JobSeeker(\"lbx\"); JobSeeker lbn = new JobSeeker(\"lbn\"); JobSeeker lbb = new JobSeeker(\"lbb\"); hh.registerObserver(lbd); hh.registerObserver(lbx); hh.registerObserver(lbn); hh.registerObserver(lbb); hh.removeObserver(lbb); hh.addJob(\"looking for Java engineers\"); hh.addJob(\"looking for Python engineers\"); &#125;&#125; 输出 lbd got notified![looking for Java engineers]lbx got notified![looking for Java engineers]lbn got notified![looking for Java engineers]lbd got notified![looking for Java engineers, looking for Python engineers]lbx got notified![looking for Java engineers, looking for Python engineers]lbn got notified![looking for Java engineers, looking for Python engineers] 总结观察者模式使主题和观察者之间松耦合，松耦合的设计能够让我们建立有弹性的OO系统，能够应对变化，因为对象之间的相互依赖降到了最低。 其他 上面的例子是观察者模式的“推”模式，还有一种“拉”模式。 Java 的 java.util 库里面，提供了一个 Observable 类以及一个 Observer 接口，构成 Java 语言对观察者模式的支持。","raw":null,"content":null,"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://linbingdong.com/categories/设计模式/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://linbingdong.com/tags/设计模式/"}]},{"title":"把数组排成最小的数","slug":"把数组排成最小的数","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/把数组排成最小的数/","link":"","permalink":"http://linbingdong.com/2017/03/11/把数组排成最小的数/","excerpt":"题目描述\n输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。\n分析\n先将整型数组转换成String数组，然后将String数组排序，最后将排好序的字符串数组拼接出来。关键就是制定排序规则。\n排序规则如下：若ab &gt; ba 则 a &gt; b，若ab &lt; ba 则 a &lt; b，若ab = ba 则 a = b；\n解释说明：比如 “3” &lt; “31”但是 “331” &gt; “313”，所以要将二者拼接起来进行比较\n代码:","text":"题目描述 输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 分析 先将整型数组转换成String数组，然后将String数组排序，最后将排好序的字符串数组拼接出来。关键就是制定排序规则。 排序规则如下：若ab &gt; ba 则 a &gt; b，若ab &lt; ba 则 a &lt; b，若ab = ba 则 a = b； 解释说明：比如 “3” &lt; “31”但是 “331” &gt; “313”，所以要将二者拼接起来进行比较 代码: import java.util.ArrayList;import java.util.Comparator;import java.util.Collections;public class Solution &#123; public String PrintMinNumber(int [] numbers) &#123; String result = \"\"; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int i = 0; i &lt; numbers.length; i++) list.add(numbers[i]); Collections.sort(list,new Comparator&lt;Integer&gt;()&#123; @Override public int compare(Integer str1,Integer str2)&#123; //制定排序规则 String s1 = str1 + \"\" + str2; String s2 = str2 + \"\" + str1; return s1.compareTo(s2); &#125; &#125;); for(Integer i : list) result += i; //拼接 return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"数值的整数次方","slug":"数值的整数次方","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/数值的整数次方/","link":"","permalink":"http://linbingdong.com/2017/03/11/数值的整数次方/","excerpt":"题目描述\n给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。\n分析\n题目比较简单，主要注意指数是负数的情况。\n代码:","text":"题目描述 给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 分析 题目比较简单，主要注意指数是负数的情况。 代码: public class Solution &#123; public double Power(double base, int exponent) &#123; int x = Math.abs(exponent); double result = 1; while (x &gt; 0)&#123; result *= base; x--; &#125; if (exponent &lt; 0) return 1 / result; else return result; &#125;&#125; 如果调用Math.pow()方法，可以一行代码搞定。 public class Solution &#123; public double Power(double base, int exponent) &#123; return exponent &lt; 0 ? 1 / Math.pow(base, -exponent) : Math.pow(base, exponent); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"计算糖果","slug":"计算糖果","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/计算糖果/","link":"","permalink":"http://linbingdong.com/2017/03/11/计算糖果/","excerpt":"A,B,C三个人是好朋友,每个人手里都有一些糖果,我们不知道他们每个人手上具体有多少个糖果,但是我们知道以下的信息：A - B, B - C, A + B, B + C. 这四个数值.每个字母代表每个人所拥有的糖果数.现在需要通过这四个数值计算出每个人手里有多少个糖果,即A,B,C。这里保证最多只有一组整数A,B,C满足所有题设条件。 ","text":"A,B,C三个人是好朋友,每个人手里都有一些糖果,我们不知道他们每个人手上具体有多少个糖果,但是我们知道以下的信息：A - B, B - C, A + B, B + C. 这四个数值.每个字母代表每个人所拥有的糖果数.现在需要通过这四个数值计算出每个人手里有多少个糖果,即A,B,C。这里保证最多只有一组整数A,B,C满足所有题设条件。 输入描述: 输入为一行，一共4个整数，分别为A - B，B - C，A + B，B + C，用空格隔开。范围均在-30到30之间(闭区间)。 输出描述: 输出为一行，如果存在满足的整数A，B，C则按顺序输出A，B，C，用空格隔开，行末无空格。如果不存在这样的整数A，B，C，则输出No 输入例子: 1 -2 3 4 输出例子: 2 1 3 代码: import java.util.Scanner; /** * Created by lbd on 2016/10/27. */public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int x1,x2,x3,x4; float a,b,c; while (sc.hasNext()) &#123; x1 = sc.nextInt(); x2 = sc.nextInt(); x3 = sc.nextInt(); x4 = sc.nextInt(); a = (x3+x1)/2; b = (x3-x1)/2; c = (x4-x2)/2; if (a - (x3+x1)/2 !=0 || b - (x3-x1)/2 !=0 || c - (x4-x2)/2 !=0 || b - (x4+x2)/2 !=0 )&#123; System.out.println(\"No\"); &#125; else &#123; System.out.println((int)a + \" \" + (int)b + \" \" + (int)c); &#125; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"表示数值的字符串","slug":"表示数值的字符串","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/表示数值的字符串/","link":"","permalink":"http://linbingdong.com/2017/03/11/表示数值的字符串/","excerpt":"题目描述\n请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。\n分析\n用正则表达式,一行搞定。\n代码:","text":"题目描述 请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 分析 用正则表达式,一行搞定。 代码: public class Solution &#123; public boolean isNumeric(char[] str) &#123; return String.valueOf(str).matches(\"[\\\\+-]?\\\\d*(\\\\.\\\\d+)?([eE][\\\\+-]?\\\\d+)?\"); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"数组中出现次数超过一半的数字","slug":"数组中出现次数超过一半的数字","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/数组中出现次数超过一半的数字/","link":"","permalink":"http://linbingdong.com/2017/03/11/数组中出现次数超过一半的数字/","excerpt":"数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。\n分析\n用HashMap，key为数组中的数字，value为该数字在数组中出现的次数。边put边计算当前该数字的次数，若超过数组长度的一半直接返回。最后返回0。\n代码:","text":"数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 分析 用HashMap，key为数组中的数字，value为该数字在数组中出现的次数。边put边计算当前该数字的次数，若超过数组长度的一半直接返回。最后返回0。 代码: import java.util.HashMap;public class Solution &#123; public int MoreThanHalfNum_Solution(int [] array) &#123; HashMap&lt;Integer,Integer&gt; hm = new HashMap&lt;Integer,Integer&gt;(); for(int i = 0; i &lt; array.length; i++)&#123; Integer value = hm.get(array[i]); if(value == null)&#123; hm.put(array[i],1); value = 1; &#125; else&#123; hm.put(array[i],value+1); &#125; if(value+1&gt;array.length/2) return array[i]; &#125; return 0; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"数组中只出现一次的数字II","slug":"数组中只出现一次的数字II","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/数组中只出现一次的数字II/","link":"","permalink":"http://linbingdong.com/2017/03/11/数组中只出现一次的数字II/","excerpt":"题目描述\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n分析\n本题是有两个未知数，是”Single Number”这道题的扩展，直接做异或肯定是不行的。有没有办法把两个未知数分开，使得可以分别应用Single Number的解法呢?设x,y是那两个未知数，那么如果对这个数组做异或的话，结果实质上等于x^y，因为其他数都出现了两次，被抵消了。但是仅仅是通过最后异或出来的值，是没办法区分出x和y的，但是足以帮助我们把 x和y划分到不同的子数组中去。\n代码:","text":"题目描述 一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。 分析 本题是有两个未知数，是”Single Number”这道题的扩展，直接做异或肯定是不行的。有没有办法把两个未知数分开，使得可以分别应用Single Number的解法呢?设x,y是那两个未知数，那么如果对这个数组做异或的话，结果实质上等于x^y，因为其他数都出现了两次，被抵消了。但是仅仅是通过最后异或出来的值，是没办法区分出x和y的，但是足以帮助我们把 x和y划分到不同的子数组中去。 代码: //num1,num2分别为长度为1的数组。传出参数//将num1[0],num2[0]设置为返回结果public class Solution &#123; public void FindNumsAppearOnce(int[] array,int num1[] , int num2[]) &#123; int xorresult = 0; int flag = 1; for (Integer i : array)&#123; xorresult ^= i; &#125; while ((xorresult &amp; flag) == 0) flag &lt;&lt;= 1; //找出x和y第一个不同的二进制位 for (Integer i : array)&#123; //把x和y划分到不同的子数组中，然后分别用异或。 if ((i &amp; flag) == 0) num2[0] ^= i; else num1[0] ^= i; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"数组中重复的数字","slug":"数组中重复的数字","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/数组中重复的数字/","link":"","permalink":"http://linbingdong.com/2017/03/11/数组中重复的数字/","excerpt":"题目描述\n在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是重复的数字2或者3。\n分析\n新建一个boolean数组arr，遍历numbers数组，并令arr[numbers[i]] = true。如果arr[numbers[i]] == true，说明numbers[i]重复了。\n代码:","text":"题目描述 在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是重复的数字2或者3。 分析 新建一个boolean数组arr，遍历numbers数组，并令arr[numbers[i]] = true。如果arr[numbers[i]] == true，说明numbers[i]重复了。 代码: public class Solution &#123; // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number,length of duplication array is 1,so using duplication[0] = ? in implementation; // Here duplication like pointor in C/C++, duplication[0] equal *duplication in C/C++ // 这里要特别注意~返回任意重复的一个，赋值duplication[0] // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false public boolean duplicate(int numbers[],int length,int [] duplication) &#123; boolean[] arr = new boolean[length]; for(int i = 0; i &lt; length; i++)&#123; if(arr[numbers[i]] == true)&#123; duplication[0] = numbers[i]; return true; &#125; arr[numbers[i]] = true; &#125; return false; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"整数中1出现的次数（从1到n整数中1出现的次数）","slug":"整数中1出现的次数（从1到n整数中1出现的次数）","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/整数中1出现的次数（从1到n整数中1出现的次数）/","link":"","permalink":"http://linbingdong.com/2017/03/11/整数中1出现的次数（从1到n整数中1出现的次数）/","excerpt":"题目描述\n求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。\n分析\n将每个数组转成字符串，算出每个字符串里的“1”的个数。\n代码:","text":"题目描述 求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。 分析 将每个数组转成字符串，算出每个字符串里的“1”的个数。 代码: public class Solution &#123; public int NumberOf1Between1AndN_Solution(int n) &#123; int count = 0; for(int i = 1; i &lt;= n; i++)&#123; String s = String.valueOf(i); for(int j = 0; j &lt; s.length(); j++)&#123; if(s.charAt(j) == '1') count++; &#125; &#125; return count; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"斐波那契数列","slug":"斐波那契数列","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/斐波那契数列/","link":"","permalink":"http://linbingdong.com/2017/03/11/斐波那契数列/","excerpt":"大家都知道斐波那契数列(0,1,1,2,3,5….)，现在要求输入一个整数n，请你输出斐波那契数列的第n项。第一项下标为0。n&lt;=39\n分析\n不要用递归！！！\n代码:","text":"大家都知道斐波那契数列(0,1,1,2,3,5….)，现在要求输入一个整数n，请你输出斐波那契数列的第n项。第一项下标为0。n&lt;=39 分析 不要用递归！！！ 代码: public class Solution &#123; public int Fibonacci(int n) &#123; int first = 0,second = 1,result = 0; if (n &lt;= 1) return n; for(int i = 0; i &lt; n-1; i++)&#123; result = first + second; first = second; second = result; &#125; return result; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"经典编程书籍","slug":"经典编程书籍","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/经典编程书籍/","link":"","permalink":"http://linbingdong.com/2017/03/11/经典编程书籍/","excerpt":"经典技术书籍，涵盖：计算机系统与网络、系统架构、算法与数据结构、前端开发、后端开发、移动开发、数据库、测试、项目与团队、程序员职业修炼、求职面试和编程相关的经典书籍。\n原文","text":"经典技术书籍，涵盖：计算机系统与网络、系统架构、算法与数据结构、前端开发、后端开发、移动开发、数据库、测试、项目与团队、程序员职业修炼、求职面试和编程相关的经典书籍。 原文 这个列表综合了伯乐在线网站以往推荐经典书籍文章中的列表，以及在微信和微博中被广泛推荐的好书。虽然已经包括了100多本，覆盖的面也比较全。仍然有很多方面需要补充，而且相信还有很多没有被收录的好书。欢迎大家在 issues 中推荐或自荐。 计算机系统与网络 《图灵的秘密:他的生平、思想及论文解读》 《计算机系统概论》 《深入理解Linux内核》 《深入Linux内核架构》 《TCP/IP详解 卷1：协议》 《Linux系统编程（第2版）》 《Linux内核设计与实现（第3版）》 《深入理解计算机系统（原书第2版）》 《计算机程序的构造和解释（原书第2版）》 《编码：隐匿在计算机软硬件背后的语言》 《性能之颠：洞悉系统、企业与云计算》 《UNIX网络编程 卷1：套接字联网API（第3版）》 《UNIX网络编程 卷2：进程间通信》 《Windows核心编程(第5版)》 《WireShark网络分析就这么简单》 《WireShark网络分析的艺术》 编程通用 《编程原本》 《代码大全》 《UNIX编程艺术》 《代码整洁之道》 《编程珠玑（第2版）》 《编程珠玑（续）》 《软件调试的艺术》 《修改代码的艺术》 《编程语言实现模式》 《编写可读代码的艺术》 《解析极限编程：拥抱变化》 《精通正则表达式（第3版）》 《编译原理（第2版）》龙书 《重构：改善既有代码的设计》 《七周七语言：理解多种编程范型》 《调试九法：软硬件错误的排查之道》 《程序设计语言：实践之路（第3版）》 《计算的本质：深入剖析程序和计算机》 《设计模式 : 可复用面向对象软件的基础》 算法与数据结构 《算法（第4版）》 《算法导论（原书第2版）》 《Python算法教程》 《算法设计与分析基础（第3版）》 《学习 JavaScript 数据结构与算法,编程题》 《数据结构与算法,编程题分析 : C++描述（第4版）》 《数据结构与算法,编程题分析 : C语言描述（第2版）》 《数据结构与算法,编程题分析 : Java语言描述（第2版）》 职业修炼与规划 《大教堂与集市》 《卓有成效的程序员》 《程序员的职业素养》 《程序员修炼之道：从小工到专家》 《软件开发者路线图：从学徒到高手》 《我编程，我快乐: 程序员职业规划之道》 《程序员的思维修炼：开发认知潜能的九堂课》 《高效程序员的45个习惯：敏捷开发修炼之道(修订版)》 大师访谈 《编程大师智慧》 《编程大师访谈录》 《编程人生 : 15位软件先驱访谈录》 《奇思妙想 : 15位计算机天才及其重大发现》 《图灵和ACM图灵奖》 架构/性能 《微服务设计》 《大数据日知录》 《企业应用架构模式》 《Web性能权威指南》 《SRE：Google运维解密》 《发布！软件的设计与部署》 《高扩展性网站的 50 条原则》 《大型网站技术架构:核心原理与案例分析》 《恰如其分的软件架构：风险驱动的设计方法》 《软件系统架构：使用视点和视角与利益相关者合作（第2版）》 Web前端 《高性能 JavaScript》 《锋利的 jQuery（第2版）》 《JavaScript 忍者秘籍》（感谢@joker-danta 补充推荐） 《编写可维护的 JavaScript》 《你不知道的 JavaScript（上）》 《JavaScript 权威指南（第6版）》 《JavaScript 语言精粹（修订版）》 《JavaScript DOM编程艺术 （第2版）》 《JavaScript 高级程序设计（第3版）》 《JavaScript 异步编程：设计快速响应的网络应用》 《Effective JavaScript：编写高质量JavaScript代码的68个有效方法》 《HTML5 权威指南》 《HTML5 秘籍（第2版）》 《HTML5 与 CSS3 基础教程（第八版）》 《CSS 揭秘》 《CSS 设计指南（第3版）》 《CSS 权威指南（第3版）》 《深入浅出 HTML 与 CSS》 Java开发 《Java8 实战》 《Java并发编程实战》 《Java性能权威指南》 《Java程序员修炼之道》 《实战Java高并发程序设计》 《Java编程思想 （第4版）》 《深入理解Java虚拟机（第2版）》 《Effective java 中文版（第2版）》 《Java核心技术·卷1：基础知识（原书第9版）》 《Java核心技术·卷2：高级特性（原书第9版）》 .NET 《精通C#（第6版）》 《深入理解C#（第3版）》 《CLR via C#（第4版）》 Python 《集体智慧编程》 《笨办法学Python》 《Python基础教程》 《Python源码剖析》 《Head First Python》 《与孩子一起学编程》 《Python学习手册（第4版）》 《Python Cookbook（第3版）》 《Python参考手册（第4版）》 《Python核心编程（第3版）》 《Python科学计算（第2版）》 《利用 Python 进行数据分析》 《Think Python：像计算机科学家一样思考Python（第2版）》 《Python编程实战:运用设计模式、并发和程序库创建高质量程序》 《Python绝技：运用Python成为顶级黑客》 《Flask Web开发:基于Python的Web应用开发实战》 Android 《Android编程权威指南（第2版）》 《移动应用UI设计模式（第2版）》 iOS 《iOS编程实战》 《iOS编程（第4版）》 《Objective-C高级编程》 《Effective Objective-C 2.0：编写高质量iOS与OS X代码的52个有效方法》 PHP 《Head First PHP &amp; MySQL（中文版）》 《深入PHP：面向对象、模式与实践（第3版）》 C语言 《C标准库》 《C和指针》 《C专家编程》 《C陷阱与缺陷》 《C语言接口与实现》 《C程序设计语言（第2版）》 《C语言参考手册（第5版）》 C++ 《C++标准库》 《C++编程思想》 《C++语言的设计与演化》 《C++程序设计原理与实践》 《C++ Primer （中文第5版）》 《C++ Primer习题集(第5版) 》 《C++程序设计语言(第1-3部分)(原书第4版) 》 《Effective C++:改善程序与设计的55个具体做法(第3版)(中文版) 》 《More Effective C++:35个改善编程与设计的有效方法(中文版) 》&nbsp; 机器学习和数据挖掘 《数据之巅》 《矩阵分析》 《机器学习》 《统计学习方法》 《机器学习导论》 《推荐系统实践》 《机器学习实战》 《Web数据挖掘》 《深入浅出统计学》 《模式分类（第2版）》 《概率论与数理统计》 《统计学习基础(第2版)(英文) 》 《数据挖掘：概念与技术（第3版）》 《数据挖掘：实用机器学习工具与技术（原书第3版）》 《大数据：互联网大规模数据挖掘与分布式处理（第2版）》 数据库 《SQL应用重构》 《SQL Cookbook》 《高性能MySQL （第3版）》 《深入浅出SQL（中文版）》 《MySQL技术内幕 : InnoDB存储引擎（第2版）》 《深入浅出MySQL : 数据库开发、优化与管理维护》 测试 《探索式软件测试》 《有效的单元测试》 《Google软件测试之道》 项目与团队 《人月神话》 《快速软件开发》 《人件（原书第3版）》 《门后的秘密：卓越管理的故事》 《极客与团队：软件工程师的团队生存秘笈》 求职面试 《程序员面试金典（第5版）》 《编程之美 : 微软技术面试心得》 《金领简历：敲开苹果、微软、谷歌的大门》 《剑指Offer：名企面试官精讲典型编程题（纪念版）》 编程之外 《暗时间》 《数学之美》 《赢得朋友》 《精益创业》 《批判性思维》 《世界是数字的》 《程序员的数学》 《程序员健康指南》 《禅与摩托车维修艺术》 《关键对话：如何高效能沟通》 《写作法宝：非虚构写作指南》 《黑客与画家 : 来自计算机时代的高见》 《软件随想录（卷1）》《软件随想录（卷2）》 《如何把事情做到最好：改变全球9800万人的人生指导书》","raw":null,"content":null,"categories":[{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/categories/学习资料/"}],"tags":[{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/tags/学习资料/"},{"name":"经典编程书籍","slug":"经典编程书籍","permalink":"http://linbingdong.com/tags/经典编程书籍/"}]},{"title":"替换空格","slug":"替换空格","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/替换空格/","link":"","permalink":"http://linbingdong.com/2017/03/11/替换空格/","excerpt":"请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。\n分析\n这道题有很多种方法，最简单的是直接调用String的replace方法\n代码:","text":"请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 分析 这道题有很多种方法，最简单的是直接调用String的replace方法 代码: public class Solution &#123; public String replaceSpace(StringBuffer str) &#123; return str.toString().replace(\" \",\"%20\"); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"翻转单词顺序列","slug":"翻转单词顺序列","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/翻转单词顺序列/","link":"","permalink":"http://linbingdong.com/2017/03/11/翻转单词顺序列/","excerpt":"题目描述\n牛客最近来了一个新员工Fish，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？\n分析\n先用String.split()将字符串按空格切分成一个String数组,然后创建一个StringBuilder将该数组从后往前拼接。\n代码:","text":"题目描述 牛客最近来了一个新员工Fish，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？ 分析 先用String.split()将字符串按空格切分成一个String数组,然后创建一个StringBuilder将该数组从后往前拼接。 代码: public class Solution &#123; public String ReverseSentence(String str) &#123; if(str == null) return null; if(str.trim().equals(\"\")) return str; String[] normal = str.split(\" \"); int len = normal.length; StringBuilder sb = new StringBuilder(); for (int i = len - 1; i &gt;= 0; i--)&#123; if (i == 0)&#123; sb.append(normal[0]); &#125;else &#123; sb.append(normal[i]); sb.append(\" \"); &#125; &#125; return sb.toString(); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"有趣的Pythonic写法","slug":"有趣的Pythonic写法","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/有趣的Pythonic写法/","link":"","permalink":"http://linbingdong.com/2017/03/11/有趣的Pythonic写法/","excerpt":"Python 这门编程语言最大的特点就是简单易用。本文列举一些典型的 Pythonic （优雅、地道、简洁）写法。","text":"Python 这门编程语言最大的特点就是简单易用。本文列举一些典型的 Pythonic （优雅、地道、简洁）写法。 变量替换普通写法 a = 10b = 20tmp = aa = bb = tmp pythonic a, b = b, a 遍历区间元素比如打印 1 3 5 7 9 其他语言，如 Java： for (int i = 1; i &lt; 10; i += 2) System.out.print(i + \" \"); pythonic for i in range(1, 10, 2) print i, 带有索引位置的列表遍历weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']for i in range(len(weekdays)): print i, '----&gt;', weekdays[i] pythonic for i, weekday in enumerate(weekdays): print i, '----&gt;', weekday 字符串连接weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']s = weekdays[0]for weekday in weekdays[1:]: s += ', ' + weekdayprint s pythonic print(', '.join(weekdays)) 打开/关闭文件打开文件最后一定要关闭文件。普通的方法是在finally语句中关闭。 f = open('test.txt')try: data = f.read()finally: f.close() pythonic with open('test.txt') as f: data = f.read() 使用 with open 语句，系统会在执行完文件操作后自动关闭文件对象。 列表推导式如要生成一个 [0, 3, 6, 9, 12] 这样的列表 ls = []for i in range(5): ls.append(i*3) pythonic [i*3 for i in range(5)] 序列解包lbd = &apos;lbd&apos;, &apos;male&apos;, &apos;25&apos;, &apos;beijing&apos;name = lbd[0]gender = lbd[1]age = lbd[2]location = lbd[3] pythonic name, gender, age, location = lbd 遍历字典的 key 和 valuefor k in d: print (k, '----&gt;', d[k]) pythonic for k, v in d.items(): print(k, '----&gt;', v) if/elseif x == y: return 0else: return 1 pythonic return 0 if x == y else 1 相当于 return x==y ? 0 : 1 字符串格式化s1 = 'lbd's2 = 25s3 = 'my name is %s and i am %d years old' % (s1, s2) pythonic s3 = 'my name is &#123;name&#125; and i am &#123;age&#125; years old'.format(name = 'lbd', age = 25) 列表切片items = range(10)# 奇数odd_items = []for i in items: if i % 2 != 0: odd_items.append(i)# 拷贝copy_items = []for i in items: copy_items.append(i) pythonic #子区间sub_items = items[1:4]#奇数odd_items = items[1::2]#拷贝copy_items = items[:] or items[::] 列表元素的下标不仅可以用正数表示，还可以用负数表示，最后一个元素的位置是 -1，从右往左，依次递减。 -------------------------- | P | y | t | h | o | n |-------------------------- 0 1 2 3 4 5 -6 -5 -4 -3 -2 -1-------------------------- 获取字典元素d = &#123;&apos;name&apos;: &apos;lbd&apos;&#125;if d.has_key(&apos;name&apos;): print(d[&apos;name&apos;])else: print(&apos;unkonwn&apos;) pythonic print (d.get('name', 'unknown')) 预设字典默认值当字典 value 为列表时，需要判断 key 是否在字典中。 data = [('foo', 10), ('bar', 20), ('foo', 39), ('bar', 49)]groups = &#123;&#125;for (key, value) in data: if key in groups: groups[key].append(value) else: groups[key] = [value] pythonic groups = &#123;&#125;for (key, value) in data: groups.setdefault(key, []).append(value) 字典推导式numbers = [1, 2, 3]d = dict([(number, number*2) for number in numbers]) pythonic d = &#123;number:number*2 for number in numbers&#125;# 还可以加过滤条件d = &#123;number:number*2 for number in numbers if number &gt; 1&#125; 参考博文：《代码这样写不止于优雅（Python版）》","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/tags/Python/"}]},{"title":"机器学习笔记（持续更新）","slug":"机器学习","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/机器学习/","link":"","permalink":"http://linbingdong.com/2017/03/11/机器学习/","excerpt":"\n任何一个有效的机器学习算法必须有一个归纳偏好（bias），否则无法产生确定的学习结果  bias的大小决定学习算法尽可能特殊或尽可能一般 可用“奥卡姆剃刀”原则来选择bias","text":"任何一个有效的机器学习算法必须有一个归纳偏好（bias），否则无法产生确定的学习结果 bias的大小决定学习算法尽可能特殊或尽可能一般 可用“奥卡姆剃刀”原则来选择bias “奥卡姆剃刀”原则：如无必要，勿增实体 Entities should not be multiplied unnecessarily NFL（No Free Lunch)原理：在某些问题上算法A比B好，必定存在某些问题，B比A好 所有评价学习算法好坏要针对具体问题 分类的目标是让泛化误差最小，但是只能从经验误差入手（因为不知道新样本是什么）因此不能让经验误差太小（太专注特殊，没有一般性），否则经常过拟合，泛化性能很差 过拟合无法完全避免，只能缓解 通过使用测试集来测试学习器对新样本的判别能力 以测试集上的测试误差（testing error）作为泛化误差的近似 测试集尽量不出现在训练集中 评估方法（留出法、交叉验证法、留一法、自助法）一般用留出法（训练集、测试集、验证集按比例分 8:1:1） 调参工作量很大（实数范围的，不可能穷举） 两类参数：模型的参数（可以很多，深度神经网络百亿个）、算法自身的参数（较少，一般10以内） SVM 1.SVM由Vapnik提出，具有坚实的统计学理论基础2.主要是用于二分类的，多分类要 专门推广，不是很方便3.可以很好用于高维分类，避免维数灾4.基于判别式分类，使用最大间隔原理（Max Margin）5.使不等式成立的点为支持向量 最大间隔为 2/||W|| 因为便签为 +1 -16.SVM基本型如下：7.SVM基本型是一个凸优化问题，更具体说是一个二次规划问题（目标函数是二次的，约束条件是线性的）8.通过拉格朗日对偶(Lagrange Duality) 变换到对偶变量（dual veriable）的优化问题进行求解9.可以引入核函数，推广到非线性分类问题10.对于非线性可分问题，可以映射到高维空间，使样本在新的特征空间变成线性可分（如果原始空间是有限维，一定存在一个高维特征空间使样本线性可分）引入核函数避开高维障碍11.高维空间中两个向量的内积等于它们在原始空间中对应的向量通过核函数运算的结果12.核函数隐式地定义了特征空间，所有核函数如果选择不当，意味着将原始空间映射到了一个不合适的特征空间，导致性能不佳13.目前还没有什么方法来确定核函数（研究点）14.SVM的兴起曾把神经网络再次打入低谷 神经网络 1. 每个神经元都是一个感知机2. 若每个激活函数都是线性函数，最终只得到线性变换（线性函数的组合还是线性函数）3. 一般都用非线性激活函数 （对数、双曲正切、阶跃、修正线性）4. BP算法基于梯度下降策略，以误差函数的负梯度方向对参数进行调整（权重和阈值）5. 梯度下降法：一种常用的一阶优化方法（只使用目标函数的一阶导数），求解无约束优化问题最经典的方法之一6. 学习率控制每一步更新的步长，太大容易震荡，太小收敛慢7. 神经网络只需输入样本和学习率 连接权重和阈值在（0，1）随机初始化8. 深度学习中更常用的做法是将softmax作为最后一层的激活函数，此时用的代价函数是log-likelihood（对数自然）9. 标准BP（每次用一个样本来更新）和累积BP（先读取一遍训练集）算法的区别，类似于随机梯度下降和（最快）梯度下降的区别 10. 神经网络模型越复杂则1.参数越多，训练效率低（慢）2.容易过拟合 解决办法1.云计算（计算能力强）2.大数据（样本多）11. 改进：1.用交叉熵代价函数代替方差代价函数 2.用分段线性函数（修正线性函数）代替sigmoid函数作隐含层激活函数","raw":null,"content":null,"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://linbingdong.com/categories/机器学习/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://linbingdong.com/tags/Machine-Learning/"}]},{"title":"构建乘积数组","slug":"构建乘积数组","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/构建乘积数组/","link":"","permalink":"http://linbingdong.com/2017/03/11/构建乘积数组/","excerpt":"题目描述\n给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]。不能使用除法。\n分析\n既然不能用除法，那就用乘法吧。把B[i]分成i左边的左半部分和i右边的右半部分。\n代码:","text":"题目描述 给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]。不能使用除法。 分析 既然不能用除法，那就用乘法吧。把B[i]分成i左边的左半部分和i右边的右半部分。 代码: import java.util.ArrayList;public class Solution &#123; public int[] multiply(int[] A) &#123; int len = A.length; int[] B = new int[len]; B[0] = 1; for(int i = 1; i &lt; len; i++)&#123; B[i] = B[i-1] * A[i-1]; &#125; int temp = 1; for(int i = len - 2; i &gt;= 0; i--)&#123; temp *= A[i+1]; B[i] *= temp; &#125; return B; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"洗牌","slug":"洗牌","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/洗牌/","link":"","permalink":"http://linbingdong.com/2017/03/11/洗牌/","excerpt":"洗牌在生活中十分常见，现在需要写一个程序模拟洗牌的过程。 现在需要洗2n张牌，从上到下依次是第1张，第2张，第3张一直到第2n张。首先，我们把这2n张牌分成两堆，左手拿着第1张到第n张（上半堆），右手拿着第n+1张到第2n张（下半堆）。接着就开始洗牌的过程，先放下右手的最后一张牌，再放下左手的最后一张牌，接着放下右手的倒数第二张牌，再放下左手的倒数第二张牌，直到最后放下左手的第一张牌。接着把牌合并起来就可以了。 例如有6张牌，最开始牌的序列是1,2,3,4,5,6。首先分成两组，左手拿着1,2,3；右手拿着4,5,6。在洗牌过程中按顺序放下了6,3,5,2,4,1。把这六张牌再次合成一组牌之后，我们按照从上往下的顺序看这组牌，就变成了序列1,4,2,5,3,6。 现在给出一个原始牌组，请输出这副牌洗牌k次之后从上往下的序列。 \n输入描述:\n第一行一个数T(T ≤ 100)，表示数据组数。对于每组数据，第一行两个数n,k(1 ≤ n,k ≤ 100)，接下来一行有2n个数a1,a2,…,a2n(1 ≤ ai ≤ 1000000000)。表示原始牌组从上到下的序列。\n输出描述:\n对于每组数据，输出一行，最终的序列。数字之间用空格隔开，不要在行末输出多余的空格。\n输入例子:\n33 11 2 3 4 5 63 21 2 3 4 5 62 21 1 1 1\n输出例子:\n1 4 2 5 3 61 5 4 3 2 61 1 1 1\n代码:","text":"洗牌在生活中十分常见，现在需要写一个程序模拟洗牌的过程。 现在需要洗2n张牌，从上到下依次是第1张，第2张，第3张一直到第2n张。首先，我们把这2n张牌分成两堆，左手拿着第1张到第n张（上半堆），右手拿着第n+1张到第2n张（下半堆）。接着就开始洗牌的过程，先放下右手的最后一张牌，再放下左手的最后一张牌，接着放下右手的倒数第二张牌，再放下左手的倒数第二张牌，直到最后放下左手的第一张牌。接着把牌合并起来就可以了。 例如有6张牌，最开始牌的序列是1,2,3,4,5,6。首先分成两组，左手拿着1,2,3；右手拿着4,5,6。在洗牌过程中按顺序放下了6,3,5,2,4,1。把这六张牌再次合成一组牌之后，我们按照从上往下的顺序看这组牌，就变成了序列1,4,2,5,3,6。 现在给出一个原始牌组，请输出这副牌洗牌k次之后从上往下的序列。 输入描述: 第一行一个数T(T ≤ 100)，表示数据组数。对于每组数据，第一行两个数n,k(1 ≤ n,k ≤ 100)，接下来一行有2n个数a1,a2,…,a2n(1 ≤ ai ≤ 1000000000)。表示原始牌组从上到下的序列。 输出描述: 对于每组数据，输出一行，最终的序列。数字之间用空格隔开，不要在行末输出多余的空格。 输入例子: 33 11 2 3 4 5 63 21 2 3 4 5 62 21 1 1 1 输出例子: 1 4 2 5 3 61 5 4 3 2 61 1 1 1 代码: import java.util.Scanner; /** * Created by lbd on 2016/10/31. */public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int group = sc.nextInt(); for (int i = 0;i &lt; group;i++)&#123; int n = sc.nextInt(); int k = sc.nextInt(); int[] cards = new int[2*n]; int[] temp = new int[2*n]; for (int a = 0; a &lt; 2*n ; a++)&#123; cards[a] = sc.nextInt(); &#125; for (int b = 0;b &lt; k;b++)&#123; for (int c = 0;c &lt; 2*n;c += 2)&#123; temp[c] = cards[c/2]; temp[c+1] = cards[c/2+n]; &#125; cards = temp.clone(); &#125; for (int d = 0;d &lt; 2*n-1;d++)&#123; System.out.print(cards[d] + \" \"); &#125; System.out.println(cards[2*n-1]); &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"统计每个单词出现的次数","slug":"统计每个单词出现的次数","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/统计每个单词出现的次数/","link":"","permalink":"http://linbingdong.com/2017/03/11/统计每个单词出现的次数/","excerpt":"/**统计单词出现的次数\n * this is a cat and this is a mice and where is the food?\n * 思路\n * 1.分割字符串\n * 2.分拣存储\n * 3.查看单词出现的次数\n * Created by linbingdong on 16/3/19.\n */\n","text":"/**统计单词出现的次数 * this is a cat and this is a mice and where is the food? * 思路 * 1.分割字符串 * 2.分拣存储 * 3.查看单词出现的次数 * Created by linbingdong on 16/3/19. */ package cn.lbd.Collection;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Set;public class MapDemo01 &#123; public static void main(String[] args)&#123; //分割字符串 String[] arr = &quot;this is a cat and this is a mice and where is the food?&quot;.split(&quot; &quot;); //分拣存储 Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); for (String key : arr)&#123; //System.out.println(key); if(!map.containsKey(key))&#123; //查看是否存在单词,不存在,加入 map.put(key,1); &#125;else&#123; //存在,value+1 map.put(key,map.get(key)+1); &#125; &#125; //3.查看单词出现的次数 Set&lt;String&gt; keySet = map.keySet();//将map中的key放入集合中 Iterator&lt;String&gt; it = keySet.iterator();//调用迭代器遍历 while (it.hasNext())&#123; String key = it.next(); Integer value = map.get(key); System.out.println(key+&quot;---&gt;&quot;+value); &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java对象流与序列化","slug":"Java对象流与序列化","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java对象流与序列化/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java对象流与序列化/","excerpt":"Java语言支持一种称为对象序列化（object serialization）的非常通用的机制，它可以将任何对象写入到流中，并在之后将其读回。被序列化的每个对象都有一个序列号，唯一标识该对象，而不是通过该对象的内存地址来表示对象。这样就能将一个对象集合从一台集群传送到另一台机器，与对象在内存中的地址无关。","text":"Java语言支持一种称为对象序列化（object serialization）的非常通用的机制，它可以将任何对象写入到流中，并在之后将其读回。被序列化的每个对象都有一个序列号，唯一标识该对象，而不是通过该对象的内存地址来表示对象。这样就能将一个对象集合从一台集群传送到另一台机器，与对象在内存中的地址无关。 示例： ObjectStreamTest.java import java.io.*;/** * Created by lbd on 2017/1/5. */public class ObjectStreamTest &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; Employee harry = new Employee(\"Harry Hacker\", 50000, 1989, 10, 1); Manager carl = new Manager(\"Carl Cracker\", 80000, 1987, 12, 15); carl.setSecretary(harry); Manager tony = new Manager(\"Tony Tester\", 40000, 1990, 3, 15); tony.setSecretary(harry); Employee[] staff = new Employee[3]; staff[0] = carl; staff[1] = harry; staff[2] = tony; try(ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(\"employee1.dat\")))&#123; out.writeObject(staff); &#125; try(ObjectInputStream in = new ObjectInputStream(new FileInputStream(\"employee1.dat\")))&#123; Employee[] newStaff = (Employee[]) in.readObject(); for (Employee e : newStaff)&#123; System.out.println(e); &#125; &#125; &#125;&#125;class Employee implements Serializable&#123; String name; double salary; int year; int month; int day; public Employee(String name,double salary,int year,int month,int day)&#123; this.name = name; this.salary = salary; this.year = year; this.month = month; this.day = day; &#125; public String getName() &#123; return name; &#125; public double getSalary() &#123; return salary; &#125; public int getYear() &#123; return year; &#125; public int getMonth() &#123; return month; &#125; public int getDay() &#123; return day; &#125; @Override public String toString() &#123; return this.name + \" \" + this.salary + \" \" + this.year + \" \" + this.month + \" \" + this.day; &#125;&#125;class Manager extends Employee implements Serializable&#123; Employee secretary; public Manager(String name, double salary, int year, int month, int day) &#123; super(name, salary, year, month, day); &#125; public void setSecretary(Employee e)&#123; this.secretary = e; &#125;&#125; 注意： Employee和Manager都必须实现Serializable接口才能被序列化!(Serializable接口没有任何方法) 对象流输出中包含所有对象的类型和数据域 每个对象都被赋予一个序列号 相同对象的重复出现将被存储为对这个对象的序列号的引用","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"疯狂跳台阶","slug":"疯狂跳台阶","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/疯狂跳台阶/","link":"","permalink":"http://linbingdong.com/2017/03/11/疯狂跳台阶/","excerpt":"一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n分析\n分析前几级可得出规律：跳法为2的n次方。这里用左移运算符效率较高。只需要一行代码。\n代码:","text":"一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 分析 分析前几级可得出规律：跳法为2的n次方。这里用左移运算符效率较高。只需要一行代码。 代码: public class Solution &#123; public int JumpFloorII(int target) &#123; return 1 &lt;&lt; --target; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Java文件管理操作","slug":"Java文件管理操作","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/Java文件管理操作/","link":"","permalink":"http://linbingdong.com/2017/03/11/Java文件管理操作/","excerpt":"linux里有mkdir、rm、cp、mv、touch等对文件或目录进行操作的命令，Java中也有对应的方法。\nPath和Files类封装了处理文件系统所需的所有功能。比如，可以用Files类删除或重命名文件，或者查询文件最后被修改的时间等。换句话说，流类关心的是文件的内容，而Files类关心的是对文件和目录的操作。","text":"linux里有mkdir、rm、cp、mv、touch等对文件或目录进行操作的命令，Java中也有对应的方法。 Path和Files类封装了处理文件系统所需的所有功能。比如，可以用Files类删除或重命名文件，或者查询文件最后被修改的时间等。换句话说，流类关心的是文件的内容，而Files类关心的是对文件和目录的操作。 Path和Files是在Java SE 7中新添加进来的类，比自JDK 1.0以来就一直使用的File类要方便得多。 java.nio.file.Paths 7Path表示的是文件或目录的路径。是一个字符串。 java.nio.file.Paths static Path get(String first, String…more) Path dir = Paths.get(\"/Users/linbingdong\",\"Downloads\",\"xxx.txt\"); Paths.get方法通过给定的字符串创建一个路径。该方法可以接受一个或多个字符串，并自动将它们用默认文件系统的路径分隔符连接起来。 要操作文件或目录之前，都需要先用Paths.get方法生成相应的路径。 java.nio.file.Files 7Files类使得普通文件操作变得快捷。 java.nio.file.Files static byte[] readAllBytes(Path path) static Path write(Path path, byte[] contents, OpenOption…options) static Path copy(Path from, Path to, CopyOption…options) static Path move (Path from, Path to, CopyOption…options) static void delete(Path path) static Path createFile(Path path, FileAttribute&lt;?&gt;… attrs) static Path createDirectory(Path path, FileAttribute&lt;?&gt;…attrs) static Path createDirectories(Path path, FileAttribute&lt;?&gt;…attrs) static boolean exists(Path path) static boolean isReadable(Path path) static boolean isDirectory(Path path) 要读入文件内容是，首先将文件内容以字节的方式读入字节数组，再将字节数组作为参数传入新建的String对象。 要将String写入文件，需要调用String.getBytes()。 具体各方法的用法见示例 示例： import java.io.IOException;import java.nio.charset.Charset;import java.nio.file.*;/** * Created by lbd on 2017/1/5. */public class TestFile &#123; public static void main(String[] args) throws IOException &#123; Path from = Paths.get(\"/Users/linbingdong/hehe\"); Path to = Paths.get(\"/Users/linbingdong/hehe2\"); Path newDir = Paths.get(\"/Users/linbingdong/test\",\"hi\",\"hei\",\"oo\"); //Files.copy(from,to); Files.createDirectories(newDir); //Files.copy(from,newDir, StandardCopyOption.COPY_ATTRIBUTES,StandardCopyOption.REPLACE_EXISTING); //Files.move(from,to); System.out.println(newDir.getParent()); System.out.println(newDir.getRoot()); System.out.println(newDir.getFileName()); //获取路径中最后一个字段,不管是目录还是文件 System.out.println(newDir.getFileSystem()); System.out.println(newDir.getNameCount()); //路径层级的个数 byte[] bytes = Files.readAllBytes(to); //获取文本内容存入byte数组 String contents = new String(bytes, Charset.defaultCharset()); //将byte数组转化成String对象 System.out.println(contents); Files.write(to,contents.getBytes()); //覆盖写 获取String对象对应的byte数组 //Files.write(to,contents.getBytes(), StandardOpenOption.APPEND); //追加写 //Files.delete(newDir); Files.createDirectories(newDir); //创建路径中的所有中间目录 相当于mkdir -p Path newFile = Paths.get(\"/Users/linbingdong/test\",\"hi\",\"hei\",\"oo\",\"hhhh\"); //Files.createFile(newFile); //创建一个新文件 最后是文件名 System.out.println(Files.exists(newFile)); //判断是否存在 System.out.println(Files.size(newFile)); //返回文件的字节数 System.out.println(Files.isDirectory(newFile)); //判断是否是文件夹 Path basePath = Paths.get(\"/Users/linbingdong/test\"); try(DirectoryStream&lt;Path&gt; entries = Files.newDirectoryStream(basePath)) &#123; //迭代目录中的文件 for (Path entry: entries) &#123; System.out.println(entry.getFileName()); &#125; &#125; &#125;&#125; 注：以上的方法适用于处理中等长度的文本文件，如果要处理的文件较大，或者是二进制文件，那么还是应该使用所熟知的流或者读入器、写出器： InputStream in = Files.newInputStream(Path);OutputStream out = Files.newOutputStream(Path);Reader in = Files.newBufferedReader(Path,charset);Writer out = Files.newBufferedWriter(path,charset);","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://linbingdong.com/tags/Java/"}]},{"title":"第一个只出现一次的字符","slug":"第一个只出现一次的字符","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/第一个只出现一次的字符/","link":"","permalink":"http://linbingdong.com/2017/03/11/第一个只出现一次的字符/","excerpt":"题目描述\n在一个字符串(1&lt;=字符串长度&lt;=10000，全部由大小写字母组成)中找到第一个只出现一次的字符,并返回它的位置\n分析\n遍历一遍字符串，用counts数组存储每个字母出现的次数。str.charAt[i] - &#39;A&#39;作为该字母在counts数组中的下标。数组大小为58（’A’的ASCLL码为65 ‘a’为97 ‘z’为122  122-65+1=58）\n代码:","text":"题目描述 在一个字符串(1&lt;=字符串长度&lt;=10000，全部由大小写字母组成)中找到第一个只出现一次的字符,并返回它的位置 分析 遍历一遍字符串，用counts数组存储每个字母出现的次数。str.charAt[i] - &#39;A&#39;作为该字母在counts数组中的下标。数组大小为58（’A’的ASCLL码为65 ‘a’为97 ‘z’为122 122-65+1=58） 代码: public class Solution &#123;public int FirstNotRepeatingChar(String str) &#123; if (str.length() == 0) &#123; return -1; &#125; char c = 'A'; int[] counts = new int[58]; for (int i = 0; i &lt; str.length(); i++) &#123; counts[str.charAt(i) - c]++; //这里比较巧妙 &#125; for (int i = 0; i &lt; str.length(); i++) &#123; if (counts[str.charAt(i) - c] == 1)&#123; return i; &#125; &#125; return -1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"程序员资料大全","slug":"程序员资料大全","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/程序员资料大全/","link":"","permalink":"http://linbingdong.com/2017/03/11/程序员资料大全/","excerpt":"活到老，学到老。","text":"活到老，学到老。 本文由stanzhai整理。 目录 资料篇 技术站点 必看书籍 大牛博客 GitHub篇 工具篇 平台工具 常用工具 第三方服务 爬虫相关(好玩的工具) 安全相关 Web服务器性能/压力测试工具/负载均衡器 大数据处理/数据分析/分布式工具 Web前端 语言篇 Scala Java Python Swift .NET C &amp; C++ 其他 游戏开发相关 日志聚合，分布式日志收集 RTP,实时传输协议与音视频 资料篇技术站点 在线学习：Coursera、edX、Udacity、MIT公开课、MOOC学院、慕课网 Hacker News：非常棒的针对编程的链接聚合网站 Techmeme：美国知名科技新闻和博客聚集网站，类似的还有（Panda, Hacker &amp; Designer News） Reddit - Programming板块：同上 Java牛人必备：Program Creek Stack Overflow：IT技术问答网站 SegmentFault：中文的技术问答社区 GitHub：全球最大的源代码管理平台，很多知名开源项目都在上面，如Linux内核，OpenStack等 码云：支持中文可免费创建私有项目的代码托管平台，可作为备选 LeetCode：来做做这些题吧，看看自己的算法水平如何？这可比什么面试宝典强多了。 LintCode：支持中文的编程题在线训练平台，可作为备选 Kaggle,Topcoder: 机器学习、大数据竞赛 掘金：高质量的技术社区 开发者头条 InfoQ：企业级应用，关注软件开发领域 V2EX: way to explore 国内老牌技术社区：OSChina、博客园、CSDN、51CTO 免费的it电子书：http://it-ebooks.info/ 在线学习：http://www.udemy.com/ 优质学习资源：http://plus.mojiax.com/ 代码练习：http://exercism.io/ and https://www.codingame.com DevStore:开发者服务商店 MSDN：微软相关的官方技术集中地，主要是文档类 谷歌开发者 码库 - 收录了实用的开源项目及资源 必看书籍 SICP(Structure and Interpretation of Computer Programs) 深入理解计算机系统 代码大全2 人件 人月神话 软件随想录 算法导论（麻省理工学院出版社） 离散数学及其应用 设计模式 编程之美 黑客与画家 编程珠玑 The Little Schemer Simply Scheme_Introducing_Computer_Science C++ Prime Effective C++ TCP/IP详解 Unix 编程艺术 技术的本质 软件随想录 计算机程序设计艺术 职业篇：程序员的自我修养,程序员修炼之道,高效能程序员的修炼 《精神分析引论》弗洛伊德 《失控》《科技想要什么》《技术元素》凯文凯利 程序开发心理学 天地一沙鸥 搞定：无压力工作的艺术 大牛博客 云风（游戏界大牛）: http://blog.codingnow.com/ 王垠（不少文章喷到蛮有道理）：http://www.yinwang.org/ 冰河-伞哥(Lisp大牛)：http://tianchunbinghe.blog.163.com/ R大【干货满满】RednaxelaFX写的文章/回答的导航帖 陈皓-左耳朵耗子：http://coolshell.cn/ Jeff Atwood（国外知名博主）: https://blog.codinghorror.com/ 阮一峰（黑客与画家译者，Web）：http://www.ruanyifeng.com/ 廖雪峰（他的Python、Git教程不少人都看过）：http://www.liaoxuefeng.com/ 道哥的黑板报（安全）：https://zhuanlan.zhihu.com/taosay 国内GitHub上关注度较高的开发者 GitHub篇 Awesome Awesome: 这是个Awesome合集，常见的资料这里面都能找到 Awesome2: 类似第一个Awesome 杂七杂八、有用没用的Awesome合集 非常不错的语言类学习资料集合：Awesomeness awesome-ios-ui awesome-android-ui Awesome-MaterialDesign awesome-public-datasets awesome-AppSec(系统安全) awesome-datascience awesome-dataviz - 数据可视化库及资料 书籍资料 free-programming-books 中文版 免费的编程中文书籍索引 《程序员编程艺术 — 面试和算法心得》 GoBooks Papers we love 自然语言处理NLP推荐学习路线及参考资料 超级棒的机器学习资料（框架，库，软件）, 中文翻译版 机器学习(Machine Learning)&amp;深入学习(Deep Learning)资料 Docker资料合集 学习使用Strom Hadoop Internals Spark Internals 大数据时代的数据分析与数据挖掘 – 基于Hadoop实现 如何制作操作系统 借助开源项目学习软件开发 几个不错的开源游戏引擎 一起写Python文章，一起看Python文章 R的极客理想系列文章 HTTP接口设计指南 分享自己长期关注的前端开发相关的优秀网站、博客、以及活跃开发者 Readings in Databases Data Science blogs 日志：每个软件工程师都应该知道的有关实时数据的统一概念 Android Code Path Android Learn Notes PHP 类库框架，资料集合 优秀项目 最值得关注的10个C语言开源项目 15款值得学习的小型开源项目 iOS-100个开源组件 十大Material Design开源项目 Android开源项目分类汇总 前端 &amp; Node.js 前端资源 前端开发指南 前端技能汇总 前端资源大导航 收集前端方面的书籍 2014年最新前端开发面试题 简单清晰的JavaScript语言教程，代码示例 JavaScript编程规范 JavaScript必看视频 JavaScript标准参考教程（阮一峰的，整理的不错） JS必看 AngularJS Guide的中文分支 Angular2学习资料 AngularJS应用的最佳实践和风格指南 React-Native学习指南 七天学会NodeJS node.js中文资料导航 Nodejs学习路线图 如何学习nodejs 工作，工具 系统管理员工具集合 Pro Git Nginx开发从入门到精通 Google 全球 IP 地址库 收集整理远程工作相关的资料 Color schemes for hackers 游戏开发工具集，MagicTools 开发者工具箱， free-for-dev GitHub秘籍 Git风格指南 Bast-App 工具篇平台工具 Phabricator: 软件开发平台，Facebook出品，现已开源，CodeReview神器（从这个往下一直到GitLab之间的工具统统可以忽略了） Redmine/Trac：项目管理平台 Jenkins/Jira(非开源)：持续集成系统（Apache Continuum，这个是Apache下的CI系统，还没来得及研究） git，svn：源代码版本控制系统 GitLab/Gitorious：构建自己的GitHub服务器 Postman:RESTful，api测试工具，HTTP接口开发必备神器 Lottie: AE动画变原生代码，设计师必备 Sonar：代码质量管理平台 Nessus: 系统漏洞扫描器 gitbook：https://www.gitbook.io/写书的好东西，当然用来写文档也很不错的（发现不少产品的文档就是用的它） Travis-ci：开源项目持续集成必备，和GitHub相结合，https://travis-ci.org/ Trello：简单高效的项目管理平台，注重看板管理 日志聚合：graylog、ELK（推荐新一代的graylog，基本上算作是开源的Splunk了） 开源测试工具、社区（Selenium、OpenQA.org） Puppet:一个自动管理引擎，可以适用于Linux、Unix以及Windows平台。所谓配置管理系统，就是管理机器里面诸如文件、用户、进程、软件包这些资源。无论是管理1台，还是上万台机器Puppet都能轻松搞定。其他类似工具：CFEngine、SaltStack、Ansible Nagios：系统状态监控报警，还有个Icinga(完全兼容nagios所有的插件,工作原理,配置文件以及方法,几乎一模一样。配置简单,功能强大) Ganglia：分布式监控系统 fleet：分布式init系统 Ansible：能够大大简化Unix管理员的自动化配置管理与流程控制方式。 GeoLite免费数据库 jsHint:js代码验证工具 haproxy: 高可用负载均衡（此外类似的系统还有nginx，lvs） linux OS性能分析工具：dstat，iostat，iotop，nmon kimono：将网页信息转换为api接口的工具 集群管理工具：pdsh，ClusterSSH，mussh（可以用它快速管理Hadoop集群）ipa-server做统一的认证管理 influxdb: 分布式时序数据库，结合Grafana可以进行实时数据分析 dot: 程序员绘图利器（是种语言，也是个工具） Graph::Easy: （Ascii Art工具）字符流程图绘制，实乃程序员装逼神器。其他类似的工具Asciiflow, vi插件：drawit! spf13-vim: 让你的vim飞起来！ Kubernetes: 容器集群管理系统 Gatling: 服务器性能压力测试工具 systemtap: Linux内核探测工具、内核调试神器 Cygwin：Windows下的类UNIX模拟环境 MinGW：Windows下的GNU工具集 常用工具 Mac下的神兵利器 asciinema: 终端录屏神器 Fiddler：非常好用的Web前端调试工具，当然是针对底层http协议的，一般情况使用Chrome等自带的调试工具也足够了，特殊情况还得用它去处理 Charles: Mac上的Web代理调试工具，类似Fiddler fir.im免费的移动App内测托管平台 wireshark：知名的网络数据包分析工具 PowerCmd:替代Windows Cmd的利器 RegexBuddy:强大的正则表达式测试工具 Soure Insight：源代码阅读神器 SublimeText：程序员最爱的编辑器 Database.NET：一个通用的关系型数据库客户端，基于.NET 4.0开发的，做简单的处理还是蛮方便的 Navicat Premium：支持MySql、PostgreSQL、Oracle、Sqlite和SQL Server的客户端，通用性上不如Database.NET，但性能方面比Database.NET好很多，自带备份功能也用于数据库定时备份。 Synergy : 局域网内一套键盘鼠标控制多台电脑 DameWare：远程协助工具集（我在公司主要控制大屏幕用） Radmin: 远程控制工具，用了一段时间的DameWare，还要破解，对Win7支持的不好，还是发现这个好用 Listary：能极大幅度提高你 Windows 文件浏览与搜索速度效率的「超级神器」 Clover：给资源管理器加上多标签，我平时工作的时候就用它，像Chrome一样使用资源管理器，甚是方便啊（这是Windows平台的） WinLaunch：模拟Mac OS的Launch工具 Fritzing：绘制电路图 LICEcap：gif教程制作 git，svn：版本控制系统 Enigma Virtual Box（将exe，dll等封装成一个可执行程序） Open DBDiff(针对SqlServer)数据库同步 SymmetricDS：数据库同步 BIEE,Infomatica，SPSS，weka，R语言：数据分析 CodeSmith，LightSwitch：代码生成 Pandoc：Markdown转换工具，出书用的。以前玩过docbook，不过现在还是Markdown盛行啊。 Window Magnet[Mac]：增强Mac窗口管理功能，想Win7一样具有窗口拖放到屏幕边缘自动调整的功能 log explorer：查看SqlServer日志 dependency walker：查询Windows应用程序dll依赖项 Shairport4w：将iPhone，iPad，iPod上的音频通过AirPlay协议传输到PC上 ngrok：内网穿透工具 Axure:快速原型制作工具，还有个在线作图的工具国内的一个创业团队做的，用着很不错http://www.processon.com/ Origami: 次世代交互设计神器 百度脑图：http://naotu.baidu.com/ tinyproxy:（Linux）小型的代理服务器支持http和https协议 EaseUS Partition Master：超级简单的分区调整工具，速度还是蛮快的，C盘不够用了就用它从D盘划点空间吧，不用重装系统这么折腾哦。 CheatEngine：玩游戏修改内存值必备神器（记得我在玩轩辕剑6的时候就用的它，超级方便呢） ApkIDE:Android反编译神器 翻、墙工具（自|由|门、天行浏览器，免费的VPN：http://www.mangovpn.com/）,发现最方便还属Lantern，免费用起来超级方便（更新于2015-08-22） 设计工具：Sketch、OmniGraffle MindManger：思维导图 MagicDraw:Uml图工具 innotop：MySql状态监测工具 墨刀：比Axure更为简单的原型工具，可以快速制作原型 Karabiner: Mac专用，修改键盘键位的神器，机械键盘必备 Timing：Mac专用，统计你的时间都花在哪了 f.lux: 护眼神器，过滤蓝光，程序员护眼必备良品 LaTeX: 基于ΤΕΧ的排版系统, 让写论文更方便 Antlr：开源的语法分析器，可以让你毫无压力的写个小parser 第三方服务 DnsPod：一个不错的智能DNS服务解析提供商 DigitalOcean：海外的云主机提供商，价格便宜，磁盘是SSD的，用过一段时间整体上还可以，不过毕竟是海外的，网速比较慢。国内的就是阿里云了。还有个比较知名的是：Linode，据说速度上比DigitalOcean好很多 移动端推送服务：个推、JPush、云巴 LeanCloud：移动应用开发服务，包括:数据存储、用户管理、消息推送、应用统计、社交分享、实时聊天等服务 Color Hunt: 漂亮炫酷的配色网站，程序员的福音 Heroku: PaaS平台 爬虫相关(好玩的工具) Phantomjs(Web自动化测试，服务端渲染等) berserkJS(基于Phantomjs的改进版本) SlimerJS CasperJS selenium HtmlUnit（开源的java 页面分析工具，也是个Headless的浏览器） 安全相关 sql注入检测：sqlmap、haviji 端口扫描：nmap 渗透测试：BurpLoader sqltools: sql漏洞利用工具 snort: 入侵检测 Web服务器性能/压力测试工具/负载均衡器 ab: ab是apache自带的一款功能强大的测试工具 curl-loader: 真实模拟、测试Web负载 http_load: 程序非常小，解压后也不到100K webbench: 是Linux下的一个网站压力测试工具，最多可以模拟3万个并发连接去测试网站的负载能力。 Siege: 一款开源的压力测试工具，可以根据配置对一个WEB站点进行多用户的并发访问，记录每个用户所有请求过程的相应时间，并在一定数量的并发访问下重复进行。 squid（前端缓存），nginx（负载），nodejs（没错它也可以，自己写点代码就能实现高性能的负载均衡器）：常用的负载均衡器 Piwik：开源网站访问量统计系统 ClickHeat：开源的网站点击情况热力图 HAProxy：高性能TCP /HTTP负载均衡器 ElasticSearch：搜索引擎基于Lucene Page Speed SDK和YSLOW HAR Viewer: HAR分析工具 protractor：E2E（end to end）自动化测试工具 大数据处理/数据分析/分布式工具 Hadoop：分布式的文件系统，结合其MapReduce编程模型可以用来做海量数据的批处理（Hive，Pig，HBase啥的就不说了），值得介绍的是Cloudera的Hadoop分支CDH5，基于YARN MRv2集成了Spark可直接用于生产环境的Hadoop，对于企业快速构建数据仓库非常有用。 Spark：大规模数据处理框架（可以应付企业中常见的三种数据处理场景：复杂的批量数据处理（batch data processing）；基于历史数据的交互式查询（interactive query）；基于实时数据流的数据处理（streaming data processing）），CSND有篇文章介绍的不错 除了Spark，其他几个不错的计算框架还有：Kylin，Flink，Drill Ceph:Linux分布式文件系统（特点：无中心） Storm：实时流数据处理，可以看下IBM的一篇介绍 （还有个Yahoo的S4，也是做流数据处理的） Druid: 实时数据分析存储系统 Ambari: 大数据平台搭建、监控利器；类似的还有CDH Tachyon：分布式内存文件系统 Mesos：计算框架一个集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享 Impala：新一代开源大数据分析引擎，提供Sql语义，比Hive强在速度上 presto: facebook的开源工具，大数据分布式sql查询引擎 SNAPPY：快速的数据压缩系统，适用于Hadoop生态系统中 Kafka:高吞吐量的分布式消息队列系统 ActiveMQ:是Apache出品，最流行的，能力强劲的开源消息总线 MQTT:Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分 RabbitMQ：记得OpenStack就是用的这个东西吧 ZeroMQ：宣称是将分布式计算变得更简单，是个分布式消息队列，可以看下云风的一篇文章的介绍 开源的日志收集系统：scribe、chukwa、kafka、flume。这有一篇对比文章 Zookeeper：可靠的分布式协调的开源项目 Databus：LinkedIn 实时低延迟数据抓取系统 数据源获取：Flume、Google Refine、Needlebase、ScraperWiki、BloomReach 序列化技术：JSON、BSON、Thrift、Avro、Google Protocol Buffers NoSql：ScyllaDB（宣称是世界上最快的NoSql）、Apache Casandra、MongoDB、Apache CouchDB、Redis、BigTable、HBase、Hypertable、Voldemort、Neo4j MapReduce相关：Hive、Pig、Cascading、Cascalog、mrjob、Caffeine、S4、MapR、Acunu、Flume、Kafka、Azkaban、Oozie、Greenplum 数据处理：R、Yahoo! Pipes、Mechanical Turk、Solr/ Lucene、ElasticSearch、Datameer、Bigsheets、Tinkerpop NLP自然语言处理：Natural Language Toolkit、Apache OpenNLP、Boilerpipe、OpenCalais 机器学习：TensorFlow（Google出品），WEKA、Mahout、scikits.learn、SkyTree 可视化技术：GraphViz、Processing、Protovis、Google Fusion Tables、Tableau、Highcharts、EChats（百度的还不错）、Raphaël.js Kettle：开源的ETL工具 Pentaho：以工作流为核心的开源BI系统 Mondrian：开源的Rolap服务器 Oozie：开源hadoop的工作流调度引擎，类似的还有：Azkaban 开源的数据分析可视化工具：Weka、Orange、KNIME Cobar：阿里巴巴的MySql分布式中间件 数据清洗：data wrangler， Google Refine Web前端 Material Design: 谷歌出品，必属精品 Vue.js: 借鉴了Angular及React的JS框架，设计理念较为先进 GRUNT: js task runner Sea.js: js模块化 knockout.js：MVVM开发前台，绑定技术 Angular.js: 使用超动感HTML &amp; JS开发WEB应用！ Highcharts.js，Flot:常用的Web图表插件 NVD3: 基于d3.js的图表库 Raw：非常不错的一款高级数据可视化工具 Rickshaw:时序图标库，可用于构建实时图表 JavaScript InfoVis Toolkit：另一款Web数据可视化插件 Pdf.js，在html中展现pdf ACE，CodeMirror：Html代码编辑器（ACE甚好啊） NProcess：绚丽的加载进度条 impress.js：让你制作出令人眩目的内容展示效果(类似的还有reveal) Threejs：3DWeb库 Hightopo：基于Html5的2D、3D可视化UI库 jQuery.dataTables.js:高度灵活的表格插件 Raphaël：js，canvas绘图库，后来发现百度指数的图形就是用它绘出来的 director.js：js路由模块，前端路由，Nodejs后端路由等，适合构造单页应用 pace.js：页面加载进度条 bower：Web包管理器 jsnice：有趣的js反编译工具，猜压缩后的变量名，http://www.jsnice.org/ D3.js: 是一个基于JavaScript数据展示库（类似的还有P5.js） Zepto.js：移动端替代jQuery的东东，当然也可以使用jquery-mobile. UI框架：Foundation，Boostrap，Pure，EasyUI，Polymer 前段UI设计师必去的几个网站：Dribbble，awwwards，unmatchedstyle，UIMaker Mozilla 开发者中心：https://developer.mozilla.org/en-US/ 图标资源：IcoMoon（我的最爱），Font Awesome, Themify Icons，FreePik，Glyphicons artDialog:非常漂亮的对话框 AdminLTE：github上的一个开源项目，基于Boostrap3的后台管理页面框架 Respond.js：让不懂爱的IE6-8支持响应式设计 require.js: js模块加载库 select2：比chosen具有更多特性的选择框替代库 AngularUI：集成angular.js的UI库 normalize.css: 采用了现代化标准让各浏览器渲染出的html保持一致的库 CreateJS：Html5游戏引擎 Less,Compass:简化CSS开发 emojify.js:用于自动识别网页上的Emoji文字并将其显示为图像 simditor:一个不错的开源的html编辑器，简洁高效 Sencha: 基于html5的移动端开发框架 SuperScrollorama+TweenMax+skrollr:打造超酷的视差滚动效果网页动画 jquery-smooth-scroll:同上，平滑滚动插件 Animate.css:实现了各种动画效果的css库 Emmet:前端工程师必备，前身为 Zen Coding React: facebook出品的js UI库 highlight.js：专门用来做语法高亮的库 GoJS: Html5交互式图表库，看demo更适合层次结构的图表。 10 Pure CSS (Mostly) Flat Mobile Devices: http://marvelapp.github.io/devices.css/ CodePen: http://codepen.io/ jsfiddle: http://jsfiddle.net/ 前端js，html，css测试利器 语言篇折腾中：Scala、Python、Lua、JavaScript、Go 待折腾： Racket OCaml Rust Julia Scala Scala Standard Library API Scala School!: A Scala tutorial by Twitter A Tour of Scala: Tutorial introducing the main concepts of Scala Scala Overview on StackOverflow: A list of useful questions sorted by topic Programming in Scala，最新的第3版，还没有电子版，电子版是第一版 《Scala for the Impatient》 《Scala in Depth》 《Programming Scala》Dean Wampler and Alex Payne. O’Reilly 2009 Scala By Example Scala Cheatsheet学习模式匹配的好资料 Glossary of Scala and FP terms Metascala: A JVM written in Scala LMS: Program Generation and Embedded Compilers in Scala Java 常用的IDE：IntelliJ IDEA(强烈推荐)，Eclipse，Netbeans fastutil: 性能更好的Java集合框架 Guava: 谷歌的Java工具包，应用广泛 Curator：Netflix公司开源的一个Zookeeper client library，用于简化Zookeeper客户端编程，现在已经是apache下的一个独立项目了。Spark的HA也用的这货。 Rx(Reactive Extensions)框架：Vert.x, RxJava(Android中用的比较多), Quasar FindBugs: 代码静态分析工具，找出代码缺陷 Java反编译工具：Luyten，JD-Gui Drools: 规则引擎 Jersey: Java RESTful 框架 canal: 阿里巴巴出品，binlog增量订阅&amp;消费组件 Web开发相关：Tomcat、Resin、Jetty、WebLogic等，常用的组件Struts，Spring，Hibernate Netty: 异步事件驱动网络应用编程框架，用于高并发网络编程比较好（NIO框架，spark 1.2.0就用netty替代了nio） MINA：简单地开发高性能和高可靠性的网络应用程序（也是个NIO框架），不少手游服务端是用它开发的 jOOQ：java Orm框架 Janino: 超级小又快的Java编译器，Spark的Tungsten引起用的它 Activiti:工作流引擎，类似的还有jBPM、Snaker Perfuse:是一个用户界面包用来把有结构与无结构数据以具有交互性的可视化图形展示出来. Gephi:复杂网络分析软件, 其主要用于各种网络和复杂系统，动态和分层图的交互可视化与探测开源工具 Nutch:知名的爬虫项目，hadoop就是从这个项目中发展出来的 web-harvest：Web数据提取工具 POM工具：Maven+Artifactory Akka:一款基于actor模型实现的 并发处理框架 EclEmma：覆盖测试工具 Shiro:安全框架 joda-time:简化时间处理 parboiled:表达式解析 dozer: 深拷贝神器 dubbo: 阿里巴巴出品的分布式服务框架 jackson databind: json序列化工具(fastjson,simplejson) Atomikos: 分布式事务管理 BoneCP：性能很赞的数据库连接池组件，据说比c3p0快好多 ProGuard: obconfuscation tool, 强大的混淆工具 S-99：Scala相关的99个问题 Python PyCharm：最佳Python IDE Eric,Eclipse+pydev,比较不错的Python IDE PyWin:Win32 api编程包 numpy:科学计算包，主要用来处理大型矩阵计算等，此外还有SciPy，Matplotlib GUI相关：PyQt，PyQwt supervisor:进程监控工具 PyGame: 基于Python的多媒体开发和游戏软件开发模块 Web框架: Django 开源web开发框架，它鼓励快速开发,并遵循MVC设计 Swift Swift精选资料 43个优秀的开源项目 客户端 糗事百科 Swift HackerNews Swift 知乎日报app Framework Twitter框架 Mac下简单HTTP Server Swifter 小工具 Swift Alarm Swift Note Swift RSS Reader Swift-PM2.5查询app 游戏 Flappy Swift FanFan Swift .NET Xilium.CefGlue:基于CEF框架的.NET封装，基于.NET开发Chrome内核浏览器 CefSharp：同上，有一款WebKit的封装，C#和Js交互会更简单 netz:免费的 .NET 可执行文件压缩工具 SmartAssembly:变态的.net代码优化混淆工具 NETDeob0：.net反混淆工具，真是魔高一尺道高一丈啊(还有个de4dot，在GitHub上，都是开源的) ILMerge：将所有引用的DLL和exe文件打成一个exe文件 ILSpy:开源.net程序反编译工具 Javascript.NET：很不错的js执行引擎，对v8做了封装 NPOI: Excel操作 DotRAS:远程访问服务的模块 WinHtmlEditor: Winform下的html编辑器 SmartThreadPool:使用C#实现的，带高级特性的线程池 Snoop: WPF Spy Utility Autofac: 轻量级IoC框架 HtmlAgilityPack：Html解析利器 Quartz.NET：Job调度 HttpLib：@CodePlex，简化http请求 SuperSocket：简化Socket操作，基于他的还有个SuperWebSocket，可以开发独立的WebSocket服务器了 DocX：未安装Office的情况下操作Word文件 Dapper：轻量级的ORM类，性能不错 HubbleDotNet：支持接入数据库的全文搜索系统 fastJSON：@CodeProject，高性能的json序列化类 ZXing.NET：@CodePlex，QR，条形码相关 Nancy：轻量级Http服务器，做个小型的Web应用可以摆脱IIS喽(Nancy.Viewengines.Razor,可以加入Razor引擎) AntiXSS：微软的XSS防御库Microsoft Web Protection Library Jint：JavaScript解释器 CS-Script：将C#代码文件作为脚本执行 Jexus：Linux下 高性能、易用、免费的ASP.NET服务器 Clay：将dynamic发挥的更加灵活，像写js一样写C# DynamicJSON：不必定义数据模型获取json数据 SharpPcap：C#版的WinPcap调用端，牛逼的网络包分析库（自带PacketNotNet用于包协议分析） Roslyn：C#，VB编译器 ImageResizer: 服务端自由控制图片大小，真乃神器也，对手机端传小图，PC端传大图，CMS用它很方便 UI相关：DevExpress, Fluent(Office 07风格), mui（Modern UI for WPF） NetSparkle：应用自动更新组件 ConfuserEx: 开源.net混淆工具 ServiceStack: 开源高性能Web服务框架，可用于构建高性能的REST服务 Expression Evaluator：Eval for C#,处理字符串表达式 http://nugetmusthaves.com/ Reactive Extensions (Rx):异步，事件驱动编程包， Rx = Observables + LINQ + Schedulers C &amp; C++ Thrift:用来进行可扩展且跨语言的服务的开发(类似的还有个Avro，Google protobuf)。 libevent:是一个事件触发的网络库，适用于windows、linux、bsd等多种平台，内部使用select、epoll、kqueue等系统调用管理事件机制。（对了还有个libev呢） Boost:不多说了，准C++标准库 Valgrind\\Ptmalloc\\Purify: 调试工具 NetworkServer架构：acceptor-&gt;dispatcher-&gt;worker(这个不算工具哦) POCO - 开源的C++类库及应用程序框架的集合,它主要提供简单的、快速的网络和可移植应用程序 breakpad:崩溃转储和分析模块，很多crashreport会用到 UI界面相关：MFC、BCG和QT这类的就不说了，高端一点的还有Html和DirectUI技术：libcef（基于chrome内核的，想想使用html5开发页面，还真有点小激动呢）、HtmlLayout、Duilib、Bolt，非C++的，还有node-webkit也不错，集成了node和webkit内核。 其他游戏开发相关 MINA：使用Java开发手游和页游服务器(对了还有Netty，也很猛的，都是基于NIO的) HP-Socket：见有有些页游服务器使用这个构建的 Unreal: 虚幻引擎，C++，基于这个引擎的游戏很多 OGRE：大名鼎鼎的3D图形渲染引擎，天龙八部OL、火炬之光等不少游戏都用了这个引擎 OpenVDB：梦工厂C++的特效库，开源的 cocos2d：跨平台2D游戏引擎 unity3d：跨平台3D游戏引擎，很火的哦 Nodejs：也有不少使用它来开发手游和也有服务器（网易的Pomelo） 日志聚合，分布式日志收集 Scribe：Facebook的（nodejs + scribe + inotify 同步日志） logstash:强大的日志收集系统，可以基于logstash+kibana+elasticsearch+redis开发强大的日志分析平台 log.io: nodejs开发的实时日志收集系统 RTP,实时传输协议与音视频 RTP，RTCP，RTSP-&gt; librtp，JRTPLIB(遵循了RFC1889标准) 环形缓冲区，实时数据传输用 SDL,ffmpeg,live555,Speex Red5:用Java开发开源的Flash流媒体服务器。它支持：把音频（MP3）和视频（FLV）转换成播放流； 录制客户端播放流（只支持FLV）；共享对象；现场直播流发布；远程调用。","raw":null,"content":null,"categories":[{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/categories/学习资料/"}],"tags":[{"name":"好文转载","slug":"好文转载","permalink":"http://linbingdong.com/tags/好文转载/"},{"name":"学习资料","slug":"学习资料","permalink":"http://linbingdong.com/tags/学习资料/"}]},{"title":"纠删码（Erasure Code）浅析","slug":"纠删码（Erasure Code）浅析","date":"2017-03-11T12:33:42.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2017/03/11/纠删码（Erasure Code）浅析/","link":"","permalink":"http://linbingdong.com/2017/03/11/纠删码（Erasure Code）浅析/","excerpt":"【摘要】：副本策略和纠删码是存储领域常见的两种数据冗余技术。相比于副本策略，纠删码具有更高的磁盘利用率。 Reed-Solomon码是一种常见的纠删码。","text":"【摘要】：副本策略和纠删码是存储领域常见的两种数据冗余技术。相比于副本策略，纠删码具有更高的磁盘利用率。 Reed-Solomon码是一种常见的纠删码。 多副本策略即将数据存储多个副本（一般是三副本，比如HDFS），当某个副本丢失时，可以通过其他副本复制回来。三副本的磁盘利用率为1/3。 纠删码技术主要是通过纠删码算法将原始的数据进行编码得到冗余，并将数据和冗余一并存储起来，以达到容错的目的。其基本思想是将n块原始的数据元素通过一定的计算，得到m块冗余元素（校验块）。对于这n+m块的元素，当其中任意的m块元素出错（包括原始数据和冗余数据）时，均可以通过对应的重构算法恢复出原来的n块数据。生成校验的过程被成为编码（encoding），恢复丢失数据块的过程被称为解码（decoding）。磁盘利用率为n/(n+m)。基于纠删码的方法与多副本方法相比具有冗余度低、磁盘利用率高等优点。 两种冗余技术对比如下表： 两种技术 磁盘利用率 计算开销 网络消耗 恢复效率 多副本(3副本) 1/3 几乎没有 较低 较高 纠删码(n+m) n/(n+m) 高 较高 较低 Reed-Solomon(RS)码Reed-Solomon（RS）码是存储系统较为常用的一种纠删码，它有两个参数n和m，记为RS(n,m)。n代表原始数据块个数。m代表校验块个数。接下来介绍RS码的原理。 RS码原理以n=5，m=3为例。即5个原始数据块，乘上一个(n+m)*n的矩阵，然后得出一个(n+m)*1的矩阵。根据矩阵特点可以得知结果矩阵中前面5个值与原来的5个数据块的值相等，而最后3个则是计算出来的校验块。 以上过程为编码过程。D是原始数据块，得到的C为校验块。 假设丢失了m块数据。如下： 那我们如何从剩余的n个数据块（注意，这里剩余的n块可能包含几个原始数据块+几个校验块）恢复出来原始的n个数据块呢，就需要通过下面的decoding（解码）过程来实现。 第一步：从编码矩阵中删去丢失数据块和丢失编码块对应行。 将删掉m个块的(n+m)*1个矩阵变形为n*1矩阵，同时B矩阵也需要删掉对应的m个行得出一个B’的变形矩阵，这个B’就是n*n矩阵。如下：假设D1、D4、C2丢失，我们得到如下B’矩阵及等式。 第二步：求出B’的逆矩阵。 第三步：等式两边分别乘上B’的逆矩阵。 B’和它的逆矩阵相乘得到单位矩阵I，如下： 左边只剩下原始数据矩阵D： 至此完成解码过程。 注：图中黄色部分为范德蒙矩阵。至于如何生成B矩阵，以及如何求B’的逆矩阵，请查看其他相关文献，这里不再赘述。 小结RS的特点： 低冗余度，高磁盘利用率。 数据恢复代价高。 丢失数据块或者编码块时， RS需要读取n个数据块和校验块才能恢复数据， 数据恢复效率也在一定程度上制约了RS的可靠性。 数据更新代价高。 数据更新相当于重新编码， 代价很高， 因此常常针对只读数据，或者冷数据。 工程实践中，一般对于热数据还是会使用多副本策略来冗余，冷数据使用纠删码。 值得期待的是，纠删码技术也即将在Hadoop 3.0中发布。 参考资料 论文《Erasure Codes for Storage Applications》 论文《存储系统中纠删码研究综述》","raw":null,"content":null,"categories":[{"name":"纠删码","slug":"纠删码","permalink":"http://linbingdong.com/categories/纠删码/"}],"tags":[{"name":"存储","slug":"存储","permalink":"http://linbingdong.com/tags/存储/"},{"name":"数据冗余","slug":"数据冗余","permalink":"http://linbingdong.com/tags/数据冗余/"},{"name":"纠删码","slug":"纠删码","permalink":"http://linbingdong.com/tags/纠删码/"}]},{"title":"对称的二叉树","slug":"对称的二叉树","date":"2017-02-23T16:00:00.000Z","updated":"2017-03-26T14:45:23.000Z","comments":true,"path":"2017/02/24/对称的二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/24/对称的二叉树/","excerpt":"题目描述\n请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。","text":"题目描述 请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。 分析 如果该二叉树的左右子树互为镜像，则该二叉树为对称的二叉树。两个二叉树 a,b 互为镜像，即 a 的左子树跟 b 的右子树互为镜像，且 a 的右子树跟 b 的左子树互为镜像。递归一下，so easy ! 妈妈再也不用担心我的二叉树问题了。 代码: public class Solution &#123; boolean isSymmetrical(TreeNode pRoot) &#123; if (pRoot == null) return true; return isSymmetrical(pRoot.left, pRoot.right); &#125; boolean isSymmetrical(TreeNode pRoot1, TreeNode pRoot2) &#123; if (pRoot1 == null &amp;&amp; pRoot2 == null) return true; if (pRoot1 == null || pRoot2 == null) return false; if (pRoot1.val != pRoot2.val) return false; return isSymmetrical(pRoot1.left, pRoot2.right) &amp;&amp; isSymmetrical(pRoot1.right, pRoot2.left); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"按之字形顺序打印二叉树","slug":"按之字形顺序打印二叉树","date":"2017-02-23T16:00:00.000Z","updated":"2017-03-26T14:45:11.000Z","comments":true,"path":"2017/02/24/按之字形顺序打印二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/24/按之字形顺序打印二叉树/","excerpt":"题目描述\n请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。","text":"题目描述 请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。 分析 跟把二叉树打印成多行一样，只不过在偶数行需要反转一下。 代码: import java.util.ArrayList;import java.util.Queue;import java.util.LinkedList;import java.util.Collections;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; resultList = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if (pRoot == null) return resultList; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); q.offer(pRoot); boolean reverse = false; while (!q.isEmpty()) &#123; int size = q.size(); ArrayList&lt;Integer&gt; levelList = new ArrayList&lt;Integer&gt;(); while (size-- &gt; 0) &#123; TreeNode node = q.poll(); levelList.add(node.val); if (node.left != null) q.offer(node.left); if (node.right != null) q.offer(node.right); &#125; if (reverse) Collections.reverse(levelList); resultList.add(levelList); reverse = !reverse; &#125; return resultList; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"把二叉树打印成多行","slug":"把二叉树打印成多行","date":"2017-02-23T16:00:00.000Z","updated":"2017-03-26T14:45:17.000Z","comments":true,"path":"2017/02/24/把二叉树打印成多行/","link":"","permalink":"http://linbingdong.com/2017/02/24/把二叉树打印成多行/","excerpt":"题目描述\n从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。","text":"题目描述 从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。 分析 就是层序遍历，不再赘述。 代码: import java.util.ArrayList;import java.util.Queue;import java.util.LinkedList;public class Solution &#123; ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; resultList = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if (pRoot == null) return resultList; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); q.offer(pRoot); while (!q.isEmpty()) &#123; int size = q.size(); ArrayList&lt;Integer&gt; levelList = new ArrayList&lt;Integer&gt;(); while (size-- &gt; 0) &#123; TreeNode node = q.poll(); levelList.add(node.val); if (node.left != null) q.offer(node.left); if (node.right != null) q.offer(node.right); &#125; resultList.add(levelList); &#125; return resultList; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"二叉树的下一个节点","slug":"二叉树的下一个节点","date":"2017-02-23T16:00:00.000Z","updated":"2017-03-26T14:44:59.000Z","comments":true,"path":"2017/02/24/二叉树的下一个节点/","link":"","permalink":"http://linbingdong.com/2017/02/24/二叉树的下一个节点/","excerpt":"题目描述\n给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。","text":"题目描述 给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。 分析 如果右子树不为空，则下一节点为右子树最左边的节点。 如果右子树为空，如果父节点为空，则返回空。 如果该节点是其父节点的左孩子，则返回其父节点。 否则依次往上找父节点，知道某个节点是其父节点的左孩子，返回该节点的父节点 代码: public class Solution &#123; public TreeLinkNode GetNext(TreeLinkNode pNode)&#123; if (pNode == null) return null; if (pNode.right != null) &#123; TreeLinkNode node = pNode.right; while (node.left != null) node = node.left; return node; &#125; if (pNode.next == null) return null; if (pNode == pNode.next.left) return pNode.next; TreeLinkNode node = pNode.next; while (node.next != null &amp;&amp; node != node.next.left) node = node.next; if (node.next != null) return node.next; return null; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"平衡二叉树","slug":"平衡二叉树","date":"2017-02-23T16:00:00.000Z","updated":"2017-03-26T14:45:28.000Z","comments":true,"path":"2017/02/24/平衡二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/24/平衡二叉树/","excerpt":"题目描述\n输入一棵二叉树，判断该二叉树是否是平衡二叉树。","text":"题目描述 输入一棵二叉树，判断该二叉树是否是平衡二叉树。 分析 判断是否平衡二叉树的关键就是判断左右子树的高度差是否大于1。问题转化成分别求左右子树的高度。树的高度为其左右字数高度的较大值加1。 代码: public class Solution &#123; public boolean IsBalanced_Solution(TreeNode root) &#123; if (root == null) return true; return Math.abs(depth(root.left) - depth(root.right)) &gt; 1 ? false : true; &#125; public int depth(TreeNode root) &#123; if (root == null) return 0; return 1 + Math.max(depth(root.left), depth(root.right)); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"二叉树中和为某一值的路径","slug":"二叉树中和为某一值的路径","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:45:50.000Z","comments":true,"path":"2017/02/23/二叉树中和为某一值的路径/","link":"","permalink":"http://linbingdong.com/2017/02/23/二叉树中和为某一值的路径/","excerpt":"题目描述\n输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。","text":"题目描述 输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。 分析 递归，分别在左右子树里找符合 target = target - root.val 的路径。 代码: import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindPath(TreeNode root,int target) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; pathList = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if (root == null || root.val &gt; target) return pathList; ArrayList&lt;Integer&gt; path = new ArrayList&lt;Integer&gt;(); FindPath(root, target, pathList, path); return pathList; &#125; public void FindPath(TreeNode root, int target, ArrayList&lt;ArrayList&lt;Integer&gt;&gt; pathList, ArrayList&lt;Integer&gt; path) &#123; if (root == null || root.val &gt; target) &#123; path.clear(); &#125; else if (root.val == target) &#123; if (root.left == null &amp;&amp; root.right == null) &#123; path.add(root.val); pathList.add(path); &#125; else path.clear(); &#125; else &#123; path.add(root.val); target -= root.val; ArrayList&lt;Integer&gt; path2 = new ArrayList&lt;Integer&gt;(); path2.addAll(path); FindPath(root.left, target, pathList, path); FindPath(root.right, target, pathList, path2); &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"旋转数组的最小数字","slug":"旋转数组的最小数字","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:46:33.000Z","comments":true,"path":"2017/02/23/旋转数组的最小数字/","link":"","permalink":"http://linbingdong.com/2017/02/23/旋转数组的最小数字/","excerpt":"题目描述\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。","text":"题目描述 把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。 分析 思路一： 从前往后遍历，如果发现 array[i] &gt; array[i+1] ，则 array[i+1] 为最小值。否则 array[0] 为最小值。 思路二： 用二分查找。 代码: 思路一： import java.util.ArrayList;public class Solution &#123; public int minNumberInRotateArray(int [] array) &#123; int len = array.length; if (len == 0) &#123; return 0; &#125; if (array[0] &lt; array[len-1]) &#123; return array[0]; &#125; for (int i = 0; i &lt; len - 1; i++) &#123; if (array[i] &gt; array[i+1]) &#123; return array[i+1]; &#125; &#125; return array[0]; &#125;&#125; 思路二：（二分查找） import java.util.ArrayList;public class Solution &#123; public int minNumberInRotateArray(int [] array) &#123; int low = 0; int high = array.length - 1; while (low &lt; high) &#123; int mid = low + (high - low) / 2; if (array[mid] &gt; array[high]) &#123; low = mid + 1; &#125; else if (array[mid] == array[high]) &#123; high--; &#125; else &#123; high = mid; &#125; &#125; return array[low]; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"LeetCode[106] Construct Binary Tree from Inorder and Postorder Traversal","slug":"LeetCode[106] Construct Binary Tree from Inorder and Postorder Traversal","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:46:08.000Z","comments":true,"path":"2017/02/23/LeetCode[106] Construct Binary Tree from Inorder and Postorder Traversal/","link":"","permalink":"http://linbingdong.com/2017/02/23/LeetCode[106] Construct Binary Tree from Inorder and Postorder Traversal/","excerpt":"Given inorder and postorder traversal of a tree, construct the binary tree.","text":"Given inorder and postorder traversal of a tree, construct the binary tree. 分析: 本题是重建二叉树（后序加中序），跟重建二叉树（先序加中序）思路一样。 代码: public class Solution &#123; public TreeNode buildTree(int[] inorder, int[] postorder) &#123; return rebuildTree(postorder, 0, postorder.length, inorder, 0, inorder.length); &#125; TreeNode rebuildTree(int[] postorder, int begin1, int end1, int[] inorder, int begin2, int end2) &#123; if (begin1 == end1) return null; TreeNode root = new TreeNode(postorder[end1 - 1]); int inPos = find(inorder, begin2, end2, postorder[end1 - 1]); int rightSize = end2 - inPos - 1; root.right = rebuildTree(postorder, end1 - rightSize - 1, end1 - 1, inorder, inPos + 1, end2); root.left = rebuildTree(postorder, begin1, end1 - rightSize - 1, inorder, begin2, inPos); return root; &#125; int find(int[] in, int begin2, int end2, int val) &#123; for (int i = begin2; i &lt; end2; i++) &#123; if (in[i] == val) return i; &#125; return -1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://linbingdong.com/tags/LeetCode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"滑动窗口的最大值","slug":"滑动窗口的最大值","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:46:23.000Z","comments":true,"path":"2017/02/23/滑动窗口的最大值/","link":"","permalink":"http://linbingdong.com/2017/02/23/滑动窗口的最大值/","excerpt":"题目描述\n给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。","text":"题目描述 给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。 分析 如果用暴力解决，可以扫描每个滑动窗口的所有数字并找出其中的最大值，如果数组长度为 n ，滑动窗口的长度为 k ，则时间复杂度为O(nk)。 换一种思路。使用一个双端队列，只把可能成为滑动窗口最大值的数加入队列，队头是最大值。每次有新值加入时，将它与队尾元素一一比较，若队尾元素小于它，则删除队尾元素，最后将该新值加入队列。如果队头元素已在滑动窗口之外，将队头元素删除。 代码: import java.util.ArrayDeque;import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; maxInWindows(int [] num, int size)&#123; ArrayList&lt;Integer&gt; maxList = new ArrayList&lt;Integer&gt;(); ArrayDeque&lt;Integer&gt; dq = new ArrayDeque&lt;Integer&gt;(); if (size == 0 || size &gt; num.length) &#123; return maxList; &#125; for (int i = 0; i &lt; size; i++) &#123; while (!dq.isEmpty() &amp;&amp; num[i] &gt; num[dq.peekLast()]) &#123; dq.pollLast(); &#125; dq.add(i); &#125; for (int i = size; i &lt; num.length; i++) &#123; maxList.add(num[dq.peekFirst()]); while (!dq.isEmpty() &amp;&amp; num[i] &gt; num[dq.peekLast()]) &#123; dq.pollLast(); &#125; dq.add(i); if (dq.peekFirst() &lt;= i - size) &#123; dq.pollFirst(); &#125; &#125; maxList.add(num[dq.peekFirst()]); return maxList; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"重建二叉树","slug":"重建二叉树","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:46:15.000Z","comments":true,"path":"2017/02/23/重建二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/23/重建二叉树/","excerpt":"题目描述\n输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。","text":"题目描述 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 分析 先序遍历第一个数为根节点。找到根节点在中序遍历中的位置，可得左子树的长度，进而可分别得到左右子树的先序和中序遍历，递归。 代码: public class Solution &#123; public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; return buildTree(pre, 0, pre.length, in, 0, in.length); &#125; TreeNode buildTree(int[] pre, int begin1, int end1, int[] in, int begin2, int end2) &#123; if (begin1 == end1) return null; TreeNode root = new TreeNode(pre[begin1]); int inPos = find(in, begin2, end2, pre[begin1]); int leftSize = inPos - begin2; root.left = buildTree(pre, begin1 + 1, begin1 + leftSize + 1, in, begin2, begin2 + leftSize); root.right = buildTree(pre, begin1 + leftSize + 1, end1, in, inPos + 1, end2); return root; &#125; int find(int[] in, int begin2, int end2, int val) &#123; for (int i = begin2; i &lt; end2; i++) &#123; if (in[i] == val) return i; &#125; return -1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"二叉树的深度","slug":"二叉树的深度","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:45:56.000Z","comments":true,"path":"2017/02/23/二叉树的深度/","link":"","permalink":"http://linbingdong.com/2017/02/23/二叉树的深度/","excerpt":"题目描述\n输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。","text":"题目描述 输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 分析 递归：二叉树的深度为其左右子树深度中大的那个数加1。两行代码搞定。 迭代：利用层序遍历，算出总共有几层，就是二叉树的深度。 代码: 递归： public class Solution &#123; public int TreeDepth(TreeNode root) &#123; if (root == null) return 0; return 1 + Math.max(TreeDepth(root.left), TreeDepth(root.right)); &#125;&#125; 迭代： import java.util.Queue;import java.util.LinkedList;public class Solution &#123; public int TreeDepth(TreeNode root) &#123; if (root == null) return 0; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); int count = 0; q.offer(root); while (!q.isEmpty()) &#123; int size = q.size(); while (size-- &gt; 0) &#123; TreeNode node = q.poll(); if (node.left != null) q.offer(node.left); if (node.right != null) q.offer(node.right); &#125; count++; &#125; return count; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"从上到下打印二叉树","slug":"从上到下打印二叉树","date":"2017-02-22T16:00:00.000Z","updated":"2017-03-26T14:46:02.000Z","comments":true,"path":"2017/02/23/从上到下打印二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/23/从上到下打印二叉树/","excerpt":"题目描述\n从上往下打印出二叉树的每个节点，同层节点从左至右打印。","text":"题目描述 从上往下打印出二叉树的每个节点，同层节点从左至右打印。 分析 其实就是二叉树的层序遍历，使用一个队列即可实现。 代码: public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); ArrayList&lt;Integer&gt; alist = new ArrayList&lt;Integer&gt;(); if (root == null) return alist; q.offer(root); while (!q.isEmpty()) &#123; TreeNode node = q.poll(); alist.add(node.val); if (node.left != null) q.offer(node.left); if (node.right != null) q.offer(node.right); &#125; return alist; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"二叉树的镜像","slug":"二叉树的镜像","date":"2017-02-22T16:00:00.000Z","updated":"2017-04-19T15:35:39.000Z","comments":true,"path":"2017/02/23/二叉树的镜像/","link":"","permalink":"http://linbingdong.com/2017/02/23/二叉树的镜像/","excerpt":"题目描述\n操作给定的二叉树，将其变换为源二叉树的镜像。 \n输入描述:\n二叉树的镜像定义：\n  源二叉树     8   /  \\  6   10 / \\  / \\5  7 9  11镜像二叉树    8   /  \\  10   6 / \\  / \\11 9 7   5","text":"题目描述 操作给定的二叉树，将其变换为源二叉树的镜像。 输入描述: 二叉树的镜像定义： 源二叉树 8 / \\ 6 10 / \\ / \\5 7 9 11镜像二叉树 8 / \\ 10 6 / \\ / \\11 9 7 5 分析 用递归可以很方便地解决。 如果不用递归的话，可以借助队列来实现。思想类似于二叉树的层序遍历 代码: 递归： public class Solution &#123; public void Mirror(TreeNode root) &#123; if (root == null) return; TreeNode temp = root.left; root.left = root.right; root.right = temp; Mirror(root.left); Mirror(root.right); &#125;&#125; 迭代： import java.util.Queue;import java.util.LinkedList;public class Solution &#123; public void Mirror(TreeNode root) &#123; Queue&lt;TreeNode&gt; q = new LinkedList&lt;TreeNode&gt;(); if (root == null) return; q.offer(root); while (!q.isEmpty()) &#123; TreeNode node = q.poll(); TreeNode temp = node.left; node.left = node.right; node.right = temp; if (node.left != null) q.offer(node.left); if (node.right != null) q.offer(node.right); &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"最小的k个数","slug":"最小的k个数","date":"2017-02-20T16:00:00.000Z","updated":"2017-04-19T15:39:40.000Z","comments":true,"path":"2017/02/21/最小的k个数/","link":"","permalink":"http://linbingdong.com/2017/02/21/最小的k个数/","excerpt":"题目描述\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。","text":"题目描述 输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 分析 堆排序。小根堆。 代码: import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int [] input, int k) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if (input.length &lt; k) return list; int len = input.length; for (int i = (len - 2) / 2; i &gt;= 0; i--) &#123; adjustHeap(input, i, len - 1); &#125; for (int i = len - 1; i &gt; len - 1 - k; i--) &#123; list.add(input[0]); input[0] = input[i]; adjustHeap(input, 0, i-1); &#125; return list; &#125; public static void adjustHeap(int[] a, int head, int tail) &#123; int i = head; for (int j = 2*i + 1; j &lt; tail; j = 2*i + 1) &#123; if (a[j+1] &lt; a[j]) j++; if (a[i] &lt;= a[j]) break; int temp = a[i]; a[i] = a[j]; a[j] = temp; i = j; &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"把字符串转换成整数","slug":"把字符串转换成整数","date":"2017-02-19T16:00:00.000Z","updated":"2017-04-20T06:11:21.000Z","comments":true,"path":"2017/02/20/把字符串转换成整数/","link":"","permalink":"http://linbingdong.com/2017/02/20/把字符串转换成整数/","excerpt":"题目描述\n将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。数值为0或者字符串不是一个合法的数值则返回0。\n输入描述:\n\n输入一个字符串,包括数字字母符号,可以为空\n\n输出描述:\n\n如果是合法的数值表达则返回该数字，否则返回0\n\n输入例子:\n\n+2147483647\n   1a33\n\n输出例子:\n\n2147483647\n   0\n","text":"题目描述 将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。数值为0或者字符串不是一个合法的数值则返回0。 输入描述: 输入一个字符串,包括数字字母符号,可以为空 输出描述: 如果是合法的数值表达则返回该数字，否则返回0 输入例子: +2147483647 1a33 输出例子: 2147483647 0 分析 首先判断特殊情况： 字符串为空 除符号为外含有非数字 整数大于Integer.MAX_VALUE或小于Integer.MIN_VALUE 如何将字符转换成数字？ str.charAt(index) - ‘0’ 代码: public class Solution &#123; public int StrToInt(String str) &#123; int len = str.length(), index = 0, total = 0, sign = 1; if (len == 0) return 0; str.trim(); if (str.charAt(index) == '+' || str.charAt(index) == '-') &#123; sign = str.charAt(index) == '+' ? 1 : -1; index++; &#125; while (index &lt; len) &#123; int digit = str.charAt(index) - '0'; if (digit &gt; 9 || digit &lt; 0) &#123; return 0; &#125; total = total * 10 + digit; if (total &gt; Integer.MAX_VALUE || total &lt; Integer.MIN_VALUE) &#123; return 0; &#125; index++; &#125; return total * sign; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"序列化二叉树","slug":"序列化二叉树","date":"2017-02-17T16:00:00.000Z","updated":"2017-05-03T01:04:26.000Z","comments":true,"path":"2017/02/18/序列化二叉树/","link":"","permalink":"http://linbingdong.com/2017/02/18/序列化二叉树/","excerpt":"题目描述\n请实现两个函数，分别用来序列化和反序列化二叉树","text":"题目描述 请实现两个函数，分别用来序列化和反序列化二叉树 分析 先序遍历，递归。 代码: public class Solution &#123; public int index = -1; StringBuilder sb = new StringBuilder(); String Serialize(TreeNode root) &#123; if (root == null)&#123; sb.append(\"#,\"); return sb.toString(); &#125; sb.append(root.val + \",\"); Serialize(root.left); Serialize(root.right); return sb.toString(); &#125; TreeNode Deserialize(String str) &#123; index++; int len = str.length(); if(index &gt; len) return null; String[] strr = str.split(\",\"); TreeNode node = null; if(!strr[index].equals(\"#\"))&#123; node = new TreeNode(Integer.valueOf(strr[index])); node.left = Deserialize(str); node.right = Deserialize(str); &#125; return node; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"数字在排序数组中出现的次数","slug":"数字在排序数组中出现的次数","date":"2017-02-16T16:00:00.000Z","updated":"2017-05-04T12:40:28.000Z","comments":true,"path":"2017/02/17/数字在排序数组中出现的次数/","link":"","permalink":"http://linbingdong.com/2017/02/17/数字在排序数组中出现的次数/","excerpt":"题目描述\n统计一个数字在排序数组中出现的次数。","text":"题目描述 统计一个数字在排序数组中出现的次数。 分析 因为有序，所以二分查找。先用二分查找找到该数字的位置，再从该位置分别往左往右计算两边跟他相等的个数。最后相加。 代码: public class Solution &#123; public int GetNumberOfK(int [] array , int k) &#123; int index = binaryFindK(array, 0, array.length - 1, k); if (index == -1) return 0; int ind = index; int leftCount, rightCount; leftCount = rightCount = 0; while ((index - 1) &gt;= 0 &amp;&amp; array[--index] == k) leftCount++; while ((ind + 1) &lt; array.length &amp;&amp; array[++ind] == k) rightCount++; return 1 + leftCount + rightCount; &#125; public int binaryFindK(int [] array, int low, int high, int k) &#123; if (low &lt;= high) &#123; int mid = low + (high-low) / 2; if (array[mid] == k) return mid; else if (array[mid] &lt; k) binaryFindK(array, mid+1, high, k); else binaryFindK(array, low, mid-1, k); &#125; return -1; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/categories/数据结构与算法/"},{"name":"编程题","slug":"数据结构与算法/编程题","permalink":"http://linbingdong.com/categories/数据结构与算法/编程题/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://linbingdong.com/tags/数据结构与算法/"},{"name":"编程题","slug":"编程题","permalink":"http://linbingdong.com/tags/编程题/"}]},{"title":"Python用yield生成杨辉三角","slug":"Python用yield生成杨辉三角","date":"2017-02-15T16:00:00.000Z","updated":"2017-03-26T14:55:40.000Z","comments":true,"path":"2017/02/16/Python用yield生成杨辉三角/","link":"","permalink":"http://linbingdong.com/2017/02/16/Python用yield生成杨辉三角/","excerpt":"so funny","text":"so funny 代码： def triangles(): n = 0 line = [1] while n &lt; 10: yield(line) line.append(0) line = [line[i-1] + line[i] for i in range(len(line))] n += 1for line in triangles(): print(line) 输出： [1][1, 1][1, 2, 1][1, 3, 3, 1][1, 4, 6, 4, 1][1, 5, 10, 10, 5, 1][1, 6, 15, 20, 15, 6, 1][1, 7, 21, 35, 35, 21, 7, 1][1, 8, 28, 56, 70, 56, 28, 8, 1][1, 9, 36, 84, 126, 126, 84, 36, 9, 1]","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://linbingdong.com/tags/Python/"}]},{"title":"Hive on Spark调优","slug":"Hive on Spark调优","date":"2016-11-29T16:00:00.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2016/11/30/Hive on Spark调优/","link":"","permalink":"http://linbingdong.com/2016/11/30/Hive on Spark调优/","excerpt":"之前在Hive on Spark跑TPCx-BB测试时，100g的数据量要跑十几个小时，一看CPU和内存的监控，发现    POWER_TEST阶段（依次执行30个查询）CPU只用了百分之十几，也就是没有把整个集群的性能利用起来，导致跑得很慢。因此，如何调整参数，使整个集群发挥最大性能显得尤为重要。","text":"之前在Hive on Spark跑TPCx-BB测试时，100g的数据量要跑十几个小时，一看CPU和内存的监控，发现 POWER_TEST阶段（依次执行30个查询）CPU只用了百分之十几，也就是没有把整个集群的性能利用起来，导致跑得很慢。因此，如何调整参数，使整个集群发挥最大性能显得尤为重要。 Spark作业运行原理 详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。 Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。 task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。 以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。 参数调优了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分。 num-executors/spark.executor.instances 参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。 参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。 executor-memory/spark.executor.memory 参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。 参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。 executor-cores/spark.executor.cores 参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。 参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。 driver-memory 参数说明：该参数用于设置Driver进程的内存。 参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。 spark.default.parallelism 参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。 参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。 spark.storage.memoryFraction 参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。 参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。 spark.shuffle.memoryFraction 参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。 参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。 调优过程数据量：10g 可以看出： 随着每个executor占用的CPU core数增加，q04查询的时间显著下降，q03也下降，但幅度没那么大。 本次调优只设置了spark.executor.memory和spark.executor.cores两个参数，没有涉及到spark.executor.instances参数，而默认的spark.executor.instances为2，也就是每个作业只用到2个executor，因此还没将性能发挥到最佳。 接下来采用100g的数据量，并且增加spark.executor.instances参数的设置。 数据量：100g 可以看出： 调优前后查询时间有了很大的飞跃； 增加spark.executor.instances设置项指定每个作业占用的executor个数后性能又有很大提升（通过监控我们发现此时CPU利用率平均有好几十，甚至可以高到百分之九十几）； 至此，我们终于将整个集群性能充分发挥出来，达到目的。 最后一列配置项是根据美团技术团队博客的建议设置的，可以看出性能相比我们之前自己的设置还是有一定提升的，至少该博客里建议的设置是比较通用的，因此之后我们都采取最后一列的设置来跑TPCx-BB测试。 最后来张大图展示调优前和调优后跑100g数据的对比： 可以看出： 绝大多数查询调优前后查询时间有了极大的飞跃； 但是像q01/q04/q14…这几个查询，可能因为查询涉及到的表比较小，调优前时间就很短，因此调优后也看不出很多差别，如果想看到大的差别，可能需要提高数据量，比如1T，3T； q10和q18调优前后时间都较长，而且调优后性能没有提升，需要再深入探索下是什么原因。 最后，用调优后的集群，分别跑10g、30g、100g的数据，结果如下： 可以看出： 随着数据量增大，很多查询时间并没有明显增加，可能是因为集群性能太强，而且数据量还不够大，可以增大数据量继续观察 对于q10、q18和q30，随着数据量增大，时间明显增大，需再深入分析 参考文献http://tech.meituan.com/spark-tuning-basic.html","raw":null,"content":null,"categories":[{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/categories/Hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/tags/Hive/"},{"name":"Spark","slug":"Spark","permalink":"http://linbingdong.com/tags/Spark/"}]},{"title":"Hive on Spark安装配置详解","slug":"Hive on Spark安装配置详解","date":"2016-10-09T16:00:00.000Z","updated":"2017-03-11T12:33:42.000Z","comments":true,"path":"2016/10/10/Hive on Spark安装配置详解/","link":"","permalink":"http://linbingdong.com/2016/10/10/Hive on Spark安装配置详解/","excerpt":"简介本文主要记录如何安装配置Hive on Spark，在执行以下步骤之前，请先确保已经安装Hadoop集群，Hive，MySQL，JDK，Scala，具体安装步骤不再赘述。","text":"简介本文主要记录如何安装配置Hive on Spark，在执行以下步骤之前，请先确保已经安装Hadoop集群，Hive，MySQL，JDK，Scala，具体安装步骤不再赘述。 背景Hive默认使用MapReduce作为执行引擎，即Hive on mr。实际上，Hive还可以使用Tez和Spark作为其执行引擎，分别为Hive on Tez和Hive on Spark。由于MapReduce中间计算均需要写入磁盘，而Spark是放在内存中，所以总体来讲Spark比MapReduce快很多。因此，Hive on Spark也会比Hive on mr快。为了对比Hive on Spark和Hive on mr的速度，需要在已经安装了Hadoop集群的机器上安装Spark集群（Spark集群是建立在Hadoop集群之上的，也就是需要先装Hadoop集群，再装Spark集群，因为Spark用了Hadoop的HDFS、YARN等），然后把Hive的执行引擎设置为Spark。 Spark运行模式分为三种1、Spark on YARN 2、Standalone Mode 3、Spark on Mesos。Hive on Spark默认支持Spark on YARN模式，因此我们选择Spark on YARN模式。Spark on YARN就是使用YARN作为Spark的资源管理器。分为Cluster和Client两种模式。 一、环境说明本教程Hadoop相关软件全部基于CDH5.5.1，用yum安装，系统环境如下： 操作系统：CentOS 7.2 Hadoop 2.6.0 Hive1.1.0 Spark1.5.0 MySQL 5.6 JDK 1.8 Maven 3.3.3 Scala 2.10 各节点规划如下： 192.168.117.51 Goblin01 nn1 jn1 rm1 worker master hive metastore mysql192.168.117.52 Goblin02 zk2 nn2 jn2 rm2 worker hive192.168.117.53 Goblin03 zk3 dn1 jn3 worker hive192.168.117.54 Goblin04 zk4 dn2 worker hive 说明：Goblin01~04是每台机器的hostname，zk代表zookeeper，nn代表hadoop的namenode，dn代表datanode，jn代表journalnode，rm代表resourcemanager，worker代表Spark的slaves，master代表Spark的master 二、编译和安装Spark（Spark on YARN）2.1 编译Spark源码要使用Hive on Spark，所用的Spark版本必须不包含Hive的相关jar包，hive on spark 的官网上说“Note that you must have a version of Spark which does not include the Hive jars”。在spark官网下载的编译的Spark都是有集成Hive的，因此需要自己下载源码来编译，并且编译的时候不指定Hive。 我们这里用的Spark源码是spark-1.5.0-cdh5.5.1版本,下载地址如下： http://archive.cloudera.com/cdh5/cdh/5/spark-1.5.0-cdh5.5.1-src.tar.gz 下载完后用 tar xzvf 命令解压，进入解压完的文件夹，准备编译。 注意：编译前请确保已经安装JDK、Maven和Scala，maven为3.3.3及以上版本，并在/etc/profile里配置环境变量。 命令行进入在源码根目录下，执行 ./make-distribution.sh --name &quot;hadoop2-without-hive&quot; --tgz &quot;-Pyarn,hadoop-provided,hadoop-2.6,parquet-provided&quot; 若编译过程出现内存不足的情况，需要在运行编译命令之前先运行： export MAVEN_OPTS=&quot;-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m&quot; 来设置Maven的内存。 编译过程由于要下载很多Maven依赖的jar包，需要时间较长（大概一两个小时），要保证网络状况良好，不然很容易编译失败。若出现以下结果，则编译成功： 编译成功后，会在源码根目录下多出一个文件(红色部分）： spark-1.5.0-cdh5.5.1-bin-hadoop2-without-hive.tgz 2.2 安装Spark 将编译完生成的spark-1.5.0-cdh5.5.1-bin-hadoop2-without-hive.tgz拷贝到Spark的安装路径，并用 tar -xzvf 命令解压 配置环境变量 $vim /etc/profileexport SPARK_HOME=spark安装路径$source /etc/profile 2.3 配置Spark配置spark-env.sh、slaves和spark-defaults.conf三个文件 spark-env.sh 主要配置JAVA\\_HOME、SCALA\\_HOME、HADOOP\\_HOME、HADOOP\\_CONF\\_DIR、SPARK\\_MASTER\\_IP等 export JAVA_HOME=/usr/lib/jvm/javaexport SCALA_HOME=/root/scalaexport HADOOP_HOME=/usr/lib/hadoopexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoopexport SPARK_LAUNCH_WITH_SCALA=0export SPARK_WORKER_MEMORY=1gexport SPARK_DRIVER_MEMORY=1gexport SPARK_MASTER_IP=192.168.117.51export SPARK_LIBRARY_PATH=/root/spark-without-hive/libexport SPARK_MASTER_WEBUI_PORT=18080export SPARK_WORKER_DIR=/root/spark-without-hive/workexport SPARK_MASTER_PORT=7077export SPARK_WORKER_PORT=7078export SPARK_LOG_DIR=/root/spark-without-hive/logexport SPARK_PID_DIR=&apos;/root/spark-without-hive/run&apos; slaves（将所有节点都加入，master节点同时也是worker节点） Goblin01Goblin02Goblin03Goblin04 spark-defaults.conf spark.master yarn-clusterspark.home /root/spark-without-hivespark.eventLog.enabled truespark.eventLog.dir hdfs://Goblin01:8020/spark-logspark.serializer org.apache.spark.serializer.KryoSerializerspark.executor.memory 1gspark.driver.memory 1gspark.executor.extraJavaOptions -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot; spark.master指定Spark运行模式，可以是yarn-client、yarn-cluster… spark.home指定SPARK_HOME路径 spark.eventLog.enabled需要设为true spark.eventLog.dir指定路径，放在master节点的hdfs中，端口要跟hdfs设置的端口一致（默认为8020），否则会报错 spark.executor.memory和spark.driver.memory指定executor和dirver的内存，512m或1g，既不能太大也不能太小，因为太小运行不了，太大又会影响其他服务 三、配置YARN配置yarn-site.xml，跟hdfs-site.xml在同一个路径下（$HADOOP_HOME/etc/hadoop) &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;&lt;/property&gt; 四、配置Hive 添加spark依赖到hive(将spark-assembly-1.5.0-cdh5.5.1-hadoop2.6.0.jar拷贝到$HIVE\\_HOME/lib目录下） 进入SPARK\\_HOME cp spark-assembly-1.5.0-cdh5.5.1-hadoop2.6.0.jar /usr/lib/hive/lib 配置hive-site.xml 配置的内容与spark-defaults.conf相同，只是形式不一样,以下内容是追加到hive-site.xml文件中的,并且注意前两个配置，如果不设置hive的spark引擎用不了，在后面会有详细的错误说明。 &lt;property&gt; &lt;name&gt;hive.execution.engine&lt;/name&gt; &lt;value&gt;spark&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.enable.spark.execution.engine&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.home&lt;/name&gt; &lt;value&gt;/root/spark-without-hive&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.master&lt;/name&gt; &lt;value&gt;yarn-client&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.enentLog.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.enentLog.dir&lt;/name&gt; &lt;value&gt;hdfs://Goblin01:8020/spark-log&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.serializer&lt;/name&gt;&lt;value&gt;org.apache.spark.serializer.KryoSerializer&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.executor.memeory&lt;/name&gt; &lt;value&gt;1g&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.driver.memeory&lt;/name&gt; &lt;value&gt;1g&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;spark.executor.extraJavaOptions&lt;/name&gt; &lt;value&gt;-XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;&lt;/value&gt;&lt;/property&gt; 五、验证是否安装配置成功1.验证Spark集群注意：在启动Spark集群之前，要确保Hadoop集群和YARN均已启动 进入$SPARK_HOME目录，执行： ./sbin/start-all.sh 用jps命令查看51节点上的master和worker，52、53、54节点上的worker是否都启动了 同样在$SPARK_HOME目录下，提交计算Pi的任务，验证Spark集群是否能正常工作，运行如下命令 ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client lib/spark-examples-1.5.0-cdh5.5.1-hadoop2.6.0.jar 10 若无报错，并且算出Pi的值，说明Spark集群能正常工作 2.验证Hive on Spark是否可用 命令行输入 hive，进入hive CLI set hive.execution.engine=spark; (将执行引擎设为Spark，默认是mr，退出hive CLI后，回到默认设置。若想让引擎默认为Spark，需要在hive-site.xml里设置） create table test(ts BIGINT,line STRING); (创建表） select count(*) from test; 若整个过程没有报错，并出现正确结果，则Hive on Spark配置成功。 六、遇到的问题0编译spark基于maven有两种方式 用mvn 命令编译 ./build/mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -DskipTests clean package 编译到倒数MQTT模块一直报错，而且编译出的文件比较大，不适合安装集群，因此不推荐。使用Intellij IDEA maven 插件报错如下： 使用spark提供的预编译脚本，网络状况稳定，会编译出需要的安装版本，推荐。命令 ./make-distribution.sh --name &quot;hadoop2-without-hive&quot; --tgz &quot;-Pyarn,hadoop-provided,hadoop-2.6,parquet-provided&quot; 结果如上文所述。 1运行： ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn lib/spark-examples-1.5.0-cdh5.5.1-hadoop2.6.0.jar 10 报错： 原因： hdfs的默认端口为8020 ，而我们在spark-default.conf中配置成了8021端口，导致连接不上HDFS报错 spark.eventLog.enabled truespark.eventLog.dir hdfs://Goblin01:8021/spark-log 解决： 配置spark-default.conf中的spark.eventLog.dir 为本地路径，也就是不持久化日志到hdfs上，也就没有和hdfs的通行 or spark-default.conf 注释掉 spark.eventLog.enabled true or 在spark-default.conf里配置的eventLog端口跟hdfs的默认端口（8020）一致 or 由于配置的hdfs是高可用的，51,52都可以作为namenode,我们的spark集群的主节点在51上，当51上的namenode变成standby，导致无法访问hdfs的8020端口（hdfs默认端口），也就是说在51上读不出hdfs上spark-log的内容，在spark-default.conf中配置为spark.eventLog.dir hdfs://Goblin01:8021/spark-log，如果发生这种情况，直接kill掉52，让namenode只在51上运行。（这个后面要搭建spark的高可用模式解决） 2运行： 在hive里设置引擎为spark，执行select count(*) from a; 报错： Failed to execute spark task, with exception &apos;org.apache.hadoop.hive.ql.metadata.HiveException(Unsupported execution engine: Spark. Please set hive.execution.engine=mr)&apos; 解决： 这是因为CDH版的Hive默认运行支持Hive on Spark（By default, Hive on Spark is not enabled）. 需要用cloudera manager（cloudera官网给的的方法，但是要装cloudera manager，比较麻烦，不建议） Go to the Hive service.Click the Configuration tab.Enter Enable Hive on Sparkin the Search field.Check the box for Enable Hive on Spark (Unsupported).Locate the Spark On YARN Service and click SPARK_ON_YARN.Click Save Changes to commit the changes. 或者 在hive-site.xml添加配置(简单、推荐） &lt;property&gt;&lt;name&gt;hive.enable.spark.execution.engine&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 3终端输入hive无法启动hive CLI 原因：namenode挂了 解决：重启namenode 4运行： ./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client lib/spark-examples-1.5.0-cdh5.5.1-hadoop2.6.0.jar 10 问题： 没有报错，但是出现以下情况，停不下来 原因： ResourceManager或者NodeManager挂掉，一直没有NodeManager响应，任务无法执行，所有停不下来。 还有一种情况是spark有别的application在运行，导致本次spark任务的等待或者失败 解决： 对于原因1，重启ResourceManager和NodeManager。 service hadoop-yarn-resourcemanager start;service hadoop-yarn-nodemanager start; 对于原因2，解决办法是在hadoop配置文件中设置yarn的并行度，在/etc/hadoop/conf/capacity-scheduler.xml文件中配置yarn.scheduler.capacity.maximum-am-resource-percent from 0.1 to 0.5 &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt; &lt;value&gt;0.5&lt;/value&gt; &lt;description&gt; Maximum percent of resources in the cluster which can be used to run application masters i.e. controls number of concurrent running applications. &lt;/description&gt; &lt;/property&gt; 参考资料 https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark:+Getting+Started http://www.cloudera.com/documentation/enterprise/5-5-x/topics/admin_hos_config.html http://spark.apache.org/docs/latest/building-spark.html http://stackoverflow.com/questions/31743586/apache-spark-running-locally-giving-refused-connection-error http://stackoverflow.com/questions/30828879/application-report-for-application-state-accepted-never-ends-for-spark-submi http://www.voidcn.com/blog/tianyiii/article/p-5986990.html http://www.imooc.com/article/8613 http://lxw1234.com/archives/2016/05/673.htm","raw":null,"content":null,"categories":[{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/categories/Hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://linbingdong.com/tags/大数据/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://linbingdong.com/tags/NoSQL/"},{"name":"Hive","slug":"Hive","permalink":"http://linbingdong.com/tags/Hive/"},{"name":"Spark","slug":"Spark","permalink":"http://linbingdong.com/tags/Spark/"}]}]}